{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install squaternion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gym\n",
    "import time\n",
    "from ascento_gym import Ascento\n",
    "# from balance_pend import InvertedPendulumEnv as Ascento\n",
    "from stable_baselines3 import PPO, DDPG, SAC\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# env = Ascento()\n",
    "# env.reset_model()\n",
    "# for i_episode in range(150):\n",
    "#     observation = env.reset()\n",
    "#     done = None\n",
    "#     while not done:\n",
    "#         env.render()\n",
    "#         print(env.yaw)\n",
    "#         action = env.action_space.sample()\n",
    "# #         action[2] = 1\n",
    "# #         action[3] = 1\n",
    "\n",
    "#         observation, reward, done, info = env.step(action)\n",
    "        \n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bmsit/.local/lib/python3.6/site-packages/gym/logger.py:34: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize(\"%s: %s\" % (\"WARN\", msg % args), \"yellow\"))\n"
     ]
    }
   ],
   "source": [
    "env = Ascento()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.50653708e+00,  5.54769695e-03,  7.91810233e-01, -8.99110199e-03,\n",
       "        1.31662288e-02, -6.27203297e+00, -5.54978574e-03,  2.01209707e-03,\n",
       "       -6.42936714e-03, -2.30647056e-03,  7.39075246e-04,  3.43360622e-04])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([-1. -1. -1. -1.], [1. 1. 1. 1.], (4,), float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.1865658 , -0.05869308, -0.47286385, -0.3740179 ], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.77887636, -0.62552128, -0.31807912, -1.00353629, -1.53367033,\n",
       "       -2.09505598, -0.15921661,  1.46301218, -2.05553094, -1.21583457,\n",
       "        1.20236824, -0.24364779])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [cart position, cart velocity, pole angle, pole angular velocity]\n",
    "env.observation_space.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.env_util import make_vec_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_env = make_vec_env(Ascento, n_envs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Ascento()\n",
    "env = DummyVecEnv([lambda: env])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join('Training', 'models_ascento')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_callback = StopTrainingOnRewardThreshold(reward_threshold = 20*1e5, verbose = 1)\n",
    "\n",
    "eval_callback = EvalCallback(env, callback_on_new_best = stop_callback,\n",
    "                            eval_freq = 5000, best_model_save_path = save_path, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "logs_dir = os.path.join('Training', 'logs_dir_ascento')\n",
    "model = PPO('MlpPolicy', vec_env, verbose = 1, tensorboard_log = logs_dir, create_eval_env = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load('/home/bmsit/Ascento/jointed_limited/Training/models_ascento/best_model.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load(\"/home/bmsit/Ascento/jointed_limited/Training/models_ascento/ppo_jl_ramp_top_v3.zip\", env = vec_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training/logs_dir_ascento/PPO_63\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 253      |\n",
      "|    ep_rew_mean     | -7.9e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 1637     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 283         |\n",
      "|    ep_rew_mean          | -4.67e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1265        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003135209 |\n",
      "|    clip_fraction        | 0.012       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.15        |\n",
      "|    explained_variance   | 0.631       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.02e+06    |\n",
      "|    n_updates            | 50870       |\n",
      "|    policy_gradient_loss | -0.00404    |\n",
      "|    std                  | 0.244       |\n",
      "|    value_loss           | 4.14e+06    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bmsit/.local/lib/python3.6/site-packages/stable_baselines3/common/evaluation.py:69: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=5000, episode_reward=-10246.17 +/- 12116.71\n",
      "Episode length: 400.60 +/- 331.09\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 401           |\n",
      "|    mean_reward          | -1.02e+04     |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 5000          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.9025377e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | 1.15          |\n",
      "|    explained_variance   | 0.35          |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 7.24e+07      |\n",
      "|    n_updates            | 50880         |\n",
      "|    policy_gradient_loss | -3.66e-05     |\n",
      "|    std                  | 0.244         |\n",
      "|    value_loss           | 9.46e+07      |\n",
      "-------------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 342       |\n",
      "|    ep_rew_mean     | -6.25e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 996       |\n",
      "|    iterations      | 3         |\n",
      "|    time_elapsed    | 6         |\n",
      "|    total_timesteps | 6144      |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 357         |\n",
      "|    ep_rew_mean          | -4.92e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1018        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001221868 |\n",
      "|    clip_fraction        | 0.000732    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.15        |\n",
      "|    explained_variance   | 0.462       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.74e+07    |\n",
      "|    n_updates            | 50890       |\n",
      "|    policy_gradient_loss | -0.00062    |\n",
      "|    std                  | 0.244       |\n",
      "|    value_loss           | 7.81e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bmsit/.local/lib/python3.6/site-packages/stable_baselines3/common/evaluation.py:69: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=10000, episode_reward=-2162.80 +/- 6596.65\n",
      "Episode length: 427.20 +/- 332.14\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 427         |\n",
      "|    mean_reward          | -2.16e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 10000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009055714 |\n",
      "|    clip_fraction        | 0.047       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.15        |\n",
      "|    explained_variance   | 0.682       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.67e+04    |\n",
      "|    n_updates            | 50900       |\n",
      "|    policy_gradient_loss | -0.00195    |\n",
      "|    std                  | 0.244       |\n",
      "|    value_loss           | 1.84e+05    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 342       |\n",
      "|    ep_rew_mean     | -4.43e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 932       |\n",
      "|    iterations      | 5         |\n",
      "|    time_elapsed    | 10        |\n",
      "|    total_timesteps | 10240     |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 307          |\n",
      "|    ep_rew_mean          | -3.69e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 956          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031196293 |\n",
      "|    clip_fraction        | 0.0109       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.15         |\n",
      "|    explained_variance   | 0.497        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.03e+06     |\n",
      "|    n_updates            | 50910        |\n",
      "|    policy_gradient_loss | -0.00391     |\n",
      "|    std                  | 0.244        |\n",
      "|    value_loss           | 2.05e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 297          |\n",
      "|    ep_rew_mean          | -4.31e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 973          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046004998 |\n",
      "|    clip_fraction        | 0.0198       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.15         |\n",
      "|    explained_variance   | 0.495        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.84e+07     |\n",
      "|    n_updates            | 50920        |\n",
      "|    policy_gradient_loss | -0.00726     |\n",
      "|    std                  | 0.244        |\n",
      "|    value_loss           | 6.71e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=15000, episode_reward=-8706.18 +/- 10674.38\n",
      "Episode length: 950.20 +/- 1367.95\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 950          |\n",
      "|    mean_reward          | -8.71e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 15000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024380514 |\n",
      "|    clip_fraction        | 0.0176       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.15         |\n",
      "|    explained_variance   | 0.511        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.73e+07     |\n",
      "|    n_updates            | 50930        |\n",
      "|    policy_gradient_loss | -0.00408     |\n",
      "|    std                  | 0.244        |\n",
      "|    value_loss           | 2.6e+07      |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 339       |\n",
      "|    ep_rew_mean     | -4.63e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 865       |\n",
      "|    iterations      | 8         |\n",
      "|    time_elapsed    | 18        |\n",
      "|    total_timesteps | 16384     |\n",
      "----------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 360           |\n",
      "|    ep_rew_mean          | -4.25e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 887           |\n",
      "|    iterations           | 9             |\n",
      "|    time_elapsed         | 20            |\n",
      "|    total_timesteps      | 18432         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00046189287 |\n",
      "|    clip_fraction        | 0.000146      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | 1.15          |\n",
      "|    explained_variance   | 0.475         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.56e+07      |\n",
      "|    n_updates            | 50940         |\n",
      "|    policy_gradient_loss | -0.000345     |\n",
      "|    std                  | 0.244         |\n",
      "|    value_loss           | 4.34e+07      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=-22140.57 +/- 30152.30\n",
      "Episode length: 561.00 +/- 603.26\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 561         |\n",
      "|    mean_reward          | -2.21e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 20000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005755626 |\n",
      "|    clip_fraction        | 0.0431      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.15        |\n",
      "|    explained_variance   | 0.748       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.65e+04    |\n",
      "|    n_updates            | 50950       |\n",
      "|    policy_gradient_loss | -0.00593    |\n",
      "|    std                  | 0.244       |\n",
      "|    value_loss           | 3.48e+05    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 364      |\n",
      "|    ep_rew_mean     | -4.3e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 853      |\n",
      "|    iterations      | 10       |\n",
      "|    time_elapsed    | 23       |\n",
      "|    total_timesteps | 20480    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 384          |\n",
      "|    ep_rew_mean          | -3.89e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 871          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 25           |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037019649 |\n",
      "|    clip_fraction        | 0.0136       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.15         |\n",
      "|    explained_variance   | 0.724        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.82e+05     |\n",
      "|    n_updates            | 50960        |\n",
      "|    policy_gradient_loss | -0.00495     |\n",
      "|    std                  | 0.244        |\n",
      "|    value_loss           | 2.3e+06      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 384         |\n",
      "|    ep_rew_mean          | -3.89e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 887         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 27          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010198131 |\n",
      "|    clip_fraction        | 0.08        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.15        |\n",
      "|    explained_variance   | 0.316       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.89e+04    |\n",
      "|    n_updates            | 50970       |\n",
      "|    policy_gradient_loss | -0.00194    |\n",
      "|    std                  | 0.244       |\n",
      "|    value_loss           | 1.81e+05    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=25000, episode_reward=-7622.91 +/- 11189.12\n",
      "Episode length: 449.20 +/- 338.84\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 449        |\n",
      "|    mean_reward          | -7.62e+03  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 25000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00717491 |\n",
      "|    clip_fraction        | 0.0386     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.14       |\n",
      "|    explained_variance   | 0.837      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 8.99e+05   |\n",
      "|    n_updates            | 50980      |\n",
      "|    policy_gradient_loss | -0.00535   |\n",
      "|    std                  | 0.244      |\n",
      "|    value_loss           | 1.21e+06   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 384       |\n",
      "|    ep_rew_mean     | -3.89e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 868       |\n",
      "|    iterations      | 13        |\n",
      "|    time_elapsed    | 30        |\n",
      "|    total_timesteps | 26624     |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 469         |\n",
      "|    ep_rew_mean          | -3.81e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 882         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 32          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007130116 |\n",
      "|    clip_fraction        | 0.0577      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.14        |\n",
      "|    explained_variance   | 0.891       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.49e+03    |\n",
      "|    n_updates            | 50990       |\n",
      "|    policy_gradient_loss | -0.00497    |\n",
      "|    std                  | 0.244       |\n",
      "|    value_loss           | 3.51e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=-45037.13 +/- 69302.95\n",
      "Episode length: 761.00 +/- 830.53\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 761          |\n",
      "|    mean_reward          | -4.5e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 30000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060897693 |\n",
      "|    clip_fraction        | 0.0414       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.14         |\n",
      "|    explained_variance   | 0.853        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.29e+03     |\n",
      "|    n_updates            | 51000        |\n",
      "|    policy_gradient_loss | -0.00421     |\n",
      "|    std                  | 0.245        |\n",
      "|    value_loss           | 8.31e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 464       |\n",
      "|    ep_rew_mean     | -3.76e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 849       |\n",
      "|    iterations      | 15        |\n",
      "|    time_elapsed    | 36        |\n",
      "|    total_timesteps | 30720     |\n",
      "----------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 448           |\n",
      "|    ep_rew_mean          | -3.42e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 861           |\n",
      "|    iterations           | 16            |\n",
      "|    time_elapsed         | 38            |\n",
      "|    total_timesteps      | 32768         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00047217077 |\n",
      "|    clip_fraction        | 0.000488      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | 1.14          |\n",
      "|    explained_variance   | 0.292         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.27e+07      |\n",
      "|    n_updates            | 51010         |\n",
      "|    policy_gradient_loss | -0.000732     |\n",
      "|    std                  | 0.245         |\n",
      "|    value_loss           | 1.35e+07      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 459         |\n",
      "|    ep_rew_mean          | -3.37e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 872         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 39          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004200431 |\n",
      "|    clip_fraction        | 0.0257      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.14        |\n",
      "|    explained_variance   | 0.428       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.79e+05    |\n",
      "|    n_updates            | 51020       |\n",
      "|    policy_gradient_loss | -0.00143    |\n",
      "|    std                  | 0.245       |\n",
      "|    value_loss           | 2.04e+06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=35000, episode_reward=-7358.69 +/- 6343.93\n",
      "Episode length: 125.80 +/- 151.99\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 126          |\n",
      "|    mean_reward          | -7.36e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 35000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022303513 |\n",
      "|    clip_fraction        | 0.0123       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.14         |\n",
      "|    explained_variance   | 0.375        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.29e+06     |\n",
      "|    n_updates            | 51030        |\n",
      "|    policy_gradient_loss | -0.00379     |\n",
      "|    std                  | 0.245        |\n",
      "|    value_loss           | 3.78e+06     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 448      |\n",
      "|    ep_rew_mean     | -3.1e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 875      |\n",
      "|    iterations      | 18       |\n",
      "|    time_elapsed    | 42       |\n",
      "|    total_timesteps | 36864    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 426         |\n",
      "|    ep_rew_mean          | -2.81e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 884         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 43          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004502484 |\n",
      "|    clip_fraction        | 0.0461      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.14        |\n",
      "|    explained_variance   | 0.4         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.5e+05     |\n",
      "|    n_updates            | 51040       |\n",
      "|    policy_gradient_loss | -0.00292    |\n",
      "|    std                  | 0.244       |\n",
      "|    value_loss           | 5.83e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=3015.75 +/- 19481.81\n",
      "Episode length: 1608.60 +/- 1721.11\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.61e+03    |\n",
      "|    mean_reward          | 3.02e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 40000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014937952 |\n",
      "|    clip_fraction        | 0.0929      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.15        |\n",
      "|    explained_variance   | 0.0404      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.68e+03    |\n",
      "|    n_updates            | 51050       |\n",
      "|    policy_gradient_loss | -0.00385    |\n",
      "|    std                  | 0.244       |\n",
      "|    value_loss           | 9.48e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 441       |\n",
      "|    ep_rew_mean     | -2.88e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 822       |\n",
      "|    iterations      | 20        |\n",
      "|    time_elapsed    | 49        |\n",
      "|    total_timesteps | 40960     |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 446         |\n",
      "|    ep_rew_mean          | -2.79e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 832         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005132852 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.15        |\n",
      "|    explained_variance   | 0.44        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.49e+07    |\n",
      "|    n_updates            | 51060       |\n",
      "|    policy_gradient_loss | -0.000843   |\n",
      "|    std                  | 0.244       |\n",
      "|    value_loss           | 1.35e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=45000, episode_reward=-7342.75 +/- 15717.26\n",
      "Episode length: 1991.40 +/- 2058.33\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.99e+03   |\n",
      "|    mean_reward          | -7.34e+03  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 45000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00675751 |\n",
      "|    clip_fraction        | 0.0508     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.15       |\n",
      "|    explained_variance   | 0.367      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.55e+05   |\n",
      "|    n_updates            | 51070      |\n",
      "|    policy_gradient_loss | -0.00529   |\n",
      "|    std                  | 0.244      |\n",
      "|    value_loss           | 3.14e+05   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 446       |\n",
      "|    ep_rew_mean     | -2.79e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 771       |\n",
      "|    iterations      | 22        |\n",
      "|    time_elapsed    | 58        |\n",
      "|    total_timesteps | 45056     |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 473        |\n",
      "|    ep_rew_mean          | -2.79e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 780        |\n",
      "|    iterations           | 23         |\n",
      "|    time_elapsed         | 60         |\n",
      "|    total_timesteps      | 47104      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00871185 |\n",
      "|    clip_fraction        | 0.089      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.15       |\n",
      "|    explained_variance   | 0.857      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.32e+03   |\n",
      "|    n_updates            | 51080      |\n",
      "|    policy_gradient_loss | -0.00279   |\n",
      "|    std                  | 0.244      |\n",
      "|    value_loss           | 1.22e+04   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 491         |\n",
      "|    ep_rew_mean          | -2.71e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 790         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 62          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007778314 |\n",
      "|    clip_fraction        | 0.0558      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.16        |\n",
      "|    explained_variance   | 0.85        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.07e+03    |\n",
      "|    n_updates            | 51090       |\n",
      "|    policy_gradient_loss | -0.00411    |\n",
      "|    std                  | 0.244       |\n",
      "|    value_loss           | 6.25e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=-14379.23 +/- 20469.26\n",
      "Episode length: 805.00 +/- 673.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 805         |\n",
      "|    mean_reward          | -1.44e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 50000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010838669 |\n",
      "|    clip_fraction        | 0.0932      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.16        |\n",
      "|    explained_variance   | 0.906       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.36e+04    |\n",
      "|    n_updates            | 51100       |\n",
      "|    policy_gradient_loss | -0.00713    |\n",
      "|    std                  | 0.244       |\n",
      "|    value_loss           | 8.11e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 493       |\n",
      "|    ep_rew_mean     | -2.67e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 775       |\n",
      "|    iterations      | 25        |\n",
      "|    time_elapsed    | 66        |\n",
      "|    total_timesteps | 51200     |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 506          |\n",
      "|    ep_rew_mean          | -2.87e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 784          |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 67           |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068804463 |\n",
      "|    clip_fraction        | 0.0575       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.16         |\n",
      "|    explained_variance   | 0.639        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.45e+04     |\n",
      "|    n_updates            | 51110        |\n",
      "|    policy_gradient_loss | -0.00578     |\n",
      "|    std                  | 0.244        |\n",
      "|    value_loss           | 1.44e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=55000, episode_reward=-32572.45 +/- 34312.88\n",
      "Episode length: 2148.60 +/- 2337.99\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.15e+03    |\n",
      "|    mean_reward          | -3.26e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 55000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001531461 |\n",
      "|    clip_fraction        | 0.0104      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.17        |\n",
      "|    explained_variance   | 0.443       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.38e+06    |\n",
      "|    n_updates            | 51120       |\n",
      "|    policy_gradient_loss | -0.00348    |\n",
      "|    std                  | 0.244       |\n",
      "|    value_loss           | 3.31e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 511       |\n",
      "|    ep_rew_mean     | -2.26e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 737       |\n",
      "|    iterations      | 27        |\n",
      "|    time_elapsed    | 74        |\n",
      "|    total_timesteps | 55296     |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 505         |\n",
      "|    ep_rew_mean          | -2.11e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 745         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 76          |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003559975 |\n",
      "|    clip_fraction        | 0.0193      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.17        |\n",
      "|    explained_variance   | 0.497       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.91e+06    |\n",
      "|    n_updates            | 51130       |\n",
      "|    policy_gradient_loss | -0.00264    |\n",
      "|    std                  | 0.244       |\n",
      "|    value_loss           | 2.01e+06    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 499         |\n",
      "|    ep_rew_mean          | -2.1e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 754         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 78          |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008278912 |\n",
      "|    clip_fraction        | 0.0569      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.16        |\n",
      "|    explained_variance   | 0.477       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.83e+07    |\n",
      "|    n_updates            | 51140       |\n",
      "|    policy_gradient_loss | -0.00273    |\n",
      "|    std                  | 0.244       |\n",
      "|    value_loss           | 4.19e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=-455.62 +/- 6777.12\n",
      "Episode length: 618.40 +/- 506.71\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 618          |\n",
      "|    mean_reward          | -456         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 60000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076135304 |\n",
      "|    clip_fraction        | 0.0849       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.16         |\n",
      "|    explained_variance   | 0.695        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.59e+04     |\n",
      "|    n_updates            | 51150        |\n",
      "|    policy_gradient_loss | -0.0047      |\n",
      "|    std                  | 0.244        |\n",
      "|    value_loss           | 3.47e+05     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 516       |\n",
      "|    ep_rew_mean     | -2.07e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 748       |\n",
      "|    iterations      | 30        |\n",
      "|    time_elapsed    | 82        |\n",
      "|    total_timesteps | 61440     |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 531          |\n",
      "|    ep_rew_mean          | -1.93e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 756          |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 83           |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060332417 |\n",
      "|    clip_fraction        | 0.026        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.16         |\n",
      "|    explained_variance   | 0.661        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.36e+06     |\n",
      "|    n_updates            | 51160        |\n",
      "|    policy_gradient_loss | -0.00345     |\n",
      "|    std                  | 0.244        |\n",
      "|    value_loss           | 1.02e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=65000, episode_reward=-32028.11 +/- 43603.80\n",
      "Episode length: 2167.60 +/- 2321.73\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.17e+03     |\n",
      "|    mean_reward          | -3.2e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 65000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052786907 |\n",
      "|    clip_fraction        | 0.0342       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.16         |\n",
      "|    explained_variance   | 0.482        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.78e+04     |\n",
      "|    n_updates            | 51170        |\n",
      "|    policy_gradient_loss | -0.00854     |\n",
      "|    std                  | 0.244        |\n",
      "|    value_loss           | 4.1e+05      |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 532       |\n",
      "|    ep_rew_mean     | -2.04e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 718       |\n",
      "|    iterations      | 32        |\n",
      "|    time_elapsed    | 91        |\n",
      "|    total_timesteps | 65536     |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 558         |\n",
      "|    ep_rew_mean          | -2.03e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 726         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 93          |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008058259 |\n",
      "|    clip_fraction        | 0.0192      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.16        |\n",
      "|    explained_variance   | 0.518       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.15e+07    |\n",
      "|    n_updates            | 51180       |\n",
      "|    policy_gradient_loss | -0.0047     |\n",
      "|    std                  | 0.244       |\n",
      "|    value_loss           | 1.42e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 569         |\n",
      "|    ep_rew_mean          | -1.44e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 733         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 94          |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005351471 |\n",
      "|    clip_fraction        | 0.0292      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.16        |\n",
      "|    explained_variance   | 0.718       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.2e+06     |\n",
      "|    n_updates            | 51190       |\n",
      "|    policy_gradient_loss | -0.00549    |\n",
      "|    std                  | 0.244       |\n",
      "|    value_loss           | 6.97e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=-18866.15 +/- 26067.11\n",
      "Episode length: 197.00 +/- 231.57\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 197          |\n",
      "|    mean_reward          | -1.89e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 70000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041516377 |\n",
      "|    clip_fraction        | 0.0336       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.16         |\n",
      "|    explained_variance   | 0.137        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.01e+05     |\n",
      "|    n_updates            | 51200        |\n",
      "|    policy_gradient_loss | -0.00123     |\n",
      "|    std                  | 0.244        |\n",
      "|    value_loss           | 2.22e+05     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.44e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 736       |\n",
      "|    iterations      | 35        |\n",
      "|    time_elapsed    | 97        |\n",
      "|    total_timesteps | 71680     |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 606        |\n",
      "|    ep_rew_mean          | -1.46e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 743        |\n",
      "|    iterations           | 36         |\n",
      "|    time_elapsed         | 99         |\n",
      "|    total_timesteps      | 73728      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01943928 |\n",
      "|    clip_fraction        | 0.107      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.16       |\n",
      "|    explained_variance   | 0.565      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.42e+03   |\n",
      "|    n_updates            | 51210      |\n",
      "|    policy_gradient_loss | -0.00579   |\n",
      "|    std                  | 0.244      |\n",
      "|    value_loss           | 6.21e+04   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=75000, episode_reward=1133.64 +/- 9264.59\n",
      "Episode length: 1536.00 +/- 1759.09\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.54e+03    |\n",
      "|    mean_reward          | 1.13e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 75000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008933416 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.16        |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.03e+03    |\n",
      "|    n_updates            | 51220       |\n",
      "|    policy_gradient_loss | -0.003      |\n",
      "|    std                  | 0.245       |\n",
      "|    value_loss           | 6.46e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 611       |\n",
      "|    ep_rew_mean     | -1.46e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 722       |\n",
      "|    iterations      | 37        |\n",
      "|    time_elapsed    | 104       |\n",
      "|    total_timesteps | 75776     |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 640         |\n",
      "|    ep_rew_mean          | -1.5e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 728         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 106         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011676023 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.16        |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.63e+03    |\n",
      "|    n_updates            | 51230       |\n",
      "|    policy_gradient_loss | -0.00208    |\n",
      "|    std                  | 0.245       |\n",
      "|    value_loss           | 7.99e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 626       |\n",
      "|    ep_rew_mean          | -1.31e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 735       |\n",
      "|    iterations           | 39        |\n",
      "|    time_elapsed         | 108       |\n",
      "|    total_timesteps      | 79872     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0134936 |\n",
      "|    clip_fraction        | 0.124     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 1.16      |\n",
      "|    explained_variance   | 0.979     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.39e+03  |\n",
      "|    n_updates            | 51240     |\n",
      "|    policy_gradient_loss | -0.0022   |\n",
      "|    std                  | 0.244     |\n",
      "|    value_loss           | 1.59e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=1529.61 +/- 3314.91\n",
      "Episode length: 2448.40 +/- 2123.97\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.45e+03     |\n",
      "|    mean_reward          | 1.53e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 80000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076851347 |\n",
      "|    clip_fraction        | 0.117        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.16         |\n",
      "|    explained_variance   | 0.532        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.53e+06     |\n",
      "|    n_updates            | 51250        |\n",
      "|    policy_gradient_loss | -0.00368     |\n",
      "|    std                  | 0.244        |\n",
      "|    value_loss           | 1.82e+06     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 628       |\n",
      "|    ep_rew_mean     | -1.24e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 703       |\n",
      "|    iterations      | 40        |\n",
      "|    time_elapsed    | 116       |\n",
      "|    total_timesteps | 81920     |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 628         |\n",
      "|    ep_rew_mean          | -1.24e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 710         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 118         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012197287 |\n",
      "|    clip_fraction        | 0.0703      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.16        |\n",
      "|    explained_variance   | 0.367       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.5e+03     |\n",
      "|    n_updates            | 51260       |\n",
      "|    policy_gradient_loss | -0.00348    |\n",
      "|    std                  | 0.244       |\n",
      "|    value_loss           | 2.96e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=85000, episode_reward=-59.91 +/- 6776.11\n",
      "Episode length: 907.80 +/- 429.30\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 908           |\n",
      "|    mean_reward          | -59.9         |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 85000         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00092811143 |\n",
      "|    clip_fraction        | 0.00547       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | 1.16          |\n",
      "|    explained_variance   | 0.471         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 5.26e+04      |\n",
      "|    n_updates            | 51270         |\n",
      "|    policy_gradient_loss | -0.00199      |\n",
      "|    std                  | 0.244         |\n",
      "|    value_loss           | 2.56e+06      |\n",
      "-------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 633       |\n",
      "|    ep_rew_mean     | -1.23e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 703       |\n",
      "|    iterations      | 42        |\n",
      "|    time_elapsed    | 122       |\n",
      "|    total_timesteps | 86016     |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 663         |\n",
      "|    ep_rew_mean          | -1.41e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 709         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 124         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008403529 |\n",
      "|    clip_fraction        | 0.0701      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.16        |\n",
      "|    explained_variance   | 0.915       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.48e+04    |\n",
      "|    n_updates            | 51280       |\n",
      "|    policy_gradient_loss | -0.00488    |\n",
      "|    std                  | 0.244       |\n",
      "|    value_loss           | 3.15e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=90000, episode_reward=-135474.06 +/- 198699.78\n",
      "Episode length: 564.60 +/- 524.32\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 565        |\n",
      "|    mean_reward          | -1.35e+05  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 90000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00734827 |\n",
      "|    clip_fraction        | 0.034      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.17       |\n",
      "|    explained_variance   | 0.504      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 7.6e+06    |\n",
      "|    n_updates            | 51290      |\n",
      "|    policy_gradient_loss | -0.00286   |\n",
      "|    std                  | 0.244      |\n",
      "|    value_loss           | 1.49e+07   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 599       |\n",
      "|    ep_rew_mean     | -1.24e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 707       |\n",
      "|    iterations      | 44        |\n",
      "|    time_elapsed    | 127       |\n",
      "|    total_timesteps | 90112     |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 589          |\n",
      "|    ep_rew_mean          | -1.21e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 713          |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 129          |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074208635 |\n",
      "|    clip_fraction        | 0.0485       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.17         |\n",
      "|    explained_variance   | 0.721        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.15e+04     |\n",
      "|    n_updates            | 51300        |\n",
      "|    policy_gradient_loss | -0.00511     |\n",
      "|    std                  | 0.244        |\n",
      "|    value_loss           | 1.31e+05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 589         |\n",
      "|    ep_rew_mean          | -1.21e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 718         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 131         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013485271 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.16        |\n",
      "|    explained_variance   | 0.848       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 900         |\n",
      "|    n_updates            | 51310       |\n",
      "|    policy_gradient_loss | -2.81e-07   |\n",
      "|    std                  | 0.245       |\n",
      "|    value_loss           | 2.65e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=95000, episode_reward=-862.14 +/- 3282.81\n",
      "Episode length: 509.20 +/- 359.12\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 509         |\n",
      "|    mean_reward          | -862        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 95000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014510302 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.17        |\n",
      "|    explained_variance   | 0.928       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 726         |\n",
      "|    n_updates            | 51320       |\n",
      "|    policy_gradient_loss | 0.00254     |\n",
      "|    std                  | 0.243       |\n",
      "|    value_loss           | 2.62e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 631       |\n",
      "|    ep_rew_mean     | -1.28e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 717       |\n",
      "|    iterations      | 47        |\n",
      "|    time_elapsed    | 134       |\n",
      "|    total_timesteps | 96256     |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 631         |\n",
      "|    ep_rew_mean          | -1.28e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 722         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 136         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008432241 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.17        |\n",
      "|    explained_variance   | 0.781       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.61e+04    |\n",
      "|    n_updates            | 51330       |\n",
      "|    policy_gradient_loss | -0.00232    |\n",
      "|    std                  | 0.243       |\n",
      "|    value_loss           | 6.63e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=-14484.52 +/- 22721.16\n",
      "Episode length: 1415.00 +/- 1872.85\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.42e+03    |\n",
      "|    mean_reward          | -1.45e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 100000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009385053 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.17        |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 753         |\n",
      "|    n_updates            | 51340       |\n",
      "|    policy_gradient_loss | -0.00245    |\n",
      "|    std                  | 0.243       |\n",
      "|    value_loss           | 1.97e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 680      |\n",
      "|    ep_rew_mean     | -1.3e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 695      |\n",
      "|    iterations      | 49       |\n",
      "|    time_elapsed    | 144      |\n",
      "|    total_timesteps | 100352   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 677         |\n",
      "|    ep_rew_mean          | -1.29e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 698         |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 146         |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013032092 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.18        |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 347         |\n",
      "|    n_updates            | 51350       |\n",
      "|    policy_gradient_loss | -0.00171    |\n",
      "|    std                  | 0.242       |\n",
      "|    value_loss           | 7.6e+03     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 679          |\n",
      "|    ep_rew_mean          | -1.33e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 702          |\n",
      "|    iterations           | 51           |\n",
      "|    time_elapsed         | 148          |\n",
      "|    total_timesteps      | 104448       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070191007 |\n",
      "|    clip_fraction        | 0.126        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.2          |\n",
      "|    explained_variance   | 0.688        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.93e+03     |\n",
      "|    n_updates            | 51360        |\n",
      "|    policy_gradient_loss | -0.00321     |\n",
      "|    std                  | 0.242        |\n",
      "|    value_loss           | 6.74e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=105000, episode_reward=-24633.16 +/- 36355.86\n",
      "Episode length: 133.60 +/- 152.13\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 134         |\n",
      "|    mean_reward          | -2.46e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 105000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009757649 |\n",
      "|    clip_fraction        | 0.0829      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.2         |\n",
      "|    explained_variance   | 0.603       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.28e+06    |\n",
      "|    n_updates            | 51370       |\n",
      "|    policy_gradient_loss | -0.00392    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 3.43e+06    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 679       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 705       |\n",
      "|    iterations      | 52        |\n",
      "|    time_elapsed    | 150       |\n",
      "|    total_timesteps | 106496    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 661          |\n",
      "|    ep_rew_mean          | -1.54e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 710          |\n",
      "|    iterations           | 53           |\n",
      "|    time_elapsed         | 152          |\n",
      "|    total_timesteps      | 108544       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042057517 |\n",
      "|    clip_fraction        | 0.0686       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.2          |\n",
      "|    explained_variance   | 0.428        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.65e+05     |\n",
      "|    n_updates            | 51380        |\n",
      "|    policy_gradient_loss | 0.00306      |\n",
      "|    std                  | 0.241        |\n",
      "|    value_loss           | 3.68e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=110000, episode_reward=-28268.47 +/- 29021.67\n",
      "Episode length: 2040.20 +/- 2416.83\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.04e+03    |\n",
      "|    mean_reward          | -2.83e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 110000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009933776 |\n",
      "|    clip_fraction        | 0.0505      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.2         |\n",
      "|    explained_variance   | 0.461       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.62e+07    |\n",
      "|    n_updates            | 51390       |\n",
      "|    policy_gradient_loss | 0.000777    |\n",
      "|    std                  | 0.242       |\n",
      "|    value_loss           | 4.16e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 606       |\n",
      "|    ep_rew_mean     | -1.77e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 693       |\n",
      "|    iterations      | 54        |\n",
      "|    time_elapsed    | 159       |\n",
      "|    total_timesteps | 110592    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 608         |\n",
      "|    ep_rew_mean          | -1.76e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 697         |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 161         |\n",
      "|    total_timesteps      | 112640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009375423 |\n",
      "|    clip_fraction        | 0.0629      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.2         |\n",
      "|    explained_variance   | 0.483       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.15e+07    |\n",
      "|    n_updates            | 51400       |\n",
      "|    policy_gradient_loss | -0.0042     |\n",
      "|    std                  | 0.242       |\n",
      "|    value_loss           | 4.6e+07     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 600        |\n",
      "|    ep_rew_mean          | -1.57e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 702        |\n",
      "|    iterations           | 56         |\n",
      "|    time_elapsed         | 163        |\n",
      "|    total_timesteps      | 114688     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01747341 |\n",
      "|    clip_fraction        | 0.134      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.19       |\n",
      "|    explained_variance   | 0.0541     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 920        |\n",
      "|    n_updates            | 51410      |\n",
      "|    policy_gradient_loss | -0.00137   |\n",
      "|    std                  | 0.242      |\n",
      "|    value_loss           | 6.4e+04    |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=115000, episode_reward=-31853.65 +/- 45251.24\n",
      "Episode length: 1142.00 +/- 1938.32\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.14e+03    |\n",
      "|    mean_reward          | -3.19e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 115000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019660264 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.19        |\n",
      "|    explained_variance   | 0.892       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.62e+03    |\n",
      "|    n_updates            | 51420       |\n",
      "|    policy_gradient_loss | 0.00223     |\n",
      "|    std                  | 0.242       |\n",
      "|    value_loss           | 1.49e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 596       |\n",
      "|    ep_rew_mean     | -1.54e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 695       |\n",
      "|    iterations      | 57        |\n",
      "|    time_elapsed    | 167       |\n",
      "|    total_timesteps | 116736    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 579          |\n",
      "|    ep_rew_mean          | -1.54e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 699          |\n",
      "|    iterations           | 58           |\n",
      "|    time_elapsed         | 169          |\n",
      "|    total_timesteps      | 118784       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030138458 |\n",
      "|    clip_fraction        | 0.0425       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.19         |\n",
      "|    explained_variance   | 0.452        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.66e+07     |\n",
      "|    n_updates            | 51430        |\n",
      "|    policy_gradient_loss | 0.000794     |\n",
      "|    std                  | 0.242        |\n",
      "|    value_loss           | 3.77e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=120000, episode_reward=-720.51 +/- 3221.54\n",
      "Episode length: 248.00 +/- 195.62\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 248         |\n",
      "|    mean_reward          | -721        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 120000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008596027 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.19        |\n",
      "|    explained_variance   | 0.495       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.21e+03    |\n",
      "|    n_updates            | 51440       |\n",
      "|    policy_gradient_loss | -0.00869    |\n",
      "|    std                  | 0.242       |\n",
      "|    value_loss           | 2.08e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 568       |\n",
      "|    ep_rew_mean     | -1.52e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 701       |\n",
      "|    iterations      | 59        |\n",
      "|    time_elapsed    | 172       |\n",
      "|    total_timesteps | 120832    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 555         |\n",
      "|    ep_rew_mean          | -1.38e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 705         |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 174         |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026820822 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.2         |\n",
      "|    explained_variance   | 0.661       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.42e+06    |\n",
      "|    n_updates            | 51450       |\n",
      "|    policy_gradient_loss | 0.00519     |\n",
      "|    std                  | 0.242       |\n",
      "|    value_loss           | 1.19e+06    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 557         |\n",
      "|    ep_rew_mean          | -1.38e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 709         |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 175         |\n",
      "|    total_timesteps      | 124928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007971609 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.19        |\n",
      "|    explained_variance   | 0.807       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.42e+04    |\n",
      "|    n_updates            | 51460       |\n",
      "|    policy_gradient_loss | -0.00379    |\n",
      "|    std                  | 0.242       |\n",
      "|    value_loss           | 6.29e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=125000, episode_reward=-1545.11 +/- 4266.72\n",
      "Episode length: 308.40 +/- 266.03\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 308         |\n",
      "|    mean_reward          | -1.55e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 125000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013230184 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.2         |\n",
      "|    explained_variance   | 0.909       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 874         |\n",
      "|    n_updates            | 51470       |\n",
      "|    policy_gradient_loss | 0.00179     |\n",
      "|    std                  | 0.242       |\n",
      "|    value_loss           | 1.48e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 530       |\n",
      "|    ep_rew_mean     | -1.37e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 711       |\n",
      "|    iterations      | 62        |\n",
      "|    time_elapsed    | 178       |\n",
      "|    total_timesteps | 126976    |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 485        |\n",
      "|    ep_rew_mean          | -1.32e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 715        |\n",
      "|    iterations           | 63         |\n",
      "|    time_elapsed         | 180        |\n",
      "|    total_timesteps      | 129024     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01750844 |\n",
      "|    clip_fraction        | 0.136      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.21       |\n",
      "|    explained_variance   | 0.87       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.4e+04    |\n",
      "|    n_updates            | 51480      |\n",
      "|    policy_gradient_loss | -0.00358   |\n",
      "|    std                  | 0.241      |\n",
      "|    value_loss           | 6.59e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=130000, episode_reward=-9440.94 +/- 21190.48\n",
      "Episode length: 1362.00 +/- 1841.37\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.36e+03    |\n",
      "|    mean_reward          | -9.44e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 130000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010297495 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.21        |\n",
      "|    explained_variance   | -0.248      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.11e+05    |\n",
      "|    n_updates            | 51490       |\n",
      "|    policy_gradient_loss | 0.000943    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 1.1e+05     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 479       |\n",
      "|    ep_rew_mean     | -1.33e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 706       |\n",
      "|    iterations      | 64        |\n",
      "|    time_elapsed    | 185       |\n",
      "|    total_timesteps | 131072    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 479         |\n",
      "|    ep_rew_mean          | -1.33e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 710         |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 187         |\n",
      "|    total_timesteps      | 133120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026481712 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.21        |\n",
      "|    explained_variance   | 0.824       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 318         |\n",
      "|    n_updates            | 51500       |\n",
      "|    policy_gradient_loss | -0.00532    |\n",
      "|    std                  | 0.242       |\n",
      "|    value_loss           | 3.3e+04     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=135000, episode_reward=-6563.64 +/- 4064.70\n",
      "Episode length: 142.00 +/- 122.88\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 142         |\n",
      "|    mean_reward          | -6.56e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 135000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017620688 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.21        |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 566         |\n",
      "|    n_updates            | 51510       |\n",
      "|    policy_gradient_loss | -0.00352    |\n",
      "|    std                  | 0.243       |\n",
      "|    value_loss           | 1.42e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 524       |\n",
      "|    ep_rew_mean     | -1.33e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 712       |\n",
      "|    iterations      | 66        |\n",
      "|    time_elapsed    | 189       |\n",
      "|    total_timesteps | 135168    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 484         |\n",
      "|    ep_rew_mean          | -1.15e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 716         |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 191         |\n",
      "|    total_timesteps      | 137216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009554199 |\n",
      "|    clip_fraction        | 0.0964      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.2         |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 678         |\n",
      "|    n_updates            | 51520       |\n",
      "|    policy_gradient_loss | -0.00453    |\n",
      "|    std                  | 0.243       |\n",
      "|    value_loss           | 1.14e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 490          |\n",
      "|    ep_rew_mean          | -1.26e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 720          |\n",
      "|    iterations           | 68           |\n",
      "|    time_elapsed         | 193          |\n",
      "|    total_timesteps      | 139264       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066590663 |\n",
      "|    clip_fraction        | 0.0739       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.2          |\n",
      "|    explained_variance   | 0.633        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.07e+05     |\n",
      "|    n_updates            | 51530        |\n",
      "|    policy_gradient_loss | -0.00242     |\n",
      "|    std                  | 0.243        |\n",
      "|    value_loss           | 1.93e+06     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=140000, episode_reward=-4049.14 +/- 11871.18\n",
      "Episode length: 458.60 +/- 572.94\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 459         |\n",
      "|    mean_reward          | -4.05e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 140000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021435494 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.2         |\n",
      "|    explained_variance   | 0.512       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.06e+05    |\n",
      "|    n_updates            | 51540       |\n",
      "|    policy_gradient_loss | 0.00474     |\n",
      "|    std                  | 0.243       |\n",
      "|    value_loss           | 1.4e+07     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 403       |\n",
      "|    ep_rew_mean     | -1.25e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 720       |\n",
      "|    iterations      | 69        |\n",
      "|    time_elapsed    | 196       |\n",
      "|    total_timesteps | 141312    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 404          |\n",
      "|    ep_rew_mean          | -1.23e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 723          |\n",
      "|    iterations           | 70           |\n",
      "|    time_elapsed         | 198          |\n",
      "|    total_timesteps      | 143360       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030972725 |\n",
      "|    clip_fraction        | 0.0507       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.2          |\n",
      "|    explained_variance   | 0.703        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.11e+05     |\n",
      "|    n_updates            | 51550        |\n",
      "|    policy_gradient_loss | 0.00331      |\n",
      "|    std                  | 0.243        |\n",
      "|    value_loss           | 2.65e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=145000, episode_reward=-34695.46 +/- 39779.41\n",
      "Episode length: 2242.80 +/- 2272.56\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.24e+03    |\n",
      "|    mean_reward          | -3.47e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 145000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008948126 |\n",
      "|    clip_fraction        | 0.0846      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.2         |\n",
      "|    explained_variance   | 0.901       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 906         |\n",
      "|    n_updates            | 51560       |\n",
      "|    policy_gradient_loss | -0.00413    |\n",
      "|    std                  | 0.242       |\n",
      "|    value_loss           | 3.17e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 405       |\n",
      "|    ep_rew_mean     | -1.19e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 708       |\n",
      "|    iterations      | 71        |\n",
      "|    time_elapsed    | 205       |\n",
      "|    total_timesteps | 145408    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 416         |\n",
      "|    ep_rew_mean          | -1.2e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 711         |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 207         |\n",
      "|    total_timesteps      | 147456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004200824 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.21        |\n",
      "|    explained_variance   | 0.698       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.45e+05    |\n",
      "|    n_updates            | 51570       |\n",
      "|    policy_gradient_loss | -0.000939   |\n",
      "|    std                  | 0.242       |\n",
      "|    value_loss           | 1.93e+06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 422         |\n",
      "|    ep_rew_mean          | -1.15e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 715         |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 209         |\n",
      "|    total_timesteps      | 149504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008386472 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.21        |\n",
      "|    explained_variance   | 0.606       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 865         |\n",
      "|    n_updates            | 51580       |\n",
      "|    policy_gradient_loss | -0.00168    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 2.19e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=150000, episode_reward=-24261.23 +/- 58511.31\n",
      "Episode length: 509.80 +/- 216.12\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 510         |\n",
      "|    mean_reward          | -2.43e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 150000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011498766 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.22        |\n",
      "|    explained_variance   | 0.719       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.41e+03    |\n",
      "|    n_updates            | 51590       |\n",
      "|    policy_gradient_loss | 0.000261    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 4.38e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 434       |\n",
      "|    ep_rew_mean     | -9.61e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 714       |\n",
      "|    iterations      | 74        |\n",
      "|    time_elapsed    | 212       |\n",
      "|    total_timesteps | 151552    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 443         |\n",
      "|    ep_rew_mean          | -9.68e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 717         |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 213         |\n",
      "|    total_timesteps      | 153600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008010402 |\n",
      "|    clip_fraction        | 0.0847      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.22        |\n",
      "|    explained_variance   | 0.423       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.09e+03    |\n",
      "|    n_updates            | 51600       |\n",
      "|    policy_gradient_loss | -0.0018     |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 6.76e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=155000, episode_reward=-53328.79 +/- 64699.30\n",
      "Episode length: 306.20 +/- 243.91\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 306         |\n",
      "|    mean_reward          | -5.33e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 155000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005144427 |\n",
      "|    clip_fraction        | 0.0221      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.22        |\n",
      "|    explained_variance   | 0.749       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.91e+04    |\n",
      "|    n_updates            | 51610       |\n",
      "|    policy_gradient_loss | -0.00269    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 3.21e+05    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 456      |\n",
      "|    ep_rew_mean     | -1e+04   |\n",
      "| time/              |          |\n",
      "|    fps             | 718      |\n",
      "|    iterations      | 76       |\n",
      "|    time_elapsed    | 216      |\n",
      "|    total_timesteps | 155648   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 446          |\n",
      "|    ep_rew_mean          | -1.04e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 721          |\n",
      "|    iterations           | 77           |\n",
      "|    time_elapsed         | 218          |\n",
      "|    total_timesteps      | 157696       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024101543 |\n",
      "|    clip_fraction        | 0.00288      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.22         |\n",
      "|    explained_variance   | 0.507        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.7e+07      |\n",
      "|    n_updates            | 51620        |\n",
      "|    policy_gradient_loss | -0.00204     |\n",
      "|    std                  | 0.241        |\n",
      "|    value_loss           | 3.56e+07     |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 466       |\n",
      "|    ep_rew_mean          | -1.33e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 724       |\n",
      "|    iterations           | 78        |\n",
      "|    time_elapsed         | 220       |\n",
      "|    total_timesteps      | 159744    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0041451 |\n",
      "|    clip_fraction        | 0.0253    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 1.22      |\n",
      "|    explained_variance   | 0.604     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.44e+05  |\n",
      "|    n_updates            | 51630     |\n",
      "|    policy_gradient_loss | -0.00266  |\n",
      "|    std                  | 0.241     |\n",
      "|    value_loss           | 6.14e+05  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=160000, episode_reward=5423.60 +/- 12476.05\n",
      "Episode length: 1352.20 +/- 1832.72\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 1.35e+03      |\n",
      "|    mean_reward          | 5.42e+03      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 160000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00050687016 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | 1.22          |\n",
      "|    explained_variance   | 0.435         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.7e+06       |\n",
      "|    n_updates            | 51640         |\n",
      "|    policy_gradient_loss | -0.000526     |\n",
      "|    std                  | 0.241         |\n",
      "|    value_loss           | 6.37e+07      |\n",
      "-------------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 470       |\n",
      "|    ep_rew_mean     | -1.74e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 717       |\n",
      "|    iterations      | 79        |\n",
      "|    time_elapsed    | 225       |\n",
      "|    total_timesteps | 161792    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 473          |\n",
      "|    ep_rew_mean          | -1.74e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 720          |\n",
      "|    iterations           | 80           |\n",
      "|    time_elapsed         | 227          |\n",
      "|    total_timesteps      | 163840       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013137355 |\n",
      "|    clip_fraction        | 0.00449      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.22         |\n",
      "|    explained_variance   | 0.451        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.98e+07     |\n",
      "|    n_updates            | 51650        |\n",
      "|    policy_gradient_loss | -0.00208     |\n",
      "|    std                  | 0.241        |\n",
      "|    value_loss           | 7.65e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=165000, episode_reward=-414.33 +/- 9807.53\n",
      "Episode length: 421.80 +/- 344.34\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 422          |\n",
      "|    mean_reward          | -414         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 165000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035425844 |\n",
      "|    clip_fraction        | 0.0415       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.22         |\n",
      "|    explained_variance   | 0.2          |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.48e+03     |\n",
      "|    n_updates            | 51660        |\n",
      "|    policy_gradient_loss | -0.00301     |\n",
      "|    std                  | 0.241        |\n",
      "|    value_loss           | 3.71e+05     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 479       |\n",
      "|    ep_rew_mean     | -1.54e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 720       |\n",
      "|    iterations      | 81        |\n",
      "|    time_elapsed    | 230       |\n",
      "|    total_timesteps | 165888    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 491         |\n",
      "|    ep_rew_mean          | -1.52e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 723         |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 232         |\n",
      "|    total_timesteps      | 167936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013506123 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.22        |\n",
      "|    explained_variance   | 0.392       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.43e+03    |\n",
      "|    n_updates            | 51670       |\n",
      "|    policy_gradient_loss | 0.00408     |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 5.93e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 481         |\n",
      "|    ep_rew_mean          | -1.93e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 726         |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 233         |\n",
      "|    total_timesteps      | 169984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006474639 |\n",
      "|    clip_fraction        | 0.0857      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.22        |\n",
      "|    explained_variance   | 0.205       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.32e+04    |\n",
      "|    n_updates            | 51680       |\n",
      "|    policy_gradient_loss | -0.00403    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 9.24e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=170000, episode_reward=3784.98 +/- 14011.48\n",
      "Episode length: 1470.40 +/- 1766.51\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.47e+03     |\n",
      "|    mean_reward          | 3.78e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 170000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023851474 |\n",
      "|    clip_fraction        | 0.00825      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.22         |\n",
      "|    explained_variance   | 0.466        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.11e+07     |\n",
      "|    n_updates            | 51690        |\n",
      "|    policy_gradient_loss | -0.00282     |\n",
      "|    std                  | 0.241        |\n",
      "|    value_loss           | 6.45e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 466       |\n",
      "|    ep_rew_mean     | -1.95e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 718       |\n",
      "|    iterations      | 84        |\n",
      "|    time_elapsed    | 239       |\n",
      "|    total_timesteps | 172032    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 470         |\n",
      "|    ep_rew_mean          | -2.16e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 721         |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 241         |\n",
      "|    total_timesteps      | 174080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007356544 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.22        |\n",
      "|    explained_variance   | 0.75        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.8e+06     |\n",
      "|    n_updates            | 51700       |\n",
      "|    policy_gradient_loss | -0.00157    |\n",
      "|    std                  | 0.242       |\n",
      "|    value_loss           | 1.65e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=175000, episode_reward=6428.24 +/- 12686.90\n",
      "Episode length: 1177.00 +/- 1923.89\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.18e+03    |\n",
      "|    mean_reward          | 6.43e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 175000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005130642 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.22        |\n",
      "|    explained_variance   | 0.435       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.26e+07    |\n",
      "|    n_updates            | 51710       |\n",
      "|    policy_gradient_loss | 4.47e-05    |\n",
      "|    std                  | 0.242       |\n",
      "|    value_loss           | 4.15e+07    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 472       |\n",
      "|    ep_rew_mean     | -2.37e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 716       |\n",
      "|    iterations      | 86        |\n",
      "|    time_elapsed    | 245       |\n",
      "|    total_timesteps | 176128    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 482         |\n",
      "|    ep_rew_mean          | -2.37e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 718         |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 247         |\n",
      "|    total_timesteps      | 178176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004187262 |\n",
      "|    clip_fraction        | 0.00635     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.22        |\n",
      "|    explained_variance   | 0.582       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.82e+06    |\n",
      "|    n_updates            | 51720       |\n",
      "|    policy_gradient_loss | -0.000258   |\n",
      "|    std                  | 0.242       |\n",
      "|    value_loss           | 1.46e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=180000, episode_reward=1339.37 +/- 4276.09\n",
      "Episode length: 503.80 +/- 288.99\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 504         |\n",
      "|    mean_reward          | 1.34e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 180000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006165909 |\n",
      "|    clip_fraction        | 0.03        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.22        |\n",
      "|    explained_variance   | 0.924       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.7e+03     |\n",
      "|    n_updates            | 51730       |\n",
      "|    policy_gradient_loss | -0.0026     |\n",
      "|    std                  | 0.242       |\n",
      "|    value_loss           | 6.82e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 507       |\n",
      "|    ep_rew_mean     | -3.23e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 718       |\n",
      "|    iterations      | 88        |\n",
      "|    time_elapsed    | 250       |\n",
      "|    total_timesteps | 180224    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 457          |\n",
      "|    ep_rew_mean          | -3.22e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 721          |\n",
      "|    iterations           | 89           |\n",
      "|    time_elapsed         | 252          |\n",
      "|    total_timesteps      | 182272       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032170406 |\n",
      "|    clip_fraction        | 0.00283      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.22         |\n",
      "|    explained_variance   | 0.4          |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.24e+07     |\n",
      "|    n_updates            | 51740        |\n",
      "|    policy_gradient_loss | -0.00146     |\n",
      "|    std                  | 0.242        |\n",
      "|    value_loss           | 1.76e+08     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 473         |\n",
      "|    ep_rew_mean          | -3.21e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 723         |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 254         |\n",
      "|    total_timesteps      | 184320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005422717 |\n",
      "|    clip_fraction        | 0.0292      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.22        |\n",
      "|    explained_variance   | 0.813       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.9e+03     |\n",
      "|    n_updates            | 51750       |\n",
      "|    policy_gradient_loss | -0.00212    |\n",
      "|    std                  | 0.242       |\n",
      "|    value_loss           | 2.26e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=185000, episode_reward=-3101.79 +/- 11202.13\n",
      "Episode length: 1265.00 +/- 1888.92\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 1.26e+03  |\n",
      "|    mean_reward          | -3.1e+03  |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 185000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0154611 |\n",
      "|    clip_fraction        | 0.143     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 1.22      |\n",
      "|    explained_variance   | 0.869     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 8.67e+04  |\n",
      "|    n_updates            | 51760     |\n",
      "|    policy_gradient_loss | 0.002     |\n",
      "|    std                  | 0.242     |\n",
      "|    value_loss           | 2.19e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 475       |\n",
      "|    ep_rew_mean     | -3.14e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 718       |\n",
      "|    iterations      | 91        |\n",
      "|    time_elapsed    | 259       |\n",
      "|    total_timesteps | 186368    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 462         |\n",
      "|    ep_rew_mean          | -3.08e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 721         |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 261         |\n",
      "|    total_timesteps      | 188416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003149767 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.22        |\n",
      "|    explained_variance   | 0.593       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.13e+06    |\n",
      "|    n_updates            | 51770       |\n",
      "|    policy_gradient_loss | 0.00204     |\n",
      "|    std                  | 0.242       |\n",
      "|    value_loss           | 5.07e+06    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=190000, episode_reward=-268.84 +/- 10994.34\n",
      "Episode length: 1383.60 +/- 1857.29\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.38e+03    |\n",
      "|    mean_reward          | -269        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 190000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008993267 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.22        |\n",
      "|    explained_variance   | 0.83        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.6e+03     |\n",
      "|    n_updates            | 51780       |\n",
      "|    policy_gradient_loss | 0.000638    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 1.36e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 457       |\n",
      "|    ep_rew_mean     | -3.25e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 714       |\n",
      "|    iterations      | 93        |\n",
      "|    time_elapsed    | 266       |\n",
      "|    total_timesteps | 190464    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 436         |\n",
      "|    ep_rew_mean          | -3.3e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 717         |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 268         |\n",
      "|    total_timesteps      | 192512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010764606 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.23        |\n",
      "|    explained_variance   | 0.454       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.55e+07    |\n",
      "|    n_updates            | 51790       |\n",
      "|    policy_gradient_loss | 0.00573     |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 2.74e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 417         |\n",
      "|    ep_rew_mean          | -3.32e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 720         |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 270         |\n",
      "|    total_timesteps      | 194560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008847908 |\n",
      "|    clip_fraction        | 0.0305      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.23        |\n",
      "|    explained_variance   | 0.624       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.6e+03     |\n",
      "|    n_updates            | 51800       |\n",
      "|    policy_gradient_loss | 0.00155     |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 5.74e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=195000, episode_reward=595.25 +/- 1413.61\n",
      "Episode length: 528.00 +/- 115.72\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 528          |\n",
      "|    mean_reward          | 595          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 195000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041284394 |\n",
      "|    clip_fraction        | 0.0231       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.23         |\n",
      "|    explained_variance   | 0.579        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.7e+05      |\n",
      "|    n_updates            | 51810        |\n",
      "|    policy_gradient_loss | -0.00514     |\n",
      "|    std                  | 0.241        |\n",
      "|    value_loss           | 5.16e+06     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 410       |\n",
      "|    ep_rew_mean     | -3.07e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 719       |\n",
      "|    iterations      | 96        |\n",
      "|    time_elapsed    | 273       |\n",
      "|    total_timesteps | 196608    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 374         |\n",
      "|    ep_rew_mean          | -2.47e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 722         |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 275         |\n",
      "|    total_timesteps      | 198656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008247204 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.23        |\n",
      "|    explained_variance   | 0.69        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.6e+06     |\n",
      "|    n_updates            | 51820       |\n",
      "|    policy_gradient_loss | -0.000966   |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 3.08e+06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=200000, episode_reward=-12764.51 +/- 16029.83\n",
      "Episode length: 1015.80 +/- 1233.95\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | -1.28e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 200000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003161013 |\n",
      "|    clip_fraction        | 0.00972     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.23        |\n",
      "|    explained_variance   | 0.51        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.17e+05    |\n",
      "|    n_updates            | 51830       |\n",
      "|    policy_gradient_loss | -0.00279    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 3.45e+06    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 357       |\n",
      "|    ep_rew_mean     | -2.46e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 718       |\n",
      "|    iterations      | 98        |\n",
      "|    time_elapsed    | 279       |\n",
      "|    total_timesteps | 200704    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 367         |\n",
      "|    ep_rew_mean          | -2.47e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 720         |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 281         |\n",
      "|    total_timesteps      | 202752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006002509 |\n",
      "|    clip_fraction        | 0.0845      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.23        |\n",
      "|    explained_variance   | 0.108       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.76e+03    |\n",
      "|    n_updates            | 51840       |\n",
      "|    policy_gradient_loss | -0.00154    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 7.09e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 362         |\n",
      "|    ep_rew_mean          | -2.63e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 723         |\n",
      "|    iterations           | 100         |\n",
      "|    time_elapsed         | 283         |\n",
      "|    total_timesteps      | 204800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016678609 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.23        |\n",
      "|    explained_variance   | 0.821       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.84e+03    |\n",
      "|    n_updates            | 51850       |\n",
      "|    policy_gradient_loss | -0.000602   |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 3.1e+05     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=205000, episode_reward=-7209.21 +/- 9088.39\n",
      "Episode length: 1298.20 +/- 1873.81\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.3e+03     |\n",
      "|    mean_reward          | -7.21e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 205000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005842621 |\n",
      "|    clip_fraction        | 0.0483      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.23        |\n",
      "|    explained_variance   | 0.505       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.25e+04    |\n",
      "|    n_updates            | 51860       |\n",
      "|    policy_gradient_loss | 0.000708    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 1.6e+07     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 374       |\n",
      "|    ep_rew_mean     | -2.39e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 718       |\n",
      "|    iterations      | 101       |\n",
      "|    time_elapsed    | 288       |\n",
      "|    total_timesteps | 206848    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 348         |\n",
      "|    ep_rew_mean          | -2.57e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 720         |\n",
      "|    iterations           | 102         |\n",
      "|    time_elapsed         | 289         |\n",
      "|    total_timesteps      | 208896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010370729 |\n",
      "|    clip_fraction        | 0.0582      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.23        |\n",
      "|    explained_variance   | 0.474       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.98e+07    |\n",
      "|    n_updates            | 51870       |\n",
      "|    policy_gradient_loss | 0.000603    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 4.62e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=210000, episode_reward=-24414.89 +/- 40207.86\n",
      "Episode length: 254.40 +/- 300.88\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 254          |\n",
      "|    mean_reward          | -2.44e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 210000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022779368 |\n",
      "|    clip_fraction        | 0.0315       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.23         |\n",
      "|    explained_variance   | 0.473        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.97e+07     |\n",
      "|    n_updates            | 51880        |\n",
      "|    policy_gradient_loss | 0.002        |\n",
      "|    std                  | 0.241        |\n",
      "|    value_loss           | 5.1e+07      |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 299       |\n",
      "|    ep_rew_mean     | -1.69e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 721       |\n",
      "|    iterations      | 103       |\n",
      "|    time_elapsed    | 292       |\n",
      "|    total_timesteps | 210944    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 297          |\n",
      "|    ep_rew_mean          | -1.67e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 723          |\n",
      "|    iterations           | 104          |\n",
      "|    time_elapsed         | 294          |\n",
      "|    total_timesteps      | 212992       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037109423 |\n",
      "|    clip_fraction        | 0.0146       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.23         |\n",
      "|    explained_variance   | 0.51         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.71e+06     |\n",
      "|    n_updates            | 51890        |\n",
      "|    policy_gradient_loss | -0.00235     |\n",
      "|    std                  | 0.241        |\n",
      "|    value_loss           | 1.8e+07      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=215000, episode_reward=-1295.45 +/- 1595.57\n",
      "Episode length: 501.00 +/- 208.36\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 501         |\n",
      "|    mean_reward          | -1.3e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 215000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011908701 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.23        |\n",
      "|    explained_variance   | 0.706       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.34e+03    |\n",
      "|    n_updates            | 51900       |\n",
      "|    policy_gradient_loss | 5.05e-05    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 2.93e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 286       |\n",
      "|    ep_rew_mean     | -1.61e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 723       |\n",
      "|    iterations      | 105       |\n",
      "|    time_elapsed    | 297       |\n",
      "|    total_timesteps | 215040    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 301         |\n",
      "|    ep_rew_mean          | -1.61e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 725         |\n",
      "|    iterations           | 106         |\n",
      "|    time_elapsed         | 299         |\n",
      "|    total_timesteps      | 217088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017070675 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.23        |\n",
      "|    explained_variance   | 0.616       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.33e+04    |\n",
      "|    n_updates            | 51910       |\n",
      "|    policy_gradient_loss | -0.00111    |\n",
      "|    std                  | 0.24        |\n",
      "|    value_loss           | 7.15e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 308         |\n",
      "|    ep_rew_mean          | -1.58e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 727         |\n",
      "|    iterations           | 107         |\n",
      "|    time_elapsed         | 301         |\n",
      "|    total_timesteps      | 219136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011692988 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.23        |\n",
      "|    explained_variance   | 0.861       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1e+03       |\n",
      "|    n_updates            | 51920       |\n",
      "|    policy_gradient_loss | -0.00142    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 1.99e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=220000, episode_reward=-1033.93 +/- 3594.14\n",
      "Episode length: 308.20 +/- 173.69\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 308         |\n",
      "|    mean_reward          | -1.03e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 220000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017540697 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.23        |\n",
      "|    explained_variance   | 0.614       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.54e+03    |\n",
      "|    n_updates            | 51930       |\n",
      "|    policy_gradient_loss | -0.00622    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 9.38e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 306       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 728       |\n",
      "|    iterations      | 108       |\n",
      "|    time_elapsed    | 303       |\n",
      "|    total_timesteps | 221184    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 316         |\n",
      "|    ep_rew_mean          | -1.45e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 730         |\n",
      "|    iterations           | 109         |\n",
      "|    time_elapsed         | 305         |\n",
      "|    total_timesteps      | 223232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010437475 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.23        |\n",
      "|    explained_variance   | 0.618       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.75e+05    |\n",
      "|    n_updates            | 51940       |\n",
      "|    policy_gradient_loss | 0.00102     |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 7.27e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=225000, episode_reward=1801.41 +/- 3837.75\n",
      "Episode length: 494.40 +/- 203.33\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 494         |\n",
      "|    mean_reward          | 1.8e+03     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 225000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009758802 |\n",
      "|    clip_fraction        | 0.0892      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.23        |\n",
      "|    explained_variance   | 0.848       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.34e+03    |\n",
      "|    n_updates            | 51950       |\n",
      "|    policy_gradient_loss | -0.00337    |\n",
      "|    std                  | 0.24        |\n",
      "|    value_loss           | 3.57e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 322       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 730       |\n",
      "|    iterations      | 110       |\n",
      "|    time_elapsed    | 308       |\n",
      "|    total_timesteps | 225280    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 319         |\n",
      "|    ep_rew_mean          | -1.33e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 732         |\n",
      "|    iterations           | 111         |\n",
      "|    time_elapsed         | 310         |\n",
      "|    total_timesteps      | 227328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016558269 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.24        |\n",
      "|    explained_variance   | 0.595       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.46e+05    |\n",
      "|    n_updates            | 51960       |\n",
      "|    policy_gradient_loss | 0.00676     |\n",
      "|    std                  | 0.24        |\n",
      "|    value_loss           | 1.92e+06    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 325        |\n",
      "|    ep_rew_mean          | -1.29e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 734        |\n",
      "|    iterations           | 112        |\n",
      "|    time_elapsed         | 312        |\n",
      "|    total_timesteps      | 229376     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01036343 |\n",
      "|    clip_fraction        | 0.113      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.24       |\n",
      "|    explained_variance   | 0.87       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.42e+03   |\n",
      "|    n_updates            | 51970      |\n",
      "|    policy_gradient_loss | -0.00511   |\n",
      "|    std                  | 0.24       |\n",
      "|    value_loss           | 1.47e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=230000, episode_reward=-23655.36 +/- 48127.84\n",
      "Episode length: 280.00 +/- 189.98\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 280         |\n",
      "|    mean_reward          | -2.37e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 230000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004227139 |\n",
      "|    clip_fraction        | 0.0497      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.24        |\n",
      "|    explained_variance   | 0.615       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.37e+03    |\n",
      "|    n_updates            | 51980       |\n",
      "|    policy_gradient_loss | -0.00636    |\n",
      "|    std                  | 0.24        |\n",
      "|    value_loss           | 1.4e+06     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 337       |\n",
      "|    ep_rew_mean     | -1.29e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 735       |\n",
      "|    iterations      | 113       |\n",
      "|    time_elapsed    | 314       |\n",
      "|    total_timesteps | 231424    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 347         |\n",
      "|    ep_rew_mean          | -1.18e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 737         |\n",
      "|    iterations           | 114         |\n",
      "|    time_elapsed         | 316         |\n",
      "|    total_timesteps      | 233472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005773442 |\n",
      "|    clip_fraction        | 0.0803      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.24        |\n",
      "|    explained_variance   | 0.535       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.52e+03    |\n",
      "|    n_updates            | 51990       |\n",
      "|    policy_gradient_loss | -0.000664   |\n",
      "|    std                  | 0.24        |\n",
      "|    value_loss           | 2.4e+05     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=235000, episode_reward=-14709.30 +/- 5682.33\n",
      "Episode length: 105.20 +/- 181.97\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 105          |\n",
      "|    mean_reward          | -1.47e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 235000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076386635 |\n",
      "|    clip_fraction        | 0.0939       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.25         |\n",
      "|    explained_variance   | 0.845        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.14e+03     |\n",
      "|    n_updates            | 52000        |\n",
      "|    policy_gradient_loss | -0.00168     |\n",
      "|    std                  | 0.24         |\n",
      "|    value_loss           | 6.92e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 359       |\n",
      "|    ep_rew_mean     | -1.24e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 738       |\n",
      "|    iterations      | 115       |\n",
      "|    time_elapsed    | 318       |\n",
      "|    total_timesteps | 235520    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 364          |\n",
      "|    ep_rew_mean          | -1.26e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 741          |\n",
      "|    iterations           | 116          |\n",
      "|    time_elapsed         | 320          |\n",
      "|    total_timesteps      | 237568       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016268613 |\n",
      "|    clip_fraction        | 0.00249      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.25         |\n",
      "|    explained_variance   | 0.426        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.98e+06     |\n",
      "|    n_updates            | 52010        |\n",
      "|    policy_gradient_loss | 0.000335     |\n",
      "|    std                  | 0.24         |\n",
      "|    value_loss           | 8.37e+06     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 371          |\n",
      "|    ep_rew_mean          | -1.43e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 743          |\n",
      "|    iterations           | 117          |\n",
      "|    time_elapsed         | 322          |\n",
      "|    total_timesteps      | 239616       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072961543 |\n",
      "|    clip_fraction        | 0.0611       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.25         |\n",
      "|    explained_variance   | 0.638        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.53e+03     |\n",
      "|    n_updates            | 52020        |\n",
      "|    policy_gradient_loss | -0.00365     |\n",
      "|    std                  | 0.24         |\n",
      "|    value_loss           | 6.26e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=240000, episode_reward=-29685.84 +/- 79154.17\n",
      "Episode length: 1413.60 +/- 1822.81\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.41e+03     |\n",
      "|    mean_reward          | -2.97e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 240000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058097374 |\n",
      "|    clip_fraction        | 0.0238       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.25         |\n",
      "|    explained_variance   | 0.481        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.67e+07     |\n",
      "|    n_updates            | 52030        |\n",
      "|    policy_gradient_loss | -0.00478     |\n",
      "|    std                  | 0.24         |\n",
      "|    value_loss           | 3.65e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 360       |\n",
      "|    ep_rew_mean     | -1.32e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 737       |\n",
      "|    iterations      | 118       |\n",
      "|    time_elapsed    | 327       |\n",
      "|    total_timesteps | 241664    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 367         |\n",
      "|    ep_rew_mean          | -1.03e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 739         |\n",
      "|    iterations           | 119         |\n",
      "|    time_elapsed         | 329         |\n",
      "|    total_timesteps      | 243712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011913693 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.25        |\n",
      "|    explained_variance   | 0.512       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.67e+03    |\n",
      "|    n_updates            | 52040       |\n",
      "|    policy_gradient_loss | -0.00261    |\n",
      "|    std                  | 0.24        |\n",
      "|    value_loss           | 2.49e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=245000, episode_reward=-5931.00 +/- 15557.35\n",
      "Episode length: 349.20 +/- 387.94\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 349         |\n",
      "|    mean_reward          | -5.93e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 245000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008613452 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.25        |\n",
      "|    explained_variance   | 0.577       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.9e+06     |\n",
      "|    n_updates            | 52050       |\n",
      "|    policy_gradient_loss | -0.0043     |\n",
      "|    std                  | 0.24        |\n",
      "|    value_loss           | 4.12e+06    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 378       |\n",
      "|    ep_rew_mean     | -1.25e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 739       |\n",
      "|    iterations      | 120       |\n",
      "|    time_elapsed    | 332       |\n",
      "|    total_timesteps | 245760    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -1.38e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 741          |\n",
      "|    iterations           | 121          |\n",
      "|    time_elapsed         | 334          |\n",
      "|    total_timesteps      | 247808       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035152435 |\n",
      "|    clip_fraction        | 0.0119       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.25         |\n",
      "|    explained_variance   | 0.479        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.05e+07     |\n",
      "|    n_updates            | 52060        |\n",
      "|    policy_gradient_loss | -0.00204     |\n",
      "|    std                  | 0.24         |\n",
      "|    value_loss           | 4.18e+07     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 404         |\n",
      "|    ep_rew_mean          | -1.38e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 743         |\n",
      "|    iterations           | 122         |\n",
      "|    time_elapsed         | 336         |\n",
      "|    total_timesteps      | 249856      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005241379 |\n",
      "|    clip_fraction        | 0.0225      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.25        |\n",
      "|    explained_variance   | 0.41        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.06e+07    |\n",
      "|    n_updates            | 52070       |\n",
      "|    policy_gradient_loss | -0.00429    |\n",
      "|    std                  | 0.24        |\n",
      "|    value_loss           | 7.37e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=250000, episode_reward=-3192.21 +/- 6484.42\n",
      "Episode length: 537.80 +/- 285.58\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 538          |\n",
      "|    mean_reward          | -3.19e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 250000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038701757 |\n",
      "|    clip_fraction        | 0.0136       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.25         |\n",
      "|    explained_variance   | 0.717        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.44e+06     |\n",
      "|    n_updates            | 52080        |\n",
      "|    policy_gradient_loss | -0.00171     |\n",
      "|    std                  | 0.24         |\n",
      "|    value_loss           | 9.66e+06     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 423       |\n",
      "|    ep_rew_mean     | -1.77e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 742       |\n",
      "|    iterations      | 123       |\n",
      "|    time_elapsed    | 339       |\n",
      "|    total_timesteps | 251904    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 432         |\n",
      "|    ep_rew_mean          | -1.83e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 744         |\n",
      "|    iterations           | 124         |\n",
      "|    time_elapsed         | 341         |\n",
      "|    total_timesteps      | 253952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012411429 |\n",
      "|    clip_fraction        | 0.0744      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.25        |\n",
      "|    explained_variance   | 0.461       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.07e+07    |\n",
      "|    n_updates            | 52090       |\n",
      "|    policy_gradient_loss | -0.000546   |\n",
      "|    std                  | 0.24        |\n",
      "|    value_loss           | 8.48e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=255000, episode_reward=3625.43 +/- 5400.42\n",
      "Episode length: 478.40 +/- 431.13\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 478        |\n",
      "|    mean_reward          | 3.63e+03   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 255000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01096973 |\n",
      "|    clip_fraction        | 0.124      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.25       |\n",
      "|    explained_variance   | 0.704      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.94e+03   |\n",
      "|    n_updates            | 52100      |\n",
      "|    policy_gradient_loss | -0.000153  |\n",
      "|    std                  | 0.239      |\n",
      "|    value_loss           | 2.31e+06   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 444       |\n",
      "|    ep_rew_mean     | -1.83e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 743       |\n",
      "|    iterations      | 125       |\n",
      "|    time_elapsed    | 344       |\n",
      "|    total_timesteps | 256000    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 443         |\n",
      "|    ep_rew_mean          | -1.84e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 745         |\n",
      "|    iterations           | 126         |\n",
      "|    time_elapsed         | 345         |\n",
      "|    total_timesteps      | 258048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022885697 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.25        |\n",
      "|    explained_variance   | 0.645       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.69e+03    |\n",
      "|    n_updates            | 52110       |\n",
      "|    policy_gradient_loss | 0.000565    |\n",
      "|    std                  | 0.239       |\n",
      "|    value_loss           | 1.25e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=260000, episode_reward=2036.11 +/- 8591.44\n",
      "Episode length: 829.80 +/- 871.64\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 830         |\n",
      "|    mean_reward          | 2.04e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 260000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015493988 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.25        |\n",
      "|    explained_variance   | 0.77        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.05e+03    |\n",
      "|    n_updates            | 52120       |\n",
      "|    policy_gradient_loss | -0.00384    |\n",
      "|    std                  | 0.24        |\n",
      "|    value_loss           | 4.68e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 452       |\n",
      "|    ep_rew_mean     | -1.81e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 743       |\n",
      "|    iterations      | 127       |\n",
      "|    time_elapsed    | 349       |\n",
      "|    total_timesteps | 260096    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 444         |\n",
      "|    ep_rew_mean          | -1.95e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 745         |\n",
      "|    iterations           | 128         |\n",
      "|    time_elapsed         | 351         |\n",
      "|    total_timesteps      | 262144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007226811 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.25        |\n",
      "|    explained_variance   | 0.578       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.41e+04    |\n",
      "|    n_updates            | 52130       |\n",
      "|    policy_gradient_loss | 0.000791    |\n",
      "|    std                  | 0.24        |\n",
      "|    value_loss           | 6.96e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 447        |\n",
      "|    ep_rew_mean          | -2e+04     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 747        |\n",
      "|    iterations           | 129        |\n",
      "|    time_elapsed         | 353        |\n",
      "|    total_timesteps      | 264192     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01082121 |\n",
      "|    clip_fraction        | 0.165      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.24       |\n",
      "|    explained_variance   | 0.519      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.34e+03   |\n",
      "|    n_updates            | 52140      |\n",
      "|    policy_gradient_loss | 0.01       |\n",
      "|    std                  | 0.24       |\n",
      "|    value_loss           | 1.54e+07   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=265000, episode_reward=-10767.15 +/- 23642.69\n",
      "Episode length: 520.40 +/- 293.56\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 520         |\n",
      "|    mean_reward          | -1.08e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 265000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003816389 |\n",
      "|    clip_fraction        | 0.0445      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.24        |\n",
      "|    explained_variance   | 0.448       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.23e+06    |\n",
      "|    n_updates            | 52150       |\n",
      "|    policy_gradient_loss | -0.00265    |\n",
      "|    std                  | 0.24        |\n",
      "|    value_loss           | 2.74e+06    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 439       |\n",
      "|    ep_rew_mean     | -1.96e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 746       |\n",
      "|    iterations      | 130       |\n",
      "|    time_elapsed    | 356       |\n",
      "|    total_timesteps | 266240    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 445         |\n",
      "|    ep_rew_mean          | -1.93e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 748         |\n",
      "|    iterations           | 131         |\n",
      "|    time_elapsed         | 358         |\n",
      "|    total_timesteps      | 268288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012370937 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.24        |\n",
      "|    explained_variance   | 0.48        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.04e+03    |\n",
      "|    n_updates            | 52160       |\n",
      "|    policy_gradient_loss | 0.000384    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 2.65e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=270000, episode_reward=-22322.72 +/- 59539.31\n",
      "Episode length: 902.20 +/- 566.75\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 902         |\n",
      "|    mean_reward          | -2.23e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 270000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011347504 |\n",
      "|    clip_fraction        | 0.0987      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.24        |\n",
      "|    explained_variance   | 0.455       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.26e+03    |\n",
      "|    n_updates            | 52170       |\n",
      "|    policy_gradient_loss | -0.00436    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 2.66e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 450       |\n",
      "|    ep_rew_mean     | -1.89e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 745       |\n",
      "|    iterations      | 132       |\n",
      "|    time_elapsed    | 362       |\n",
      "|    total_timesteps | 270336    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 472          |\n",
      "|    ep_rew_mean          | -2.06e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 747          |\n",
      "|    iterations           | 133          |\n",
      "|    time_elapsed         | 364          |\n",
      "|    total_timesteps      | 272384       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067868503 |\n",
      "|    clip_fraction        | 0.0621       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.24         |\n",
      "|    explained_variance   | 0.968        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.56e+03     |\n",
      "|    n_updates            | 52180        |\n",
      "|    policy_gradient_loss | -0.00345     |\n",
      "|    std                  | 0.241        |\n",
      "|    value_loss           | 1.85e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 482          |\n",
      "|    ep_rew_mean          | -2.4e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 749          |\n",
      "|    iterations           | 134          |\n",
      "|    time_elapsed         | 366          |\n",
      "|    total_timesteps      | 274432       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014026609 |\n",
      "|    clip_fraction        | 0.00171      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.24         |\n",
      "|    explained_variance   | 0.425        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.93e+06     |\n",
      "|    n_updates            | 52190        |\n",
      "|    policy_gradient_loss | -0.00127     |\n",
      "|    std                  | 0.241        |\n",
      "|    value_loss           | 2.14e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=275000, episode_reward=-58812.89 +/- 44501.64\n",
      "Episode length: 437.60 +/- 501.66\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 438          |\n",
      "|    mean_reward          | -5.88e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 275000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059156255 |\n",
      "|    clip_fraction        | 0.0127       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.24         |\n",
      "|    explained_variance   | 0.484        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.19e+07     |\n",
      "|    n_updates            | 52200        |\n",
      "|    policy_gradient_loss | -0.00181     |\n",
      "|    std                  | 0.241        |\n",
      "|    value_loss           | 6.05e+07     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 482      |\n",
      "|    ep_rew_mean     | -2.4e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 748      |\n",
      "|    iterations      | 135      |\n",
      "|    time_elapsed    | 369      |\n",
      "|    total_timesteps | 276480   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 482         |\n",
      "|    ep_rew_mean          | -2.4e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 750         |\n",
      "|    iterations           | 136         |\n",
      "|    time_elapsed         | 370         |\n",
      "|    total_timesteps      | 278528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014493738 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.24        |\n",
      "|    explained_variance   | 0.664       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 879         |\n",
      "|    n_updates            | 52210       |\n",
      "|    policy_gradient_loss | 0.000591    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 2.82e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=280000, episode_reward=-91148.99 +/- 158583.12\n",
      "Episode length: 998.60 +/- 1520.11\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 999         |\n",
      "|    mean_reward          | -9.11e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 280000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014317092 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.25        |\n",
      "|    explained_variance   | 0.811       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.9e+03     |\n",
      "|    n_updates            | 52220       |\n",
      "|    policy_gradient_loss | -0.00787    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 5.61e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 534       |\n",
      "|    ep_rew_mean     | -2.48e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 747       |\n",
      "|    iterations      | 137       |\n",
      "|    time_elapsed    | 375       |\n",
      "|    total_timesteps | 280576    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 535          |\n",
      "|    ep_rew_mean          | -2.53e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 749          |\n",
      "|    iterations           | 138          |\n",
      "|    time_elapsed         | 377          |\n",
      "|    total_timesteps      | 282624       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043228446 |\n",
      "|    clip_fraction        | 0.138        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.25         |\n",
      "|    explained_variance   | 0.543        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.72e+07     |\n",
      "|    n_updates            | 52230        |\n",
      "|    policy_gradient_loss | -0.00147     |\n",
      "|    std                  | 0.241        |\n",
      "|    value_loss           | 1.88e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 541          |\n",
      "|    ep_rew_mean          | -2.5e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 751          |\n",
      "|    iterations           | 139          |\n",
      "|    time_elapsed         | 378          |\n",
      "|    total_timesteps      | 284672       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015965865 |\n",
      "|    clip_fraction        | 0.00371      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.25         |\n",
      "|    explained_variance   | 0.574        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.21e+06     |\n",
      "|    n_updates            | 52240        |\n",
      "|    policy_gradient_loss | -0.00297     |\n",
      "|    std                  | 0.241        |\n",
      "|    value_loss           | 5.09e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=285000, episode_reward=-19111.85 +/- 22511.85\n",
      "Episode length: 494.40 +/- 380.15\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 494        |\n",
      "|    mean_reward          | -1.91e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 285000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00637603 |\n",
      "|    clip_fraction        | 0.0331     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.25       |\n",
      "|    explained_variance   | 0.915      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.22e+03   |\n",
      "|    n_updates            | 52250      |\n",
      "|    policy_gradient_loss | -0.00167   |\n",
      "|    std                  | 0.241      |\n",
      "|    value_loss           | 8.52e+04   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 537       |\n",
      "|    ep_rew_mean     | -2.54e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 750       |\n",
      "|    iterations      | 140       |\n",
      "|    time_elapsed    | 381       |\n",
      "|    total_timesteps | 286720    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 515         |\n",
      "|    ep_rew_mean          | -2.57e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 752         |\n",
      "|    iterations           | 141         |\n",
      "|    time_elapsed         | 383         |\n",
      "|    total_timesteps      | 288768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004668073 |\n",
      "|    clip_fraction        | 0.05        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.25        |\n",
      "|    explained_variance   | 0.721       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.82e+03    |\n",
      "|    n_updates            | 52260       |\n",
      "|    policy_gradient_loss | -0.00106    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 1.3e+06     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=290000, episode_reward=13134.58 +/- 17177.07\n",
      "Episode length: 1399.20 +/- 1820.65\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.4e+03      |\n",
      "|    mean_reward          | 1.31e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 290000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058302423 |\n",
      "|    clip_fraction        | 0.0386       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.25         |\n",
      "|    explained_variance   | 0.561        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.85e+06     |\n",
      "|    n_updates            | 52270        |\n",
      "|    policy_gradient_loss | -0.00574     |\n",
      "|    std                  | 0.241        |\n",
      "|    value_loss           | 5.77e+06     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 501       |\n",
      "|    ep_rew_mean     | -2.38e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 747       |\n",
      "|    iterations      | 142       |\n",
      "|    time_elapsed    | 389       |\n",
      "|    total_timesteps | 290816    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 513         |\n",
      "|    ep_rew_mean          | -2.6e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 749         |\n",
      "|    iterations           | 143         |\n",
      "|    time_elapsed         | 390         |\n",
      "|    total_timesteps      | 292864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009150239 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.26        |\n",
      "|    explained_variance   | 0.767       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.46e+03    |\n",
      "|    n_updates            | 52280       |\n",
      "|    policy_gradient_loss | -0.00666    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 1.96e+05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 509          |\n",
      "|    ep_rew_mean          | -2.68e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 750          |\n",
      "|    iterations           | 144          |\n",
      "|    time_elapsed         | 392          |\n",
      "|    total_timesteps      | 294912       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047942875 |\n",
      "|    clip_fraction        | 0.0534       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.26         |\n",
      "|    explained_variance   | 0.446        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.38e+07     |\n",
      "|    n_updates            | 52290        |\n",
      "|    policy_gradient_loss | -0.00342     |\n",
      "|    std                  | 0.241        |\n",
      "|    value_loss           | 4.36e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=295000, episode_reward=6364.08 +/- 5852.45\n",
      "Episode length: 824.20 +/- 368.31\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 824          |\n",
      "|    mean_reward          | 6.36e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 295000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025213165 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.26         |\n",
      "|    explained_variance   | 0.463        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.46e+06     |\n",
      "|    n_updates            | 52300        |\n",
      "|    policy_gradient_loss | -0.000638    |\n",
      "|    std                  | 0.241        |\n",
      "|    value_loss           | 9.63e+06     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 509       |\n",
      "|    ep_rew_mean     | -2.68e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 748       |\n",
      "|    iterations      | 145       |\n",
      "|    time_elapsed    | 396       |\n",
      "|    total_timesteps | 296960    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 557         |\n",
      "|    ep_rew_mean          | -3.06e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 750         |\n",
      "|    iterations           | 146         |\n",
      "|    time_elapsed         | 398         |\n",
      "|    total_timesteps      | 299008      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009203045 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.26        |\n",
      "|    explained_variance   | 0.892       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.12e+03    |\n",
      "|    n_updates            | 52310       |\n",
      "|    policy_gradient_loss | -0.00183    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 5.35e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=300000, episode_reward=10383.56 +/- 17542.90\n",
      "Episode length: 2009.40 +/- 1774.22\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.01e+03     |\n",
      "|    mean_reward          | 1.04e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 300000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016136845 |\n",
      "|    clip_fraction        | 0.0212       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.26         |\n",
      "|    explained_variance   | 0.468        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.02e+07     |\n",
      "|    n_updates            | 52320        |\n",
      "|    policy_gradient_loss | 0.000588     |\n",
      "|    std                  | 0.241        |\n",
      "|    value_loss           | 9.02e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 557       |\n",
      "|    ep_rew_mean     | -3.06e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 742       |\n",
      "|    iterations      | 147       |\n",
      "|    time_elapsed    | 405       |\n",
      "|    total_timesteps | 301056    |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 557        |\n",
      "|    ep_rew_mean          | -3.06e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 743        |\n",
      "|    iterations           | 148        |\n",
      "|    time_elapsed         | 407        |\n",
      "|    total_timesteps      | 303104     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01336276 |\n",
      "|    clip_fraction        | 0.113      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.27       |\n",
      "|    explained_variance   | 0.913      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 642        |\n",
      "|    n_updates            | 52330      |\n",
      "|    policy_gradient_loss | -0.00163   |\n",
      "|    std                  | 0.24       |\n",
      "|    value_loss           | 3.21e+03   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=305000, episode_reward=-105973.37 +/- 174703.49\n",
      "Episode length: 417.60 +/- 360.35\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 418         |\n",
      "|    mean_reward          | -1.06e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 305000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012193739 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.27        |\n",
      "|    explained_variance   | 0.741       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 551         |\n",
      "|    n_updates            | 52340       |\n",
      "|    policy_gradient_loss | -0.00204    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 2.01e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 583       |\n",
      "|    ep_rew_mean     | -3.21e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 742       |\n",
      "|    iterations      | 149       |\n",
      "|    time_elapsed    | 410       |\n",
      "|    total_timesteps | 305152    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 585         |\n",
      "|    ep_rew_mean          | -2.8e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 744         |\n",
      "|    iterations           | 150         |\n",
      "|    time_elapsed         | 412         |\n",
      "|    total_timesteps      | 307200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007237705 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.26        |\n",
      "|    explained_variance   | 0.491       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.5e+07     |\n",
      "|    n_updates            | 52350       |\n",
      "|    policy_gradient_loss | 0.00206     |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 6.71e+07    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 583          |\n",
      "|    ep_rew_mean          | -2.37e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 745          |\n",
      "|    iterations           | 151          |\n",
      "|    time_elapsed         | 414          |\n",
      "|    total_timesteps      | 309248       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026251674 |\n",
      "|    clip_fraction        | 0.00337      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.26         |\n",
      "|    explained_variance   | 0.849        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.56e+05     |\n",
      "|    n_updates            | 52360        |\n",
      "|    policy_gradient_loss | -0.00206     |\n",
      "|    std                  | 0.241        |\n",
      "|    value_loss           | 8.1e+05      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=310000, episode_reward=-78392.38 +/- 153544.48\n",
      "Episode length: 564.60 +/- 279.19\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 565         |\n",
      "|    mean_reward          | -7.84e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 310000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004026226 |\n",
      "|    clip_fraction        | 0.012       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.26        |\n",
      "|    explained_variance   | 0.694       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.41e+06    |\n",
      "|    n_updates            | 52370       |\n",
      "|    policy_gradient_loss | -0.00514    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 9.22e+06    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 574       |\n",
      "|    ep_rew_mean     | -2.48e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 742       |\n",
      "|    iterations      | 152       |\n",
      "|    time_elapsed    | 419       |\n",
      "|    total_timesteps | 311296    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 567         |\n",
      "|    ep_rew_mean          | -2.61e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 744         |\n",
      "|    iterations           | 153         |\n",
      "|    time_elapsed         | 421         |\n",
      "|    total_timesteps      | 313344      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002710522 |\n",
      "|    clip_fraction        | 0.0063      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.26        |\n",
      "|    explained_variance   | 0.638       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.39e+07    |\n",
      "|    n_updates            | 52380       |\n",
      "|    policy_gradient_loss | -0.00357    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 1.43e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=315000, episode_reward=-79049.63 +/- 159452.40\n",
      "Episode length: 1601.20 +/- 1712.13\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.6e+03      |\n",
      "|    mean_reward          | -7.9e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 315000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010435916 |\n",
      "|    clip_fraction        | 0.00083      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.26         |\n",
      "|    explained_variance   | 0.739        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.1e+06      |\n",
      "|    n_updates            | 52390        |\n",
      "|    policy_gradient_loss | -0.00129     |\n",
      "|    std                  | 0.241        |\n",
      "|    value_loss           | 6.1e+06      |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 569       |\n",
      "|    ep_rew_mean     | -2.62e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 738       |\n",
      "|    iterations      | 154       |\n",
      "|    time_elapsed    | 427       |\n",
      "|    total_timesteps | 315392    |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 563        |\n",
      "|    ep_rew_mean          | -2.82e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 740        |\n",
      "|    iterations           | 155        |\n",
      "|    time_elapsed         | 428        |\n",
      "|    total_timesteps      | 317440     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00553888 |\n",
      "|    clip_fraction        | 0.0201     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.26       |\n",
      "|    explained_variance   | 0.861      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.78e+05   |\n",
      "|    n_updates            | 52400      |\n",
      "|    policy_gradient_loss | -0.0047    |\n",
      "|    std                  | 0.241      |\n",
      "|    value_loss           | 1.3e+06    |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 572          |\n",
      "|    ep_rew_mean          | -2.83e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 741          |\n",
      "|    iterations           | 156          |\n",
      "|    time_elapsed         | 430          |\n",
      "|    total_timesteps      | 319488       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017966958 |\n",
      "|    clip_fraction        | 0.00342      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.26         |\n",
      "|    explained_variance   | 0.476        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.77e+07     |\n",
      "|    n_updates            | 52410        |\n",
      "|    policy_gradient_loss | -0.00264     |\n",
      "|    std                  | 0.241        |\n",
      "|    value_loss           | 2.73e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=320000, episode_reward=-61621.53 +/- 95344.16\n",
      "Episode length: 1649.00 +/- 1887.63\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.65e+03     |\n",
      "|    mean_reward          | -6.16e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 320000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028975792 |\n",
      "|    clip_fraction        | 0.0114       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.26         |\n",
      "|    explained_variance   | 0.448        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.69e+07     |\n",
      "|    n_updates            | 52420        |\n",
      "|    policy_gradient_loss | -0.00374     |\n",
      "|    std                  | 0.241        |\n",
      "|    value_loss           | 8.47e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -3.15e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 736       |\n",
      "|    iterations      | 157       |\n",
      "|    time_elapsed    | 436       |\n",
      "|    total_timesteps | 321536    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 591         |\n",
      "|    ep_rew_mean          | -3.15e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 737         |\n",
      "|    iterations           | 158         |\n",
      "|    time_elapsed         | 438         |\n",
      "|    total_timesteps      | 323584      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002881608 |\n",
      "|    clip_fraction        | 0.00547     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.26        |\n",
      "|    explained_variance   | 0.639       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.23e+04    |\n",
      "|    n_updates            | 52430       |\n",
      "|    policy_gradient_loss | -0.00277    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 4.06e+06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=325000, episode_reward=23312.69 +/- 22924.87\n",
      "Episode length: 2689.60 +/- 1987.80\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.69e+03     |\n",
      "|    mean_reward          | 2.33e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 325000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026006126 |\n",
      "|    clip_fraction        | 0.011        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.26         |\n",
      "|    explained_variance   | 0.69         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.47e+05     |\n",
      "|    n_updates            | 52440        |\n",
      "|    policy_gradient_loss | -0.00111     |\n",
      "|    std                  | 0.241        |\n",
      "|    value_loss           | 7.1e+05      |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 591       |\n",
      "|    ep_rew_mean     | -3.15e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 728       |\n",
      "|    iterations      | 159       |\n",
      "|    time_elapsed    | 446       |\n",
      "|    total_timesteps | 325632    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 633         |\n",
      "|    ep_rew_mean          | -3.52e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 730         |\n",
      "|    iterations           | 160         |\n",
      "|    time_elapsed         | 448         |\n",
      "|    total_timesteps      | 327680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016688006 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.25        |\n",
      "|    explained_variance   | 0.916       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 346         |\n",
      "|    n_updates            | 52450       |\n",
      "|    policy_gradient_loss | 0.000958    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 1.77e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 640        |\n",
      "|    ep_rew_mean          | -3.56e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 731        |\n",
      "|    iterations           | 161        |\n",
      "|    time_elapsed         | 450        |\n",
      "|    total_timesteps      | 329728     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00485071 |\n",
      "|    clip_fraction        | 0.0466     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.24       |\n",
      "|    explained_variance   | 0.453      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.78e+07   |\n",
      "|    n_updates            | 52460      |\n",
      "|    policy_gradient_loss | -0.000206  |\n",
      "|    std                  | 0.241      |\n",
      "|    value_loss           | 8.21e+07   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=330000, episode_reward=-73942.56 +/- 183643.78\n",
      "Episode length: 2614.20 +/- 1877.11\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.61e+03     |\n",
      "|    mean_reward          | -7.39e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 330000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069864755 |\n",
      "|    clip_fraction        | 0.0324       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.25         |\n",
      "|    explained_variance   | 0.77         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.1e+04      |\n",
      "|    n_updates            | 52470        |\n",
      "|    policy_gradient_loss | -0.00277     |\n",
      "|    std                  | 0.241        |\n",
      "|    value_loss           | 4.69e+05     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 640       |\n",
      "|    ep_rew_mean     | -3.57e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 723       |\n",
      "|    iterations      | 162       |\n",
      "|    time_elapsed    | 458       |\n",
      "|    total_timesteps | 331776    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 640         |\n",
      "|    ep_rew_mean          | -3.57e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 724         |\n",
      "|    iterations           | 163         |\n",
      "|    time_elapsed         | 460         |\n",
      "|    total_timesteps      | 333824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010607265 |\n",
      "|    clip_fraction        | 0.0756      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.25        |\n",
      "|    explained_variance   | 0.76        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.77e+03    |\n",
      "|    n_updates            | 52480       |\n",
      "|    policy_gradient_loss | -0.00346    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 1.71e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=335000, episode_reward=-86596.70 +/- 161470.65\n",
      "Episode length: 1074.40 +/- 1394.61\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.07e+03    |\n",
      "|    mean_reward          | -8.66e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 335000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022996316 |\n",
      "|    clip_fraction        | 0.27        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.24        |\n",
      "|    explained_variance   | 0.898       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 323         |\n",
      "|    n_updates            | 52490       |\n",
      "|    policy_gradient_loss | 0.0078      |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 741         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 685       |\n",
      "|    ep_rew_mean     | -3.54e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 722       |\n",
      "|    iterations      | 164       |\n",
      "|    time_elapsed    | 465       |\n",
      "|    total_timesteps | 335872    |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 684        |\n",
      "|    ep_rew_mean          | -3.54e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 723        |\n",
      "|    iterations           | 165        |\n",
      "|    time_elapsed         | 466        |\n",
      "|    total_timesteps      | 337920     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01099241 |\n",
      "|    clip_fraction        | 0.0924     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.25       |\n",
      "|    explained_variance   | 0.8        |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.68e+03   |\n",
      "|    n_updates            | 52500      |\n",
      "|    policy_gradient_loss | -0.00446   |\n",
      "|    std                  | 0.241      |\n",
      "|    value_loss           | 1.37e+04   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 684         |\n",
      "|    ep_rew_mean          | -3.54e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 725         |\n",
      "|    iterations           | 166         |\n",
      "|    time_elapsed         | 468         |\n",
      "|    total_timesteps      | 339968      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005808899 |\n",
      "|    clip_fraction        | 0.0835      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.25        |\n",
      "|    explained_variance   | 0.868       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.3e+03     |\n",
      "|    n_updates            | 52510       |\n",
      "|    policy_gradient_loss | -0.00196    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 3.42e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=340000, episode_reward=-10412.78 +/- 59599.51\n",
      "Episode length: 1580.20 +/- 1822.64\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.58e+03    |\n",
      "|    mean_reward          | -1.04e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 340000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005520586 |\n",
      "|    clip_fraction        | 0.0563      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.24        |\n",
      "|    explained_variance   | 0.783       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.95e+03    |\n",
      "|    n_updates            | 52520       |\n",
      "|    policy_gradient_loss | -0.00337    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 1.27e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 706       |\n",
      "|    ep_rew_mean     | -3.82e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 720       |\n",
      "|    iterations      | 167       |\n",
      "|    time_elapsed    | 474       |\n",
      "|    total_timesteps | 342016    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 723         |\n",
      "|    ep_rew_mean          | -3.78e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 722         |\n",
      "|    iterations           | 168         |\n",
      "|    time_elapsed         | 476         |\n",
      "|    total_timesteps      | 344064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004078266 |\n",
      "|    clip_fraction        | 0.0321      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.24        |\n",
      "|    explained_variance   | 0.481       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.32e+07    |\n",
      "|    n_updates            | 52530       |\n",
      "|    policy_gradient_loss | -0.000406   |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 8.78e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=345000, episode_reward=21400.33 +/- 64219.52\n",
      "Episode length: 3046.60 +/- 2392.43\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.05e+03    |\n",
      "|    mean_reward          | 2.14e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 345000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046246104 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.25        |\n",
      "|    explained_variance   | 0.538       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.34e+04    |\n",
      "|    n_updates            | 52540       |\n",
      "|    policy_gradient_loss | -0.00447    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 5.07e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 729       |\n",
      "|    ep_rew_mean     | -3.77e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 712       |\n",
      "|    iterations      | 169       |\n",
      "|    time_elapsed    | 485       |\n",
      "|    total_timesteps | 346112    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 729         |\n",
      "|    ep_rew_mean          | -3.77e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 714         |\n",
      "|    iterations           | 170         |\n",
      "|    time_elapsed         | 487         |\n",
      "|    total_timesteps      | 348160      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007022646 |\n",
      "|    clip_fraction        | 0.0728      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.24        |\n",
      "|    explained_variance   | 0.54        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.21e+03    |\n",
      "|    n_updates            | 52550       |\n",
      "|    policy_gradient_loss | -0.00197    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 1.31e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=350000, episode_reward=-41489.25 +/- 175909.37\n",
      "Episode length: 4105.20 +/- 1789.60\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.11e+03    |\n",
      "|    mean_reward          | -4.15e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 350000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.050412625 |\n",
      "|    clip_fraction        | 0.348       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.25        |\n",
      "|    explained_variance   | 0.895       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 159         |\n",
      "|    n_updates            | 52560       |\n",
      "|    policy_gradient_loss | 0.0177      |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 415         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 729       |\n",
      "|    ep_rew_mean     | -3.77e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 701       |\n",
      "|    iterations      | 171       |\n",
      "|    time_elapsed    | 499       |\n",
      "|    total_timesteps | 350208    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 774         |\n",
      "|    ep_rew_mean          | -3.38e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 702         |\n",
      "|    iterations           | 172         |\n",
      "|    time_elapsed         | 501         |\n",
      "|    total_timesteps      | 352256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009442058 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.25        |\n",
      "|    explained_variance   | 0.746       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 130         |\n",
      "|    n_updates            | 52570       |\n",
      "|    policy_gradient_loss | 0.00298     |\n",
      "|    std                  | 0.242       |\n",
      "|    value_loss           | 451         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 774         |\n",
      "|    ep_rew_mean          | -3.38e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 704         |\n",
      "|    iterations           | 173         |\n",
      "|    time_elapsed         | 503         |\n",
      "|    total_timesteps      | 354304      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008836072 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.27        |\n",
      "|    explained_variance   | 0.893       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 272         |\n",
      "|    n_updates            | 52580       |\n",
      "|    policy_gradient_loss | 0.00144     |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 2.28e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=355000, episode_reward=-158374.23 +/- 172875.00\n",
      "Episode length: 1948.20 +/- 2292.81\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.95e+03   |\n",
      "|    mean_reward          | -1.58e+05  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 355000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06329886 |\n",
      "|    clip_fraction        | 0.335      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.27       |\n",
      "|    explained_variance   | 0.911      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 37.5       |\n",
      "|    n_updates            | 52590      |\n",
      "|    policy_gradient_loss | 0.00899    |\n",
      "|    std                  | 0.243      |\n",
      "|    value_loss           | 147        |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 823       |\n",
      "|    ep_rew_mean     | -3.32e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 699       |\n",
      "|    iterations      | 174       |\n",
      "|    time_elapsed    | 509       |\n",
      "|    total_timesteps | 356352    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 823         |\n",
      "|    ep_rew_mean          | -3.32e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 700         |\n",
      "|    iterations           | 175         |\n",
      "|    time_elapsed         | 511         |\n",
      "|    total_timesteps      | 358400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004122153 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.25        |\n",
      "|    explained_variance   | 0.676       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 270         |\n",
      "|    n_updates            | 52600       |\n",
      "|    policy_gradient_loss | 0.00273     |\n",
      "|    std                  | 0.244       |\n",
      "|    value_loss           | 3.63e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=360000, episode_reward=-149573.18 +/- 232339.39\n",
      "Episode length: 2859.60 +/- 2202.16\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2.86e+03   |\n",
      "|    mean_reward          | -1.5e+05   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 360000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03757227 |\n",
      "|    clip_fraction        | 0.215      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.27       |\n",
      "|    explained_variance   | -0.05      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 57.2       |\n",
      "|    n_updates            | 52610      |\n",
      "|    policy_gradient_loss | 0.00341    |\n",
      "|    std                  | 0.241      |\n",
      "|    value_loss           | 286        |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 823       |\n",
      "|    ep_rew_mean     | -3.32e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 692       |\n",
      "|    iterations      | 176       |\n",
      "|    time_elapsed    | 520       |\n",
      "|    total_timesteps | 360448    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 814         |\n",
      "|    ep_rew_mean          | -3.24e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 694         |\n",
      "|    iterations           | 177         |\n",
      "|    time_elapsed         | 521         |\n",
      "|    total_timesteps      | 362496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014979018 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.3         |\n",
      "|    explained_variance   | 0.431       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 36.6        |\n",
      "|    n_updates            | 52620       |\n",
      "|    policy_gradient_loss | 0.002       |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 140         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 814          |\n",
      "|    ep_rew_mean          | -3.24e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 695          |\n",
      "|    iterations           | 178          |\n",
      "|    time_elapsed         | 523          |\n",
      "|    total_timesteps      | 364544       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037895227 |\n",
      "|    clip_fraction        | 0.126        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.31         |\n",
      "|    explained_variance   | 0.649        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.84e+05     |\n",
      "|    n_updates            | 52630        |\n",
      "|    policy_gradient_loss | 0.00244      |\n",
      "|    std                  | 0.241        |\n",
      "|    value_loss           | 3.01e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=365000, episode_reward=-46149.06 +/- 197022.67\n",
      "Episode length: 3647.60 +/- 1913.52\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.65e+03    |\n",
      "|    mean_reward          | -4.61e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 365000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.060773373 |\n",
      "|    clip_fraction        | 0.479       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.32        |\n",
      "|    explained_variance   | 0.69        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.3        |\n",
      "|    n_updates            | 52640       |\n",
      "|    policy_gradient_loss | 0.0649      |\n",
      "|    std                  | 0.239       |\n",
      "|    value_loss           | 78.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 847       |\n",
      "|    ep_rew_mean     | -3.19e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 685       |\n",
      "|    iterations      | 179       |\n",
      "|    time_elapsed    | 534       |\n",
      "|    total_timesteps | 366592    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 847          |\n",
      "|    ep_rew_mean          | -3.19e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 685          |\n",
      "|    iterations           | 180          |\n",
      "|    time_elapsed         | 537          |\n",
      "|    total_timesteps      | 368640       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044608233 |\n",
      "|    clip_fraction        | 0.134        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.34         |\n",
      "|    explained_variance   | 0.174        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 511          |\n",
      "|    n_updates            | 52650        |\n",
      "|    policy_gradient_loss | 0.00317      |\n",
      "|    std                  | 0.239        |\n",
      "|    value_loss           | 1.45e+05     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=370000, episode_reward=-91386.15 +/- 179152.00\n",
      "Episode length: 3214.60 +/- 1825.05\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 3.21e+03   |\n",
      "|    mean_reward          | -9.14e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 370000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01131259 |\n",
      "|    clip_fraction        | 0.139      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.34       |\n",
      "|    explained_variance   | 0.941      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 102        |\n",
      "|    n_updates            | 52660      |\n",
      "|    policy_gradient_loss | -0.0039    |\n",
      "|    std                  | 0.239      |\n",
      "|    value_loss           | 257        |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 847       |\n",
      "|    ep_rew_mean     | -3.19e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 675       |\n",
      "|    iterations      | 181       |\n",
      "|    time_elapsed    | 548       |\n",
      "|    total_timesteps | 370688    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 897          |\n",
      "|    ep_rew_mean          | -3.06e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 677          |\n",
      "|    iterations           | 182          |\n",
      "|    time_elapsed         | 550          |\n",
      "|    total_timesteps      | 372736       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0084025655 |\n",
      "|    clip_fraction        | 0.138        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.35         |\n",
      "|    explained_variance   | 0.748        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 127          |\n",
      "|    n_updates            | 52670        |\n",
      "|    policy_gradient_loss | -0.00454     |\n",
      "|    std                  | 0.239        |\n",
      "|    value_loss           | 535          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 897          |\n",
      "|    ep_rew_mean          | -3.06e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 678          |\n",
      "|    iterations           | 183          |\n",
      "|    time_elapsed         | 552          |\n",
      "|    total_timesteps      | 374784       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041569527 |\n",
      "|    clip_fraction        | 0.0304       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.35         |\n",
      "|    explained_variance   | 0.823        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.54e+04     |\n",
      "|    n_updates            | 52680        |\n",
      "|    policy_gradient_loss | -0.00105     |\n",
      "|    std                  | 0.239        |\n",
      "|    value_loss           | 1.39e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=375000, episode_reward=-160699.92 +/- 167595.02\n",
      "Episode length: 3223.60 +/- 1534.88\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.22e+03    |\n",
      "|    mean_reward          | -1.61e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 375000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016284328 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.36        |\n",
      "|    explained_variance   | 0.889       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 144         |\n",
      "|    n_updates            | 52690       |\n",
      "|    policy_gradient_loss | -0.00555    |\n",
      "|    std                  | 0.238       |\n",
      "|    value_loss           | 254         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 916       |\n",
      "|    ep_rew_mean     | -3.02e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 670       |\n",
      "|    iterations      | 184       |\n",
      "|    time_elapsed    | 561       |\n",
      "|    total_timesteps | 376832    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 916          |\n",
      "|    ep_rew_mean          | -3.02e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 672          |\n",
      "|    iterations           | 185          |\n",
      "|    time_elapsed         | 563          |\n",
      "|    total_timesteps      | 378880       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040662372 |\n",
      "|    clip_fraction        | 0.0809       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.37         |\n",
      "|    explained_variance   | 0.652        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.71e+05     |\n",
      "|    n_updates            | 52700        |\n",
      "|    policy_gradient_loss | -0.000149    |\n",
      "|    std                  | 0.238        |\n",
      "|    value_loss           | 6.39e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=380000, episode_reward=-125440.53 +/- 186473.62\n",
      "Episode length: 2350.40 +/- 2050.25\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.35e+03    |\n",
      "|    mean_reward          | -1.25e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 380000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009203436 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.37        |\n",
      "|    explained_variance   | 0.953       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 74.4        |\n",
      "|    n_updates            | 52710       |\n",
      "|    policy_gradient_loss | -0.00718    |\n",
      "|    std                  | 0.237       |\n",
      "|    value_loss           | 329         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 916       |\n",
      "|    ep_rew_mean     | -3.02e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 666       |\n",
      "|    iterations      | 186       |\n",
      "|    time_elapsed    | 571       |\n",
      "|    total_timesteps | 380928    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 958         |\n",
      "|    ep_rew_mean          | -3.16e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 668         |\n",
      "|    iterations           | 187         |\n",
      "|    time_elapsed         | 573         |\n",
      "|    total_timesteps      | 382976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040040217 |\n",
      "|    clip_fraction        | 0.314       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.41        |\n",
      "|    explained_variance   | 0.93        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 26.4        |\n",
      "|    n_updates            | 52720       |\n",
      "|    policy_gradient_loss | 0.00576     |\n",
      "|    std                  | 0.234       |\n",
      "|    value_loss           | 114         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=385000, episode_reward=-74276.65 +/- 147562.62\n",
      "Episode length: 835.00 +/- 1243.80\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 835         |\n",
      "|    mean_reward          | -7.43e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 385000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047907844 |\n",
      "|    clip_fraction        | 0.509       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.44        |\n",
      "|    explained_variance   | 0.5         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.18e+07    |\n",
      "|    n_updates            | 52730       |\n",
      "|    policy_gradient_loss | 0.0198      |\n",
      "|    std                  | 0.234       |\n",
      "|    value_loss           | 3.91e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 958       |\n",
      "|    ep_rew_mean     | -3.16e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 667       |\n",
      "|    iterations      | 188       |\n",
      "|    time_elapsed    | 577       |\n",
      "|    total_timesteps | 385024    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 994          |\n",
      "|    ep_rew_mean          | -3.67e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 668          |\n",
      "|    iterations           | 189          |\n",
      "|    time_elapsed         | 578          |\n",
      "|    total_timesteps      | 387072       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071885316 |\n",
      "|    clip_fraction        | 0.0614       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.44         |\n",
      "|    explained_variance   | 0.921        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 604          |\n",
      "|    n_updates            | 52740        |\n",
      "|    policy_gradient_loss | -0.00245     |\n",
      "|    std                  | 0.233        |\n",
      "|    value_loss           | 1.95e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.01e+03     |\n",
      "|    ep_rew_mean          | -3.66e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 669          |\n",
      "|    iterations           | 190          |\n",
      "|    time_elapsed         | 580          |\n",
      "|    total_timesteps      | 389120       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029738354 |\n",
      "|    clip_fraction        | 0.0257       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.44         |\n",
      "|    explained_variance   | 0.495        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.31e+07     |\n",
      "|    n_updates            | 52750        |\n",
      "|    policy_gradient_loss | 0.00144      |\n",
      "|    std                  | 0.233        |\n",
      "|    value_loss           | 1.07e+08     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=390000, episode_reward=-62030.42 +/- 159173.79\n",
      "Episode length: 1644.00 +/- 1999.04\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.64e+03    |\n",
      "|    mean_reward          | -6.2e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 390000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008496564 |\n",
      "|    clip_fraction        | 0.0489      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.45        |\n",
      "|    explained_variance   | 0.386       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 276         |\n",
      "|    n_updates            | 52760       |\n",
      "|    policy_gradient_loss | -0.00255    |\n",
      "|    std                  | 0.233       |\n",
      "|    value_loss           | 3.39e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.01e+03  |\n",
      "|    ep_rew_mean     | -3.66e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 666       |\n",
      "|    iterations      | 191       |\n",
      "|    time_elapsed    | 586       |\n",
      "|    total_timesteps | 391168    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.05e+03    |\n",
      "|    ep_rew_mean          | -3.86e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 668         |\n",
      "|    iterations           | 192         |\n",
      "|    time_elapsed         | 588         |\n",
      "|    total_timesteps      | 393216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014659626 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.45        |\n",
      "|    explained_variance   | 0.922       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 49          |\n",
      "|    n_updates            | 52770       |\n",
      "|    policy_gradient_loss | -0.00546    |\n",
      "|    std                  | 0.233       |\n",
      "|    value_loss           | 189         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=395000, episode_reward=-242471.05 +/- 201615.74\n",
      "Episode length: 1742.00 +/- 972.47\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.74e+03    |\n",
      "|    mean_reward          | -2.42e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 395000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003983759 |\n",
      "|    clip_fraction        | 0.0464      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.46        |\n",
      "|    explained_variance   | 0.493       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.44e+07    |\n",
      "|    n_updates            | 52780       |\n",
      "|    policy_gradient_loss | -0.0011     |\n",
      "|    std                  | 0.233       |\n",
      "|    value_loss           | 5.48e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.05e+03  |\n",
      "|    ep_rew_mean     | -3.86e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 664       |\n",
      "|    iterations      | 193       |\n",
      "|    time_elapsed    | 594       |\n",
      "|    total_timesteps | 395264    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.08e+03    |\n",
      "|    ep_rew_mean          | -4.1e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 666         |\n",
      "|    iterations           | 194         |\n",
      "|    time_elapsed         | 596         |\n",
      "|    total_timesteps      | 397312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013063227 |\n",
      "|    clip_fraction        | 0.0701      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.46        |\n",
      "|    explained_variance   | 0.891       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.02e+04    |\n",
      "|    n_updates            | 52790       |\n",
      "|    policy_gradient_loss | -0.00339    |\n",
      "|    std                  | 0.233       |\n",
      "|    value_loss           | 6.69e+05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.1e+03      |\n",
      "|    ep_rew_mean          | -5.29e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 667          |\n",
      "|    iterations           | 195          |\n",
      "|    time_elapsed         | 598          |\n",
      "|    total_timesteps      | 399360       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031095145 |\n",
      "|    clip_fraction        | 0.0288       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.46         |\n",
      "|    explained_variance   | 0.494        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.45e+07     |\n",
      "|    n_updates            | 52800        |\n",
      "|    policy_gradient_loss | -0.000272    |\n",
      "|    std                  | 0.233        |\n",
      "|    value_loss           | 6.34e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=400000, episode_reward=-320853.62 +/- 161702.57\n",
      "Episode length: 1734.80 +/- 863.21\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 1.73e+03      |\n",
      "|    mean_reward          | -3.21e+05     |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 400000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00094028236 |\n",
      "|    clip_fraction        | 0.00313       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | 1.46          |\n",
      "|    explained_variance   | 0.462         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 9.82e+07      |\n",
      "|    n_updates            | 52810         |\n",
      "|    policy_gradient_loss | -5.33e-05     |\n",
      "|    std                  | 0.234         |\n",
      "|    value_loss           | 2.11e+08      |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.1e+03   |\n",
      "|    ep_rew_mean     | -5.29e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 664       |\n",
      "|    iterations      | 196       |\n",
      "|    time_elapsed    | 604       |\n",
      "|    total_timesteps | 401408    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.12e+03     |\n",
      "|    ep_rew_mean          | -5.63e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 665          |\n",
      "|    iterations           | 197          |\n",
      "|    time_elapsed         | 606          |\n",
      "|    total_timesteps      | 403456       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009334283 |\n",
      "|    clip_fraction        | 0.00254      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.46         |\n",
      "|    explained_variance   | 0.563        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.8e+06      |\n",
      "|    n_updates            | 52820        |\n",
      "|    policy_gradient_loss | -0.00215     |\n",
      "|    std                  | 0.233        |\n",
      "|    value_loss           | 1.42e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=405000, episode_reward=-301076.62 +/- 133415.59\n",
      "Episode length: 1722.80 +/- 1272.86\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.72e+03    |\n",
      "|    mean_reward          | -3.01e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 405000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011694258 |\n",
      "|    clip_fraction        | 0.0611      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.45        |\n",
      "|    explained_variance   | 0.523       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.79e+07    |\n",
      "|    n_updates            | 52830       |\n",
      "|    policy_gradient_loss | 0.00226     |\n",
      "|    std                  | 0.234       |\n",
      "|    value_loss           | 4.42e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.14e+03  |\n",
      "|    ep_rew_mean     | -5.89e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 662       |\n",
      "|    iterations      | 198       |\n",
      "|    time_elapsed    | 612       |\n",
      "|    total_timesteps | 405504    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.14e+03     |\n",
      "|    ep_rew_mean          | -5.89e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 663          |\n",
      "|    iterations           | 199          |\n",
      "|    time_elapsed         | 614          |\n",
      "|    total_timesteps      | 407552       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016114071 |\n",
      "|    clip_fraction        | 0.0107       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.45         |\n",
      "|    explained_variance   | 0.499        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.84e+07     |\n",
      "|    n_updates            | 52840        |\n",
      "|    policy_gradient_loss | -0.000981    |\n",
      "|    std                  | 0.234        |\n",
      "|    value_loss           | 9.79e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.17e+03     |\n",
      "|    ep_rew_mean          | -6.24e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 664          |\n",
      "|    iterations           | 200          |\n",
      "|    time_elapsed         | 616          |\n",
      "|    total_timesteps      | 409600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062609906 |\n",
      "|    clip_fraction        | 0.0564       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.46         |\n",
      "|    explained_variance   | 0.897        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 906          |\n",
      "|    n_updates            | 52850        |\n",
      "|    policy_gradient_loss | -0.00401     |\n",
      "|    std                  | 0.234        |\n",
      "|    value_loss           | 4.04e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=410000, episode_reward=-228562.85 +/- 191293.29\n",
      "Episode length: 1422.80 +/- 938.31\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.42e+03    |\n",
      "|    mean_reward          | -2.29e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 410000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003562103 |\n",
      "|    clip_fraction        | 0.0301      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.47        |\n",
      "|    explained_variance   | 0.486       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.09e+07    |\n",
      "|    n_updates            | 52860       |\n",
      "|    policy_gradient_loss | -0.000442   |\n",
      "|    std                  | 0.234       |\n",
      "|    value_loss           | 7.55e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.17e+03  |\n",
      "|    ep_rew_mean     | -6.24e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 662       |\n",
      "|    iterations      | 201       |\n",
      "|    time_elapsed    | 621       |\n",
      "|    total_timesteps | 411648    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.2e+03      |\n",
      "|    ep_rew_mean          | -6.6e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 663          |\n",
      "|    iterations           | 202          |\n",
      "|    time_elapsed         | 623          |\n",
      "|    total_timesteps      | 413696       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021678791 |\n",
      "|    clip_fraction        | 0.00293      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.47         |\n",
      "|    explained_variance   | 0.916        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.47e+05     |\n",
      "|    n_updates            | 52870        |\n",
      "|    policy_gradient_loss | -0.00356     |\n",
      "|    std                  | 0.234        |\n",
      "|    value_loss           | 4.18e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=415000, episode_reward=-269616.30 +/- 133833.20\n",
      "Episode length: 1342.80 +/- 1267.68\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.34e+03     |\n",
      "|    mean_reward          | -2.7e+05     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 415000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010472366 |\n",
      "|    clip_fraction        | 0.00615      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.47         |\n",
      "|    explained_variance   | 0.507        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.61e+07     |\n",
      "|    n_updates            | 52880        |\n",
      "|    policy_gradient_loss | -0.000474    |\n",
      "|    std                  | 0.234        |\n",
      "|    value_loss           | 6.88e+07     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.21e+03 |\n",
      "|    ep_rew_mean     | -7e+04   |\n",
      "| time/              |          |\n",
      "|    fps             | 661      |\n",
      "|    iterations      | 203      |\n",
      "|    time_elapsed    | 628      |\n",
      "|    total_timesteps | 415744   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.24e+03     |\n",
      "|    ep_rew_mean          | -7.31e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 662          |\n",
      "|    iterations           | 204          |\n",
      "|    time_elapsed         | 630          |\n",
      "|    total_timesteps      | 417792       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030648152 |\n",
      "|    clip_fraction        | 0.0207       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.47         |\n",
      "|    explained_variance   | 0.519        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.25e+07     |\n",
      "|    n_updates            | 52890        |\n",
      "|    policy_gradient_loss | -0.00329     |\n",
      "|    std                  | 0.234        |\n",
      "|    value_loss           | 8.94e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.2e+03      |\n",
      "|    ep_rew_mean          | -7.22e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 664          |\n",
      "|    iterations           | 205          |\n",
      "|    time_elapsed         | 632          |\n",
      "|    total_timesteps      | 419840       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017869014 |\n",
      "|    clip_fraction        | 0.0111       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.47         |\n",
      "|    explained_variance   | 0.493        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.76e+07     |\n",
      "|    n_updates            | 52900        |\n",
      "|    policy_gradient_loss | -0.00208     |\n",
      "|    std                  | 0.234        |\n",
      "|    value_loss           | 1.25e+08     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=420000, episode_reward=-135048.50 +/- 176830.45\n",
      "Episode length: 1036.20 +/- 1396.77\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.04e+03     |\n",
      "|    mean_reward          | -1.35e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 420000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068782927 |\n",
      "|    clip_fraction        | 0.0884       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.47         |\n",
      "|    explained_variance   | 0.752        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.53e+04     |\n",
      "|    n_updates            | 52910        |\n",
      "|    policy_gradient_loss | 0.00164      |\n",
      "|    std                  | 0.233        |\n",
      "|    value_loss           | 4.77e+05     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.2e+03   |\n",
      "|    ep_rew_mean     | -7.22e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 662       |\n",
      "|    iterations      | 206       |\n",
      "|    time_elapsed    | 636       |\n",
      "|    total_timesteps | 421888    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.23e+03    |\n",
      "|    ep_rew_mean          | -7.54e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 664         |\n",
      "|    iterations           | 207         |\n",
      "|    time_elapsed         | 638         |\n",
      "|    total_timesteps      | 423936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004844399 |\n",
      "|    clip_fraction        | 0.0128      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.47        |\n",
      "|    explained_variance   | 0.877       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.22e+05    |\n",
      "|    n_updates            | 52920       |\n",
      "|    policy_gradient_loss | -0.00642    |\n",
      "|    std                  | 0.233       |\n",
      "|    value_loss           | 7.1e+05     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=425000, episode_reward=-70877.71 +/- 151236.50\n",
      "Episode length: 1457.80 +/- 1767.20\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.46e+03     |\n",
      "|    mean_reward          | -7.09e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 425000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069429204 |\n",
      "|    clip_fraction        | 0.0461       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.47         |\n",
      "|    explained_variance   | 0.502        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.65e+07     |\n",
      "|    n_updates            | 52930        |\n",
      "|    policy_gradient_loss | -0.0044      |\n",
      "|    std                  | 0.234        |\n",
      "|    value_loss           | 7.03e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.21e+03  |\n",
      "|    ep_rew_mean     | -8.07e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 661       |\n",
      "|    iterations      | 208       |\n",
      "|    time_elapsed    | 643       |\n",
      "|    total_timesteps | 425984    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.22e+03     |\n",
      "|    ep_rew_mean          | -8.48e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 663          |\n",
      "|    iterations           | 209          |\n",
      "|    time_elapsed         | 645          |\n",
      "|    total_timesteps      | 428032       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027783741 |\n",
      "|    clip_fraction        | 0.0187       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.47         |\n",
      "|    explained_variance   | 0.494        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.95e+07     |\n",
      "|    n_updates            | 52940        |\n",
      "|    policy_gradient_loss | 0.00033      |\n",
      "|    std                  | 0.234        |\n",
      "|    value_loss           | 9.79e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=430000, episode_reward=-146055.40 +/- 165139.46\n",
      "Episode length: 1160.20 +/- 1141.25\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.16e+03    |\n",
      "|    mean_reward          | -1.46e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 430000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004215734 |\n",
      "|    clip_fraction        | 0.028       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.47        |\n",
      "|    explained_variance   | 0.492       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.22e+07    |\n",
      "|    n_updates            | 52950       |\n",
      "|    policy_gradient_loss | -0.00549    |\n",
      "|    std                  | 0.234       |\n",
      "|    value_loss           | 1.52e+08    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.22e+03  |\n",
      "|    ep_rew_mean     | -8.48e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 661       |\n",
      "|    iterations      | 210       |\n",
      "|    time_elapsed    | 650       |\n",
      "|    total_timesteps | 430080    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.25e+03     |\n",
      "|    ep_rew_mean          | -8.87e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 662          |\n",
      "|    iterations           | 211          |\n",
      "|    time_elapsed         | 652          |\n",
      "|    total_timesteps      | 432128       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061446265 |\n",
      "|    clip_fraction        | 0.0453       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.47         |\n",
      "|    explained_variance   | 0.896        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.41e+03     |\n",
      "|    n_updates            | 52960        |\n",
      "|    policy_gradient_loss | -0.00405     |\n",
      "|    std                  | 0.233        |\n",
      "|    value_loss           | 1.23e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.27e+03    |\n",
      "|    ep_rew_mean          | -9.11e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 663         |\n",
      "|    iterations           | 212         |\n",
      "|    time_elapsed         | 653         |\n",
      "|    total_timesteps      | 434176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004733326 |\n",
      "|    clip_fraction        | 0.0267      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.47        |\n",
      "|    explained_variance   | 0.507       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.59e+07    |\n",
      "|    n_updates            | 52970       |\n",
      "|    policy_gradient_loss | -0.00329    |\n",
      "|    std                  | 0.233       |\n",
      "|    value_loss           | 8.27e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=435000, episode_reward=21209.72 +/- 91373.64\n",
      "Episode length: 3469.80 +/- 2014.09\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3.47e+03     |\n",
      "|    mean_reward          | 2.12e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 435000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036413847 |\n",
      "|    clip_fraction        | 0.0163       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.47         |\n",
      "|    explained_variance   | 0.509        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.21e+07     |\n",
      "|    n_updates            | 52980        |\n",
      "|    policy_gradient_loss | -0.00419     |\n",
      "|    std                  | 0.233        |\n",
      "|    value_loss           | 6.28e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.27e+03  |\n",
      "|    ep_rew_mean     | -9.11e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 655       |\n",
      "|    iterations      | 213       |\n",
      "|    time_elapsed    | 665       |\n",
      "|    total_timesteps | 436224    |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.27e+03   |\n",
      "|    ep_rew_mean          | -9.11e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 656        |\n",
      "|    iterations           | 214        |\n",
      "|    time_elapsed         | 667        |\n",
      "|    total_timesteps      | 438272     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01612724 |\n",
      "|    clip_fraction        | 0.169      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.47       |\n",
      "|    explained_variance   | 0.862      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 159        |\n",
      "|    n_updates            | 52990      |\n",
      "|    policy_gradient_loss | 0.000893   |\n",
      "|    std                  | 0.234      |\n",
      "|    value_loss           | 896        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=440000, episode_reward=-290486.54 +/- 176064.70\n",
      "Episode length: 2388.60 +/- 1314.13\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.39e+03    |\n",
      "|    mean_reward          | -2.9e+05    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 440000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005734534 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.47        |\n",
      "|    explained_variance   | 0.491       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.12e+07    |\n",
      "|    n_updates            | 53000       |\n",
      "|    policy_gradient_loss | -0.00114    |\n",
      "|    std                  | 0.234       |\n",
      "|    value_loss           | 5.38e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.31e+03  |\n",
      "|    ep_rew_mean     | -9.53e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 652       |\n",
      "|    iterations      | 215       |\n",
      "|    time_elapsed    | 675       |\n",
      "|    total_timesteps | 440320    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.31e+03     |\n",
      "|    ep_rew_mean          | -9.53e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 653          |\n",
      "|    iterations           | 216          |\n",
      "|    time_elapsed         | 676          |\n",
      "|    total_timesteps      | 442368       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012636468 |\n",
      "|    clip_fraction        | 0.00835      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.47         |\n",
      "|    explained_variance   | 0.549        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.25e+04     |\n",
      "|    n_updates            | 53010        |\n",
      "|    policy_gradient_loss | -0.00262     |\n",
      "|    std                  | 0.234        |\n",
      "|    value_loss           | 2.93e+07     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.34e+03    |\n",
      "|    ep_rew_mean          | -9.91e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 654         |\n",
      "|    iterations           | 217         |\n",
      "|    time_elapsed         | 678         |\n",
      "|    total_timesteps      | 444416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014054898 |\n",
      "|    clip_fraction        | 0.0989      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.47        |\n",
      "|    explained_variance   | 0.929       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.28e+03    |\n",
      "|    n_updates            | 53020       |\n",
      "|    policy_gradient_loss | -0.00459    |\n",
      "|    std                  | 0.234       |\n",
      "|    value_loss           | 4.11e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=445000, episode_reward=-299027.78 +/- 177569.94\n",
      "Episode length: 3285.80 +/- 1823.33\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3.29e+03     |\n",
      "|    mean_reward          | -2.99e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 445000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009115766 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.48         |\n",
      "|    explained_variance   | 0.51         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.45e+07     |\n",
      "|    n_updates            | 53030        |\n",
      "|    policy_gradient_loss | -0.000829    |\n",
      "|    std                  | 0.234        |\n",
      "|    value_loss           | 9.3e+07      |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.34e+03  |\n",
      "|    ep_rew_mean     | -9.91e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 648       |\n",
      "|    iterations      | 218       |\n",
      "|    time_elapsed    | 688       |\n",
      "|    total_timesteps | 446464    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.39e+03     |\n",
      "|    ep_rew_mean          | -9.84e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 649          |\n",
      "|    iterations           | 219          |\n",
      "|    time_elapsed         | 690          |\n",
      "|    total_timesteps      | 448512       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071191937 |\n",
      "|    clip_fraction        | 0.0772       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.48         |\n",
      "|    explained_variance   | 0.895        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 976          |\n",
      "|    n_updates            | 53040        |\n",
      "|    policy_gradient_loss | -0.00673     |\n",
      "|    std                  | 0.233        |\n",
      "|    value_loss           | 7.41e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=450000, episode_reward=-42832.49 +/- 81279.03\n",
      "Episode length: 1171.20 +/- 1344.79\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.17e+03     |\n",
      "|    mean_reward          | -4.28e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 450000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020738598 |\n",
      "|    clip_fraction        | 0.000977     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.49         |\n",
      "|    explained_variance   | 0.859        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.65e+05     |\n",
      "|    n_updates            | 53050        |\n",
      "|    policy_gradient_loss | -0.00326     |\n",
      "|    std                  | 0.233        |\n",
      "|    value_loss           | 4.62e+05     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.4e+03  |\n",
      "|    ep_rew_mean     | -1e+05   |\n",
      "| time/              |          |\n",
      "|    fps             | 648      |\n",
      "|    iterations      | 220      |\n",
      "|    time_elapsed    | 695      |\n",
      "|    total_timesteps | 450560   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.4e+03     |\n",
      "|    ep_rew_mean          | -1e+05      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 649         |\n",
      "|    iterations           | 221         |\n",
      "|    time_elapsed         | 697         |\n",
      "|    total_timesteps      | 452608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009159516 |\n",
      "|    clip_fraction        | 0.0404      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.49        |\n",
      "|    explained_variance   | 0.526       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.41e+07    |\n",
      "|    n_updates            | 53060       |\n",
      "|    policy_gradient_loss | 0.00105     |\n",
      "|    std                  | 0.233       |\n",
      "|    value_loss           | 3.42e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.4e+03     |\n",
      "|    ep_rew_mean          | -1e+05      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 650         |\n",
      "|    iterations           | 222         |\n",
      "|    time_elapsed         | 698         |\n",
      "|    total_timesteps      | 454656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016341124 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.51        |\n",
      "|    explained_variance   | 0.87        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 90.3        |\n",
      "|    n_updates            | 53070       |\n",
      "|    policy_gradient_loss | 0.00634     |\n",
      "|    std                  | 0.232       |\n",
      "|    value_loss           | 362         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=455000, episode_reward=-112269.32 +/- 144799.71\n",
      "Episode length: 889.00 +/- 974.36\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 889         |\n",
      "|    mean_reward          | -1.12e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 455000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007934272 |\n",
      "|    clip_fraction        | 0.0656      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.53        |\n",
      "|    explained_variance   | 0.883       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 322         |\n",
      "|    n_updates            | 53080       |\n",
      "|    policy_gradient_loss | -0.00517    |\n",
      "|    std                  | 0.231       |\n",
      "|    value_loss           | 2.18e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.44e+03  |\n",
      "|    ep_rew_mean     | -9.88e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 649       |\n",
      "|    iterations      | 223       |\n",
      "|    time_elapsed    | 702       |\n",
      "|    total_timesteps | 456704    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.47e+03     |\n",
      "|    ep_rew_mean          | -1e+05       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 650          |\n",
      "|    iterations           | 224          |\n",
      "|    time_elapsed         | 704          |\n",
      "|    total_timesteps      | 458752       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020484084 |\n",
      "|    clip_fraction        | 0.00708      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.54         |\n",
      "|    explained_variance   | 0.819        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.09e+04     |\n",
      "|    n_updates            | 53090        |\n",
      "|    policy_gradient_loss | -0.00337     |\n",
      "|    std                  | 0.231        |\n",
      "|    value_loss           | 3.23e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=460000, episode_reward=35584.81 +/- 77803.18\n",
      "Episode length: 4311.20 +/- 1377.60\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4.31e+03     |\n",
      "|    mean_reward          | 3.56e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 460000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015523684 |\n",
      "|    clip_fraction        | 0.00752      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.54         |\n",
      "|    explained_variance   | 0.455        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6e+06        |\n",
      "|    n_updates            | 53100        |\n",
      "|    policy_gradient_loss | -0.00396     |\n",
      "|    std                  | 0.231        |\n",
      "|    value_loss           | 3.99e+07     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.47e+03 |\n",
      "|    ep_rew_mean     | -1e+05   |\n",
      "| time/              |          |\n",
      "|    fps             | 642      |\n",
      "|    iterations      | 225      |\n",
      "|    time_elapsed    | 716      |\n",
      "|    total_timesteps | 460800   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.49e+03     |\n",
      "|    ep_rew_mean          | -1.02e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 643          |\n",
      "|    iterations           | 226          |\n",
      "|    time_elapsed         | 718          |\n",
      "|    total_timesteps      | 462848       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032074763 |\n",
      "|    clip_fraction        | 0.0135       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.54         |\n",
      "|    explained_variance   | 0.953        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.43e+04     |\n",
      "|    n_updates            | 53110        |\n",
      "|    policy_gradient_loss | -0.00231     |\n",
      "|    std                  | 0.231        |\n",
      "|    value_loss           | 1.14e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.49e+03     |\n",
      "|    ep_rew_mean          | -1.02e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 645          |\n",
      "|    iterations           | 227          |\n",
      "|    time_elapsed         | 720          |\n",
      "|    total_timesteps      | 464896       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007944091 |\n",
      "|    clip_fraction        | 0.00186      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.54         |\n",
      "|    explained_variance   | 0.468        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.09e+07     |\n",
      "|    n_updates            | 53120        |\n",
      "|    policy_gradient_loss | -0.00151     |\n",
      "|    std                  | 0.231        |\n",
      "|    value_loss           | 5.89e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=465000, episode_reward=14909.60 +/- 35446.84\n",
      "Episode length: 1129.60 +/- 1939.71\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.13e+03    |\n",
      "|    mean_reward          | 1.49e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 465000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008327263 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.53        |\n",
      "|    explained_variance   | 0.882       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 221         |\n",
      "|    n_updates            | 53130       |\n",
      "|    policy_gradient_loss | -0.00275    |\n",
      "|    std                  | 0.231       |\n",
      "|    value_loss           | 1.11e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.49e+03  |\n",
      "|    ep_rew_mean     | -1.02e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 643       |\n",
      "|    iterations      | 228       |\n",
      "|    time_elapsed    | 725       |\n",
      "|    total_timesteps | 466944    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.53e+03    |\n",
      "|    ep_rew_mean          | -1.01e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 645         |\n",
      "|    iterations           | 229         |\n",
      "|    time_elapsed         | 727         |\n",
      "|    total_timesteps      | 468992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006927468 |\n",
      "|    clip_fraction        | 0.0781      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.53        |\n",
      "|    explained_variance   | 0.802       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 303         |\n",
      "|    n_updates            | 53140       |\n",
      "|    policy_gradient_loss | -0.00464    |\n",
      "|    std                  | 0.231       |\n",
      "|    value_loss           | 2.32e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=470000, episode_reward=26191.32 +/- 37441.25\n",
      "Episode length: 2155.40 +/- 2332.78\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.16e+03     |\n",
      "|    mean_reward          | 2.62e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 470000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048539764 |\n",
      "|    clip_fraction        | 0.0187       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.54         |\n",
      "|    explained_variance   | 0.708        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.02e+04     |\n",
      "|    n_updates            | 53150        |\n",
      "|    policy_gradient_loss | -0.00341     |\n",
      "|    std                  | 0.231        |\n",
      "|    value_loss           | 6.69e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.53e+03  |\n",
      "|    ep_rew_mean     | -1.01e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 640       |\n",
      "|    iterations      | 230       |\n",
      "|    time_elapsed    | 735       |\n",
      "|    total_timesteps | 471040    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.58e+03  |\n",
      "|    ep_rew_mean          | -1.01e+05 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 640       |\n",
      "|    iterations           | 231       |\n",
      "|    time_elapsed         | 738       |\n",
      "|    total_timesteps      | 473088    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0094601 |\n",
      "|    clip_fraction        | 0.0936    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 1.54      |\n",
      "|    explained_variance   | 0.824     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 803       |\n",
      "|    n_updates            | 53160     |\n",
      "|    policy_gradient_loss | -0.00427  |\n",
      "|    std                  | 0.232     |\n",
      "|    value_loss           | 2.08e+03  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=475000, episode_reward=27548.75 +/- 34880.79\n",
      "Episode length: 3012.00 +/- 2434.83\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3.01e+03     |\n",
      "|    mean_reward          | 2.75e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 475000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005011412 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.53         |\n",
      "|    explained_variance   | 0.57         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3e+05        |\n",
      "|    n_updates            | 53170        |\n",
      "|    policy_gradient_loss | -0.000843    |\n",
      "|    std                  | 0.232        |\n",
      "|    value_loss           | 6.6e+05      |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.58e+03  |\n",
      "|    ep_rew_mean     | -1.01e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 633       |\n",
      "|    iterations      | 232       |\n",
      "|    time_elapsed    | 750       |\n",
      "|    total_timesteps | 475136    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.58e+03     |\n",
      "|    ep_rew_mean          | -1.01e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 634          |\n",
      "|    iterations           | 233          |\n",
      "|    time_elapsed         | 752          |\n",
      "|    total_timesteps      | 477184       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047934754 |\n",
      "|    clip_fraction        | 0.0457       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.53         |\n",
      "|    explained_variance   | 0.849        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.94e+03     |\n",
      "|    n_updates            | 53180        |\n",
      "|    policy_gradient_loss | -0.00037     |\n",
      "|    std                  | 0.232        |\n",
      "|    value_loss           | 1.43e+05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.61e+03    |\n",
      "|    ep_rew_mean          | -1.03e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 635         |\n",
      "|    iterations           | 234         |\n",
      "|    time_elapsed         | 754         |\n",
      "|    total_timesteps      | 479232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009659631 |\n",
      "|    clip_fraction        | 0.0578      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.53        |\n",
      "|    explained_variance   | 0.765       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 460         |\n",
      "|    n_updates            | 53190       |\n",
      "|    policy_gradient_loss | -0.00542    |\n",
      "|    std                  | 0.232       |\n",
      "|    value_loss           | 2.92e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=480000, episode_reward=-30031.23 +/- 54113.35\n",
      "Episode length: 286.80 +/- 383.19\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 287          |\n",
      "|    mean_reward          | -3e+04       |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 480000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037178006 |\n",
      "|    clip_fraction        | 0.0332       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.53         |\n",
      "|    explained_variance   | 0.484        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.66e+07     |\n",
      "|    n_updates            | 53200        |\n",
      "|    policy_gradient_loss | 1.39e-05     |\n",
      "|    std                  | 0.232        |\n",
      "|    value_loss           | 7.93e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.61e+03  |\n",
      "|    ep_rew_mean     | -1.04e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 635       |\n",
      "|    iterations      | 235       |\n",
      "|    time_elapsed    | 756       |\n",
      "|    total_timesteps | 481280    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.61e+03     |\n",
      "|    ep_rew_mean          | -1.04e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 636          |\n",
      "|    iterations           | 236          |\n",
      "|    time_elapsed         | 759          |\n",
      "|    total_timesteps      | 483328       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053977957 |\n",
      "|    clip_fraction        | 0.0469       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.53         |\n",
      "|    explained_variance   | 0.488        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.47e+07     |\n",
      "|    n_updates            | 53210        |\n",
      "|    policy_gradient_loss | -0.00105     |\n",
      "|    std                  | 0.232        |\n",
      "|    value_loss           | 5.36e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=485000, episode_reward=-8392.79 +/- 15011.28\n",
      "Episode length: 1401.00 +/- 1880.42\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.4e+03     |\n",
      "|    mean_reward          | -8.39e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 485000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019878749 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.54        |\n",
      "|    explained_variance   | 0.935       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 286         |\n",
      "|    n_updates            | 53220       |\n",
      "|    policy_gradient_loss | -0.00656    |\n",
      "|    std                  | 0.231       |\n",
      "|    value_loss           | 882         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.65e+03  |\n",
      "|    ep_rew_mean     | -9.99e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 634       |\n",
      "|    iterations      | 237       |\n",
      "|    time_elapsed    | 764       |\n",
      "|    total_timesteps | 485376    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.65e+03    |\n",
      "|    ep_rew_mean          | -9.99e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 635         |\n",
      "|    iterations           | 238         |\n",
      "|    time_elapsed         | 766         |\n",
      "|    total_timesteps      | 487424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006948444 |\n",
      "|    clip_fraction        | 0.0915      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.56        |\n",
      "|    explained_variance   | 0.846       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 621         |\n",
      "|    n_updates            | 53230       |\n",
      "|    policy_gradient_loss | -0.00787    |\n",
      "|    std                  | 0.231       |\n",
      "|    value_loss           | 1.08e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.69e+03     |\n",
      "|    ep_rew_mean          | -1.03e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 636          |\n",
      "|    iterations           | 239          |\n",
      "|    time_elapsed         | 768          |\n",
      "|    total_timesteps      | 489472       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041706385 |\n",
      "|    clip_fraction        | 0.0144       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.56         |\n",
      "|    explained_variance   | 0.829        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.52e+04     |\n",
      "|    n_updates            | 53240        |\n",
      "|    policy_gradient_loss | -0.00251     |\n",
      "|    std                  | 0.231        |\n",
      "|    value_loss           | 6.54e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=490000, episode_reward=-67785.96 +/- 144755.25\n",
      "Episode length: 2078.20 +/- 2385.71\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.08e+03     |\n",
      "|    mean_reward          | -6.78e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 490000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015221762 |\n",
      "|    clip_fraction        | 0.00615      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.56         |\n",
      "|    explained_variance   | 0.338        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.16e+07     |\n",
      "|    n_updates            | 53250        |\n",
      "|    policy_gradient_loss | -0.00281     |\n",
      "|    std                  | 0.231        |\n",
      "|    value_loss           | 7.35e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.69e+03  |\n",
      "|    ep_rew_mean     | -1.03e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 633       |\n",
      "|    iterations      | 240       |\n",
      "|    time_elapsed    | 775       |\n",
      "|    total_timesteps | 491520    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.69e+03    |\n",
      "|    ep_rew_mean          | -1.03e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 634         |\n",
      "|    iterations           | 241         |\n",
      "|    time_elapsed         | 777         |\n",
      "|    total_timesteps      | 493568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004078995 |\n",
      "|    clip_fraction        | 0.00991     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.56        |\n",
      "|    explained_variance   | 0.712       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.34e+04    |\n",
      "|    n_updates            | 53260       |\n",
      "|    policy_gradient_loss | -0.00416    |\n",
      "|    std                  | 0.231       |\n",
      "|    value_loss           | 3.13e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=495000, episode_reward=1621.45 +/- 3424.06\n",
      "Episode length: 1312.80 +/- 1862.37\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.31e+03    |\n",
      "|    mean_reward          | 1.62e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 495000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008937204 |\n",
      "|    clip_fraction        | 0.0821      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.56        |\n",
      "|    explained_variance   | 0.868       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 981         |\n",
      "|    n_updates            | 53270       |\n",
      "|    policy_gradient_loss | -0.00308    |\n",
      "|    std                  | 0.231       |\n",
      "|    value_loss           | 4.19e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.69e+03  |\n",
      "|    ep_rew_mean     | -1.03e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 633       |\n",
      "|    iterations      | 242       |\n",
      "|    time_elapsed    | 782       |\n",
      "|    total_timesteps | 495616    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.68e+03    |\n",
      "|    ep_rew_mean          | -9.88e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 634         |\n",
      "|    iterations           | 243         |\n",
      "|    time_elapsed         | 784         |\n",
      "|    total_timesteps      | 497664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010967189 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.57        |\n",
      "|    explained_variance   | 0.913       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 232         |\n",
      "|    n_updates            | 53280       |\n",
      "|    policy_gradient_loss | -0.00667    |\n",
      "|    std                  | 0.231       |\n",
      "|    value_loss           | 1.09e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.67e+03     |\n",
      "|    ep_rew_mean          | -9.88e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 635          |\n",
      "|    iterations           | 244          |\n",
      "|    time_elapsed         | 786          |\n",
      "|    total_timesteps      | 499712       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046791187 |\n",
      "|    clip_fraction        | 0.0299       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.58         |\n",
      "|    explained_variance   | 0.748        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.4e+03      |\n",
      "|    n_updates            | 53290        |\n",
      "|    policy_gradient_loss | -0.00341     |\n",
      "|    std                  | 0.231        |\n",
      "|    value_loss           | 5.23e+04     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=500000, episode_reward=-32703.56 +/- 131749.85\n",
      "Episode length: 3051.60 +/- 2386.38\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.05e+03    |\n",
      "|    mean_reward          | -3.27e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 500000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016790252 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.57        |\n",
      "|    explained_variance   | 0.855       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 303         |\n",
      "|    n_updates            | 53300       |\n",
      "|    policy_gradient_loss | -0.00474    |\n",
      "|    std                  | 0.231       |\n",
      "|    value_loss           | 1.41e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.67e+03  |\n",
      "|    ep_rew_mean     | -9.88e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 630       |\n",
      "|    iterations      | 245       |\n",
      "|    time_elapsed    | 795       |\n",
      "|    total_timesteps | 501760    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.63e+03    |\n",
      "|    ep_rew_mean          | -9.73e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 631         |\n",
      "|    iterations           | 246         |\n",
      "|    time_elapsed         | 797         |\n",
      "|    total_timesteps      | 503808      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018095398 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.59        |\n",
      "|    explained_variance   | 0.913       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 122         |\n",
      "|    n_updates            | 53310       |\n",
      "|    policy_gradient_loss | -0.00772    |\n",
      "|    std                  | 0.229       |\n",
      "|    value_loss           | 357         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=505000, episode_reward=-38023.67 +/- 70936.54\n",
      "Episode length: 1794.20 +/- 2151.94\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 1.79e+03  |\n",
      "|    mean_reward          | -3.8e+04  |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 505000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0101393 |\n",
      "|    clip_fraction        | 0.0469    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 1.6       |\n",
      "|    explained_variance   | 0.498     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.81e+07  |\n",
      "|    n_updates            | 53320     |\n",
      "|    policy_gradient_loss | -0.00101  |\n",
      "|    std                  | 0.229     |\n",
      "|    value_loss           | 3.76e+07  |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.55e+03 |\n",
      "|    ep_rew_mean     | -1e+05   |\n",
      "| time/              |          |\n",
      "|    fps             | 629      |\n",
      "|    iterations      | 247      |\n",
      "|    time_elapsed    | 803      |\n",
      "|    total_timesteps | 505856   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.5e+03      |\n",
      "|    ep_rew_mean          | -1.01e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 630          |\n",
      "|    iterations           | 248          |\n",
      "|    time_elapsed         | 805          |\n",
      "|    total_timesteps      | 507904       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006137506 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.6          |\n",
      "|    explained_variance   | 0.435        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.93e+06     |\n",
      "|    n_updates            | 53330        |\n",
      "|    policy_gradient_loss | -9.79e-05    |\n",
      "|    std                  | 0.229        |\n",
      "|    value_loss           | 2.81e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.38e+03     |\n",
      "|    ep_rew_mean          | -1.06e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 631          |\n",
      "|    iterations           | 249          |\n",
      "|    time_elapsed         | 807          |\n",
      "|    total_timesteps      | 509952       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046169967 |\n",
      "|    clip_fraction        | 0.0123       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.6          |\n",
      "|    explained_variance   | 0.858        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.55e+05     |\n",
      "|    n_updates            | 53340        |\n",
      "|    policy_gradient_loss | -0.00292     |\n",
      "|    std                  | 0.229        |\n",
      "|    value_loss           | 4.89e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=510000, episode_reward=17075.33 +/- 28547.19\n",
      "Episode length: 2041.40 +/- 2415.88\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.04e+03     |\n",
      "|    mean_reward          | 1.71e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 510000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035373478 |\n",
      "|    clip_fraction        | 0.0107       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.6          |\n",
      "|    explained_variance   | 0.483        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.38e+07     |\n",
      "|    n_updates            | 53350        |\n",
      "|    policy_gradient_loss | -0.00407     |\n",
      "|    std                  | 0.229        |\n",
      "|    value_loss           | 6.22e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.35e+03  |\n",
      "|    ep_rew_mean     | -1.07e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 628       |\n",
      "|    iterations      | 250       |\n",
      "|    time_elapsed    | 814       |\n",
      "|    total_timesteps | 512000    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.25e+03    |\n",
      "|    ep_rew_mean          | -1.03e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 629         |\n",
      "|    iterations           | 251         |\n",
      "|    time_elapsed         | 816         |\n",
      "|    total_timesteps      | 514048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011307418 |\n",
      "|    clip_fraction        | 0.0942      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.6         |\n",
      "|    explained_variance   | 0.135       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.01e+03    |\n",
      "|    n_updates            | 53360       |\n",
      "|    policy_gradient_loss | -0.00425    |\n",
      "|    std                  | 0.229       |\n",
      "|    value_loss           | 6.46e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=515000, episode_reward=-145403.82 +/- 123219.74\n",
      "Episode length: 1308.80 +/- 1497.36\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.31e+03     |\n",
      "|    mean_reward          | -1.45e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 515000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029506811 |\n",
      "|    clip_fraction        | 0.0221       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.6          |\n",
      "|    explained_variance   | 0.479        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.24e+06     |\n",
      "|    n_updates            | 53370        |\n",
      "|    policy_gradient_loss | -0.00289     |\n",
      "|    std                  | 0.229        |\n",
      "|    value_loss           | 4.27e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.25e+03  |\n",
      "|    ep_rew_mean     | -1.03e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 628       |\n",
      "|    iterations      | 252       |\n",
      "|    time_elapsed    | 821       |\n",
      "|    total_timesteps | 516096    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.21e+03    |\n",
      "|    ep_rew_mean          | -1.01e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 629         |\n",
      "|    iterations           | 253         |\n",
      "|    time_elapsed         | 823         |\n",
      "|    total_timesteps      | 518144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009138817 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.6         |\n",
      "|    explained_variance   | 0.783       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.47e+03    |\n",
      "|    n_updates            | 53380       |\n",
      "|    policy_gradient_loss | -0.004      |\n",
      "|    std                  | 0.23        |\n",
      "|    value_loss           | 6.07e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=520000, episode_reward=-54968.69 +/- 62033.61\n",
      "Episode length: 93.60 +/- 65.26\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 93.6         |\n",
      "|    mean_reward          | -5.5e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 520000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027212894 |\n",
      "|    clip_fraction        | 0.0207       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.59         |\n",
      "|    explained_variance   | 0.477        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.52e+07     |\n",
      "|    n_updates            | 53390        |\n",
      "|    policy_gradient_loss | -0.000289    |\n",
      "|    std                  | 0.23         |\n",
      "|    value_loss           | 6.22e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.21e+03  |\n",
      "|    ep_rew_mean     | -1.01e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 630       |\n",
      "|    iterations      | 254       |\n",
      "|    time_elapsed    | 825       |\n",
      "|    total_timesteps | 520192    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.24e+03     |\n",
      "|    ep_rew_mean          | -9.43e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 631          |\n",
      "|    iterations           | 255          |\n",
      "|    time_elapsed         | 827          |\n",
      "|    total_timesteps      | 522240       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0089551015 |\n",
      "|    clip_fraction        | 0.127        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.6          |\n",
      "|    explained_variance   | 0.917        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 377          |\n",
      "|    n_updates            | 53400        |\n",
      "|    policy_gradient_loss | -0.00224     |\n",
      "|    std                  | 0.229        |\n",
      "|    value_loss           | 1.39e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.25e+03    |\n",
      "|    ep_rew_mean          | -9.35e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 632         |\n",
      "|    iterations           | 256         |\n",
      "|    time_elapsed         | 828         |\n",
      "|    total_timesteps      | 524288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010997051 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.62        |\n",
      "|    explained_variance   | 0.63        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.96e+06    |\n",
      "|    n_updates            | 53410       |\n",
      "|    policy_gradient_loss | 0.00181     |\n",
      "|    std                  | 0.229       |\n",
      "|    value_loss           | 4.08e+06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=525000, episode_reward=8413.67 +/- 24430.37\n",
      "Episode length: 1142.00 +/- 1936.42\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.14e+03     |\n",
      "|    mean_reward          | 8.41e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 525000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064593814 |\n",
      "|    clip_fraction        | 0.0213       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.62         |\n",
      "|    explained_variance   | 0.845        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.1e+04      |\n",
      "|    n_updates            | 53420        |\n",
      "|    policy_gradient_loss | -0.00244     |\n",
      "|    std                  | 0.229        |\n",
      "|    value_loss           | 2.38e+05     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.27e+03  |\n",
      "|    ep_rew_mean     | -8.94e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 631       |\n",
      "|    iterations      | 257       |\n",
      "|    time_elapsed    | 833       |\n",
      "|    total_timesteps | 526336    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.22e+03    |\n",
      "|    ep_rew_mean          | -8.29e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 632         |\n",
      "|    iterations           | 258         |\n",
      "|    time_elapsed         | 835         |\n",
      "|    total_timesteps      | 528384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004857988 |\n",
      "|    clip_fraction        | 0.0159      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.62        |\n",
      "|    explained_variance   | 0.728       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.66e+06    |\n",
      "|    n_updates            | 53430       |\n",
      "|    policy_gradient_loss | -0.00549    |\n",
      "|    std                  | 0.229       |\n",
      "|    value_loss           | 2.82e+06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=530000, episode_reward=-2944.46 +/- 11597.37\n",
      "Episode length: 2466.20 +/- 2192.88\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.47e+03     |\n",
      "|    mean_reward          | -2.94e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 530000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067023686 |\n",
      "|    clip_fraction        | 0.0483       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.61         |\n",
      "|    explained_variance   | 0.482        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.67e+04     |\n",
      "|    n_updates            | 53440        |\n",
      "|    policy_gradient_loss | -0.00643     |\n",
      "|    std                  | 0.229        |\n",
      "|    value_loss           | 1.32e+05     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.18e+03  |\n",
      "|    ep_rew_mean     | -7.77e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 628       |\n",
      "|    iterations      | 259       |\n",
      "|    time_elapsed    | 843       |\n",
      "|    total_timesteps | 530432    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.18e+03     |\n",
      "|    ep_rew_mean          | -7.77e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 628          |\n",
      "|    iterations           | 260          |\n",
      "|    time_elapsed         | 846          |\n",
      "|    total_timesteps      | 532480       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021074591 |\n",
      "|    clip_fraction        | 0.00981      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.61         |\n",
      "|    explained_variance   | 0.419        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.1e+06      |\n",
      "|    n_updates            | 53450        |\n",
      "|    policy_gradient_loss | -0.00386     |\n",
      "|    std                  | 0.229        |\n",
      "|    value_loss           | 6.17e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.18e+03    |\n",
      "|    ep_rew_mean          | -7.77e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 629         |\n",
      "|    iterations           | 261         |\n",
      "|    time_elapsed         | 849         |\n",
      "|    total_timesteps      | 534528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013963266 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.62        |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 459         |\n",
      "|    n_updates            | 53460       |\n",
      "|    policy_gradient_loss | -0.00318    |\n",
      "|    std                  | 0.228       |\n",
      "|    value_loss           | 1.8e+03     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=535000, episode_reward=-118839.09 +/- 98529.73\n",
      "Episode length: 250.40 +/- 243.42\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 250         |\n",
      "|    mean_reward          | -1.19e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 535000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010349455 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.64        |\n",
      "|    explained_variance   | 0.887       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 269         |\n",
      "|    n_updates            | 53470       |\n",
      "|    policy_gradient_loss | 0.000907    |\n",
      "|    std                  | 0.227       |\n",
      "|    value_loss           | 958         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.23e+03 |\n",
      "|    ep_rew_mean     | -7.7e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 630      |\n",
      "|    iterations      | 262      |\n",
      "|    time_elapsed    | 851      |\n",
      "|    total_timesteps | 536576   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.24e+03    |\n",
      "|    ep_rew_mean          | -7.22e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 631         |\n",
      "|    iterations           | 263         |\n",
      "|    time_elapsed         | 853         |\n",
      "|    total_timesteps      | 538624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014512103 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.64        |\n",
      "|    explained_variance   | 0.553       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 410         |\n",
      "|    n_updates            | 53480       |\n",
      "|    policy_gradient_loss | -0.00753    |\n",
      "|    std                  | 0.227       |\n",
      "|    value_loss           | 1.75e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=540000, episode_reward=-98403.38 +/- 117166.90\n",
      "Episode length: 1279.40 +/- 1860.44\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.28e+03     |\n",
      "|    mean_reward          | -9.84e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 540000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070532956 |\n",
      "|    clip_fraction        | 0.0426       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.64         |\n",
      "|    explained_variance   | 0.858        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.88e+03     |\n",
      "|    n_updates            | 53490        |\n",
      "|    policy_gradient_loss | -0.00227     |\n",
      "|    std                  | 0.227        |\n",
      "|    value_loss           | 1.55e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.22e+03  |\n",
      "|    ep_rew_mean     | -6.88e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 627       |\n",
      "|    iterations      | 264       |\n",
      "|    time_elapsed    | 860       |\n",
      "|    total_timesteps | 540672    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.22e+03     |\n",
      "|    ep_rew_mean          | -6.88e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 628          |\n",
      "|    iterations           | 265          |\n",
      "|    time_elapsed         | 863          |\n",
      "|    total_timesteps      | 542720       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050028847 |\n",
      "|    clip_fraction        | 0.034        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.64         |\n",
      "|    explained_variance   | 0.478        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.14e+04     |\n",
      "|    n_updates            | 53500        |\n",
      "|    policy_gradient_loss | -0.00413     |\n",
      "|    std                  | 0.227        |\n",
      "|    value_loss           | 5.69e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.22e+03    |\n",
      "|    ep_rew_mean          | -6.28e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 629         |\n",
      "|    iterations           | 266         |\n",
      "|    time_elapsed         | 865         |\n",
      "|    total_timesteps      | 544768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015112879 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.63        |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 354         |\n",
      "|    n_updates            | 53510       |\n",
      "|    policy_gradient_loss | -0.00519    |\n",
      "|    std                  | 0.227       |\n",
      "|    value_loss           | 1.4e+03     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=545000, episode_reward=-70953.72 +/- 95933.33\n",
      "Episode length: 483.00 +/- 568.43\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 483         |\n",
      "|    mean_reward          | -7.1e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 545000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004990269 |\n",
      "|    clip_fraction        | 0.0905      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.63        |\n",
      "|    explained_variance   | 0.746       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.76e+06    |\n",
      "|    n_updates            | 53520       |\n",
      "|    policy_gradient_loss | 0.00106     |\n",
      "|    std                  | 0.227       |\n",
      "|    value_loss           | 3.08e+06    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.22e+03  |\n",
      "|    ep_rew_mean     | -5.81e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 629       |\n",
      "|    iterations      | 267       |\n",
      "|    time_elapsed    | 868       |\n",
      "|    total_timesteps | 546816    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.1e+03      |\n",
      "|    ep_rew_mean          | -4.02e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 630          |\n",
      "|    iterations           | 268          |\n",
      "|    time_elapsed         | 869          |\n",
      "|    total_timesteps      | 548864       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010224399 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.63         |\n",
      "|    explained_variance   | 0.61         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.94e+04     |\n",
      "|    n_updates            | 53530        |\n",
      "|    policy_gradient_loss | -0.00274     |\n",
      "|    std                  | 0.227        |\n",
      "|    value_loss           | 4.46e+05     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=550000, episode_reward=-6852.56 +/- 5561.56\n",
      "Episode length: 178.40 +/- 94.31\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 178          |\n",
      "|    mean_reward          | -6.85e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 550000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018665087 |\n",
      "|    clip_fraction        | 0.00645      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.63         |\n",
      "|    explained_variance   | 0.626        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.36e+05     |\n",
      "|    n_updates            | 53540        |\n",
      "|    policy_gradient_loss | -0.00359     |\n",
      "|    std                  | 0.227        |\n",
      "|    value_loss           | 5.95e+06     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.02e+03  |\n",
      "|    ep_rew_mean     | -3.68e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 631       |\n",
      "|    iterations      | 269       |\n",
      "|    time_elapsed    | 872       |\n",
      "|    total_timesteps | 550912    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 973          |\n",
      "|    ep_rew_mean          | -3.75e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 632          |\n",
      "|    iterations           | 270          |\n",
      "|    time_elapsed         | 874          |\n",
      "|    total_timesteps      | 552960       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019401663 |\n",
      "|    clip_fraction        | 0.002        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.63         |\n",
      "|    explained_variance   | 0.644        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.79e+06     |\n",
      "|    n_updates            | 53550        |\n",
      "|    policy_gradient_loss | -0.00273     |\n",
      "|    std                  | 0.227        |\n",
      "|    value_loss           | 2.91e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=555000, episode_reward=-57277.47 +/- 94777.05\n",
      "Episode length: 2485.20 +/- 2157.52\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.49e+03     |\n",
      "|    mean_reward          | -5.73e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 555000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039776843 |\n",
      "|    clip_fraction        | 0.019        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.63         |\n",
      "|    explained_variance   | 0.519        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.26e+07     |\n",
      "|    n_updates            | 53560        |\n",
      "|    policy_gradient_loss | -0.00309     |\n",
      "|    std                  | 0.227        |\n",
      "|    value_loss           | 3.21e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 931       |\n",
      "|    ep_rew_mean     | -3.23e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 629       |\n",
      "|    iterations      | 271       |\n",
      "|    time_elapsed    | 882       |\n",
      "|    total_timesteps | 555008    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 836         |\n",
      "|    ep_rew_mean          | -3.35e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 630         |\n",
      "|    iterations           | 272         |\n",
      "|    time_elapsed         | 884         |\n",
      "|    total_timesteps      | 557056      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005796188 |\n",
      "|    clip_fraction        | 0.0227      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.63        |\n",
      "|    explained_variance   | 0.722       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.44e+04    |\n",
      "|    n_updates            | 53570       |\n",
      "|    policy_gradient_loss | -0.00371    |\n",
      "|    std                  | 0.227       |\n",
      "|    value_loss           | 6.07e+05    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 790           |\n",
      "|    ep_rew_mean          | -3.68e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 631           |\n",
      "|    iterations           | 273           |\n",
      "|    time_elapsed         | 885           |\n",
      "|    total_timesteps      | 559104        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00037664676 |\n",
      "|    clip_fraction        | 9.77e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | 1.63          |\n",
      "|    explained_variance   | 0.609         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.05e+07      |\n",
      "|    n_updates            | 53580         |\n",
      "|    policy_gradient_loss | -0.00132      |\n",
      "|    std                  | 0.227         |\n",
      "|    value_loss           | 1.67e+07      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=560000, episode_reward=-51534.35 +/- 103175.37\n",
      "Episode length: 140.20 +/- 130.20\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 140         |\n",
      "|    mean_reward          | -5.15e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 560000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004046224 |\n",
      "|    clip_fraction        | 0.0211      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.63        |\n",
      "|    explained_variance   | 0.474       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.59e+07    |\n",
      "|    n_updates            | 53590       |\n",
      "|    policy_gradient_loss | -0.000919   |\n",
      "|    std                  | 0.227       |\n",
      "|    value_loss           | 2.01e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 703       |\n",
      "|    ep_rew_mean     | -3.26e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 631       |\n",
      "|    iterations      | 274       |\n",
      "|    time_elapsed    | 888       |\n",
      "|    total_timesteps | 561152    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 661         |\n",
      "|    ep_rew_mean          | -3.47e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 632         |\n",
      "|    iterations           | 275         |\n",
      "|    time_elapsed         | 890         |\n",
      "|    total_timesteps      | 563200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001995525 |\n",
      "|    clip_fraction        | 0.0388      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.63        |\n",
      "|    explained_variance   | 0.457       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.49e+07    |\n",
      "|    n_updates            | 53600       |\n",
      "|    policy_gradient_loss | 0.000784    |\n",
      "|    std                  | 0.227       |\n",
      "|    value_loss           | 9.98e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=565000, episode_reward=-10450.89 +/- 15544.31\n",
      "Episode length: 1128.00 +/- 1936.39\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.13e+03    |\n",
      "|    mean_reward          | -1.05e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 565000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003989574 |\n",
      "|    clip_fraction        | 0.0259      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.63        |\n",
      "|    explained_variance   | 0.506       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.42e+07    |\n",
      "|    n_updates            | 53610       |\n",
      "|    policy_gradient_loss | 0.00032     |\n",
      "|    std                  | 0.227       |\n",
      "|    value_loss           | 1.8e+07     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 658       |\n",
      "|    ep_rew_mean     | -3.47e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 630       |\n",
      "|    iterations      | 276       |\n",
      "|    time_elapsed    | 897       |\n",
      "|    total_timesteps | 565248    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 658         |\n",
      "|    ep_rew_mean          | -3.47e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 631         |\n",
      "|    iterations           | 277         |\n",
      "|    time_elapsed         | 898         |\n",
      "|    total_timesteps      | 567296      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009744631 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.63        |\n",
      "|    explained_variance   | 0.507       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.61e+03    |\n",
      "|    n_updates            | 53620       |\n",
      "|    policy_gradient_loss | -0.000661   |\n",
      "|    std                  | 0.226       |\n",
      "|    value_loss           | 6.57e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 705         |\n",
      "|    ep_rew_mean          | -3.45e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 632         |\n",
      "|    iterations           | 278         |\n",
      "|    time_elapsed         | 900         |\n",
      "|    total_timesteps      | 569344      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010911692 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.64        |\n",
      "|    explained_variance   | 0.911       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 497         |\n",
      "|    n_updates            | 53630       |\n",
      "|    policy_gradient_loss | -0.00169    |\n",
      "|    std                  | 0.227       |\n",
      "|    value_loss           | 2.25e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=570000, episode_reward=-94825.41 +/- 114439.13\n",
      "Episode length: 359.60 +/- 188.73\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 360          |\n",
      "|    mean_reward          | -9.48e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 570000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062180078 |\n",
      "|    clip_fraction        | 0.0596       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.64         |\n",
      "|    explained_variance   | 0.777        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.48e+03     |\n",
      "|    n_updates            | 53640        |\n",
      "|    policy_gradient_loss | -0.00295     |\n",
      "|    std                  | 0.227        |\n",
      "|    value_loss           | 3.11e+05     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 676       |\n",
      "|    ep_rew_mean     | -3.55e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 632       |\n",
      "|    iterations      | 279       |\n",
      "|    time_elapsed    | 903       |\n",
      "|    total_timesteps | 571392    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 668          |\n",
      "|    ep_rew_mean          | -3.38e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 633          |\n",
      "|    iterations           | 280          |\n",
      "|    time_elapsed         | 905          |\n",
      "|    total_timesteps      | 573440       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013357124 |\n",
      "|    clip_fraction        | 0.00645      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.64         |\n",
      "|    explained_variance   | 0.531        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.38e+07     |\n",
      "|    n_updates            | 53650        |\n",
      "|    policy_gradient_loss | -0.00327     |\n",
      "|    std                  | 0.227        |\n",
      "|    value_loss           | 3.88e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=575000, episode_reward=-52949.39 +/- 96606.88\n",
      "Episode length: 411.20 +/- 326.71\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 411         |\n",
      "|    mean_reward          | -5.29e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 575000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008218362 |\n",
      "|    clip_fraction        | 0.0242      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.64        |\n",
      "|    explained_variance   | 0.734       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.69e+04    |\n",
      "|    n_updates            | 53660       |\n",
      "|    policy_gradient_loss | -0.00327    |\n",
      "|    std                  | 0.227       |\n",
      "|    value_loss           | 1.24e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 669       |\n",
      "|    ep_rew_mean     | -3.24e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 633       |\n",
      "|    iterations      | 281       |\n",
      "|    time_elapsed    | 908       |\n",
      "|    total_timesteps | 575488    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 683       |\n",
      "|    ep_rew_mean          | -2.92e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 634       |\n",
      "|    iterations           | 282       |\n",
      "|    time_elapsed         | 909       |\n",
      "|    total_timesteps      | 577536    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.004854  |\n",
      "|    clip_fraction        | 0.0285    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 1.64      |\n",
      "|    explained_variance   | 0.706     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.23e+05  |\n",
      "|    n_updates            | 53670     |\n",
      "|    policy_gradient_loss | -0.00185  |\n",
      "|    std                  | 0.226     |\n",
      "|    value_loss           | 3.32e+05  |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 668          |\n",
      "|    ep_rew_mean          | -3.9e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 635          |\n",
      "|    iterations           | 283          |\n",
      "|    time_elapsed         | 911          |\n",
      "|    total_timesteps      | 579584       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055129435 |\n",
      "|    clip_fraction        | 0.0267       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.64         |\n",
      "|    explained_variance   | 0.648        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.02e+03     |\n",
      "|    n_updates            | 53680        |\n",
      "|    policy_gradient_loss | -0.00464     |\n",
      "|    std                  | 0.226        |\n",
      "|    value_loss           | 1.17e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=580000, episode_reward=-41979.47 +/- 92025.95\n",
      "Episode length: 353.20 +/- 117.04\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 353         |\n",
      "|    mean_reward          | -4.2e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 580000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001467413 |\n",
      "|    clip_fraction        | 0.00117     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.64        |\n",
      "|    explained_variance   | 0.499       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.88e+07    |\n",
      "|    n_updates            | 53690       |\n",
      "|    policy_gradient_loss | -0.000932   |\n",
      "|    std                  | 0.226       |\n",
      "|    value_loss           | 1.55e+08    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 668      |\n",
      "|    ep_rew_mean     | -3.9e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 635      |\n",
      "|    iterations      | 284      |\n",
      "|    time_elapsed    | 914      |\n",
      "|    total_timesteps | 581632   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 711         |\n",
      "|    ep_rew_mean          | -3.9e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 636         |\n",
      "|    iterations           | 285         |\n",
      "|    time_elapsed         | 916         |\n",
      "|    total_timesteps      | 583680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014968387 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.65        |\n",
      "|    explained_variance   | 0.918       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 75.8        |\n",
      "|    n_updates            | 53700       |\n",
      "|    policy_gradient_loss | 0.0153      |\n",
      "|    std                  | 0.225       |\n",
      "|    value_loss           | 205         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=585000, episode_reward=-79621.18 +/- 100076.35\n",
      "Episode length: 254.00 +/- 128.65\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 254        |\n",
      "|    mean_reward          | -7.96e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 585000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02562721 |\n",
      "|    clip_fraction        | 0.558      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.67       |\n",
      "|    explained_variance   | 0.709      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.01e+03   |\n",
      "|    n_updates            | 53710      |\n",
      "|    policy_gradient_loss | 0.0492     |\n",
      "|    std                  | 0.225      |\n",
      "|    value_loss           | 2.6e+04    |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 726       |\n",
      "|    ep_rew_mean     | -3.58e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 637       |\n",
      "|    iterations      | 286       |\n",
      "|    time_elapsed    | 919       |\n",
      "|    total_timesteps | 585728    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 658          |\n",
      "|    ep_rew_mean          | -4.29e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 638          |\n",
      "|    iterations           | 287          |\n",
      "|    time_elapsed         | 920          |\n",
      "|    total_timesteps      | 587776       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010019758 |\n",
      "|    clip_fraction        | 0.00151      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.67         |\n",
      "|    explained_variance   | 0.615        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.7e+04      |\n",
      "|    n_updates            | 53720        |\n",
      "|    policy_gradient_loss | -0.00164     |\n",
      "|    std                  | 0.225        |\n",
      "|    value_loss           | 1.47e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 543          |\n",
      "|    ep_rew_mean          | -4.84e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 639          |\n",
      "|    iterations           | 288          |\n",
      "|    time_elapsed         | 922          |\n",
      "|    total_timesteps      | 589824       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.380075e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.67         |\n",
      "|    explained_variance   | 0.442        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.21e+07     |\n",
      "|    n_updates            | 53730        |\n",
      "|    policy_gradient_loss | -0.000329    |\n",
      "|    std                  | 0.225        |\n",
      "|    value_loss           | 1.96e+08     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=590000, episode_reward=9370.66 +/- 19941.82\n",
      "Episode length: 1195.40 +/- 1909.43\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.2e+03      |\n",
      "|    mean_reward          | 9.37e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 590000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.901598e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.67         |\n",
      "|    explained_variance   | 0.482        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.78e+07     |\n",
      "|    n_updates            | 53740        |\n",
      "|    policy_gradient_loss | -0.000327    |\n",
      "|    std                  | 0.225        |\n",
      "|    value_loss           | 1.37e+08     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 517       |\n",
      "|    ep_rew_mean     | -5.07e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 638       |\n",
      "|    iterations      | 289       |\n",
      "|    time_elapsed    | 927       |\n",
      "|    total_timesteps | 591872    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 517          |\n",
      "|    ep_rew_mean          | -5.07e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 638          |\n",
      "|    iterations           | 290          |\n",
      "|    time_elapsed         | 929          |\n",
      "|    total_timesteps      | 593920       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039134505 |\n",
      "|    clip_fraction        | 0.0151       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.67         |\n",
      "|    explained_variance   | 0.594        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 642          |\n",
      "|    n_updates            | 53750        |\n",
      "|    policy_gradient_loss | -0.00293     |\n",
      "|    std                  | 0.225        |\n",
      "|    value_loss           | 4.06e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=595000, episode_reward=-52456.28 +/- 51324.48\n",
      "Episode length: 697.20 +/- 918.93\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 697         |\n",
      "|    mean_reward          | -5.25e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 595000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010413269 |\n",
      "|    clip_fraction        | 0.0851      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.67        |\n",
      "|    explained_variance   | 0.933       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 612         |\n",
      "|    n_updates            | 53760       |\n",
      "|    policy_gradient_loss | -0.00523    |\n",
      "|    std                  | 0.225       |\n",
      "|    value_loss           | 3.08e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 506       |\n",
      "|    ep_rew_mean     | -5.34e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 637       |\n",
      "|    iterations      | 291       |\n",
      "|    time_elapsed    | 934       |\n",
      "|    total_timesteps | 595968    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 506          |\n",
      "|    ep_rew_mean          | -5.34e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 638          |\n",
      "|    iterations           | 292          |\n",
      "|    time_elapsed         | 937          |\n",
      "|    total_timesteps      | 598016       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031905612 |\n",
      "|    clip_fraction        | 0.0308       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.68         |\n",
      "|    explained_variance   | 0.459        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.23e+07     |\n",
      "|    n_updates            | 53770        |\n",
      "|    policy_gradient_loss | 0.00143      |\n",
      "|    std                  | 0.225        |\n",
      "|    value_loss           | 4.59e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=600000, episode_reward=-197350.35 +/- 98225.19\n",
      "Episode length: 222.20 +/- 103.13\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 222         |\n",
      "|    mean_reward          | -1.97e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 600000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016349196 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.68        |\n",
      "|    explained_variance   | 0.852       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 501         |\n",
      "|    n_updates            | 53780       |\n",
      "|    policy_gradient_loss | -0.00227    |\n",
      "|    std                  | 0.225       |\n",
      "|    value_loss           | 1.28e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 531       |\n",
      "|    ep_rew_mean     | -5.47e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 638       |\n",
      "|    iterations      | 293       |\n",
      "|    time_elapsed    | 939       |\n",
      "|    total_timesteps | 600064    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 521         |\n",
      "|    ep_rew_mean          | -5.76e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 639         |\n",
      "|    iterations           | 294         |\n",
      "|    time_elapsed         | 941         |\n",
      "|    total_timesteps      | 602112      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010522123 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.68        |\n",
      "|    explained_variance   | 0.509       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.34e+07    |\n",
      "|    n_updates            | 53790       |\n",
      "|    policy_gradient_loss | 0.0013      |\n",
      "|    std                  | 0.225       |\n",
      "|    value_loss           | 5.38e+07    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 521           |\n",
      "|    ep_rew_mean          | -5.76e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 640           |\n",
      "|    iterations           | 295           |\n",
      "|    time_elapsed         | 943           |\n",
      "|    total_timesteps      | 604160        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00029234376 |\n",
      "|    clip_fraction        | 9.77e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | 1.68          |\n",
      "|    explained_variance   | 0.423         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.37e+07      |\n",
      "|    n_updates            | 53800         |\n",
      "|    policy_gradient_loss | -0.00129      |\n",
      "|    std                  | 0.225         |\n",
      "|    value_loss           | 3.5e+07       |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=605000, episode_reward=315.74 +/- 8053.52\n",
      "Episode length: 529.60 +/- 790.72\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 530         |\n",
      "|    mean_reward          | 316         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 605000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008450501 |\n",
      "|    clip_fraction        | 0.0536      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.68        |\n",
      "|    explained_variance   | 0.759       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.07e+03    |\n",
      "|    n_updates            | 53810       |\n",
      "|    policy_gradient_loss | -0.000574   |\n",
      "|    std                  | 0.224       |\n",
      "|    value_loss           | 3.69e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 523       |\n",
      "|    ep_rew_mean     | -5.99e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 640       |\n",
      "|    iterations      | 296       |\n",
      "|    time_elapsed    | 946       |\n",
      "|    total_timesteps | 606208    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 532          |\n",
      "|    ep_rew_mean          | -6.15e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 641          |\n",
      "|    iterations           | 297          |\n",
      "|    time_elapsed         | 948          |\n",
      "|    total_timesteps      | 608256       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039157905 |\n",
      "|    clip_fraction        | 0.0495       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.69         |\n",
      "|    explained_variance   | 0.453        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.18e+07     |\n",
      "|    n_updates            | 53820        |\n",
      "|    policy_gradient_loss | -0.000342    |\n",
      "|    std                  | 0.224        |\n",
      "|    value_loss           | 4.89e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=610000, episode_reward=-2013.57 +/- 15997.81\n",
      "Episode length: 1598.40 +/- 1868.83\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.6e+03     |\n",
      "|    mean_reward          | -2.01e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 610000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000455593 |\n",
      "|    clip_fraction        | 0.000146    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.69        |\n",
      "|    explained_variance   | 0.495       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.73e+07    |\n",
      "|    n_updates            | 53830       |\n",
      "|    policy_gradient_loss | -8.17e-05   |\n",
      "|    std                  | 0.224       |\n",
      "|    value_loss           | 5.33e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 508       |\n",
      "|    ep_rew_mean     | -6.45e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 639       |\n",
      "|    iterations      | 298       |\n",
      "|    time_elapsed    | 954       |\n",
      "|    total_timesteps | 610304    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 501          |\n",
      "|    ep_rew_mean          | -6.06e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 640          |\n",
      "|    iterations           | 299          |\n",
      "|    time_elapsed         | 956          |\n",
      "|    total_timesteps      | 612352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001956923 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.69         |\n",
      "|    explained_variance   | 0.451        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.54e+07     |\n",
      "|    n_updates            | 53840        |\n",
      "|    policy_gradient_loss | -0.000756    |\n",
      "|    std                  | 0.224        |\n",
      "|    value_loss           | 9.42e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 500          |\n",
      "|    ep_rew_mean          | -6.06e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 641          |\n",
      "|    iterations           | 300          |\n",
      "|    time_elapsed         | 957          |\n",
      "|    total_timesteps      | 614400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011391831 |\n",
      "|    clip_fraction        | 0.0041       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.69         |\n",
      "|    explained_variance   | 0.489        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.86e+07     |\n",
      "|    n_updates            | 53850        |\n",
      "|    policy_gradient_loss | -0.00387     |\n",
      "|    std                  | 0.224        |\n",
      "|    value_loss           | 4.37e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=615000, episode_reward=-50832.43 +/- 97246.94\n",
      "Episode length: 587.80 +/- 773.25\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 588        |\n",
      "|    mean_reward          | -5.08e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 615000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00401276 |\n",
      "|    clip_fraction        | 0.0152     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.69       |\n",
      "|    explained_variance   | 0.843      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 6.91e+05   |\n",
      "|    n_updates            | 53860      |\n",
      "|    policy_gradient_loss | -0.0062    |\n",
      "|    std                  | 0.224      |\n",
      "|    value_loss           | 2.6e+06    |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 500       |\n",
      "|    ep_rew_mean     | -6.06e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 641       |\n",
      "|    iterations      | 301       |\n",
      "|    time_elapsed    | 961       |\n",
      "|    total_timesteps | 616448    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 550         |\n",
      "|    ep_rew_mean          | -6.01e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 642         |\n",
      "|    iterations           | 302         |\n",
      "|    time_elapsed         | 963         |\n",
      "|    total_timesteps      | 618496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029542351 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.71        |\n",
      "|    explained_variance   | 0.907       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 217         |\n",
      "|    n_updates            | 53870       |\n",
      "|    policy_gradient_loss | 0.00195     |\n",
      "|    std                  | 0.222       |\n",
      "|    value_loss           | 536         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=620000, episode_reward=-5759.20 +/- 11416.63\n",
      "Episode length: 186.80 +/- 140.08\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 187         |\n",
      "|    mean_reward          | -5.76e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 620000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007957363 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.73        |\n",
      "|    explained_variance   | 0.769       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.48e+03    |\n",
      "|    n_updates            | 53880       |\n",
      "|    policy_gradient_loss | 0.00619     |\n",
      "|    std                  | 0.222       |\n",
      "|    value_loss           | 7.34e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 500       |\n",
      "|    ep_rew_mean     | -6.25e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 642       |\n",
      "|    iterations      | 303       |\n",
      "|    time_elapsed    | 965       |\n",
      "|    total_timesteps | 620544    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 496          |\n",
      "|    ep_rew_mean          | -6.24e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 643          |\n",
      "|    iterations           | 304          |\n",
      "|    time_elapsed         | 967          |\n",
      "|    total_timesteps      | 622592       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010096309 |\n",
      "|    clip_fraction        | 0.00117      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.73         |\n",
      "|    explained_variance   | 0.451        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.18e+07     |\n",
      "|    n_updates            | 53890        |\n",
      "|    policy_gradient_loss | -0.000654    |\n",
      "|    std                  | 0.222        |\n",
      "|    value_loss           | 8.07e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 496          |\n",
      "|    ep_rew_mean          | -6.24e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 644          |\n",
      "|    iterations           | 305          |\n",
      "|    time_elapsed         | 969          |\n",
      "|    total_timesteps      | 624640       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069297804 |\n",
      "|    clip_fraction        | 0.0343       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.73         |\n",
      "|    explained_variance   | 0.686        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.36e+03     |\n",
      "|    n_updates            | 53900        |\n",
      "|    policy_gradient_loss | -0.00412     |\n",
      "|    std                  | 0.222        |\n",
      "|    value_loss           | 7.15e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=625000, episode_reward=-2670.85 +/- 24947.39\n",
      "Episode length: 756.80 +/- 1229.96\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 757         |\n",
      "|    mean_reward          | -2.67e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 625000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018521303 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.73        |\n",
      "|    explained_variance   | 0.638       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 97.6        |\n",
      "|    n_updates            | 53910       |\n",
      "|    policy_gradient_loss | 0.0121      |\n",
      "|    std                  | 0.223       |\n",
      "|    value_loss           | 352         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 496       |\n",
      "|    ep_rew_mean     | -6.24e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 644       |\n",
      "|    iterations      | 306       |\n",
      "|    time_elapsed    | 972       |\n",
      "|    total_timesteps | 626688    |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 536        |\n",
      "|    ep_rew_mean          | -6.33e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 644        |\n",
      "|    iterations           | 307        |\n",
      "|    time_elapsed         | 975        |\n",
      "|    total_timesteps      | 628736     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01613023 |\n",
      "|    clip_fraction        | 0.169      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.73       |\n",
      "|    explained_variance   | 0.905      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 65.7       |\n",
      "|    n_updates            | 53920      |\n",
      "|    policy_gradient_loss | 0.00141    |\n",
      "|    std                  | 0.222      |\n",
      "|    value_loss           | 517        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=630000, episode_reward=-64426.66 +/- 74851.76\n",
      "Episode length: 158.40 +/- 154.31\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 158         |\n",
      "|    mean_reward          | -6.44e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 630000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010122383 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.74        |\n",
      "|    explained_variance   | 0.549       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.59e+06    |\n",
      "|    n_updates            | 53930       |\n",
      "|    policy_gradient_loss | 0.00414     |\n",
      "|    std                  | 0.222       |\n",
      "|    value_loss           | 1.95e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 556       |\n",
      "|    ep_rew_mean     | -6.38e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 644       |\n",
      "|    iterations      | 308       |\n",
      "|    time_elapsed    | 978       |\n",
      "|    total_timesteps | 630784    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 566          |\n",
      "|    ep_rew_mean          | -6.4e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 645          |\n",
      "|    iterations           | 309          |\n",
      "|    time_elapsed         | 980          |\n",
      "|    total_timesteps      | 632832       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0131467115 |\n",
      "|    clip_fraction        | 0.0682       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.74         |\n",
      "|    explained_variance   | 0.597        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.35e+06     |\n",
      "|    n_updates            | 53940        |\n",
      "|    policy_gradient_loss | -0.00789     |\n",
      "|    std                  | 0.222        |\n",
      "|    value_loss           | 3.71e+06     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 565         |\n",
      "|    ep_rew_mean          | -6.02e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 646         |\n",
      "|    iterations           | 310         |\n",
      "|    time_elapsed         | 982         |\n",
      "|    total_timesteps      | 634880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004229361 |\n",
      "|    clip_fraction        | 0.014       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.74        |\n",
      "|    explained_variance   | 0.481       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.31e+05    |\n",
      "|    n_updates            | 53950       |\n",
      "|    policy_gradient_loss | -0.00202    |\n",
      "|    std                  | 0.222       |\n",
      "|    value_loss           | 6.52e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=635000, episode_reward=-24578.66 +/- 41711.16\n",
      "Episode length: 626.60 +/- 1093.80\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 627         |\n",
      "|    mean_reward          | -2.46e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 635000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004949145 |\n",
      "|    clip_fraction        | 0.019       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.74        |\n",
      "|    explained_variance   | 0.517       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.67e+03    |\n",
      "|    n_updates            | 53960       |\n",
      "|    policy_gradient_loss | -0.00399    |\n",
      "|    std                  | 0.222       |\n",
      "|    value_loss           | 1.27e+05    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 521      |\n",
      "|    ep_rew_mean     | -5.5e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 645      |\n",
      "|    iterations      | 311      |\n",
      "|    time_elapsed    | 986      |\n",
      "|    total_timesteps | 636928   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 518         |\n",
      "|    ep_rew_mean          | -5.51e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 646         |\n",
      "|    iterations           | 312         |\n",
      "|    time_elapsed         | 987         |\n",
      "|    total_timesteps      | 638976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001922351 |\n",
      "|    clip_fraction        | 0.00278     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.74        |\n",
      "|    explained_variance   | 0.499       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.72e+05    |\n",
      "|    n_updates            | 53970       |\n",
      "|    policy_gradient_loss | -0.00196    |\n",
      "|    std                  | 0.222       |\n",
      "|    value_loss           | 1.01e+06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=640000, episode_reward=-9204.27 +/- 45459.40\n",
      "Episode length: 1623.40 +/- 2001.25\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.62e+03    |\n",
      "|    mean_reward          | -9.2e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 640000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008823989 |\n",
      "|    clip_fraction        | 0.046       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.74        |\n",
      "|    explained_variance   | 0.747       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.29e+03    |\n",
      "|    n_updates            | 53980       |\n",
      "|    policy_gradient_loss | -0.00381    |\n",
      "|    std                  | 0.222       |\n",
      "|    value_loss           | 2.31e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 518       |\n",
      "|    ep_rew_mean     | -5.51e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 644       |\n",
      "|    iterations      | 313       |\n",
      "|    time_elapsed    | 993       |\n",
      "|    total_timesteps | 641024    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 559         |\n",
      "|    ep_rew_mean          | -5.04e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 645         |\n",
      "|    iterations           | 314         |\n",
      "|    time_elapsed         | 995         |\n",
      "|    total_timesteps      | 643072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009022603 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.75        |\n",
      "|    explained_variance   | 0.921       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 216         |\n",
      "|    n_updates            | 53990       |\n",
      "|    policy_gradient_loss | -0.000455   |\n",
      "|    std                  | 0.221       |\n",
      "|    value_loss           | 1.24e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=645000, episode_reward=-87362.54 +/- 92201.25\n",
      "Episode length: 149.00 +/- 102.01\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 149         |\n",
      "|    mean_reward          | -8.74e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 645000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012780096 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.76        |\n",
      "|    explained_variance   | 0.454       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.92e+06    |\n",
      "|    n_updates            | 54000       |\n",
      "|    policy_gradient_loss | 0.00319     |\n",
      "|    std                  | 0.221       |\n",
      "|    value_loss           | 4.46e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 560       |\n",
      "|    ep_rew_mean     | -5.04e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 645       |\n",
      "|    iterations      | 315       |\n",
      "|    time_elapsed    | 999       |\n",
      "|    total_timesteps | 645120    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 580          |\n",
      "|    ep_rew_mean          | -4.79e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 646          |\n",
      "|    iterations           | 316          |\n",
      "|    time_elapsed         | 1001         |\n",
      "|    total_timesteps      | 647168       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048246556 |\n",
      "|    clip_fraction        | 0.053        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.76         |\n",
      "|    explained_variance   | 0.0029       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.51e+05     |\n",
      "|    n_updates            | 54010        |\n",
      "|    policy_gradient_loss | -0.00284     |\n",
      "|    std                  | 0.221        |\n",
      "|    value_loss           | 7.47e+04     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 603         |\n",
      "|    ep_rew_mean          | -5.02e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 647         |\n",
      "|    iterations           | 317         |\n",
      "|    time_elapsed         | 1003        |\n",
      "|    total_timesteps      | 649216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008563176 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.76        |\n",
      "|    explained_variance   | 0.74        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.49e+04    |\n",
      "|    n_updates            | 54020       |\n",
      "|    policy_gradient_loss | -0.00409    |\n",
      "|    std                  | 0.221       |\n",
      "|    value_loss           | 2.65e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=650000, episode_reward=-7802.93 +/- 21744.27\n",
      "Episode length: 570.40 +/- 664.74\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 570         |\n",
      "|    mean_reward          | -7.8e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 650000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002544441 |\n",
      "|    clip_fraction        | 0.0137      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.76        |\n",
      "|    explained_variance   | 0.455       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.33e+07    |\n",
      "|    n_updates            | 54030       |\n",
      "|    policy_gradient_loss | -0.00207    |\n",
      "|    std                  | 0.221       |\n",
      "|    value_loss           | 9.01e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 610       |\n",
      "|    ep_rew_mean     | -4.98e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 646       |\n",
      "|    iterations      | 318       |\n",
      "|    time_elapsed    | 1006      |\n",
      "|    total_timesteps | 651264    |\n",
      "----------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 630           |\n",
      "|    ep_rew_mean          | -4.65e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 647           |\n",
      "|    iterations           | 319           |\n",
      "|    time_elapsed         | 1008          |\n",
      "|    total_timesteps      | 653312        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00092834723 |\n",
      "|    clip_fraction        | 0.00537       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | 1.76          |\n",
      "|    explained_variance   | 0.516         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.76e+07      |\n",
      "|    n_updates            | 54040         |\n",
      "|    policy_gradient_loss | -0.00296      |\n",
      "|    std                  | 0.221         |\n",
      "|    value_loss           | 3.36e+07      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=655000, episode_reward=-17009.32 +/- 25509.07\n",
      "Episode length: 425.20 +/- 425.53\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 425        |\n",
      "|    mean_reward          | -1.7e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 655000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00325482 |\n",
      "|    clip_fraction        | 0.0164     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.76       |\n",
      "|    explained_variance   | 0.636      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 7.6e+04    |\n",
      "|    n_updates            | 54050      |\n",
      "|    policy_gradient_loss | -0.00261   |\n",
      "|    std                  | 0.221      |\n",
      "|    value_loss           | 7.85e+05   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 630       |\n",
      "|    ep_rew_mean     | -4.65e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 647       |\n",
      "|    iterations      | 320       |\n",
      "|    time_elapsed    | 1011      |\n",
      "|    total_timesteps | 655360    |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 587        |\n",
      "|    ep_rew_mean          | -4.5e+04   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 648        |\n",
      "|    iterations           | 321        |\n",
      "|    time_elapsed         | 1013       |\n",
      "|    total_timesteps      | 657408     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01106739 |\n",
      "|    clip_fraction        | 0.0675     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.76       |\n",
      "|    explained_variance   | 0.867      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 719        |\n",
      "|    n_updates            | 54060      |\n",
      "|    policy_gradient_loss | 0.000545   |\n",
      "|    std                  | 0.221      |\n",
      "|    value_loss           | 4.8e+03    |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 580          |\n",
      "|    ep_rew_mean          | -4.76e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 649          |\n",
      "|    iterations           | 322          |\n",
      "|    time_elapsed         | 1015         |\n",
      "|    total_timesteps      | 659456       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033436213 |\n",
      "|    clip_fraction        | 0.043        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.77         |\n",
      "|    explained_variance   | 0.5          |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.33e+07     |\n",
      "|    n_updates            | 54070        |\n",
      "|    policy_gradient_loss | -0.00354     |\n",
      "|    std                  | 0.221        |\n",
      "|    value_loss           | 6.69e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=660000, episode_reward=-1622.43 +/- 13934.88\n",
      "Episode length: 630.40 +/- 649.20\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 630          |\n",
      "|    mean_reward          | -1.62e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 660000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007399898 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.77         |\n",
      "|    explained_variance   | 0.455        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.6e+07      |\n",
      "|    n_updates            | 54080        |\n",
      "|    policy_gradient_loss | -0.00156     |\n",
      "|    std                  | 0.221        |\n",
      "|    value_loss           | 8.76e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 597       |\n",
      "|    ep_rew_mean     | -5.17e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 648       |\n",
      "|    iterations      | 323       |\n",
      "|    time_elapsed    | 1019      |\n",
      "|    total_timesteps | 661504    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 558         |\n",
      "|    ep_rew_mean          | -5.17e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 649         |\n",
      "|    iterations           | 324         |\n",
      "|    time_elapsed         | 1021        |\n",
      "|    total_timesteps      | 663552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001956008 |\n",
      "|    clip_fraction        | 0.00488     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.77        |\n",
      "|    explained_variance   | 0.48        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.39e+07    |\n",
      "|    n_updates            | 54090       |\n",
      "|    policy_gradient_loss | -0.0028     |\n",
      "|    std                  | 0.221       |\n",
      "|    value_loss           | 1.17e+08    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=665000, episode_reward=-110312.65 +/- 92448.29\n",
      "Episode length: 189.20 +/- 213.82\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 189           |\n",
      "|    mean_reward          | -1.1e+05      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 665000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00031739913 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | 1.77          |\n",
      "|    explained_variance   | 0.521         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.03e+07      |\n",
      "|    n_updates            | 54100         |\n",
      "|    policy_gradient_loss | -0.00154      |\n",
      "|    std                  | 0.221         |\n",
      "|    value_loss           | 3.68e+07      |\n",
      "-------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 573       |\n",
      "|    ep_rew_mean     | -5.09e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 650       |\n",
      "|    iterations      | 325       |\n",
      "|    time_elapsed    | 1023      |\n",
      "|    total_timesteps | 665600    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 573          |\n",
      "|    ep_rew_mean          | -5.09e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 650          |\n",
      "|    iterations           | 326          |\n",
      "|    time_elapsed         | 1025         |\n",
      "|    total_timesteps      | 667648       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066807154 |\n",
      "|    clip_fraction        | 0.0348       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.77         |\n",
      "|    explained_variance   | -0.0124      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.59e+04     |\n",
      "|    n_updates            | 54110        |\n",
      "|    policy_gradient_loss | -0.00391     |\n",
      "|    std                  | 0.221        |\n",
      "|    value_loss           | 1.05e+05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 620         |\n",
      "|    ep_rew_mean          | -4.8e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 651         |\n",
      "|    iterations           | 327         |\n",
      "|    time_elapsed         | 1027        |\n",
      "|    total_timesteps      | 669696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015844854 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.77        |\n",
      "|    explained_variance   | 0.711       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 478         |\n",
      "|    n_updates            | 54120       |\n",
      "|    policy_gradient_loss | -0.00861    |\n",
      "|    std                  | 0.222       |\n",
      "|    value_loss           | 1.3e+03     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=670000, episode_reward=-68239.56 +/- 105510.41\n",
      "Episode length: 677.40 +/- 1074.75\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 677          |\n",
      "|    mean_reward          | -6.82e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 670000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073871193 |\n",
      "|    clip_fraction        | 0.111        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.78         |\n",
      "|    explained_variance   | 0.734        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.16e+03     |\n",
      "|    n_updates            | 54130        |\n",
      "|    policy_gradient_loss | -0.00539     |\n",
      "|    std                  | 0.222        |\n",
      "|    value_loss           | 1.84e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 634       |\n",
      "|    ep_rew_mean     | -4.76e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 651       |\n",
      "|    iterations      | 328       |\n",
      "|    time_elapsed    | 1031      |\n",
      "|    total_timesteps | 671744    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 629          |\n",
      "|    ep_rew_mean          | -4.88e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 652          |\n",
      "|    iterations           | 329          |\n",
      "|    time_elapsed         | 1033         |\n",
      "|    total_timesteps      | 673792       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016579998 |\n",
      "|    clip_fraction        | 0.00605      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.78         |\n",
      "|    explained_variance   | 0.49         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.91e+06     |\n",
      "|    n_updates            | 54140        |\n",
      "|    policy_gradient_loss | -0.00156     |\n",
      "|    std                  | 0.222        |\n",
      "|    value_loss           | 1.77e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=675000, episode_reward=-38052.42 +/- 72112.94\n",
      "Episode length: 834.00 +/- 1233.92\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 834           |\n",
      "|    mean_reward          | -3.81e+04     |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 675000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00086417526 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | 1.78          |\n",
      "|    explained_variance   | 0.533         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.37e+07      |\n",
      "|    n_updates            | 54150         |\n",
      "|    policy_gradient_loss | -0.000686     |\n",
      "|    std                  | 0.222         |\n",
      "|    value_loss           | 4.32e+07      |\n",
      "-------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 650       |\n",
      "|    ep_rew_mean     | -4.88e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 650       |\n",
      "|    iterations      | 330       |\n",
      "|    time_elapsed    | 1038      |\n",
      "|    total_timesteps | 675840    |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 661        |\n",
      "|    ep_rew_mean          | -4.62e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 651        |\n",
      "|    iterations           | 331        |\n",
      "|    time_elapsed         | 1040       |\n",
      "|    total_timesteps      | 677888     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00580153 |\n",
      "|    clip_fraction        | 0.024      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.78       |\n",
      "|    explained_variance   | 0.869      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.2e+06    |\n",
      "|    n_updates            | 54160      |\n",
      "|    policy_gradient_loss | -0.00231   |\n",
      "|    std                  | 0.222      |\n",
      "|    value_loss           | 6.65e+05   |\n",
      "----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 671           |\n",
      "|    ep_rew_mean          | -4.98e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 651           |\n",
      "|    iterations           | 332           |\n",
      "|    time_elapsed         | 1043          |\n",
      "|    total_timesteps      | 679936        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00018804835 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | 1.78          |\n",
      "|    explained_variance   | 0.715         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.36e+06      |\n",
      "|    n_updates            | 54170         |\n",
      "|    policy_gradient_loss | -9.92e-05     |\n",
      "|    std                  | 0.222         |\n",
      "|    value_loss           | 3.97e+06      |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=680000, episode_reward=-73121.36 +/- 53528.60\n",
      "Episode length: 62.60 +/- 37.47\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 62.6         |\n",
      "|    mean_reward          | -7.31e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 680000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026133973 |\n",
      "|    clip_fraction        | 0.00767      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.78         |\n",
      "|    explained_variance   | 0.495        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.74e+07     |\n",
      "|    n_updates            | 54180        |\n",
      "|    policy_gradient_loss | -0.000885    |\n",
      "|    std                  | 0.222        |\n",
      "|    value_loss           | 6.45e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 682       |\n",
      "|    ep_rew_mean     | -4.92e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 652       |\n",
      "|    iterations      | 333       |\n",
      "|    time_elapsed    | 1045      |\n",
      "|    total_timesteps | 681984    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 682          |\n",
      "|    ep_rew_mean          | -4.92e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 653          |\n",
      "|    iterations           | 334          |\n",
      "|    time_elapsed         | 1047         |\n",
      "|    total_timesteps      | 684032       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019441075 |\n",
      "|    clip_fraction        | 0.0041       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.78         |\n",
      "|    explained_variance   | 0.581        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.96e+06     |\n",
      "|    n_updates            | 54190        |\n",
      "|    policy_gradient_loss | -0.00289     |\n",
      "|    std                  | 0.222        |\n",
      "|    value_loss           | 2.22e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=685000, episode_reward=-86714.22 +/- 95047.66\n",
      "Episode length: 319.80 +/- 416.64\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 320         |\n",
      "|    mean_reward          | -8.67e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 685000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016156774 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.78        |\n",
      "|    explained_variance   | 0.944       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 152         |\n",
      "|    n_updates            | 54200       |\n",
      "|    policy_gradient_loss | 0.00333     |\n",
      "|    std                  | 0.221       |\n",
      "|    value_loss           | 762         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 649       |\n",
      "|    ep_rew_mean     | -5.08e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 653       |\n",
      "|    iterations      | 335       |\n",
      "|    time_elapsed    | 1049      |\n",
      "|    total_timesteps | 686080    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 649          |\n",
      "|    ep_rew_mean          | -5.08e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 654          |\n",
      "|    iterations           | 336          |\n",
      "|    time_elapsed         | 1051         |\n",
      "|    total_timesteps      | 688128       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036031427 |\n",
      "|    clip_fraction        | 0.0269       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.79         |\n",
      "|    explained_variance   | 0.504        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.59e+07     |\n",
      "|    n_updates            | 54210        |\n",
      "|    policy_gradient_loss | -0.00119     |\n",
      "|    std                  | 0.221        |\n",
      "|    value_loss           | 7.08e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=690000, episode_reward=-70016.29 +/- 96325.75\n",
      "Episode length: 1765.20 +/- 2097.19\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.77e+03    |\n",
      "|    mean_reward          | -7e+04      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 690000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036539182 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.79        |\n",
      "|    explained_variance   | 0.908       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 90.9        |\n",
      "|    n_updates            | 54220       |\n",
      "|    policy_gradient_loss | 0.00285     |\n",
      "|    std                  | 0.221       |\n",
      "|    value_loss           | 410         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 697       |\n",
      "|    ep_rew_mean     | -4.79e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 652       |\n",
      "|    iterations      | 337       |\n",
      "|    time_elapsed    | 1058      |\n",
      "|    total_timesteps | 690176    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 645         |\n",
      "|    ep_rew_mean          | -5.29e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 652         |\n",
      "|    iterations           | 338         |\n",
      "|    time_elapsed         | 1060        |\n",
      "|    total_timesteps      | 692224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013815509 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.8         |\n",
      "|    explained_variance   | -0.136      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 230         |\n",
      "|    n_updates            | 54230       |\n",
      "|    policy_gradient_loss | 0.000878    |\n",
      "|    std                  | 0.22        |\n",
      "|    value_loss           | 4.27e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 629       |\n",
      "|    ep_rew_mean          | -5.7e+04  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 653       |\n",
      "|    iterations           | 339       |\n",
      "|    time_elapsed         | 1062      |\n",
      "|    total_timesteps      | 694272    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0201461 |\n",
      "|    clip_fraction        | 0.216     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 1.8       |\n",
      "|    explained_variance   | 0.451     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.1e+07   |\n",
      "|    n_updates            | 54240     |\n",
      "|    policy_gradient_loss | 0.0183    |\n",
      "|    std                  | 0.22      |\n",
      "|    value_loss           | 1.44e+08  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=695000, episode_reward=-51231.61 +/- 66869.51\n",
      "Episode length: 344.00 +/- 414.57\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 344          |\n",
      "|    mean_reward          | -5.12e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 695000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010238942 |\n",
      "|    clip_fraction        | 0.00112      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.8          |\n",
      "|    explained_variance   | 0.491        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.45e+07     |\n",
      "|    n_updates            | 54250        |\n",
      "|    policy_gradient_loss | -0.00297     |\n",
      "|    std                  | 0.22         |\n",
      "|    value_loss           | 4.18e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 629      |\n",
      "|    ep_rew_mean     | -5.7e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 653      |\n",
      "|    iterations      | 340      |\n",
      "|    time_elapsed    | 1065     |\n",
      "|    total_timesteps | 696320   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 661         |\n",
      "|    ep_rew_mean          | -6.02e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 654         |\n",
      "|    iterations           | 341         |\n",
      "|    time_elapsed         | 1067        |\n",
      "|    total_timesteps      | 698368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011356702 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.81        |\n",
      "|    explained_variance   | 0.812       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 364         |\n",
      "|    n_updates            | 54260       |\n",
      "|    policy_gradient_loss | -0.000756   |\n",
      "|    std                  | 0.22        |\n",
      "|    value_loss           | 1e+03       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=700000, episode_reward=-85980.87 +/- 107230.69\n",
      "Episode length: 187.80 +/- 126.71\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 188         |\n",
      "|    mean_reward          | -8.6e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 700000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005184341 |\n",
      "|    clip_fraction        | 0.0724      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.82        |\n",
      "|    explained_variance   | 0.514       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.17e+07    |\n",
      "|    n_updates            | 54270       |\n",
      "|    policy_gradient_loss | -0.00448    |\n",
      "|    std                  | 0.22        |\n",
      "|    value_loss           | 7.03e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 636       |\n",
      "|    ep_rew_mean     | -6.03e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 654       |\n",
      "|    iterations      | 342       |\n",
      "|    time_elapsed    | 1069      |\n",
      "|    total_timesteps | 700416    |\n",
      "----------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 636           |\n",
      "|    ep_rew_mean          | -6.03e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 655           |\n",
      "|    iterations           | 343           |\n",
      "|    time_elapsed         | 1071          |\n",
      "|    total_timesteps      | 702464        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00020572536 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | 1.81          |\n",
      "|    explained_variance   | 0.558         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.4e+05       |\n",
      "|    n_updates            | 54280         |\n",
      "|    policy_gradient_loss | -0.000756     |\n",
      "|    std                  | 0.22          |\n",
      "|    value_loss           | 1.24e+06      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 670         |\n",
      "|    ep_rew_mean          | -6.09e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 656         |\n",
      "|    iterations           | 344         |\n",
      "|    time_elapsed         | 1073        |\n",
      "|    total_timesteps      | 704512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028318044 |\n",
      "|    clip_fraction        | 0.302       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.83        |\n",
      "|    explained_variance   | 0.921       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 41          |\n",
      "|    n_updates            | 54290       |\n",
      "|    policy_gradient_loss | 0.00996     |\n",
      "|    std                  | 0.219       |\n",
      "|    value_loss           | 240         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=705000, episode_reward=-77712.95 +/- 97327.85\n",
      "Episode length: 111.60 +/- 36.71\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 112         |\n",
      "|    mean_reward          | -7.77e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 705000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010386074 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.84        |\n",
      "|    explained_variance   | 0.544       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.3e+06     |\n",
      "|    n_updates            | 54300       |\n",
      "|    policy_gradient_loss | 0.00139     |\n",
      "|    std                  | 0.219       |\n",
      "|    value_loss           | 1.34e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 670       |\n",
      "|    ep_rew_mean     | -6.09e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 656       |\n",
      "|    iterations      | 345       |\n",
      "|    time_elapsed    | 1075      |\n",
      "|    total_timesteps | 706560    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 702          |\n",
      "|    ep_rew_mean          | -6.65e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 657          |\n",
      "|    iterations           | 346          |\n",
      "|    time_elapsed         | 1077         |\n",
      "|    total_timesteps      | 708608       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011121004 |\n",
      "|    clip_fraction        | 0.00288      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.84         |\n",
      "|    explained_variance   | 0.539        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.48e+07     |\n",
      "|    n_updates            | 54310        |\n",
      "|    policy_gradient_loss | -0.00138     |\n",
      "|    std                  | 0.219        |\n",
      "|    value_loss           | 7.8e+07      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=710000, episode_reward=-13867.19 +/- 14059.73\n",
      "Episode length: 652.80 +/- 1073.35\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 653          |\n",
      "|    mean_reward          | -1.39e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 710000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020037508 |\n",
      "|    clip_fraction        | 0.00693      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.84         |\n",
      "|    explained_variance   | 0.699        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.19e+06     |\n",
      "|    n_updates            | 54320        |\n",
      "|    policy_gradient_loss | -0.00249     |\n",
      "|    std                  | 0.219        |\n",
      "|    value_loss           | 3.51e+06     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 736      |\n",
      "|    ep_rew_mean     | -6.6e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 657      |\n",
      "|    iterations      | 347      |\n",
      "|    time_elapsed    | 1081     |\n",
      "|    total_timesteps | 710656   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 736          |\n",
      "|    ep_rew_mean          | -6.6e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 657          |\n",
      "|    iterations           | 348          |\n",
      "|    time_elapsed         | 1083         |\n",
      "|    total_timesteps      | 712704       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033922927 |\n",
      "|    clip_fraction        | 0.00767      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.84         |\n",
      "|    explained_variance   | 0.82         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.31e+03     |\n",
      "|    n_updates            | 54330        |\n",
      "|    policy_gradient_loss | -0.00297     |\n",
      "|    std                  | 0.219        |\n",
      "|    value_loss           | 1.05e+05     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 724         |\n",
      "|    ep_rew_mean          | -7.29e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 658         |\n",
      "|    iterations           | 349         |\n",
      "|    time_elapsed         | 1085        |\n",
      "|    total_timesteps      | 714752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009953931 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.84        |\n",
      "|    explained_variance   | 0.944       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 177         |\n",
      "|    n_updates            | 54340       |\n",
      "|    policy_gradient_loss | -0.0036     |\n",
      "|    std                  | 0.218       |\n",
      "|    value_loss           | 537         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=715000, episode_reward=-94933.65 +/- 84185.72\n",
      "Episode length: 221.00 +/- 231.86\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 221          |\n",
      "|    mean_reward          | -9.49e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 715000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046526096 |\n",
      "|    clip_fraction        | 0.0457       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.85         |\n",
      "|    explained_variance   | 0.519        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.61e+07     |\n",
      "|    n_updates            | 54350        |\n",
      "|    policy_gradient_loss | -0.00136     |\n",
      "|    std                  | 0.218        |\n",
      "|    value_loss           | 1.28e+08     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 666      |\n",
      "|    ep_rew_mean     | -6.9e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 659      |\n",
      "|    iterations      | 350      |\n",
      "|    time_elapsed    | 1087     |\n",
      "|    total_timesteps | 716800   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 622          |\n",
      "|    ep_rew_mean          | -7.16e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 659          |\n",
      "|    iterations           | 351          |\n",
      "|    time_elapsed         | 1089         |\n",
      "|    total_timesteps      | 718848       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.480315e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.85         |\n",
      "|    explained_variance   | 0.531        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.57e+07     |\n",
      "|    n_updates            | 54360        |\n",
      "|    policy_gradient_loss | -0.000406    |\n",
      "|    std                  | 0.218        |\n",
      "|    value_loss           | 5.8e+07      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=720000, episode_reward=-56893.14 +/- 85291.67\n",
      "Episode length: 195.80 +/- 90.95\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 196           |\n",
      "|    mean_reward          | -5.69e+04     |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 720000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00035263866 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | 1.85          |\n",
      "|    explained_variance   | 0.495         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 6.01e+07      |\n",
      "|    n_updates            | 54370         |\n",
      "|    policy_gradient_loss | -0.00114      |\n",
      "|    std                  | 0.218         |\n",
      "|    value_loss           | 7.42e+07      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 621      |\n",
      "|    ep_rew_mean     | -7.3e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 660      |\n",
      "|    iterations      | 352      |\n",
      "|    time_elapsed    | 1092     |\n",
      "|    total_timesteps | 720896   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 657         |\n",
      "|    ep_rew_mean          | -7.68e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 660         |\n",
      "|    iterations           | 353         |\n",
      "|    time_elapsed         | 1094        |\n",
      "|    total_timesteps      | 722944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005319656 |\n",
      "|    clip_fraction        | 0.0225      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.85        |\n",
      "|    explained_variance   | 0.506       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.05e+07    |\n",
      "|    n_updates            | 54380       |\n",
      "|    policy_gradient_loss | 0.00137     |\n",
      "|    std                  | 0.218       |\n",
      "|    value_loss           | 4.18e+07    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 658          |\n",
      "|    ep_rew_mean          | -7.48e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 661          |\n",
      "|    iterations           | 354          |\n",
      "|    time_elapsed         | 1095         |\n",
      "|    total_timesteps      | 724992       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020681217 |\n",
      "|    clip_fraction        | 0.00791      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.85         |\n",
      "|    explained_variance   | 0.537        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.92e+07     |\n",
      "|    n_updates            | 54390        |\n",
      "|    policy_gradient_loss | -0.00384     |\n",
      "|    std                  | 0.218        |\n",
      "|    value_loss           | 8.92e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=725000, episode_reward=-27811.07 +/- 52828.86\n",
      "Episode length: 252.80 +/- 157.06\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 253         |\n",
      "|    mean_reward          | -2.78e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 725000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010173837 |\n",
      "|    clip_fraction        | 0.0402      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.85        |\n",
      "|    explained_variance   | 0.469       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.13e+07    |\n",
      "|    n_updates            | 54400       |\n",
      "|    policy_gradient_loss | 0.00258     |\n",
      "|    std                  | 0.218       |\n",
      "|    value_loss           | 4.69e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 658       |\n",
      "|    ep_rew_mean     | -7.48e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 661       |\n",
      "|    iterations      | 355       |\n",
      "|    time_elapsed    | 1098      |\n",
      "|    total_timesteps | 727040    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 696         |\n",
      "|    ep_rew_mean          | -7.76e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 662         |\n",
      "|    iterations           | 356         |\n",
      "|    time_elapsed         | 1100        |\n",
      "|    total_timesteps      | 729088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006142175 |\n",
      "|    clip_fraction        | 0.0956      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.86        |\n",
      "|    explained_variance   | 0.811       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.95e+03    |\n",
      "|    n_updates            | 54410       |\n",
      "|    policy_gradient_loss | -0.00595    |\n",
      "|    std                  | 0.217       |\n",
      "|    value_loss           | 3.78e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=730000, episode_reward=-10753.71 +/- 10394.18\n",
      "Episode length: 222.00 +/- 128.76\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 222          |\n",
      "|    mean_reward          | -1.08e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 730000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017057378 |\n",
      "|    clip_fraction        | 0.00342      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.87         |\n",
      "|    explained_variance   | 0.507        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.08e+07     |\n",
      "|    n_updates            | 54420        |\n",
      "|    policy_gradient_loss | -0.00242     |\n",
      "|    std                  | 0.217        |\n",
      "|    value_loss           | 6.81e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 695       |\n",
      "|    ep_rew_mean     | -7.77e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 662       |\n",
      "|    iterations      | 357       |\n",
      "|    time_elapsed    | 1102      |\n",
      "|    total_timesteps | 731136    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 695         |\n",
      "|    ep_rew_mean          | -7.77e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 663         |\n",
      "|    iterations           | 358         |\n",
      "|    time_elapsed         | 1104        |\n",
      "|    total_timesteps      | 733184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011224893 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.87        |\n",
      "|    explained_variance   | 0.313       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 579         |\n",
      "|    n_updates            | 54430       |\n",
      "|    policy_gradient_loss | -0.00129    |\n",
      "|    std                  | 0.217       |\n",
      "|    value_loss           | 4.63e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=735000, episode_reward=-25183.84 +/- 16148.04\n",
      "Episode length: 100.00 +/- 88.11\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 100         |\n",
      "|    mean_reward          | -2.52e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 735000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013349973 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.88        |\n",
      "|    explained_variance   | 0.864       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 651         |\n",
      "|    n_updates            | 54440       |\n",
      "|    policy_gradient_loss | -0.00859    |\n",
      "|    std                  | 0.217       |\n",
      "|    value_loss           | 2.2e+03     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 734       |\n",
      "|    ep_rew_mean     | -7.23e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 664       |\n",
      "|    iterations      | 359       |\n",
      "|    time_elapsed    | 1107      |\n",
      "|    total_timesteps | 735232    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 753         |\n",
      "|    ep_rew_mean          | -6.9e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 664         |\n",
      "|    iterations           | 360         |\n",
      "|    time_elapsed         | 1109        |\n",
      "|    total_timesteps      | 737280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009280791 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.89        |\n",
      "|    explained_variance   | 0.535       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.38e+03    |\n",
      "|    n_updates            | 54450       |\n",
      "|    policy_gradient_loss | -0.0053     |\n",
      "|    std                  | 0.217       |\n",
      "|    value_loss           | 1.2e+05     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 753          |\n",
      "|    ep_rew_mean          | -6.9e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 665          |\n",
      "|    iterations           | 361          |\n",
      "|    time_elapsed         | 1110         |\n",
      "|    total_timesteps      | 739328       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004910899 |\n",
      "|    clip_fraction        | 0.00161      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.89         |\n",
      "|    explained_variance   | 0.446        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.15e+07     |\n",
      "|    n_updates            | 54460        |\n",
      "|    policy_gradient_loss | -0.00222     |\n",
      "|    std                  | 0.217        |\n",
      "|    value_loss           | 3.97e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=740000, episode_reward=-95478.48 +/- 80256.01\n",
      "Episode length: 1327.20 +/- 1859.20\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.33e+03    |\n",
      "|    mean_reward          | -9.55e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 740000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006780946 |\n",
      "|    clip_fraction        | 0.054       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.89        |\n",
      "|    explained_variance   | 0.738       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.06e+03    |\n",
      "|    n_updates            | 54470       |\n",
      "|    policy_gradient_loss | -0.00415    |\n",
      "|    std                  | 0.217       |\n",
      "|    value_loss           | 1.26e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 706       |\n",
      "|    ep_rew_mean     | -7.66e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 664       |\n",
      "|    iterations      | 362       |\n",
      "|    time_elapsed    | 1116      |\n",
      "|    total_timesteps | 741376    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 716          |\n",
      "|    ep_rew_mean          | -7.58e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 664          |\n",
      "|    iterations           | 363          |\n",
      "|    time_elapsed         | 1118         |\n",
      "|    total_timesteps      | 743424       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018587017 |\n",
      "|    clip_fraction        | 0.00571      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.89         |\n",
      "|    explained_variance   | 0.506        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.97e+07     |\n",
      "|    n_updates            | 54480        |\n",
      "|    policy_gradient_loss | -0.00212     |\n",
      "|    std                  | 0.217        |\n",
      "|    value_loss           | 1.09e+08     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=745000, episode_reward=-7011.99 +/- 15472.12\n",
      "Episode length: 1201.40 +/- 1904.17\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.2e+03     |\n",
      "|    mean_reward          | -7.01e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 745000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006099852 |\n",
      "|    clip_fraction        | 0.0318      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.89        |\n",
      "|    explained_variance   | 0.48        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.34e+06    |\n",
      "|    n_updates            | 54490       |\n",
      "|    policy_gradient_loss | -0.00371    |\n",
      "|    std                  | 0.217       |\n",
      "|    value_loss           | 8.15e+06    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 728       |\n",
      "|    ep_rew_mean     | -7.53e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 663       |\n",
      "|    iterations      | 364       |\n",
      "|    time_elapsed    | 1123      |\n",
      "|    total_timesteps | 745472    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 720          |\n",
      "|    ep_rew_mean          | -7.63e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 662          |\n",
      "|    iterations           | 365          |\n",
      "|    time_elapsed         | 1128         |\n",
      "|    total_timesteps      | 747520       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049549844 |\n",
      "|    clip_fraction        | 0.0366       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.89         |\n",
      "|    explained_variance   | 0.512        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.37e+07     |\n",
      "|    n_updates            | 54500        |\n",
      "|    policy_gradient_loss | -0.0014      |\n",
      "|    std                  | 0.217        |\n",
      "|    value_loss           | 2.88e+07     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 721         |\n",
      "|    ep_rew_mean          | -7.78e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 662         |\n",
      "|    iterations           | 366         |\n",
      "|    time_elapsed         | 1130        |\n",
      "|    total_timesteps      | 749568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001293203 |\n",
      "|    clip_fraction        | 0.00205     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.89        |\n",
      "|    explained_variance   | 0.526       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.55e+06    |\n",
      "|    n_updates            | 54510       |\n",
      "|    policy_gradient_loss | -0.00164    |\n",
      "|    std                  | 0.217       |\n",
      "|    value_loss           | 3.34e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=750000, episode_reward=-56525.58 +/- 62409.36\n",
      "Episode length: 74.20 +/- 73.01\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 74.2         |\n",
      "|    mean_reward          | -5.65e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 750000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074467966 |\n",
      "|    clip_fraction        | 0.0342       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.89         |\n",
      "|    explained_variance   | 0.527        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.29e+07     |\n",
      "|    n_updates            | 54520        |\n",
      "|    policy_gradient_loss | -0.00298     |\n",
      "|    std                  | 0.217        |\n",
      "|    value_loss           | 2.96e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 722       |\n",
      "|    ep_rew_mean     | -7.73e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 663       |\n",
      "|    iterations      | 367       |\n",
      "|    time_elapsed    | 1133      |\n",
      "|    total_timesteps | 751616    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 740          |\n",
      "|    ep_rew_mean          | -7.49e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 664          |\n",
      "|    iterations           | 368          |\n",
      "|    time_elapsed         | 1135         |\n",
      "|    total_timesteps      | 753664       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035364479 |\n",
      "|    clip_fraction        | 0.0161       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.89         |\n",
      "|    explained_variance   | 0.55         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.19e+06     |\n",
      "|    n_updates            | 54530        |\n",
      "|    policy_gradient_loss | -0.00124     |\n",
      "|    std                  | 0.217        |\n",
      "|    value_loss           | 1.23e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=755000, episode_reward=-40750.22 +/- 56713.99\n",
      "Episode length: 163.00 +/- 57.27\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 163          |\n",
      "|    mean_reward          | -4.08e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 755000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049988152 |\n",
      "|    clip_fraction        | 0.0177       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.89         |\n",
      "|    explained_variance   | 0.725        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.17e+04     |\n",
      "|    n_updates            | 54540        |\n",
      "|    policy_gradient_loss | -0.00351     |\n",
      "|    std                  | 0.217        |\n",
      "|    value_loss           | 7.84e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 748       |\n",
      "|    ep_rew_mean     | -7.32e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 664       |\n",
      "|    iterations      | 369       |\n",
      "|    time_elapsed    | 1137      |\n",
      "|    total_timesteps | 755712    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 722          |\n",
      "|    ep_rew_mean          | -7.44e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 664          |\n",
      "|    iterations           | 370          |\n",
      "|    time_elapsed         | 1139         |\n",
      "|    total_timesteps      | 757760       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047350265 |\n",
      "|    clip_fraction        | 0.0189       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.89         |\n",
      "|    explained_variance   | 0.623        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.59e+05     |\n",
      "|    n_updates            | 54550        |\n",
      "|    policy_gradient_loss | -0.00357     |\n",
      "|    std                  | 0.217        |\n",
      "|    value_loss           | 2.68e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 682          |\n",
      "|    ep_rew_mean          | -6.72e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 665          |\n",
      "|    iterations           | 371          |\n",
      "|    time_elapsed         | 1141         |\n",
      "|    total_timesteps      | 759808       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026767068 |\n",
      "|    clip_fraction        | 0.00991      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.89         |\n",
      "|    explained_variance   | 0.514        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.86e+06     |\n",
      "|    n_updates            | 54560        |\n",
      "|    policy_gradient_loss | -0.00121     |\n",
      "|    std                  | 0.217        |\n",
      "|    value_loss           | 1.58e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=760000, episode_reward=-74595.84 +/- 82706.92\n",
      "Episode length: 476.20 +/- 376.64\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 476         |\n",
      "|    mean_reward          | -7.46e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 760000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003435159 |\n",
      "|    clip_fraction        | 0.0124      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.89        |\n",
      "|    explained_variance   | 0.423       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.82e+04    |\n",
      "|    n_updates            | 54570       |\n",
      "|    policy_gradient_loss | -0.00468    |\n",
      "|    std                  | 0.217       |\n",
      "|    value_loss           | 3.08e+05    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 690       |\n",
      "|    ep_rew_mean     | -6.23e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 665       |\n",
      "|    iterations      | 372       |\n",
      "|    time_elapsed    | 1144      |\n",
      "|    total_timesteps | 761856    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 599          |\n",
      "|    ep_rew_mean          | -5.88e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 666          |\n",
      "|    iterations           | 373          |\n",
      "|    time_elapsed         | 1146         |\n",
      "|    total_timesteps      | 763904       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044584014 |\n",
      "|    clip_fraction        | 0.0194       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.89         |\n",
      "|    explained_variance   | 0.49         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.58e+06     |\n",
      "|    n_updates            | 54580        |\n",
      "|    policy_gradient_loss | -0.00231     |\n",
      "|    std                  | 0.217        |\n",
      "|    value_loss           | 2.58e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=765000, episode_reward=-91137.89 +/- 108709.32\n",
      "Episode length: 392.60 +/- 347.79\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 393           |\n",
      "|    mean_reward          | -9.11e+04     |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 765000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00034775963 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | 1.89          |\n",
      "|    explained_variance   | 0.578         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 3.02e+06      |\n",
      "|    n_updates            | 54590         |\n",
      "|    policy_gradient_loss | -0.000655     |\n",
      "|    std                  | 0.217         |\n",
      "|    value_loss           | 8.67e+06      |\n",
      "-------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 515       |\n",
      "|    ep_rew_mean     | -5.01e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 666       |\n",
      "|    iterations      | 374       |\n",
      "|    time_elapsed    | 1149      |\n",
      "|    total_timesteps | 765952    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 526          |\n",
      "|    ep_rew_mean          | -4.81e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 667          |\n",
      "|    iterations           | 375          |\n",
      "|    time_elapsed         | 1151         |\n",
      "|    total_timesteps      | 768000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016535737 |\n",
      "|    clip_fraction        | 0.00859      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.89         |\n",
      "|    explained_variance   | 0.531        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.01e+07     |\n",
      "|    n_updates            | 54600        |\n",
      "|    policy_gradient_loss | -0.00145     |\n",
      "|    std                  | 0.216        |\n",
      "|    value_loss           | 2.45e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=770000, episode_reward=-39526.44 +/- 49324.79\n",
      "Episode length: 326.40 +/- 224.10\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 326         |\n",
      "|    mean_reward          | -3.95e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 770000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004684993 |\n",
      "|    clip_fraction        | 0.0233      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.89        |\n",
      "|    explained_variance   | 0.65        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.79e+04    |\n",
      "|    n_updates            | 54610       |\n",
      "|    policy_gradient_loss | -0.00471    |\n",
      "|    std                  | 0.216       |\n",
      "|    value_loss           | 3.78e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 547       |\n",
      "|    ep_rew_mean     | -4.77e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 667       |\n",
      "|    iterations      | 376       |\n",
      "|    time_elapsed    | 1154      |\n",
      "|    total_timesteps | 770048    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 543         |\n",
      "|    ep_rew_mean          | -4.63e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 667         |\n",
      "|    iterations           | 377         |\n",
      "|    time_elapsed         | 1155        |\n",
      "|    total_timesteps      | 772096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002972906 |\n",
      "|    clip_fraction        | 0.0342      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.89        |\n",
      "|    explained_variance   | 0.568       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.84e+06    |\n",
      "|    n_updates            | 54620       |\n",
      "|    policy_gradient_loss | -0.00299    |\n",
      "|    std                  | 0.216       |\n",
      "|    value_loss           | 1.75e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 578         |\n",
      "|    ep_rew_mean          | -4.63e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 668         |\n",
      "|    iterations           | 378         |\n",
      "|    time_elapsed         | 1157        |\n",
      "|    total_timesteps      | 774144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014699761 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.89        |\n",
      "|    explained_variance   | 0.258       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.15e+03    |\n",
      "|    n_updates            | 54630       |\n",
      "|    policy_gradient_loss | -0.0041     |\n",
      "|    std                  | 0.216       |\n",
      "|    value_loss           | 5.84e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=775000, episode_reward=-77666.41 +/- 79640.03\n",
      "Episode length: 288.20 +/- 112.79\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 288          |\n",
      "|    mean_reward          | -7.77e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 775000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0100193955 |\n",
      "|    clip_fraction        | 0.0937       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.9          |\n",
      "|    explained_variance   | 0.63         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.56e+03     |\n",
      "|    n_updates            | 54640        |\n",
      "|    policy_gradient_loss | -0.00366     |\n",
      "|    std                  | 0.216        |\n",
      "|    value_loss           | 1.64e+05     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 596       |\n",
      "|    ep_rew_mean     | -4.58e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 668       |\n",
      "|    iterations      | 379       |\n",
      "|    time_elapsed    | 1160      |\n",
      "|    total_timesteps | 776192    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 614         |\n",
      "|    ep_rew_mean          | -4.52e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 669         |\n",
      "|    iterations           | 380         |\n",
      "|    time_elapsed         | 1162        |\n",
      "|    total_timesteps      | 778240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012171373 |\n",
      "|    clip_fraction        | 0.05        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.9         |\n",
      "|    explained_variance   | 0.852       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.01e+03    |\n",
      "|    n_updates            | 54650       |\n",
      "|    policy_gradient_loss | -0.00221    |\n",
      "|    std                  | 0.216       |\n",
      "|    value_loss           | 2.24e+05    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=780000, episode_reward=-54551.81 +/- 73936.34\n",
      "Episode length: 199.60 +/- 249.19\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | -5.46e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 780000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026646089 |\n",
      "|    clip_fraction        | 0.0354       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.9          |\n",
      "|    explained_variance   | 0.52         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.23e+06     |\n",
      "|    n_updates            | 54660        |\n",
      "|    policy_gradient_loss | -0.000454    |\n",
      "|    std                  | 0.216        |\n",
      "|    value_loss           | 2.04e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 564       |\n",
      "|    ep_rew_mean     | -3.72e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 669       |\n",
      "|    iterations      | 381       |\n",
      "|    time_elapsed    | 1165      |\n",
      "|    total_timesteps | 780288    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 586          |\n",
      "|    ep_rew_mean          | -3.65e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 670          |\n",
      "|    iterations           | 382          |\n",
      "|    time_elapsed         | 1166         |\n",
      "|    total_timesteps      | 782336       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010042317 |\n",
      "|    clip_fraction        | 0.00278      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.9          |\n",
      "|    explained_variance   | 0.467        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.8e+07      |\n",
      "|    n_updates            | 54670        |\n",
      "|    policy_gradient_loss | -0.00248     |\n",
      "|    std                  | 0.216        |\n",
      "|    value_loss           | 9.64e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 558          |\n",
      "|    ep_rew_mean          | -3.59e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 671          |\n",
      "|    iterations           | 383          |\n",
      "|    time_elapsed         | 1168         |\n",
      "|    total_timesteps      | 784384       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024529565 |\n",
      "|    clip_fraction        | 0.0172       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.9          |\n",
      "|    explained_variance   | 0.617        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.85e+05     |\n",
      "|    n_updates            | 54680        |\n",
      "|    policy_gradient_loss | -0.00221     |\n",
      "|    std                  | 0.216        |\n",
      "|    value_loss           | 5.04e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=785000, episode_reward=-77695.11 +/- 57822.82\n",
      "Episode length: 466.40 +/- 341.68\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 466         |\n",
      "|    mean_reward          | -7.77e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 785000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011220113 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.9         |\n",
      "|    explained_variance   | 0.284       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.69e+03    |\n",
      "|    n_updates            | 54690       |\n",
      "|    policy_gradient_loss | -0.0045     |\n",
      "|    std                  | 0.216       |\n",
      "|    value_loss           | 8.98e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 520       |\n",
      "|    ep_rew_mean     | -3.52e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 670       |\n",
      "|    iterations      | 384       |\n",
      "|    time_elapsed    | 1172      |\n",
      "|    total_timesteps | 786432    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 476          |\n",
      "|    ep_rew_mean          | -3.36e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 671          |\n",
      "|    iterations           | 385          |\n",
      "|    time_elapsed         | 1173         |\n",
      "|    total_timesteps      | 788480       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022048478 |\n",
      "|    clip_fraction        | 0.0151       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.9          |\n",
      "|    explained_variance   | 0.536        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.41e+07     |\n",
      "|    n_updates            | 54700        |\n",
      "|    policy_gradient_loss | 0.000158     |\n",
      "|    std                  | 0.216        |\n",
      "|    value_loss           | 1.84e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=790000, episode_reward=-10746.57 +/- 7995.59\n",
      "Episode length: 83.40 +/- 72.44\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 83.4         |\n",
      "|    mean_reward          | -1.07e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 790000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011495913 |\n",
      "|    clip_fraction        | 0.00244      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.9          |\n",
      "|    explained_variance   | 0.485        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.79e+07     |\n",
      "|    n_updates            | 54710        |\n",
      "|    policy_gradient_loss | -0.00137     |\n",
      "|    std                  | 0.216        |\n",
      "|    value_loss           | 6.65e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 471       |\n",
      "|    ep_rew_mean     | -3.09e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 672       |\n",
      "|    iterations      | 386       |\n",
      "|    time_elapsed    | 1176      |\n",
      "|    total_timesteps | 790528    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 489          |\n",
      "|    ep_rew_mean          | -2.87e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 672          |\n",
      "|    iterations           | 387          |\n",
      "|    time_elapsed         | 1178         |\n",
      "|    total_timesteps      | 792576       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042707575 |\n",
      "|    clip_fraction        | 0.0227       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.9          |\n",
      "|    explained_variance   | 0.768        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.18e+04     |\n",
      "|    n_updates            | 54720        |\n",
      "|    policy_gradient_loss | -0.00326     |\n",
      "|    std                  | 0.216        |\n",
      "|    value_loss           | 1.84e+05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 470         |\n",
      "|    ep_rew_mean          | -3.02e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 673         |\n",
      "|    iterations           | 388         |\n",
      "|    time_elapsed         | 1180        |\n",
      "|    total_timesteps      | 794624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012660803 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.9         |\n",
      "|    explained_variance   | 0.712       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.47e+04    |\n",
      "|    n_updates            | 54730       |\n",
      "|    policy_gradient_loss | -0.00103    |\n",
      "|    std                  | 0.216       |\n",
      "|    value_loss           | 4.1e+04     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=795000, episode_reward=-51251.03 +/- 81899.95\n",
      "Episode length: 85.20 +/- 68.10\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 85.2         |\n",
      "|    mean_reward          | -5.13e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 795000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064244457 |\n",
      "|    clip_fraction        | 0.0518       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.9          |\n",
      "|    explained_variance   | 0.49         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.55e+05     |\n",
      "|    n_updates            | 54740        |\n",
      "|    policy_gradient_loss | -0.00134     |\n",
      "|    std                  | 0.215        |\n",
      "|    value_loss           | 3.04e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 470       |\n",
      "|    ep_rew_mean     | -3.02e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 673       |\n",
      "|    iterations      | 389       |\n",
      "|    time_elapsed    | 1182      |\n",
      "|    total_timesteps | 796672    |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 516        |\n",
      "|    ep_rew_mean          | -2.79e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 674        |\n",
      "|    iterations           | 390        |\n",
      "|    time_elapsed         | 1184       |\n",
      "|    total_timesteps      | 798720     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00723736 |\n",
      "|    clip_fraction        | 0.11       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.91       |\n",
      "|    explained_variance   | 0.952      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 884        |\n",
      "|    n_updates            | 54750      |\n",
      "|    policy_gradient_loss | -0.00289   |\n",
      "|    std                  | 0.214      |\n",
      "|    value_loss           | 3.02e+03   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=800000, episode_reward=-17130.91 +/- 27998.24\n",
      "Episode length: 1080.80 +/- 1920.54\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.08e+03     |\n",
      "|    mean_reward          | -1.71e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 800000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071622143 |\n",
      "|    clip_fraction        | 0.0456       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.92         |\n",
      "|    explained_variance   | 0.868        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.11e+03     |\n",
      "|    n_updates            | 54760        |\n",
      "|    policy_gradient_loss | 2.93e-05     |\n",
      "|    std                  | 0.214        |\n",
      "|    value_loss           | 3.16e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 495       |\n",
      "|    ep_rew_mean     | -2.65e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 673       |\n",
      "|    iterations      | 391       |\n",
      "|    time_elapsed    | 1189      |\n",
      "|    total_timesteps | 800768    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 505         |\n",
      "|    ep_rew_mean          | -2.54e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 674         |\n",
      "|    iterations           | 392         |\n",
      "|    time_elapsed         | 1191        |\n",
      "|    total_timesteps      | 802816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004886276 |\n",
      "|    clip_fraction        | 0.0394      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.92        |\n",
      "|    explained_variance   | 0.649       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.65e+03    |\n",
      "|    n_updates            | 54770       |\n",
      "|    policy_gradient_loss | -0.00358    |\n",
      "|    std                  | 0.215       |\n",
      "|    value_loss           | 2.36e+06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 505         |\n",
      "|    ep_rew_mean          | -2.54e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 674         |\n",
      "|    iterations           | 393         |\n",
      "|    time_elapsed         | 1193        |\n",
      "|    total_timesteps      | 804864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008287445 |\n",
      "|    clip_fraction        | 0.0586      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.92        |\n",
      "|    explained_variance   | 0.191       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.33e+03    |\n",
      "|    n_updates            | 54780       |\n",
      "|    policy_gradient_loss | -0.00185    |\n",
      "|    std                  | 0.215       |\n",
      "|    value_loss           | 1.22e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=805000, episode_reward=-19257.87 +/- 67514.65\n",
      "Episode length: 1372.20 +/- 1845.59\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.37e+03    |\n",
      "|    mean_reward          | -1.93e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 805000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009424116 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.93        |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 509         |\n",
      "|    n_updates            | 54790       |\n",
      "|    policy_gradient_loss | 0.00447     |\n",
      "|    std                  | 0.213       |\n",
      "|    value_loss           | 1.11e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 537       |\n",
      "|    ep_rew_mean     | -2.48e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 673       |\n",
      "|    iterations      | 394       |\n",
      "|    time_elapsed    | 1198      |\n",
      "|    total_timesteps | 806912    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 537          |\n",
      "|    ep_rew_mean          | -2.48e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 673          |\n",
      "|    iterations           | 395          |\n",
      "|    time_elapsed         | 1200         |\n",
      "|    total_timesteps      | 808960       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049211057 |\n",
      "|    clip_fraction        | 0.0287       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.94         |\n",
      "|    explained_variance   | 0.894        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.23e+04     |\n",
      "|    n_updates            | 54800        |\n",
      "|    policy_gradient_loss | -0.00279     |\n",
      "|    std                  | 0.213        |\n",
      "|    value_loss           | 6.32e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=810000, episode_reward=-6571.12 +/- 19408.97\n",
      "Episode length: 427.60 +/- 344.46\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 428         |\n",
      "|    mean_reward          | -6.57e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 810000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009951867 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.94        |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 309         |\n",
      "|    n_updates            | 54810       |\n",
      "|    policy_gradient_loss | -0.00409    |\n",
      "|    std                  | 0.212       |\n",
      "|    value_loss           | 2.13e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 537       |\n",
      "|    ep_rew_mean     | -2.48e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 673       |\n",
      "|    iterations      | 396       |\n",
      "|    time_elapsed    | 1203      |\n",
      "|    total_timesteps | 811008    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 562         |\n",
      "|    ep_rew_mean          | -2.5e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 674         |\n",
      "|    iterations           | 397         |\n",
      "|    time_elapsed         | 1205        |\n",
      "|    total_timesteps      | 813056      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014009013 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.94        |\n",
      "|    explained_variance   | 0.956       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 302         |\n",
      "|    n_updates            | 54820       |\n",
      "|    policy_gradient_loss | -0.0027     |\n",
      "|    std                  | 0.213       |\n",
      "|    value_loss           | 1.37e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=815000, episode_reward=3421.22 +/- 28449.95\n",
      "Episode length: 1497.40 +/- 1780.78\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.5e+03     |\n",
      "|    mean_reward          | 3.42e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 815000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012632687 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.92        |\n",
      "|    explained_variance   | 0.45        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.53e+06    |\n",
      "|    n_updates            | 54830       |\n",
      "|    policy_gradient_loss | -0.00137    |\n",
      "|    std                  | 0.213       |\n",
      "|    value_loss           | 3.34e+07    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 557      |\n",
      "|    ep_rew_mean     | -3.2e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 672      |\n",
      "|    iterations      | 398      |\n",
      "|    time_elapsed    | 1211     |\n",
      "|    total_timesteps | 815104   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 539          |\n",
      "|    ep_rew_mean          | -3.53e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 673          |\n",
      "|    iterations           | 399          |\n",
      "|    time_elapsed         | 1213         |\n",
      "|    total_timesteps      | 817152       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015789237 |\n",
      "|    clip_fraction        | 0.00586      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.92         |\n",
      "|    explained_variance   | 0.466        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.99e+07     |\n",
      "|    n_updates            | 54840        |\n",
      "|    policy_gradient_loss | -0.00386     |\n",
      "|    std                  | 0.213        |\n",
      "|    value_loss           | 1.13e+08     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 539           |\n",
      "|    ep_rew_mean          | -3.53e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 674           |\n",
      "|    iterations           | 400           |\n",
      "|    time_elapsed         | 1215          |\n",
      "|    total_timesteps      | 819200        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00063769356 |\n",
      "|    clip_fraction        | 0.000586      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | 1.92          |\n",
      "|    explained_variance   | 0.517         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 5.96e+07      |\n",
      "|    n_updates            | 54850         |\n",
      "|    policy_gradient_loss | -0.00141      |\n",
      "|    std                  | 0.213         |\n",
      "|    value_loss           | 6.58e+07      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=820000, episode_reward=-42469.03 +/- 64162.44\n",
      "Episode length: 214.20 +/- 142.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 214         |\n",
      "|    mean_reward          | -4.25e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 820000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010336818 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.92        |\n",
      "|    explained_variance   | 0.937       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 774         |\n",
      "|    n_updates            | 54860       |\n",
      "|    policy_gradient_loss | -0.00329    |\n",
      "|    std                  | 0.213       |\n",
      "|    value_loss           | 2.34e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 589       |\n",
      "|    ep_rew_mean     | -3.44e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 674       |\n",
      "|    iterations      | 401       |\n",
      "|    time_elapsed    | 1217      |\n",
      "|    total_timesteps | 821248    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 589         |\n",
      "|    ep_rew_mean          | -3.44e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 675         |\n",
      "|    iterations           | 402         |\n",
      "|    time_elapsed         | 1219        |\n",
      "|    total_timesteps      | 823296      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020614065 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.92        |\n",
      "|    explained_variance   | 0.795       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.7e+03     |\n",
      "|    n_updates            | 54870       |\n",
      "|    policy_gradient_loss | -0.00125    |\n",
      "|    std                  | 0.213       |\n",
      "|    value_loss           | 1.29e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=825000, episode_reward=-36436.29 +/- 59304.09\n",
      "Episode length: 212.00 +/- 177.42\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 212          |\n",
      "|    mean_reward          | -3.64e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 825000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0101290215 |\n",
      "|    clip_fraction        | 0.143        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.92         |\n",
      "|    explained_variance   | 0.98         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.14e+03     |\n",
      "|    n_updates            | 54880        |\n",
      "|    policy_gradient_loss | -0.00355     |\n",
      "|    std                  | 0.213        |\n",
      "|    value_loss           | 2.06e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 589       |\n",
      "|    ep_rew_mean     | -3.44e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 675       |\n",
      "|    iterations      | 403       |\n",
      "|    time_elapsed    | 1222      |\n",
      "|    total_timesteps | 825344    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 636          |\n",
      "|    ep_rew_mean          | -3.47e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 675          |\n",
      "|    iterations           | 404          |\n",
      "|    time_elapsed         | 1224         |\n",
      "|    total_timesteps      | 827392       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0094954325 |\n",
      "|    clip_fraction        | 0.0662       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.92         |\n",
      "|    explained_variance   | 0.787        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.87e+03     |\n",
      "|    n_updates            | 54890        |\n",
      "|    policy_gradient_loss | -0.0037      |\n",
      "|    std                  | 0.213        |\n",
      "|    value_loss           | 4.13e+04     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 636          |\n",
      "|    ep_rew_mean          | -3.47e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 676          |\n",
      "|    iterations           | 405          |\n",
      "|    time_elapsed         | 1226         |\n",
      "|    total_timesteps      | 829440       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014241261 |\n",
      "|    clip_fraction        | 0.0101       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.92         |\n",
      "|    explained_variance   | 0.559        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.6e+06      |\n",
      "|    n_updates            | 54900        |\n",
      "|    policy_gradient_loss | -0.000308    |\n",
      "|    std                  | 0.213        |\n",
      "|    value_loss           | 1.32e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=830000, episode_reward=-75286.80 +/- 96110.52\n",
      "Episode length: 219.40 +/- 135.69\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 219          |\n",
      "|    mean_reward          | -7.53e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 830000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075976187 |\n",
      "|    clip_fraction        | 0.091        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.92         |\n",
      "|    explained_variance   | 0.834        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 894          |\n",
      "|    n_updates            | 54910        |\n",
      "|    policy_gradient_loss | -0.0016      |\n",
      "|    std                  | 0.213        |\n",
      "|    value_loss           | 4.13e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 686       |\n",
      "|    ep_rew_mean     | -3.51e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 676       |\n",
      "|    iterations      | 406       |\n",
      "|    time_elapsed    | 1228      |\n",
      "|    total_timesteps | 831488    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 681         |\n",
      "|    ep_rew_mean          | -3.51e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 677         |\n",
      "|    iterations           | 407         |\n",
      "|    time_elapsed         | 1230        |\n",
      "|    total_timesteps      | 833536      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006639648 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.93        |\n",
      "|    explained_variance   | 0.573       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.59e+06    |\n",
      "|    n_updates            | 54920       |\n",
      "|    policy_gradient_loss | -0.00348    |\n",
      "|    std                  | 0.213       |\n",
      "|    value_loss           | 1.73e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=835000, episode_reward=-16170.70 +/- 13200.91\n",
      "Episode length: 476.20 +/- 407.44\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 476          |\n",
      "|    mean_reward          | -1.62e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 835000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018767264 |\n",
      "|    clip_fraction        | 0.0043       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.93         |\n",
      "|    explained_variance   | 0.504        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.1e+07      |\n",
      "|    n_updates            | 54930        |\n",
      "|    policy_gradient_loss | -0.00184     |\n",
      "|    std                  | 0.213        |\n",
      "|    value_loss           | 2.15e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 681       |\n",
      "|    ep_rew_mean     | -3.51e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 677       |\n",
      "|    iterations      | 408       |\n",
      "|    time_elapsed    | 1233      |\n",
      "|    total_timesteps | 835584    |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 710        |\n",
      "|    ep_rew_mean          | -3.66e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 677        |\n",
      "|    iterations           | 409        |\n",
      "|    time_elapsed         | 1235       |\n",
      "|    total_timesteps      | 837632     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01391153 |\n",
      "|    clip_fraction        | 0.162      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.93       |\n",
      "|    explained_variance   | 0.97       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 300        |\n",
      "|    n_updates            | 54940      |\n",
      "|    policy_gradient_loss | -0.00314   |\n",
      "|    std                  | 0.213      |\n",
      "|    value_loss           | 1.69e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 714         |\n",
      "|    ep_rew_mean          | -3.66e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 678         |\n",
      "|    iterations           | 410         |\n",
      "|    time_elapsed         | 1237        |\n",
      "|    total_timesteps      | 839680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008935408 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.94        |\n",
      "|    explained_variance   | 0.58        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.33e+05    |\n",
      "|    n_updates            | 54950       |\n",
      "|    policy_gradient_loss | 0.00783     |\n",
      "|    std                  | 0.213       |\n",
      "|    value_loss           | 2.34e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=840000, episode_reward=-88097.59 +/- 85254.69\n",
      "Episode length: 1196.00 +/- 1493.24\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.2e+03      |\n",
      "|    mean_reward          | -8.81e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 840000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026488993 |\n",
      "|    clip_fraction        | 0.00552      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.94         |\n",
      "|    explained_variance   | 0.838        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.36e+03     |\n",
      "|    n_updates            | 54960        |\n",
      "|    policy_gradient_loss | -0.00221     |\n",
      "|    std                  | 0.213        |\n",
      "|    value_loss           | 3.51e+05     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 714       |\n",
      "|    ep_rew_mean     | -3.66e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 677       |\n",
      "|    iterations      | 411       |\n",
      "|    time_elapsed    | 1242      |\n",
      "|    total_timesteps | 841728    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 733         |\n",
      "|    ep_rew_mean          | -3.62e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 677         |\n",
      "|    iterations           | 412         |\n",
      "|    time_elapsed         | 1244        |\n",
      "|    total_timesteps      | 843776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018949378 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.95        |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 353         |\n",
      "|    n_updates            | 54970       |\n",
      "|    policy_gradient_loss | -0.00094    |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 1.73e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=845000, episode_reward=47.21 +/- 8008.89\n",
      "Episode length: 476.60 +/- 358.90\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 477          |\n",
      "|    mean_reward          | 47.2         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 845000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070271953 |\n",
      "|    clip_fraction        | 0.133        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.591        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.19e+06     |\n",
      "|    n_updates            | 54980        |\n",
      "|    policy_gradient_loss | -0.000834    |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 1.44e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 677       |\n",
      "|    ep_rew_mean     | -3.68e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 677       |\n",
      "|    iterations      | 413       |\n",
      "|    time_elapsed    | 1247      |\n",
      "|    total_timesteps | 845824    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 679          |\n",
      "|    ep_rew_mean          | -3.37e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 678          |\n",
      "|    iterations           | 414          |\n",
      "|    time_elapsed         | 1249         |\n",
      "|    total_timesteps      | 847872       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011324476 |\n",
      "|    clip_fraction        | 0.00674      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.481        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.44e+06     |\n",
      "|    n_updates            | 54990        |\n",
      "|    policy_gradient_loss | -0.00409     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 3.27e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 677          |\n",
      "|    ep_rew_mean          | -3.49e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 679          |\n",
      "|    iterations           | 415          |\n",
      "|    time_elapsed         | 1251         |\n",
      "|    total_timesteps      | 849920       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006531159 |\n",
      "|    clip_fraction        | 0.0019       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.512        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.78e+07     |\n",
      "|    n_updates            | 55000        |\n",
      "|    policy_gradient_loss | -0.00239     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 3.1e+07      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=850000, episode_reward=-44795.11 +/- 56224.99\n",
      "Episode length: 1155.20 +/- 1459.98\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.16e+03     |\n",
      "|    mean_reward          | -4.48e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 850000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009786575 |\n",
      "|    clip_fraction        | 0.00352      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.518        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.57e+07     |\n",
      "|    n_updates            | 55010        |\n",
      "|    policy_gradient_loss | -0.00201     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 3.63e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 653       |\n",
      "|    ep_rew_mean     | -3.57e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 678       |\n",
      "|    iterations      | 416       |\n",
      "|    time_elapsed    | 1256      |\n",
      "|    total_timesteps | 851968    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 664          |\n",
      "|    ep_rew_mean          | -3.57e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 678          |\n",
      "|    iterations           | 417          |\n",
      "|    time_elapsed         | 1258         |\n",
      "|    total_timesteps      | 854016       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013027206 |\n",
      "|    clip_fraction        | 0.0042       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.423        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.08e+07     |\n",
      "|    n_updates            | 55020        |\n",
      "|    policy_gradient_loss | -0.00156     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 1.63e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=855000, episode_reward=-45565.00 +/- 49079.00\n",
      "Episode length: 747.20 +/- 495.20\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 747          |\n",
      "|    mean_reward          | -4.56e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 855000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018708906 |\n",
      "|    clip_fraction        | 0.00654      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.507        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.54e+07     |\n",
      "|    n_updates            | 55030        |\n",
      "|    policy_gradient_loss | -0.00415     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 3.49e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 683       |\n",
      "|    ep_rew_mean     | -3.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 678       |\n",
      "|    iterations      | 418       |\n",
      "|    time_elapsed    | 1262      |\n",
      "|    total_timesteps | 856064    |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 700        |\n",
      "|    ep_rew_mean          | -3.47e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 678        |\n",
      "|    iterations           | 419        |\n",
      "|    time_elapsed         | 1264       |\n",
      "|    total_timesteps      | 858112     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00761073 |\n",
      "|    clip_fraction        | 0.0586     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.95       |\n",
      "|    explained_variance   | 0.671      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 4.03e+03   |\n",
      "|    n_updates            | 55040      |\n",
      "|    policy_gradient_loss | -0.0059    |\n",
      "|    std                  | 0.211      |\n",
      "|    value_loss           | 1.13e+05   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=860000, episode_reward=-82440.88 +/- 51490.48\n",
      "Episode length: 166.40 +/- 187.37\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 166          |\n",
      "|    mean_reward          | -8.24e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 860000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006053442 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.475        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.66e+07     |\n",
      "|    n_updates            | 55050        |\n",
      "|    policy_gradient_loss | -0.00123     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 3.87e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 700       |\n",
      "|    ep_rew_mean     | -3.48e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 679       |\n",
      "|    iterations      | 420       |\n",
      "|    time_elapsed    | 1266      |\n",
      "|    total_timesteps | 860160    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 696          |\n",
      "|    ep_rew_mean          | -3.51e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 679          |\n",
      "|    iterations           | 421          |\n",
      "|    time_elapsed         | 1268         |\n",
      "|    total_timesteps      | 862208       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034942504 |\n",
      "|    clip_fraction        | 0.0139       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.582        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.25e+05     |\n",
      "|    n_updates            | 55060        |\n",
      "|    policy_gradient_loss | -0.00564     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 4.17e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 699          |\n",
      "|    ep_rew_mean          | -3.49e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 680          |\n",
      "|    iterations           | 422          |\n",
      "|    time_elapsed         | 1270         |\n",
      "|    total_timesteps      | 864256       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076560695 |\n",
      "|    clip_fraction        | 0.029        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.738        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.71e+04     |\n",
      "|    n_updates            | 55070        |\n",
      "|    policy_gradient_loss | -0.00212     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 2.36e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=865000, episode_reward=-34212.98 +/- 52552.68\n",
      "Episode length: 481.60 +/- 473.64\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 482         |\n",
      "|    mean_reward          | -3.42e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 865000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016955333 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.95        |\n",
      "|    explained_variance   | 0.892       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 616         |\n",
      "|    n_updates            | 55080       |\n",
      "|    policy_gradient_loss | -0.00211    |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 4.25e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 671       |\n",
      "|    ep_rew_mean     | -3.36e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 680       |\n",
      "|    iterations      | 423       |\n",
      "|    time_elapsed    | 1273      |\n",
      "|    total_timesteps | 866304    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 664          |\n",
      "|    ep_rew_mean          | -3.57e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 680          |\n",
      "|    iterations           | 424          |\n",
      "|    time_elapsed         | 1275         |\n",
      "|    total_timesteps      | 868352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054288986 |\n",
      "|    clip_fraction        | 0.0667       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.686        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.5e+05      |\n",
      "|    n_updates            | 55090        |\n",
      "|    policy_gradient_loss | -0.00275     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 2.8e+06      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=870000, episode_reward=-114857.87 +/- 93322.72\n",
      "Episode length: 205.20 +/- 122.99\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 205           |\n",
      "|    mean_reward          | -1.15e+05     |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 870000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00073169265 |\n",
      "|    clip_fraction        | 0.000244      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | 1.95          |\n",
      "|    explained_variance   | 0.582         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 5.73e+06      |\n",
      "|    n_updates            | 55100         |\n",
      "|    policy_gradient_loss | -0.00176      |\n",
      "|    std                  | 0.211         |\n",
      "|    value_loss           | 2.03e+07      |\n",
      "-------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 636       |\n",
      "|    ep_rew_mean     | -3.73e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 681       |\n",
      "|    iterations      | 425       |\n",
      "|    time_elapsed    | 1278      |\n",
      "|    total_timesteps | 870400    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 579          |\n",
      "|    ep_rew_mean          | -3.64e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 681          |\n",
      "|    iterations           | 426          |\n",
      "|    time_elapsed         | 1279         |\n",
      "|    total_timesteps      | 872448       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006252886 |\n",
      "|    clip_fraction        | 0.000928     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.586        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.54e+06     |\n",
      "|    n_updates            | 55110        |\n",
      "|    policy_gradient_loss | -0.00087     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 6.98e+06     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 586          |\n",
      "|    ep_rew_mean          | -2.92e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 682          |\n",
      "|    iterations           | 427          |\n",
      "|    time_elapsed         | 1281         |\n",
      "|    total_timesteps      | 874496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013221533 |\n",
      "|    clip_fraction        | 0.0042       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.502        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.87e+06     |\n",
      "|    n_updates            | 55120        |\n",
      "|    policy_gradient_loss | -0.00135     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 1.98e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=875000, episode_reward=-99055.44 +/- 138440.69\n",
      "Episode length: 233.60 +/- 307.36\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 234          |\n",
      "|    mean_reward          | -9.91e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 875000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043230485 |\n",
      "|    clip_fraction        | 0.0229       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.694        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.15e+05     |\n",
      "|    n_updates            | 55130        |\n",
      "|    policy_gradient_loss | -0.00654     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 1.02e+06     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 507       |\n",
      "|    ep_rew_mean     | -2.67e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 682       |\n",
      "|    iterations      | 428       |\n",
      "|    time_elapsed    | 1284      |\n",
      "|    total_timesteps | 876544    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 453          |\n",
      "|    ep_rew_mean          | -3.27e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 682          |\n",
      "|    iterations           | 429          |\n",
      "|    time_elapsed         | 1286         |\n",
      "|    total_timesteps      | 878592       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011703009 |\n",
      "|    clip_fraction        | 0.00425      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.511        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.18e+07     |\n",
      "|    n_updates            | 55140        |\n",
      "|    policy_gradient_loss | -0.00121     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 2.88e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=880000, episode_reward=-148041.42 +/- 145763.06\n",
      "Episode length: 518.20 +/- 269.45\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 518         |\n",
      "|    mean_reward          | -1.48e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 880000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003495092 |\n",
      "|    clip_fraction        | 0.0212      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.95        |\n",
      "|    explained_variance   | 0.489       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.48e+07    |\n",
      "|    n_updates            | 55150       |\n",
      "|    policy_gradient_loss | -0.00495    |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 1.07e+08    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 426       |\n",
      "|    ep_rew_mean     | -3.21e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 682       |\n",
      "|    iterations      | 430       |\n",
      "|    time_elapsed    | 1289      |\n",
      "|    total_timesteps | 880640    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 380          |\n",
      "|    ep_rew_mean          | -3.38e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 683          |\n",
      "|    iterations           | 431          |\n",
      "|    time_elapsed         | 1291         |\n",
      "|    total_timesteps      | 882688       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020666942 |\n",
      "|    clip_fraction        | 0.00669      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.52         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.48e+06     |\n",
      "|    n_updates            | 55160        |\n",
      "|    policy_gradient_loss | -0.00372     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 2.1e+07      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 375         |\n",
      "|    ep_rew_mean          | -3.28e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 683         |\n",
      "|    iterations           | 432         |\n",
      "|    time_elapsed         | 1293        |\n",
      "|    total_timesteps      | 884736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001880385 |\n",
      "|    clip_fraction        | 0.0149      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.95        |\n",
      "|    explained_variance   | 0.508       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.59e+07    |\n",
      "|    n_updates            | 55170       |\n",
      "|    policy_gradient_loss | -0.00302    |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 4.11e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=885000, episode_reward=-40321.40 +/- 52888.13\n",
      "Episode length: 242.60 +/- 189.51\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 243          |\n",
      "|    mean_reward          | -4.03e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 885000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008294933 |\n",
      "|    clip_fraction        | 0.00259      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.565        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.56e+06     |\n",
      "|    n_updates            | 55180        |\n",
      "|    policy_gradient_loss | -0.00297     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 9.08e+06     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 387       |\n",
      "|    ep_rew_mean     | -3.26e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 684       |\n",
      "|    iterations      | 433       |\n",
      "|    time_elapsed    | 1296      |\n",
      "|    total_timesteps | 886784    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 382          |\n",
      "|    ep_rew_mean          | -3.42e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 684          |\n",
      "|    iterations           | 434          |\n",
      "|    time_elapsed         | 1298         |\n",
      "|    total_timesteps      | 888832       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014034929 |\n",
      "|    clip_fraction        | 0.00439      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.501        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.27e+07     |\n",
      "|    n_updates            | 55190        |\n",
      "|    policy_gradient_loss | -0.00126     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 4.47e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=890000, episode_reward=-30533.68 +/- 54061.31\n",
      "Episode length: 118.60 +/- 72.95\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 119         |\n",
      "|    mean_reward          | -3.05e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 890000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002581934 |\n",
      "|    clip_fraction        | 0.00479     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.95        |\n",
      "|    explained_variance   | 0.46        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.58e+07    |\n",
      "|    n_updates            | 55200       |\n",
      "|    policy_gradient_loss | -0.00172    |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 7.13e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 390       |\n",
      "|    ep_rew_mean     | -3.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 685       |\n",
      "|    iterations      | 435       |\n",
      "|    time_elapsed    | 1300      |\n",
      "|    total_timesteps | 890880    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 392         |\n",
      "|    ep_rew_mean          | -3.45e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 685         |\n",
      "|    iterations           | 436         |\n",
      "|    time_elapsed         | 1302        |\n",
      "|    total_timesteps      | 892928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004406333 |\n",
      "|    clip_fraction        | 0.0241      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.95        |\n",
      "|    explained_variance   | 0.444       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.21e+04    |\n",
      "|    n_updates            | 55210       |\n",
      "|    policy_gradient_loss | -0.00384    |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 1.58e+05    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 359          |\n",
      "|    ep_rew_mean          | -3.54e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 686          |\n",
      "|    iterations           | 437          |\n",
      "|    time_elapsed         | 1304         |\n",
      "|    total_timesteps      | 894976       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013198364 |\n",
      "|    clip_fraction        | 0.00103      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.48         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.58e+07     |\n",
      "|    n_updates            | 55220        |\n",
      "|    policy_gradient_loss | -0.000548    |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 4.16e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=895000, episode_reward=-67783.29 +/- 128460.44\n",
      "Episode length: 439.40 +/- 470.42\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 439          |\n",
      "|    mean_reward          | -6.78e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 895000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016471581 |\n",
      "|    clip_fraction        | 0.00327      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.463        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.92e+06     |\n",
      "|    n_updates            | 55230        |\n",
      "|    policy_gradient_loss | -0.0031      |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 4.66e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 364       |\n",
      "|    ep_rew_mean     | -3.56e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 686       |\n",
      "|    iterations      | 438       |\n",
      "|    time_elapsed    | 1307      |\n",
      "|    total_timesteps | 897024    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 334         |\n",
      "|    ep_rew_mean          | -4.06e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 686         |\n",
      "|    iterations           | 439         |\n",
      "|    time_elapsed         | 1309        |\n",
      "|    total_timesteps      | 899072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001893191 |\n",
      "|    clip_fraction        | 0.00605     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.95        |\n",
      "|    explained_variance   | 0.459       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.01e+07    |\n",
      "|    n_updates            | 55240       |\n",
      "|    policy_gradient_loss | -0.00275    |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 2.74e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=900000, episode_reward=-81099.53 +/- 69759.29\n",
      "Episode length: 385.80 +/- 297.06\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 386          |\n",
      "|    mean_reward          | -8.11e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 900000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007215962 |\n",
      "|    clip_fraction        | 0.00317      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.491        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.51e+07     |\n",
      "|    n_updates            | 55250        |\n",
      "|    policy_gradient_loss | -0.00172     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 4.95e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 316       |\n",
      "|    ep_rew_mean     | -3.94e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 686       |\n",
      "|    iterations      | 440       |\n",
      "|    time_elapsed    | 1312      |\n",
      "|    total_timesteps | 901120    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 319          |\n",
      "|    ep_rew_mean          | -3.75e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 687          |\n",
      "|    iterations           | 441          |\n",
      "|    time_elapsed         | 1314         |\n",
      "|    total_timesteps      | 903168       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027754642 |\n",
      "|    clip_fraction        | 0.0109       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.684        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.51e+06     |\n",
      "|    n_updates            | 55260        |\n",
      "|    policy_gradient_loss | -0.00161     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 5.4e+06      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=905000, episode_reward=-106637.88 +/- 119409.85\n",
      "Episode length: 406.40 +/- 298.93\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 406          |\n",
      "|    mean_reward          | -1.07e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 905000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026269981 |\n",
      "|    clip_fraction        | 0.00356      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.663        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.4e+05      |\n",
      "|    n_updates            | 55270        |\n",
      "|    policy_gradient_loss | -0.00151     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 6.02e+05     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 322       |\n",
      "|    ep_rew_mean     | -4.14e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 687       |\n",
      "|    iterations      | 442       |\n",
      "|    time_elapsed    | 1317      |\n",
      "|    total_timesteps | 905216    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 332          |\n",
      "|    ep_rew_mean          | -4.56e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 687          |\n",
      "|    iterations           | 443          |\n",
      "|    time_elapsed         | 1319         |\n",
      "|    total_timesteps      | 907264       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010132449 |\n",
      "|    clip_fraction        | 0.00308      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.486        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.03e+07     |\n",
      "|    n_updates            | 55280        |\n",
      "|    policy_gradient_loss | -0.00242     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 4.6e+07      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 320         |\n",
      "|    ep_rew_mean          | -4.34e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 688         |\n",
      "|    iterations           | 444         |\n",
      "|    time_elapsed         | 1321        |\n",
      "|    total_timesteps      | 909312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005292215 |\n",
      "|    clip_fraction        | 0.0421      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.95        |\n",
      "|    explained_variance   | 0.475       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.91e+07    |\n",
      "|    n_updates            | 55290       |\n",
      "|    policy_gradient_loss | -0.00104    |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 8.07e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=910000, episode_reward=-36363.13 +/- 58509.00\n",
      "Episode length: 237.20 +/- 102.87\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 237          |\n",
      "|    mean_reward          | -3.64e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 910000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020047927 |\n",
      "|    clip_fraction        | 0.00947      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.515        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.48e+07     |\n",
      "|    n_updates            | 55300        |\n",
      "|    policy_gradient_loss | -0.00404     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 1.92e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 336       |\n",
      "|    ep_rew_mean     | -4.04e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 688       |\n",
      "|    iterations      | 445       |\n",
      "|    time_elapsed    | 1323      |\n",
      "|    total_timesteps | 911360    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 337          |\n",
      "|    ep_rew_mean          | -3.88e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 689          |\n",
      "|    iterations           | 446          |\n",
      "|    time_elapsed         | 1325         |\n",
      "|    total_timesteps      | 913408       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041399584 |\n",
      "|    clip_fraction        | 0.0137       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.791        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.58e+04     |\n",
      "|    n_updates            | 55310        |\n",
      "|    policy_gradient_loss | -0.00364     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 3.71e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=915000, episode_reward=-37543.19 +/- 66546.46\n",
      "Episode length: 425.80 +/- 415.12\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 426         |\n",
      "|    mean_reward          | -3.75e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 915000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005428077 |\n",
      "|    clip_fraction        | 0.0275      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.95        |\n",
      "|    explained_variance   | 0.665       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.66e+06    |\n",
      "|    n_updates            | 55320       |\n",
      "|    policy_gradient_loss | -0.00442    |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 3.22e+06    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 351       |\n",
      "|    ep_rew_mean     | -3.74e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 689       |\n",
      "|    iterations      | 447       |\n",
      "|    time_elapsed    | 1328      |\n",
      "|    total_timesteps | 915456    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 355         |\n",
      "|    ep_rew_mean          | -3.68e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 689         |\n",
      "|    iterations           | 448         |\n",
      "|    time_elapsed         | 1330        |\n",
      "|    total_timesteps      | 917504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007240559 |\n",
      "|    clip_fraction        | 0.037       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.95        |\n",
      "|    explained_variance   | 0.829       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.67e+05    |\n",
      "|    n_updates            | 55330       |\n",
      "|    policy_gradient_loss | -0.00205    |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 1.38e+06    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 374          |\n",
      "|    ep_rew_mean          | -3.69e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 690          |\n",
      "|    iterations           | 449          |\n",
      "|    time_elapsed         | 1332         |\n",
      "|    total_timesteps      | 919552       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037572728 |\n",
      "|    clip_fraction        | 0.0184       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.772        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.02e+04     |\n",
      "|    n_updates            | 55340        |\n",
      "|    policy_gradient_loss | -0.00214     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 2.02e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=920000, episode_reward=-27799.32 +/- 34825.42\n",
      "Episode length: 748.20 +/- 1230.13\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 748         |\n",
      "|    mean_reward          | -2.78e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 920000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008601338 |\n",
      "|    clip_fraction        | 0.0648      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.95        |\n",
      "|    explained_variance   | 0.705       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.72e+03    |\n",
      "|    n_updates            | 55350       |\n",
      "|    policy_gradient_loss | -0.00226    |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 8.82e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 374       |\n",
      "|    ep_rew_mean     | -3.69e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 689       |\n",
      "|    iterations      | 450       |\n",
      "|    time_elapsed    | 1336      |\n",
      "|    total_timesteps | 921600    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 407         |\n",
      "|    ep_rew_mean          | -3.52e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 689         |\n",
      "|    iterations           | 451         |\n",
      "|    time_elapsed         | 1340        |\n",
      "|    total_timesteps      | 923648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018346671 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.94        |\n",
      "|    explained_variance   | 0.938       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 863         |\n",
      "|    n_updates            | 55360       |\n",
      "|    policy_gradient_loss | 0.00302     |\n",
      "|    std                  | 0.212       |\n",
      "|    value_loss           | 2.28e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=925000, episode_reward=-18892.28 +/- 23129.94\n",
      "Episode length: 507.40 +/- 448.24\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 507        |\n",
      "|    mean_reward          | -1.89e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 925000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00816167 |\n",
      "|    clip_fraction        | 0.0603     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.93       |\n",
      "|    explained_variance   | 0.576      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.64e+07   |\n",
      "|    n_updates            | 55370      |\n",
      "|    policy_gradient_loss | 0.00103    |\n",
      "|    std                  | 0.212      |\n",
      "|    value_loss           | 1.12e+07   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 426       |\n",
      "|    ep_rew_mean     | -3.55e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 688       |\n",
      "|    iterations      | 452       |\n",
      "|    time_elapsed    | 1344      |\n",
      "|    total_timesteps | 925696    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 413          |\n",
      "|    ep_rew_mean          | -3.49e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 689          |\n",
      "|    iterations           | 453          |\n",
      "|    time_elapsed         | 1346         |\n",
      "|    total_timesteps      | 927744       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031907423 |\n",
      "|    clip_fraction        | 0.00874      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.93         |\n",
      "|    explained_variance   | 0.599        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.97e+03     |\n",
      "|    n_updates            | 55380        |\n",
      "|    policy_gradient_loss | -0.00378     |\n",
      "|    std                  | 0.212        |\n",
      "|    value_loss           | 3.95e+06     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 413          |\n",
      "|    ep_rew_mean          | -3.49e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 689          |\n",
      "|    iterations           | 454          |\n",
      "|    time_elapsed         | 1348         |\n",
      "|    total_timesteps      | 929792       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024826159 |\n",
      "|    clip_fraction        | 0.0119       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.93         |\n",
      "|    explained_variance   | 0.697        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.8e+05      |\n",
      "|    n_updates            | 55390        |\n",
      "|    policy_gradient_loss | -0.00338     |\n",
      "|    std                  | 0.212        |\n",
      "|    value_loss           | 1.55e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=930000, episode_reward=-9628.04 +/- 6611.78\n",
      "Episode length: 183.00 +/- 205.75\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 183        |\n",
      "|    mean_reward          | -9.63e+03  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 930000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01616993 |\n",
      "|    clip_fraction        | 0.187      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.94       |\n",
      "|    explained_variance   | 0.882      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 751        |\n",
      "|    n_updates            | 55400      |\n",
      "|    policy_gradient_loss | -0.00112   |\n",
      "|    std                  | 0.211      |\n",
      "|    value_loss           | 2.81e+03   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 435       |\n",
      "|    ep_rew_mean     | -2.95e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 689       |\n",
      "|    iterations      | 455       |\n",
      "|    time_elapsed    | 1351      |\n",
      "|    total_timesteps | 931840    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 425         |\n",
      "|    ep_rew_mean          | -3.43e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 690         |\n",
      "|    iterations           | 456         |\n",
      "|    time_elapsed         | 1353        |\n",
      "|    total_timesteps      | 933888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004587495 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.96        |\n",
      "|    explained_variance   | 0.598       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.25e+07    |\n",
      "|    n_updates            | 55410       |\n",
      "|    policy_gradient_loss | -0.00511    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 2.23e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=935000, episode_reward=-7743.72 +/- 16970.73\n",
      "Episode length: 220.40 +/- 146.71\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 220          |\n",
      "|    mean_reward          | -7.74e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 935000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007653007 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.96         |\n",
      "|    explained_variance   | 0.507        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.51e+07     |\n",
      "|    n_updates            | 55420        |\n",
      "|    policy_gradient_loss | -1.69e-05    |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 7.44e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 434       |\n",
      "|    ep_rew_mean     | -3.39e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 690       |\n",
      "|    iterations      | 457       |\n",
      "|    time_elapsed    | 1355      |\n",
      "|    total_timesteps | 935936    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 429          |\n",
      "|    ep_rew_mean          | -3.37e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 690          |\n",
      "|    iterations           | 458          |\n",
      "|    time_elapsed         | 1357         |\n",
      "|    total_timesteps      | 937984       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031412018 |\n",
      "|    clip_fraction        | 0.00557      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.96         |\n",
      "|    explained_variance   | 0.651        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.86e+05     |\n",
      "|    n_updates            | 55430        |\n",
      "|    policy_gradient_loss | -0.00367     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 1.14e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=940000, episode_reward=-16199.95 +/- 35388.77\n",
      "Episode length: 1269.00 +/- 1653.21\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.27e+03     |\n",
      "|    mean_reward          | -1.62e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 940000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001406704 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.96         |\n",
      "|    explained_variance   | 0.501        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.07e+07     |\n",
      "|    n_updates            | 55440        |\n",
      "|    policy_gradient_loss | -0.00037     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 6.38e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 416       |\n",
      "|    ep_rew_mean     | -3.06e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 689       |\n",
      "|    iterations      | 459       |\n",
      "|    time_elapsed    | 1362      |\n",
      "|    total_timesteps | 940032    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 421          |\n",
      "|    ep_rew_mean          | -3.05e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 690          |\n",
      "|    iterations           | 460          |\n",
      "|    time_elapsed         | 1364         |\n",
      "|    total_timesteps      | 942080       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046558566 |\n",
      "|    clip_fraction        | 0.0245       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.96         |\n",
      "|    explained_variance   | 0.797        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.35e+04     |\n",
      "|    n_updates            | 55450        |\n",
      "|    policy_gradient_loss | -0.00528     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 3.88e+05     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 421         |\n",
      "|    ep_rew_mean          | -3.05e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 691         |\n",
      "|    iterations           | 461         |\n",
      "|    time_elapsed         | 1366        |\n",
      "|    total_timesteps      | 944128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017733723 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.95        |\n",
      "|    explained_variance   | 0.938       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 432         |\n",
      "|    n_updates            | 55460       |\n",
      "|    policy_gradient_loss | -0.000354   |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 1.63e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=945000, episode_reward=-99425.65 +/- 99848.46\n",
      "Episode length: 261.20 +/- 184.14\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 261         |\n",
      "|    mean_reward          | -9.94e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 945000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009031856 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.95        |\n",
      "|    explained_variance   | 0.853       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.23e+03    |\n",
      "|    n_updates            | 55470       |\n",
      "|    policy_gradient_loss | 0.00117     |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 1.22e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 466      |\n",
      "|    ep_rew_mean     | -2.9e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 691      |\n",
      "|    iterations      | 462      |\n",
      "|    time_elapsed    | 1368     |\n",
      "|    total_timesteps | 946176   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 477          |\n",
      "|    ep_rew_mean          | -2.95e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 691          |\n",
      "|    iterations           | 463          |\n",
      "|    time_elapsed         | 1370         |\n",
      "|    total_timesteps      | 948224       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073442645 |\n",
      "|    clip_fraction        | 0.0572       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.573        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.8e+05      |\n",
      "|    n_updates            | 55480        |\n",
      "|    policy_gradient_loss | -0.00578     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 7.05e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=950000, episode_reward=-42090.86 +/- 64011.53\n",
      "Episode length: 264.80 +/- 89.54\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 265         |\n",
      "|    mean_reward          | -4.21e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 950000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002936211 |\n",
      "|    clip_fraction        | 0.0106      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.95        |\n",
      "|    explained_variance   | 0.602       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.1e+07     |\n",
      "|    n_updates            | 55490       |\n",
      "|    policy_gradient_loss | -0.00183    |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 2.09e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 484       |\n",
      "|    ep_rew_mean     | -2.97e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 691       |\n",
      "|    iterations      | 464       |\n",
      "|    time_elapsed    | 1373      |\n",
      "|    total_timesteps | 950272    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 488         |\n",
      "|    ep_rew_mean          | -2.83e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 692         |\n",
      "|    iterations           | 465         |\n",
      "|    time_elapsed         | 1375        |\n",
      "|    total_timesteps      | 952320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010472017 |\n",
      "|    clip_fraction        | 0.0867      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.95        |\n",
      "|    explained_variance   | 0.545       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.05e+07    |\n",
      "|    n_updates            | 55500       |\n",
      "|    policy_gradient_loss | -0.00177    |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 6.86e+06    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 466          |\n",
      "|    ep_rew_mean          | -2.35e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 692          |\n",
      "|    iterations           | 466          |\n",
      "|    time_elapsed         | 1377         |\n",
      "|    total_timesteps      | 954368       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043301964 |\n",
      "|    clip_fraction        | 0.039        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.704        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.96e+04     |\n",
      "|    n_updates            | 55510        |\n",
      "|    policy_gradient_loss | -0.00407     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 1.72e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=955000, episode_reward=-116658.46 +/- 78072.48\n",
      "Episode length: 338.20 +/- 179.45\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 338          |\n",
      "|    mean_reward          | -1.17e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 955000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027690628 |\n",
      "|    clip_fraction        | 0.00815      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.529        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.44e+06     |\n",
      "|    n_updates            | 55520        |\n",
      "|    policy_gradient_loss | -0.00306     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 2.25e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 453       |\n",
      "|    ep_rew_mean     | -2.64e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 692       |\n",
      "|    iterations      | 467       |\n",
      "|    time_elapsed    | 1380      |\n",
      "|    total_timesteps | 956416    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 445          |\n",
      "|    ep_rew_mean          | -3e+04       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 693          |\n",
      "|    iterations           | 468          |\n",
      "|    time_elapsed         | 1382         |\n",
      "|    total_timesteps      | 958464       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012459334 |\n",
      "|    clip_fraction        | 0.00317      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.567        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.1e+07      |\n",
      "|    n_updates            | 55530        |\n",
      "|    policy_gradient_loss | -0.00327     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 4.86e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=960000, episode_reward=-34354.46 +/- 55659.35\n",
      "Episode length: 136.60 +/- 85.94\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 137          |\n",
      "|    mean_reward          | -3.44e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 960000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007019745 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.531        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.94e+07     |\n",
      "|    n_updates            | 55540        |\n",
      "|    policy_gradient_loss | -0.00154     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 5.21e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 432       |\n",
      "|    ep_rew_mean     | -3.33e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 693       |\n",
      "|    iterations      | 469       |\n",
      "|    time_elapsed    | 1384      |\n",
      "|    total_timesteps | 960512    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 394          |\n",
      "|    ep_rew_mean          | -3.22e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 694          |\n",
      "|    iterations           | 470          |\n",
      "|    time_elapsed         | 1386         |\n",
      "|    total_timesteps      | 962560       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019243554 |\n",
      "|    clip_fraction        | 0.0043       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.484        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.29e+07     |\n",
      "|    n_updates            | 55550        |\n",
      "|    policy_gradient_loss | -0.00199     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 6.13e+07     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 401         |\n",
      "|    ep_rew_mean          | -3.41e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 694         |\n",
      "|    iterations           | 471         |\n",
      "|    time_elapsed         | 1388        |\n",
      "|    total_timesteps      | 964608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006438368 |\n",
      "|    clip_fraction        | 0.0301      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.96        |\n",
      "|    explained_variance   | 0.0561      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.08e+03    |\n",
      "|    n_updates            | 55560       |\n",
      "|    policy_gradient_loss | -0.00167    |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 9.4e+04     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=965000, episode_reward=-51253.29 +/- 74564.39\n",
      "Episode length: 264.60 +/- 196.09\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 265          |\n",
      "|    mean_reward          | -5.13e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 965000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017090328 |\n",
      "|    clip_fraction        | 0.0083       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.96         |\n",
      "|    explained_variance   | 0.487        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.3e+07      |\n",
      "|    n_updates            | 55570        |\n",
      "|    policy_gradient_loss | -0.0017      |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 3.67e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 407       |\n",
      "|    ep_rew_mean     | -3.52e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 695       |\n",
      "|    iterations      | 472       |\n",
      "|    time_elapsed    | 1390      |\n",
      "|    total_timesteps | 966656    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 367          |\n",
      "|    ep_rew_mean          | -3.57e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 695          |\n",
      "|    iterations           | 473          |\n",
      "|    time_elapsed         | 1392         |\n",
      "|    total_timesteps      | 968704       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040520984 |\n",
      "|    clip_fraction        | 0.0192       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.96         |\n",
      "|    explained_variance   | 0.63         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.64e+06     |\n",
      "|    n_updates            | 55580        |\n",
      "|    policy_gradient_loss | -0.00365     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 1.48e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=970000, episode_reward=-17488.26 +/- 23404.07\n",
      "Episode length: 168.20 +/- 43.78\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 168          |\n",
      "|    mean_reward          | -1.75e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 970000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031152018 |\n",
      "|    clip_fraction        | 0.0109       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.96         |\n",
      "|    explained_variance   | 0.491        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.88e+07     |\n",
      "|    n_updates            | 55590        |\n",
      "|    policy_gradient_loss | -0.0041      |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 3.62e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 368       |\n",
      "|    ep_rew_mean     | -3.26e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 695       |\n",
      "|    iterations      | 474       |\n",
      "|    time_elapsed    | 1394      |\n",
      "|    total_timesteps | 970752    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 372         |\n",
      "|    ep_rew_mean          | -3.31e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 696         |\n",
      "|    iterations           | 475         |\n",
      "|    time_elapsed         | 1396        |\n",
      "|    total_timesteps      | 972800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001474736 |\n",
      "|    clip_fraction        | 0.00371     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.96        |\n",
      "|    explained_variance   | 0.517       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.83e+07    |\n",
      "|    n_updates            | 55600       |\n",
      "|    policy_gradient_loss | -0.00111    |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 1.85e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 369         |\n",
      "|    ep_rew_mean          | -3.23e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 697         |\n",
      "|    iterations           | 476         |\n",
      "|    time_elapsed         | 1398        |\n",
      "|    total_timesteps      | 974848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002726337 |\n",
      "|    clip_fraction        | 0.0141      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.96        |\n",
      "|    explained_variance   | 0.472       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.06e+07    |\n",
      "|    n_updates            | 55610       |\n",
      "|    policy_gradient_loss | -0.000323   |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 3.42e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=975000, episode_reward=-44130.48 +/- 64308.01\n",
      "Episode length: 177.20 +/- 62.13\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 177          |\n",
      "|    mean_reward          | -4.41e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 975000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021951133 |\n",
      "|    clip_fraction        | 0.00811      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.525        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.57e+07     |\n",
      "|    n_updates            | 55620        |\n",
      "|    policy_gradient_loss | -0.00125     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 2.31e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 379       |\n",
      "|    ep_rew_mean     | -3.02e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 697       |\n",
      "|    iterations      | 477       |\n",
      "|    time_elapsed    | 1401      |\n",
      "|    total_timesteps | 976896    |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 383        |\n",
      "|    ep_rew_mean          | -3.24e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 697        |\n",
      "|    iterations           | 478        |\n",
      "|    time_elapsed         | 1403       |\n",
      "|    total_timesteps      | 978944     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00523379 |\n",
      "|    clip_fraction        | 0.031      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.95       |\n",
      "|    explained_variance   | 0.645      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.62e+03   |\n",
      "|    n_updates            | 55630      |\n",
      "|    policy_gradient_loss | -0.00303   |\n",
      "|    std                  | 0.211      |\n",
      "|    value_loss           | 1.03e+05   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=980000, episode_reward=-40560.88 +/- 80689.38\n",
      "Episode length: 256.80 +/- 165.50\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 257          |\n",
      "|    mean_reward          | -4.06e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 980000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021594162 |\n",
      "|    clip_fraction        | 0.00757      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.514        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.38e+07     |\n",
      "|    n_updates            | 55640        |\n",
      "|    policy_gradient_loss | -0.00172     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 4.75e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 345       |\n",
      "|    ep_rew_mean     | -3.43e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 697       |\n",
      "|    iterations      | 479       |\n",
      "|    time_elapsed    | 1406      |\n",
      "|    total_timesteps | 980992    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 372         |\n",
      "|    ep_rew_mean          | -3.35e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 697         |\n",
      "|    iterations           | 480         |\n",
      "|    time_elapsed         | 1408        |\n",
      "|    total_timesteps      | 983040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.062231578 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.95        |\n",
      "|    explained_variance   | 0.558       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.21e+03    |\n",
      "|    n_updates            | 55650       |\n",
      "|    policy_gradient_loss | 0.00715     |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 6.9e+06     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=985000, episode_reward=-5545.41 +/- 6634.68\n",
      "Episode length: 222.20 +/- 197.80\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 222        |\n",
      "|    mean_reward          | -5.55e+03  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 985000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01267455 |\n",
      "|    clip_fraction        | 0.102      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.95       |\n",
      "|    explained_variance   | 0.927      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.73e+03   |\n",
      "|    n_updates            | 55660      |\n",
      "|    policy_gradient_loss | -0.00291   |\n",
      "|    std                  | 0.211      |\n",
      "|    value_loss           | 8.07e+04   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 367       |\n",
      "|    ep_rew_mean     | -3.36e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 698       |\n",
      "|    iterations      | 481       |\n",
      "|    time_elapsed    | 1410      |\n",
      "|    total_timesteps | 985088    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 349          |\n",
      "|    ep_rew_mean          | -3.68e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 698          |\n",
      "|    iterations           | 482          |\n",
      "|    time_elapsed         | 1412         |\n",
      "|    total_timesteps      | 987136       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043737586 |\n",
      "|    clip_fraction        | 0.128        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.624        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.29e+06     |\n",
      "|    n_updates            | 55670        |\n",
      "|    policy_gradient_loss | 0.00204      |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 8.52e+06     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 360          |\n",
      "|    ep_rew_mean          | -3.5e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 699          |\n",
      "|    iterations           | 483          |\n",
      "|    time_elapsed         | 1414         |\n",
      "|    total_timesteps      | 989184       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028759968 |\n",
      "|    clip_fraction        | 0.00498      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.497        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.69e+07     |\n",
      "|    n_updates            | 55680        |\n",
      "|    policy_gradient_loss | -0.00179     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 6.62e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=990000, episode_reward=-36240.25 +/- 67474.01\n",
      "Episode length: 171.80 +/- 135.61\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 172         |\n",
      "|    mean_reward          | -3.62e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 990000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001357327 |\n",
      "|    clip_fraction        | 0.000781    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.95        |\n",
      "|    explained_variance   | 0.498       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.73e+04    |\n",
      "|    n_updates            | 55690       |\n",
      "|    policy_gradient_loss | -0.00205    |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 5.85e+05    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 352       |\n",
      "|    ep_rew_mean     | -3.76e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 699       |\n",
      "|    iterations      | 484       |\n",
      "|    time_elapsed    | 1416      |\n",
      "|    total_timesteps | 991232    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 360          |\n",
      "|    ep_rew_mean          | -3.72e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 700          |\n",
      "|    iterations           | 485          |\n",
      "|    time_elapsed         | 1418         |\n",
      "|    total_timesteps      | 993280       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027395175 |\n",
      "|    clip_fraction        | 0.0143       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.476        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.4e+07      |\n",
      "|    n_updates            | 55700        |\n",
      "|    policy_gradient_loss | -0.00449     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 8.93e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=995000, episode_reward=-6913.16 +/- 5576.21\n",
      "Episode length: 331.00 +/- 458.20\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 331          |\n",
      "|    mean_reward          | -6.91e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 995000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017882668 |\n",
      "|    clip_fraction        | 0.00557      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.475        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.29e+07     |\n",
      "|    n_updates            | 55710        |\n",
      "|    policy_gradient_loss | -0.00358     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 2.17e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 377       |\n",
      "|    ep_rew_mean     | -3.69e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 700       |\n",
      "|    iterations      | 486       |\n",
      "|    time_elapsed    | 1421      |\n",
      "|    total_timesteps | 995328    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 376         |\n",
      "|    ep_rew_mean          | -3.41e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 700         |\n",
      "|    iterations           | 487         |\n",
      "|    time_elapsed         | 1423        |\n",
      "|    total_timesteps      | 997376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013277749 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.96        |\n",
      "|    explained_variance   | 0.326       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.5e+03     |\n",
      "|    n_updates            | 55720       |\n",
      "|    policy_gradient_loss | -0.0061     |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 4.6e+04     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 385          |\n",
      "|    ep_rew_mean          | -3.5e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 700          |\n",
      "|    iterations           | 488          |\n",
      "|    time_elapsed         | 1427         |\n",
      "|    total_timesteps      | 999424       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065867878 |\n",
      "|    clip_fraction        | 0.0618       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.96         |\n",
      "|    explained_variance   | 0.549        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.02e+07     |\n",
      "|    n_updates            | 55730        |\n",
      "|    policy_gradient_loss | -0.00625     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 3.37e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1000000, episode_reward=-6997.51 +/- 11404.47\n",
      "Episode length: 440.80 +/- 435.15\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 441          |\n",
      "|    mean_reward          | -7e+03       |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1000000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050680926 |\n",
      "|    clip_fraction        | 0.022        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.96         |\n",
      "|    explained_variance   | 0.531        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.34e+07     |\n",
      "|    n_updates            | 55740        |\n",
      "|    policy_gradient_loss | -0.00381     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 3.71e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 341       |\n",
      "|    ep_rew_mean     | -3.34e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 699       |\n",
      "|    iterations      | 489       |\n",
      "|    time_elapsed    | 1431      |\n",
      "|    total_timesteps | 1001472   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 357         |\n",
      "|    ep_rew_mean          | -3.09e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 700         |\n",
      "|    iterations           | 490         |\n",
      "|    time_elapsed         | 1432        |\n",
      "|    total_timesteps      | 1003520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005320745 |\n",
      "|    clip_fraction        | 0.0336      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.96        |\n",
      "|    explained_variance   | 0.499       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.27e+07    |\n",
      "|    n_updates            | 55750       |\n",
      "|    policy_gradient_loss | -0.00165    |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 2.58e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1005000, episode_reward=-53005.31 +/- 50076.84\n",
      "Episode length: 78.80 +/- 86.94\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 78.8        |\n",
      "|    mean_reward          | -5.3e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1005000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009754993 |\n",
      "|    clip_fraction        | 0.0638      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.96        |\n",
      "|    explained_variance   | 0.637       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.17e+05    |\n",
      "|    n_updates            | 55760       |\n",
      "|    policy_gradient_loss | -0.00474    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 1.99e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 366       |\n",
      "|    ep_rew_mean     | -3.54e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 700       |\n",
      "|    iterations      | 491       |\n",
      "|    time_elapsed    | 1435      |\n",
      "|    total_timesteps | 1005568   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 366          |\n",
      "|    ep_rew_mean          | -3.38e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 701          |\n",
      "|    iterations           | 492          |\n",
      "|    time_elapsed         | 1436         |\n",
      "|    total_timesteps      | 1007616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044287723 |\n",
      "|    clip_fraction        | 0.0205       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.96         |\n",
      "|    explained_variance   | 0.474        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.01e+07     |\n",
      "|    n_updates            | 55770        |\n",
      "|    policy_gradient_loss | -0.00367     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 7.78e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 364         |\n",
      "|    ep_rew_mean          | -3.39e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 701         |\n",
      "|    iterations           | 493         |\n",
      "|    time_elapsed         | 1438        |\n",
      "|    total_timesteps      | 1009664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006063072 |\n",
      "|    clip_fraction        | 0.0435      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.96        |\n",
      "|    explained_variance   | 0.315       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.66e+03    |\n",
      "|    n_updates            | 55780       |\n",
      "|    policy_gradient_loss | -0.00086    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 2.17e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1010000, episode_reward=-14176.35 +/- 32217.77\n",
      "Episode length: 355.40 +/- 318.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 355          |\n",
      "|    mean_reward          | -1.42e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1010000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059342184 |\n",
      "|    clip_fraction        | 0.0486       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.96         |\n",
      "|    explained_variance   | 0.491        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.36e+07     |\n",
      "|    n_updates            | 55790        |\n",
      "|    policy_gradient_loss | -0.00166     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 2.68e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 369       |\n",
      "|    ep_rew_mean     | -3.24e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 701       |\n",
      "|    iterations      | 494       |\n",
      "|    time_elapsed    | 1441      |\n",
      "|    total_timesteps | 1011712   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 385          |\n",
      "|    ep_rew_mean          | -3.23e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 702          |\n",
      "|    iterations           | 495          |\n",
      "|    time_elapsed         | 1443         |\n",
      "|    total_timesteps      | 1013760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077021667 |\n",
      "|    clip_fraction        | 0.0823       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.96         |\n",
      "|    explained_variance   | 0.796        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.69e+04     |\n",
      "|    n_updates            | 55800        |\n",
      "|    policy_gradient_loss | -0.00222     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 5.7e+05      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1015000, episode_reward=-34421.90 +/- 62727.21\n",
      "Episode length: 475.20 +/- 469.79\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 475         |\n",
      "|    mean_reward          | -3.44e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1015000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009786254 |\n",
      "|    clip_fraction        | 0.071       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.96        |\n",
      "|    explained_variance   | 0.759       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.5e+03     |\n",
      "|    n_updates            | 55810       |\n",
      "|    policy_gradient_loss | -0.000264   |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 4.39e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 375       |\n",
      "|    ep_rew_mean     | -3.34e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 702       |\n",
      "|    iterations      | 496       |\n",
      "|    time_elapsed    | 1446      |\n",
      "|    total_timesteps | 1015808   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 393          |\n",
      "|    ep_rew_mean          | -3.11e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 702          |\n",
      "|    iterations           | 497          |\n",
      "|    time_elapsed         | 1448         |\n",
      "|    total_timesteps      | 1017856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044150683 |\n",
      "|    clip_fraction        | 0.116        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.96         |\n",
      "|    explained_variance   | 0.509        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.86e+07     |\n",
      "|    n_updates            | 55820        |\n",
      "|    policy_gradient_loss | 0.00107      |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 1.95e+07     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 367         |\n",
      "|    ep_rew_mean          | -2.95e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 703         |\n",
      "|    iterations           | 498         |\n",
      "|    time_elapsed         | 1449        |\n",
      "|    total_timesteps      | 1019904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007900742 |\n",
      "|    clip_fraction        | 0.0826      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.96        |\n",
      "|    explained_variance   | 0.845       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2e+03       |\n",
      "|    n_updates            | 55830       |\n",
      "|    policy_gradient_loss | -0.00595    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 1.04e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1020000, episode_reward=-53758.05 +/- 106891.27\n",
      "Episode length: 871.20 +/- 1033.45\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 871          |\n",
      "|    mean_reward          | -5.38e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1020000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063450327 |\n",
      "|    clip_fraction        | 0.0467       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.97         |\n",
      "|    explained_variance   | 0.668        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.12e+05     |\n",
      "|    n_updates            | 55840        |\n",
      "|    policy_gradient_loss | -0.00408     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 1.42e+06     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 377       |\n",
      "|    ep_rew_mean     | -3.26e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 702       |\n",
      "|    iterations      | 499       |\n",
      "|    time_elapsed    | 1453      |\n",
      "|    total_timesteps | 1021952   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 377          |\n",
      "|    ep_rew_mean          | -3.44e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 703          |\n",
      "|    iterations           | 500          |\n",
      "|    time_elapsed         | 1455         |\n",
      "|    total_timesteps      | 1024000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045791273 |\n",
      "|    clip_fraction        | 0.0308       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.97         |\n",
      "|    explained_variance   | 0.531        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.34e+07     |\n",
      "|    n_updates            | 55850        |\n",
      "|    policy_gradient_loss | -0.000887    |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 6.58e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1025000, episode_reward=-46707.09 +/- 57126.40\n",
      "Episode length: 1005.60 +/- 1250.89\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.01e+03     |\n",
      "|    mean_reward          | -4.67e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1025000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039689485 |\n",
      "|    clip_fraction        | 0.0189       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.97         |\n",
      "|    explained_variance   | 0.495        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.08e+07     |\n",
      "|    n_updates            | 55860        |\n",
      "|    policy_gradient_loss | -0.00232     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 2.98e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 397       |\n",
      "|    ep_rew_mean     | -3.44e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 702       |\n",
      "|    iterations      | 501       |\n",
      "|    time_elapsed    | 1460      |\n",
      "|    total_timesteps | 1026048   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 405         |\n",
      "|    ep_rew_mean          | -3.24e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 703         |\n",
      "|    iterations           | 502         |\n",
      "|    time_elapsed         | 1461        |\n",
      "|    total_timesteps      | 1028096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010236473 |\n",
      "|    clip_fraction        | 0.0984      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.97        |\n",
      "|    explained_variance   | 0.819       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.68e+03    |\n",
      "|    n_updates            | 55870       |\n",
      "|    policy_gradient_loss | -0.00098    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 1.47e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1030000, episode_reward=-12382.94 +/- 21565.06\n",
      "Episode length: 584.20 +/- 475.28\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 584         |\n",
      "|    mean_reward          | -1.24e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1030000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004083563 |\n",
      "|    clip_fraction        | 0.0321      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.97        |\n",
      "|    explained_variance   | 0.548       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.37e+04    |\n",
      "|    n_updates            | 55880       |\n",
      "|    policy_gradient_loss | -0.00438    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 6.87e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 425       |\n",
      "|    ep_rew_mean     | -3.44e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 703       |\n",
      "|    iterations      | 503       |\n",
      "|    time_elapsed    | 1465      |\n",
      "|    total_timesteps | 1030144   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 438          |\n",
      "|    ep_rew_mean          | -3.43e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 703          |\n",
      "|    iterations           | 504          |\n",
      "|    time_elapsed         | 1467         |\n",
      "|    total_timesteps      | 1032192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041568438 |\n",
      "|    clip_fraction        | 0.0112       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.97         |\n",
      "|    explained_variance   | 0.492        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.73e+07     |\n",
      "|    n_updates            | 55890        |\n",
      "|    policy_gradient_loss | -0.00162     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 7.12e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 439          |\n",
      "|    ep_rew_mean          | -3.2e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 704          |\n",
      "|    iterations           | 505          |\n",
      "|    time_elapsed         | 1468         |\n",
      "|    total_timesteps      | 1034240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0084609315 |\n",
      "|    clip_fraction        | 0.088        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.97         |\n",
      "|    explained_variance   | -0.165       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.41e+03     |\n",
      "|    n_updates            | 55900        |\n",
      "|    policy_gradient_loss | -0.00191     |\n",
      "|    std                  | 0.209        |\n",
      "|    value_loss           | 9.16e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1035000, episode_reward=1498.62 +/- 11521.71\n",
      "Episode length: 717.00 +/- 435.23\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 717         |\n",
      "|    mean_reward          | 1.5e+03     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1035000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014339038 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.97        |\n",
      "|    explained_variance   | -0.00704    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.34e+04    |\n",
      "|    n_updates            | 55910       |\n",
      "|    policy_gradient_loss | -0.00163    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 6.88e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 447       |\n",
      "|    ep_rew_mean     | -3.01e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 703       |\n",
      "|    iterations      | 506       |\n",
      "|    time_elapsed    | 1472      |\n",
      "|    total_timesteps | 1036288   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 450          |\n",
      "|    ep_rew_mean          | -3.01e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 704          |\n",
      "|    iterations           | 507          |\n",
      "|    time_elapsed         | 1474         |\n",
      "|    total_timesteps      | 1038336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0081555545 |\n",
      "|    clip_fraction        | 0.0905       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.97         |\n",
      "|    explained_variance   | 0.472        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.65e+07     |\n",
      "|    n_updates            | 55920        |\n",
      "|    policy_gradient_loss | 0.00327      |\n",
      "|    std                  | 0.209        |\n",
      "|    value_loss           | 2.88e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1040000, episode_reward=-21542.05 +/- 39005.44\n",
      "Episode length: 961.00 +/- 1317.28\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 961         |\n",
      "|    mean_reward          | -2.15e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1040000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006740451 |\n",
      "|    clip_fraction        | 0.0775      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.97        |\n",
      "|    explained_variance   | 0.547       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.02e+04    |\n",
      "|    n_updates            | 55930       |\n",
      "|    policy_gradient_loss | -0.00216    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 5.75e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 462       |\n",
      "|    ep_rew_mean     | -2.98e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 703       |\n",
      "|    iterations      | 508       |\n",
      "|    time_elapsed    | 1479      |\n",
      "|    total_timesteps | 1040384   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 462         |\n",
      "|    ep_rew_mean          | -2.98e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 703         |\n",
      "|    iterations           | 509         |\n",
      "|    time_elapsed         | 1481        |\n",
      "|    total_timesteps      | 1042432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006667736 |\n",
      "|    clip_fraction        | 0.0416      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.97        |\n",
      "|    explained_variance   | 0.533       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.92e+03    |\n",
      "|    n_updates            | 55940       |\n",
      "|    policy_gradient_loss | -0.00551    |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 5.99e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 509         |\n",
      "|    ep_rew_mean          | -2.92e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 704         |\n",
      "|    iterations           | 510         |\n",
      "|    time_elapsed         | 1483        |\n",
      "|    total_timesteps      | 1044480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014524324 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.97        |\n",
      "|    explained_variance   | 0.923       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 319         |\n",
      "|    n_updates            | 55950       |\n",
      "|    policy_gradient_loss | 0.00409     |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 1.22e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1045000, episode_reward=-16289.34 +/- 30395.54\n",
      "Episode length: 1364.80 +/- 1356.99\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.36e+03    |\n",
      "|    mean_reward          | -1.63e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1045000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009647084 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.98        |\n",
      "|    explained_variance   | 0.558       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.81e+07    |\n",
      "|    n_updates            | 55960       |\n",
      "|    policy_gradient_loss | 0.000576    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 1.83e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 500       |\n",
      "|    ep_rew_mean     | -2.91e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 703       |\n",
      "|    iterations      | 511       |\n",
      "|    time_elapsed    | 1488      |\n",
      "|    total_timesteps | 1046528   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 515         |\n",
      "|    ep_rew_mean          | -2.91e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 703         |\n",
      "|    iterations           | 512         |\n",
      "|    time_elapsed         | 1490        |\n",
      "|    total_timesteps      | 1048576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009051585 |\n",
      "|    clip_fraction        | 0.0895      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.97        |\n",
      "|    explained_variance   | 0.901       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.12e+03    |\n",
      "|    n_updates            | 55970       |\n",
      "|    policy_gradient_loss | -0.00604    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 4.55e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1050000, episode_reward=-40928.60 +/- 52421.74\n",
      "Episode length: 937.00 +/- 891.02\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 937         |\n",
      "|    mean_reward          | -4.09e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1050000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007677711 |\n",
      "|    clip_fraction        | 0.0346      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.97        |\n",
      "|    explained_variance   | 0.771       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.31e+04    |\n",
      "|    n_updates            | 55980       |\n",
      "|    policy_gradient_loss | -0.00198    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 1.5e+05     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 516       |\n",
      "|    ep_rew_mean     | -2.85e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 702       |\n",
      "|    iterations      | 513       |\n",
      "|    time_elapsed    | 1494      |\n",
      "|    total_timesteps | 1050624   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 521          |\n",
      "|    ep_rew_mean          | -2.85e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 703          |\n",
      "|    iterations           | 514          |\n",
      "|    time_elapsed         | 1496         |\n",
      "|    total_timesteps      | 1052672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047638104 |\n",
      "|    clip_fraction        | 0.0317       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.97         |\n",
      "|    explained_variance   | 0.504        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.7e+07      |\n",
      "|    n_updates            | 55990        |\n",
      "|    policy_gradient_loss | -0.00268     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 6.17e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 543          |\n",
      "|    ep_rew_mean          | -2.94e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 703          |\n",
      "|    iterations           | 515          |\n",
      "|    time_elapsed         | 1498         |\n",
      "|    total_timesteps      | 1054720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026748672 |\n",
      "|    clip_fraction        | 0.0251       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.97         |\n",
      "|    explained_variance   | 0.694        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.9e+06      |\n",
      "|    n_updates            | 56000        |\n",
      "|    policy_gradient_loss | -0.00461     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 1.01e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1055000, episode_reward=-17547.23 +/- 46104.30\n",
      "Episode length: 1598.80 +/- 1013.78\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.6e+03     |\n",
      "|    mean_reward          | -1.75e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1055000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024932204 |\n",
      "|    clip_fraction        | 0.0658      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.97        |\n",
      "|    explained_variance   | 0.608       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.85e+06    |\n",
      "|    n_updates            | 56010       |\n",
      "|    policy_gradient_loss | 0.00333     |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 1.39e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 543       |\n",
      "|    ep_rew_mean     | -2.94e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 702       |\n",
      "|    iterations      | 516       |\n",
      "|    time_elapsed    | 1503      |\n",
      "|    total_timesteps | 1056768   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 569         |\n",
      "|    ep_rew_mean          | -2.96e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 702         |\n",
      "|    iterations           | 517         |\n",
      "|    time_elapsed         | 1507        |\n",
      "|    total_timesteps      | 1058816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013049165 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.96        |\n",
      "|    explained_variance   | 0.925       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 899         |\n",
      "|    n_updates            | 56020       |\n",
      "|    policy_gradient_loss | 0.0014      |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 3.54e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1060000, episode_reward=119.93 +/- 11583.05\n",
      "Episode length: 1334.80 +/- 999.66\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.33e+03    |\n",
      "|    mean_reward          | 120         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1060000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008688288 |\n",
      "|    clip_fraction        | 0.055       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.96        |\n",
      "|    explained_variance   | 0.601       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.72e+06    |\n",
      "|    n_updates            | 56030       |\n",
      "|    policy_gradient_loss | -0.00383    |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 1.6e+07     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 600       |\n",
      "|    ep_rew_mean     | -2.95e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 701       |\n",
      "|    iterations      | 518       |\n",
      "|    time_elapsed    | 1512      |\n",
      "|    total_timesteps | 1060864   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 600         |\n",
      "|    ep_rew_mean          | -2.95e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 701         |\n",
      "|    iterations           | 519         |\n",
      "|    time_elapsed         | 1514        |\n",
      "|    total_timesteps      | 1062912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013970007 |\n",
      "|    clip_fraction        | 0.0804      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.96        |\n",
      "|    explained_variance   | 0.534       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.67e+06    |\n",
      "|    n_updates            | 56040       |\n",
      "|    policy_gradient_loss | -0.00438    |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 1.89e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 618         |\n",
      "|    ep_rew_mean          | -2.94e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 702         |\n",
      "|    iterations           | 520         |\n",
      "|    time_elapsed         | 1515        |\n",
      "|    total_timesteps      | 1064960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014056737 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.96        |\n",
      "|    explained_variance   | 0.8         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.33e+05    |\n",
      "|    n_updates            | 56050       |\n",
      "|    policy_gradient_loss | -0.0041     |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 3.76e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1065000, episode_reward=-23352.05 +/- 51483.99\n",
      "Episode length: 643.20 +/- 767.35\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 643         |\n",
      "|    mean_reward          | -2.34e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1065000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028281204 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.95        |\n",
      "|    explained_variance   | 0.933       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.42e+03    |\n",
      "|    n_updates            | 56060       |\n",
      "|    policy_gradient_loss | 0.00681     |\n",
      "|    std                  | 0.212       |\n",
      "|    value_loss           | 5.71e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 618       |\n",
      "|    ep_rew_mean     | -2.94e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 702       |\n",
      "|    iterations      | 521       |\n",
      "|    time_elapsed    | 1519      |\n",
      "|    total_timesteps | 1067008   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 643         |\n",
      "|    ep_rew_mean          | -2.78e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 702         |\n",
      "|    iterations           | 522         |\n",
      "|    time_elapsed         | 1521        |\n",
      "|    total_timesteps      | 1069056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012741146 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.94        |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 796         |\n",
      "|    n_updates            | 56070       |\n",
      "|    policy_gradient_loss | -0.00385    |\n",
      "|    std                  | 0.212       |\n",
      "|    value_loss           | 3.98e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1070000, episode_reward=510.37 +/- 8484.94\n",
      "Episode length: 1453.60 +/- 812.39\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.45e+03     |\n",
      "|    mean_reward          | 510          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1070000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064291083 |\n",
      "|    clip_fraction        | 0.107        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.94         |\n",
      "|    explained_variance   | 0.494        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.33e+06     |\n",
      "|    n_updates            | 56080        |\n",
      "|    policy_gradient_loss | -0.00104     |\n",
      "|    std                  | 0.212        |\n",
      "|    value_loss           | 2.48e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 653       |\n",
      "|    ep_rew_mean     | -2.65e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 701       |\n",
      "|    iterations      | 523       |\n",
      "|    time_elapsed    | 1526      |\n",
      "|    total_timesteps | 1071104   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 666          |\n",
      "|    ep_rew_mean          | -2.79e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 702          |\n",
      "|    iterations           | 524          |\n",
      "|    time_elapsed         | 1528         |\n",
      "|    total_timesteps      | 1073152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011321154 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.94         |\n",
      "|    explained_variance   | 0.624        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.52e+06     |\n",
      "|    n_updates            | 56090        |\n",
      "|    policy_gradient_loss | -0.00191     |\n",
      "|    std                  | 0.212        |\n",
      "|    value_loss           | 3.32e+06     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1075000, episode_reward=-36036.33 +/- 57701.00\n",
      "Episode length: 1016.80 +/- 798.52\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.02e+03   |\n",
      "|    mean_reward          | -3.6e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1075000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18767625 |\n",
      "|    clip_fraction        | 0.177      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.94       |\n",
      "|    explained_variance   | 0.519      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.28e+06   |\n",
      "|    n_updates            | 56100      |\n",
      "|    policy_gradient_loss | 0.00936    |\n",
      "|    std                  | 0.212      |\n",
      "|    value_loss           | 2.15e+07   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 666       |\n",
      "|    ep_rew_mean     | -2.79e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 701       |\n",
      "|    iterations      | 525       |\n",
      "|    time_elapsed    | 1532      |\n",
      "|    total_timesteps | 1075200   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 688        |\n",
      "|    ep_rew_mean          | -2.76e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 701        |\n",
      "|    iterations           | 526        |\n",
      "|    time_elapsed         | 1534       |\n",
      "|    total_timesteps      | 1077248    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01792892 |\n",
      "|    clip_fraction        | 0.191      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.95       |\n",
      "|    explained_variance   | 0.972      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 419        |\n",
      "|    n_updates            | 56110      |\n",
      "|    policy_gradient_loss | 0.00857    |\n",
      "|    std                  | 0.211      |\n",
      "|    value_loss           | 1.72e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 702         |\n",
      "|    ep_rew_mean          | -2.76e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 702         |\n",
      "|    iterations           | 527         |\n",
      "|    time_elapsed         | 1536        |\n",
      "|    total_timesteps      | 1079296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009302237 |\n",
      "|    clip_fraction        | 0.0954      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.96        |\n",
      "|    explained_variance   | 0.843       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.89e+05    |\n",
      "|    n_updates            | 56120       |\n",
      "|    policy_gradient_loss | -0.0061     |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 8.47e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1080000, episode_reward=-70914.33 +/- 86417.98\n",
      "Episode length: 827.20 +/- 769.84\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 827        |\n",
      "|    mean_reward          | -7.09e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1080000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01301824 |\n",
      "|    clip_fraction        | 0.12       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.97       |\n",
      "|    explained_variance   | 0.875      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 363        |\n",
      "|    n_updates            | 56130      |\n",
      "|    policy_gradient_loss | 0.00043    |\n",
      "|    std                  | 0.21       |\n",
      "|    value_loss           | 3.36e+04   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 719       |\n",
      "|    ep_rew_mean     | -2.74e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 702       |\n",
      "|    iterations      | 528       |\n",
      "|    time_elapsed    | 1540      |\n",
      "|    total_timesteps | 1081344   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 731          |\n",
      "|    ep_rew_mean          | -2.9e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 702          |\n",
      "|    iterations           | 529          |\n",
      "|    time_elapsed         | 1542         |\n",
      "|    total_timesteps      | 1083392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039515486 |\n",
      "|    clip_fraction        | 0.0779       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.97         |\n",
      "|    explained_variance   | 0.457        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.66e+06     |\n",
      "|    n_updates            | 56140        |\n",
      "|    policy_gradient_loss | 0.00129      |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 3.33e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1085000, episode_reward=-38669.24 +/- 93257.15\n",
      "Episode length: 1154.00 +/- 853.77\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.15e+03     |\n",
      "|    mean_reward          | -3.87e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1085000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011137633 |\n",
      "|    clip_fraction        | 0.00244      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.97         |\n",
      "|    explained_variance   | 0.591        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.89e+05     |\n",
      "|    n_updates            | 56150        |\n",
      "|    policy_gradient_loss | -0.00238     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 1.5e+07      |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 751       |\n",
      "|    ep_rew_mean     | -2.85e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 701       |\n",
      "|    iterations      | 530       |\n",
      "|    time_elapsed    | 1546      |\n",
      "|    total_timesteps | 1085440   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 776         |\n",
      "|    ep_rew_mean          | -3.02e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 702         |\n",
      "|    iterations           | 531         |\n",
      "|    time_elapsed         | 1548        |\n",
      "|    total_timesteps      | 1087488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012123177 |\n",
      "|    clip_fraction        | 0.097       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.97        |\n",
      "|    explained_variance   | 0.877       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.52e+03    |\n",
      "|    n_updates            | 56160       |\n",
      "|    policy_gradient_loss | -0.00142    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 3.13e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 776         |\n",
      "|    ep_rew_mean          | -3.02e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 702         |\n",
      "|    iterations           | 532         |\n",
      "|    time_elapsed         | 1550        |\n",
      "|    total_timesteps      | 1089536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006473097 |\n",
      "|    clip_fraction        | 0.0396      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.97        |\n",
      "|    explained_variance   | 0.4         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.02e+06    |\n",
      "|    n_updates            | 56170       |\n",
      "|    policy_gradient_loss | 0.000364    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 2.27e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1090000, episode_reward=-4578.29 +/- 12987.47\n",
      "Episode length: 409.80 +/- 713.17\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 410         |\n",
      "|    mean_reward          | -4.58e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1090000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012412484 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.98        |\n",
      "|    explained_variance   | 0.874       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 624         |\n",
      "|    n_updates            | 56180       |\n",
      "|    policy_gradient_loss | 0.00219     |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 2.59e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 804       |\n",
      "|    ep_rew_mean     | -3.15e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 702       |\n",
      "|    iterations      | 533       |\n",
      "|    time_elapsed    | 1553      |\n",
      "|    total_timesteps | 1091584   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 786          |\n",
      "|    ep_rew_mean          | -3.37e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 703          |\n",
      "|    iterations           | 534          |\n",
      "|    time_elapsed         | 1555         |\n",
      "|    total_timesteps      | 1093632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045627854 |\n",
      "|    clip_fraction        | 0.035        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.98         |\n",
      "|    explained_variance   | 0.52         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.93e+07     |\n",
      "|    n_updates            | 56190        |\n",
      "|    policy_gradient_loss | -0.000722    |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 2.73e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1095000, episode_reward=-37486.12 +/- 53484.60\n",
      "Episode length: 286.80 +/- 506.18\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 287          |\n",
      "|    mean_reward          | -3.75e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1095000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013742929 |\n",
      "|    clip_fraction        | 0.0129       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.98         |\n",
      "|    explained_variance   | 0.574        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.66e+06     |\n",
      "|    n_updates            | 56200        |\n",
      "|    policy_gradient_loss | -0.000773    |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 2.35e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 781       |\n",
      "|    ep_rew_mean     | -3.25e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 703       |\n",
      "|    iterations      | 535       |\n",
      "|    time_elapsed    | 1557      |\n",
      "|    total_timesteps | 1095680   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 795        |\n",
      "|    ep_rew_mean          | -3.24e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 703        |\n",
      "|    iterations           | 536        |\n",
      "|    time_elapsed         | 1559       |\n",
      "|    total_timesteps      | 1097728    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01695916 |\n",
      "|    clip_fraction        | 0.163      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.98       |\n",
      "|    explained_variance   | 0.849      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 876        |\n",
      "|    n_updates            | 56210      |\n",
      "|    policy_gradient_loss | -0.00165   |\n",
      "|    std                  | 0.21       |\n",
      "|    value_loss           | 1.42e+05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 794         |\n",
      "|    ep_rew_mean          | -3.22e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 704         |\n",
      "|    iterations           | 537         |\n",
      "|    time_elapsed         | 1561        |\n",
      "|    total_timesteps      | 1099776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014247401 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.98        |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 486         |\n",
      "|    n_updates            | 56220       |\n",
      "|    policy_gradient_loss | -0.00187    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 4e+03       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1100000, episode_reward=-8116.10 +/- 24695.74\n",
      "Episode length: 871.60 +/- 1007.20\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 872         |\n",
      "|    mean_reward          | -8.12e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1100000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012632706 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.98        |\n",
      "|    explained_variance   | 0.922       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.49e+03    |\n",
      "|    n_updates            | 56230       |\n",
      "|    policy_gradient_loss | -0.00548    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 2.34e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 817       |\n",
      "|    ep_rew_mean     | -3.18e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 702       |\n",
      "|    iterations      | 538       |\n",
      "|    time_elapsed    | 1567      |\n",
      "|    total_timesteps | 1101824   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 832        |\n",
      "|    ep_rew_mean          | -3.32e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 703        |\n",
      "|    iterations           | 539        |\n",
      "|    time_elapsed         | 1569       |\n",
      "|    total_timesteps      | 1103872    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01209381 |\n",
      "|    clip_fraction        | 0.0891     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.98       |\n",
      "|    explained_variance   | 0.866      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.09e+03   |\n",
      "|    n_updates            | 56240      |\n",
      "|    policy_gradient_loss | -7.58e-05  |\n",
      "|    std                  | 0.21       |\n",
      "|    value_loss           | 3.4e+04    |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1105000, episode_reward=1471.50 +/- 4788.52\n",
      "Episode length: 520.60 +/- 847.20\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 521          |\n",
      "|    mean_reward          | 1.47e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1105000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040449603 |\n",
      "|    clip_fraction        | 0.047        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.98         |\n",
      "|    explained_variance   | 0.571        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.33e+07     |\n",
      "|    n_updates            | 56250        |\n",
      "|    policy_gradient_loss | 0.00214      |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 2.16e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 846      |\n",
      "|    ep_rew_mean     | -3.3e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 703      |\n",
      "|    iterations      | 540      |\n",
      "|    time_elapsed    | 1572     |\n",
      "|    total_timesteps | 1105920  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 861        |\n",
      "|    ep_rew_mean          | -3.15e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 703        |\n",
      "|    iterations           | 541        |\n",
      "|    time_elapsed         | 1574       |\n",
      "|    total_timesteps      | 1107968    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02487038 |\n",
      "|    clip_fraction        | 0.188      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.97       |\n",
      "|    explained_variance   | 0.982      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 472        |\n",
      "|    n_updates            | 56260      |\n",
      "|    policy_gradient_loss | 0.00605    |\n",
      "|    std                  | 0.211      |\n",
      "|    value_loss           | 2.15e+03   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1110000, episode_reward=-46307.28 +/- 90182.93\n",
      "Episode length: 540.40 +/- 877.42\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 540        |\n",
      "|    mean_reward          | -4.63e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1110000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.13630846 |\n",
      "|    clip_fraction        | 0.196      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.97       |\n",
      "|    explained_variance   | 0.567      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1e+07      |\n",
      "|    n_updates            | 56270      |\n",
      "|    policy_gradient_loss | -0.00154   |\n",
      "|    std                  | 0.211      |\n",
      "|    value_loss           | 1.14e+07   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 835       |\n",
      "|    ep_rew_mean     | -2.81e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 703       |\n",
      "|    iterations      | 542       |\n",
      "|    time_elapsed    | 1578      |\n",
      "|    total_timesteps | 1110016   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 833         |\n",
      "|    ep_rew_mean          | -2.81e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 703         |\n",
      "|    iterations           | 543         |\n",
      "|    time_elapsed         | 1579        |\n",
      "|    total_timesteps      | 1112064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006186582 |\n",
      "|    clip_fraction        | 0.0512      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.97        |\n",
      "|    explained_variance   | 0.624       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.86e+05    |\n",
      "|    n_updates            | 56280       |\n",
      "|    policy_gradient_loss | -0.00679    |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 1.17e+06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 834         |\n",
      "|    ep_rew_mean          | -2.36e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 704         |\n",
      "|    iterations           | 544         |\n",
      "|    time_elapsed         | 1581        |\n",
      "|    total_timesteps      | 1114112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018905375 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.96        |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 452         |\n",
      "|    n_updates            | 56290       |\n",
      "|    policy_gradient_loss | 0.000144    |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 2.66e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1115000, episode_reward=-90057.47 +/- 69208.72\n",
      "Episode length: 1345.20 +/- 1148.84\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.35e+03    |\n",
      "|    mean_reward          | -9.01e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1115000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006197034 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.97        |\n",
      "|    explained_variance   | 0.806       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.1e+03     |\n",
      "|    n_updates            | 56300       |\n",
      "|    policy_gradient_loss | -0.00161    |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 2.92e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 842       |\n",
      "|    ep_rew_mean     | -2.43e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 702       |\n",
      "|    iterations      | 545       |\n",
      "|    time_elapsed    | 1587      |\n",
      "|    total_timesteps | 1116160   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 850         |\n",
      "|    ep_rew_mean          | -2.54e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 703         |\n",
      "|    iterations           | 546         |\n",
      "|    time_elapsed         | 1589        |\n",
      "|    total_timesteps      | 1118208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.063047305 |\n",
      "|    clip_fraction        | 0.092       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.97        |\n",
      "|    explained_variance   | 0.592       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.05e+06    |\n",
      "|    n_updates            | 56310       |\n",
      "|    policy_gradient_loss | 0.00187     |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 5.85e+06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1120000, episode_reward=-60671.56 +/- 86044.53\n",
      "Episode length: 1649.20 +/- 1267.88\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.65e+03     |\n",
      "|    mean_reward          | -6.07e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1120000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062962403 |\n",
      "|    clip_fraction        | 0.0406       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.97         |\n",
      "|    explained_variance   | 0.547        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.89e+06     |\n",
      "|    n_updates            | 56320        |\n",
      "|    policy_gradient_loss | 0.00337      |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 2.08e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 861       |\n",
      "|    ep_rew_mean     | -2.53e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 702       |\n",
      "|    iterations      | 547       |\n",
      "|    time_elapsed    | 1595      |\n",
      "|    total_timesteps | 1120256   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 878          |\n",
      "|    ep_rew_mean          | -2.76e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 702          |\n",
      "|    iterations           | 548          |\n",
      "|    time_elapsed         | 1597         |\n",
      "|    total_timesteps      | 1122304      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0154872555 |\n",
      "|    clip_fraction        | 0.177        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.97         |\n",
      "|    explained_variance   | 0.934        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.26e+03     |\n",
      "|    n_updates            | 56330        |\n",
      "|    policy_gradient_loss | 0.00198      |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 7.41e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 888         |\n",
      "|    ep_rew_mean          | -2.72e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 703         |\n",
      "|    iterations           | 549         |\n",
      "|    time_elapsed         | 1599        |\n",
      "|    total_timesteps      | 1124352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009578971 |\n",
      "|    clip_fraction        | 0.0699      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.96        |\n",
      "|    explained_variance   | 0.541       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1e+07       |\n",
      "|    n_updates            | 56340       |\n",
      "|    policy_gradient_loss | -0.00176    |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 3.91e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1125000, episode_reward=-95696.59 +/- 48565.39\n",
      "Episode length: 1334.00 +/- 636.85\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.33e+03     |\n",
      "|    mean_reward          | -9.57e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1125000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028683464 |\n",
      "|    clip_fraction        | 0.0169       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.96         |\n",
      "|    explained_variance   | 0.57         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.08e+04     |\n",
      "|    n_updates            | 56350        |\n",
      "|    policy_gradient_loss | -0.00547     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 1.85e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 905       |\n",
      "|    ep_rew_mean     | -2.85e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 702       |\n",
      "|    iterations      | 550       |\n",
      "|    time_elapsed    | 1604      |\n",
      "|    total_timesteps | 1126400   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 918        |\n",
      "|    ep_rew_mean          | -2.95e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 702        |\n",
      "|    iterations           | 551        |\n",
      "|    time_elapsed         | 1605       |\n",
      "|    total_timesteps      | 1128448    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04365673 |\n",
      "|    clip_fraction        | 0.0774     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.96       |\n",
      "|    explained_variance   | 0.571      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.83e+07   |\n",
      "|    n_updates            | 56360      |\n",
      "|    policy_gradient_loss | 0.0179     |\n",
      "|    std                  | 0.211      |\n",
      "|    value_loss           | 2.03e+07   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1130000, episode_reward=-83272.57 +/- 38248.67\n",
      "Episode length: 965.40 +/- 753.83\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 965         |\n",
      "|    mean_reward          | -8.33e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1130000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013769226 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.96        |\n",
      "|    explained_variance   | 0.601       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.69e+06    |\n",
      "|    n_updates            | 56370       |\n",
      "|    policy_gradient_loss | 0.0108      |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 1.63e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 938       |\n",
      "|    ep_rew_mean     | -3.17e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 702       |\n",
      "|    iterations      | 552       |\n",
      "|    time_elapsed    | 1610      |\n",
      "|    total_timesteps | 1130496   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 951         |\n",
      "|    ep_rew_mean          | -3.3e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 702         |\n",
      "|    iterations           | 553         |\n",
      "|    time_elapsed         | 1611        |\n",
      "|    total_timesteps      | 1132544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006935332 |\n",
      "|    clip_fraction        | 0.0301      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.96        |\n",
      "|    explained_variance   | 0.572       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.18e+07    |\n",
      "|    n_updates            | 56380       |\n",
      "|    policy_gradient_loss | -0.00186    |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 3.21e+07    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 960          |\n",
      "|    ep_rew_mean          | -3.43e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 703          |\n",
      "|    iterations           | 554          |\n",
      "|    time_elapsed         | 1613         |\n",
      "|    total_timesteps      | 1134592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056308676 |\n",
      "|    clip_fraction        | 0.0561       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.562        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.45e+07     |\n",
      "|    n_updates            | 56390        |\n",
      "|    policy_gradient_loss | 0.00224      |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 2.4e+07      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1135000, episode_reward=-74614.59 +/- 70720.29\n",
      "Episode length: 942.20 +/- 707.81\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 942          |\n",
      "|    mean_reward          | -7.46e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1135000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010086935 |\n",
      "|    clip_fraction        | 0.00991      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.569        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.58e+04     |\n",
      "|    n_updates            | 56400        |\n",
      "|    policy_gradient_loss | 0.000298     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 2.54e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 964       |\n",
      "|    ep_rew_mean     | -3.47e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 702       |\n",
      "|    iterations      | 555       |\n",
      "|    time_elapsed    | 1617      |\n",
      "|    total_timesteps | 1136640   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 922         |\n",
      "|    ep_rew_mean          | -3.4e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 703         |\n",
      "|    iterations           | 556         |\n",
      "|    time_elapsed         | 1619        |\n",
      "|    total_timesteps      | 1138688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014729232 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.96        |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 893         |\n",
      "|    n_updates            | 56410       |\n",
      "|    policy_gradient_loss | 0.000745    |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 3.22e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1140000, episode_reward=-55111.62 +/- 35362.47\n",
      "Episode length: 1317.40 +/- 760.63\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.32e+03    |\n",
      "|    mean_reward          | -5.51e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1140000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010669215 |\n",
      "|    clip_fraction        | 0.0998      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.97        |\n",
      "|    explained_variance   | 0.643       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.58e+03    |\n",
      "|    n_updates            | 56420       |\n",
      "|    policy_gradient_loss | -0.000756   |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 1.18e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 914       |\n",
      "|    ep_rew_mean     | -3.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 701       |\n",
      "|    iterations      | 557       |\n",
      "|    time_elapsed    | 1626      |\n",
      "|    total_timesteps | 1140736   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 922         |\n",
      "|    ep_rew_mean          | -3.25e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 701         |\n",
      "|    iterations           | 558         |\n",
      "|    time_elapsed         | 1628        |\n",
      "|    total_timesteps      | 1142784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010843392 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.97        |\n",
      "|    explained_variance   | 0.765       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.42e+05    |\n",
      "|    n_updates            | 56430       |\n",
      "|    policy_gradient_loss | -0.0031     |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 1.15e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 926         |\n",
      "|    ep_rew_mean          | -3.31e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 702         |\n",
      "|    iterations           | 559         |\n",
      "|    time_elapsed         | 1630        |\n",
      "|    total_timesteps      | 1144832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012567291 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.97        |\n",
      "|    explained_variance   | 0.621       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.86e+06    |\n",
      "|    n_updates            | 56440       |\n",
      "|    policy_gradient_loss | 0.00918     |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 1.39e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1145000, episode_reward=-30993.66 +/- 45582.27\n",
      "Episode length: 1264.80 +/- 1091.12\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.26e+03    |\n",
      "|    mean_reward          | -3.1e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1145000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007555652 |\n",
      "|    clip_fraction        | 0.0623      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.97        |\n",
      "|    explained_variance   | 0.597       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.41e+06    |\n",
      "|    n_updates            | 56450       |\n",
      "|    policy_gradient_loss | -0.00418    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 2.1e+07     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 924       |\n",
      "|    ep_rew_mean     | -3.32e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 701       |\n",
      "|    iterations      | 560       |\n",
      "|    time_elapsed    | 1635      |\n",
      "|    total_timesteps | 1146880   |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 917       |\n",
      "|    ep_rew_mean          | -3.33e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 701       |\n",
      "|    iterations           | 561       |\n",
      "|    time_elapsed         | 1636      |\n",
      "|    total_timesteps      | 1148928   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0058821 |\n",
      "|    clip_fraction        | 0.0355    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 1.97      |\n",
      "|    explained_variance   | 0.619     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.46e+07  |\n",
      "|    n_updates            | 56460     |\n",
      "|    policy_gradient_loss | -0.00474  |\n",
      "|    std                  | 0.21      |\n",
      "|    value_loss           | 1.32e+07  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=1150000, episode_reward=-82800.65 +/- 14359.82\n",
      "Episode length: 1840.80 +/- 1470.55\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.84e+03    |\n",
      "|    mean_reward          | -8.28e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1150000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013911464 |\n",
      "|    clip_fraction        | 0.0974      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.97        |\n",
      "|    explained_variance   | 0.605       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.16e+07    |\n",
      "|    n_updates            | 56470       |\n",
      "|    policy_gradient_loss | -0.000369   |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 1.66e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 913       |\n",
      "|    ep_rew_mean     | -3.44e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 700       |\n",
      "|    iterations      | 562       |\n",
      "|    time_elapsed    | 1643      |\n",
      "|    total_timesteps | 1150976   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 913         |\n",
      "|    ep_rew_mean          | -3.44e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 700         |\n",
      "|    iterations           | 563         |\n",
      "|    time_elapsed         | 1644        |\n",
      "|    total_timesteps      | 1153024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010401363 |\n",
      "|    clip_fraction        | 0.0594      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.97        |\n",
      "|    explained_variance   | 0.58        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.05e+06    |\n",
      "|    n_updates            | 56480       |\n",
      "|    policy_gradient_loss | 0.000152    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 2.06e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1155000, episode_reward=-6634.19 +/- 7821.31\n",
      "Episode length: 106.20 +/- 14.78\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 106         |\n",
      "|    mean_reward          | -6.63e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1155000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009355681 |\n",
      "|    clip_fraction        | 0.0718      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.97        |\n",
      "|    explained_variance   | 0.894       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.45e+03    |\n",
      "|    n_updates            | 56490       |\n",
      "|    policy_gradient_loss | -0.00494    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 2.93e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 942       |\n",
      "|    ep_rew_mean     | -3.54e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 701       |\n",
      "|    iterations      | 564       |\n",
      "|    time_elapsed    | 1646      |\n",
      "|    total_timesteps | 1155072   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 954          |\n",
      "|    ep_rew_mean          | -3.44e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 701          |\n",
      "|    iterations           | 565          |\n",
      "|    time_elapsed         | 1648         |\n",
      "|    total_timesteps      | 1157120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056360653 |\n",
      "|    clip_fraction        | 0.0642       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.97         |\n",
      "|    explained_variance   | 0.598        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.26e+06     |\n",
      "|    n_updates            | 56500        |\n",
      "|    policy_gradient_loss | -0.00382     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 1.57e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 954          |\n",
      "|    ep_rew_mean          | -3.44e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 702          |\n",
      "|    iterations           | 566          |\n",
      "|    time_elapsed         | 1650         |\n",
      "|    total_timesteps      | 1159168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075988923 |\n",
      "|    clip_fraction        | 0.0589       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.97         |\n",
      "|    explained_variance   | 0.416        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.62e+05     |\n",
      "|    n_updates            | 56510        |\n",
      "|    policy_gradient_loss | -0.00162     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 5.65e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1160000, episode_reward=-18315.05 +/- 20373.17\n",
      "Episode length: 1652.60 +/- 1947.94\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.65e+03    |\n",
      "|    mean_reward          | -1.83e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1160000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011390546 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.97        |\n",
      "|    explained_variance   | 0.925       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 685         |\n",
      "|    n_updates            | 56520       |\n",
      "|    policy_gradient_loss | 0.00205     |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 7.68e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 980       |\n",
      "|    ep_rew_mean     | -3.42e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 701       |\n",
      "|    iterations      | 567       |\n",
      "|    time_elapsed    | 1656      |\n",
      "|    total_timesteps | 1161216   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 988         |\n",
      "|    ep_rew_mean          | -3.4e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 701         |\n",
      "|    iterations           | 568         |\n",
      "|    time_elapsed         | 1658        |\n",
      "|    total_timesteps      | 1163264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023815991 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.97        |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 685         |\n",
      "|    n_updates            | 56530       |\n",
      "|    policy_gradient_loss | 0.0062      |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 5.44e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1165000, episode_reward=28155.66 +/- 27597.97\n",
      "Episode length: 3031.00 +/- 2030.70\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.03e+03    |\n",
      "|    mean_reward          | 2.82e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1165000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006310149 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.97        |\n",
      "|    explained_variance   | 0.809       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.84e+04    |\n",
      "|    n_updates            | 56540       |\n",
      "|    policy_gradient_loss | -0.000479   |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 1.31e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 961       |\n",
      "|    ep_rew_mean     | -3.27e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 698       |\n",
      "|    iterations      | 569       |\n",
      "|    time_elapsed    | 1667      |\n",
      "|    total_timesteps | 1165312   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 963          |\n",
      "|    ep_rew_mean          | -3.28e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 699          |\n",
      "|    iterations           | 570          |\n",
      "|    time_elapsed         | 1669         |\n",
      "|    total_timesteps      | 1167360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055144206 |\n",
      "|    clip_fraction        | 0.0349       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.97         |\n",
      "|    explained_variance   | 0.736        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.92e+04     |\n",
      "|    n_updates            | 56550        |\n",
      "|    policy_gradient_loss | -0.00403     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 1.56e+05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 968         |\n",
      "|    ep_rew_mean          | -3.47e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 699         |\n",
      "|    iterations           | 571         |\n",
      "|    time_elapsed         | 1670        |\n",
      "|    total_timesteps      | 1169408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030103968 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.97        |\n",
      "|    explained_variance   | 0.954       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 540         |\n",
      "|    n_updates            | 56560       |\n",
      "|    policy_gradient_loss | 0.00928     |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 1.6e+04     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1170000, episode_reward=-63087.06 +/- 65473.53\n",
      "Episode length: 1742.20 +/- 1449.73\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.74e+03    |\n",
      "|    mean_reward          | -6.31e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1170000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028590623 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.97        |\n",
      "|    explained_variance   | 0.56        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.82e+07    |\n",
      "|    n_updates            | 56570       |\n",
      "|    policy_gradient_loss | 0.0144      |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 3.3e+07     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 978       |\n",
      "|    ep_rew_mean     | -3.46e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 698       |\n",
      "|    iterations      | 572       |\n",
      "|    time_elapsed    | 1676      |\n",
      "|    total_timesteps | 1171456   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 940         |\n",
      "|    ep_rew_mean          | -3.44e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 699         |\n",
      "|    iterations           | 573         |\n",
      "|    time_elapsed         | 1678        |\n",
      "|    total_timesteps      | 1173504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016439069 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.97        |\n",
      "|    explained_variance   | 0.802       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 493         |\n",
      "|    n_updates            | 56580       |\n",
      "|    policy_gradient_loss | 0.00388     |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 8.41e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1175000, episode_reward=3061.96 +/- 30322.18\n",
      "Episode length: 2486.80 +/- 1977.34\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.49e+03     |\n",
      "|    mean_reward          | 3.06e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1175000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075915717 |\n",
      "|    clip_fraction        | 0.0793       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.96         |\n",
      "|    explained_variance   | 0.635        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.28e+05     |\n",
      "|    n_updates            | 56590        |\n",
      "|    policy_gradient_loss | -0.00432     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 9.9e+06      |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 936       |\n",
      "|    ep_rew_mean     | -3.21e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 697       |\n",
      "|    iterations      | 574       |\n",
      "|    time_elapsed    | 1686      |\n",
      "|    total_timesteps | 1175552   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 936         |\n",
      "|    ep_rew_mean          | -3.21e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 697         |\n",
      "|    iterations           | 575         |\n",
      "|    time_elapsed         | 1688        |\n",
      "|    total_timesteps      | 1177600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023581598 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.96        |\n",
      "|    explained_variance   | 0.901       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.23e+03    |\n",
      "|    n_updates            | 56600       |\n",
      "|    policy_gradient_loss | 0.00255     |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 2.4e+04     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 936          |\n",
      "|    ep_rew_mean          | -3.21e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 697          |\n",
      "|    iterations           | 576          |\n",
      "|    time_elapsed         | 1690         |\n",
      "|    total_timesteps      | 1179648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049287155 |\n",
      "|    clip_fraction        | 0.0525       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.96         |\n",
      "|    explained_variance   | 0.912        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.2e+04      |\n",
      "|    n_updates            | 56610        |\n",
      "|    policy_gradient_loss | -0.00355     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 4.2e+04      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1180000, episode_reward=-5731.27 +/- 10578.57\n",
      "Episode length: 878.60 +/- 1572.20\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 879         |\n",
      "|    mean_reward          | -5.73e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1180000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010418166 |\n",
      "|    clip_fraction        | 0.084       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.96        |\n",
      "|    explained_variance   | 0.915       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 661         |\n",
      "|    n_updates            | 56620       |\n",
      "|    policy_gradient_loss | -0.002      |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 1.1e+04     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 951       |\n",
      "|    ep_rew_mean     | -3.07e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 697       |\n",
      "|    iterations      | 577       |\n",
      "|    time_elapsed    | 1694      |\n",
      "|    total_timesteps | 1181696   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 951         |\n",
      "|    ep_rew_mean          | -3.07e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 697         |\n",
      "|    iterations           | 578         |\n",
      "|    time_elapsed         | 1695        |\n",
      "|    total_timesteps      | 1183744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007840467 |\n",
      "|    clip_fraction        | 0.0535      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.96        |\n",
      "|    explained_variance   | 0.867       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.55e+03    |\n",
      "|    n_updates            | 56630       |\n",
      "|    policy_gradient_loss | -0.0052     |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 9.72e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1185000, episode_reward=-3375.85 +/- 37529.27\n",
      "Episode length: 1756.60 +/- 2080.73\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.76e+03    |\n",
      "|    mean_reward          | -3.38e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1185000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012036909 |\n",
      "|    clip_fraction        | 0.0565      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.95        |\n",
      "|    explained_variance   | 0.549       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.42e+06    |\n",
      "|    n_updates            | 56640       |\n",
      "|    policy_gradient_loss | -0.00309    |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 1.17e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 954       |\n",
      "|    ep_rew_mean     | -3.03e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 696       |\n",
      "|    iterations      | 579       |\n",
      "|    time_elapsed    | 1702      |\n",
      "|    total_timesteps | 1185792   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 954         |\n",
      "|    ep_rew_mean          | -3.03e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 697         |\n",
      "|    iterations           | 580         |\n",
      "|    time_elapsed         | 1704        |\n",
      "|    total_timesteps      | 1187840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016927488 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.95        |\n",
      "|    explained_variance   | 0.696       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.92e+04    |\n",
      "|    n_updates            | 56650       |\n",
      "|    policy_gradient_loss | 0.0048      |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 1.75e+06    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 987         |\n",
      "|    ep_rew_mean          | -2.83e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 696         |\n",
      "|    iterations           | 581         |\n",
      "|    time_elapsed         | 1708        |\n",
      "|    total_timesteps      | 1189888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025369333 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.95        |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 132         |\n",
      "|    n_updates            | 56660       |\n",
      "|    policy_gradient_loss | 0.00716     |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 769         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1190000, episode_reward=-11667.28 +/- 45639.05\n",
      "Episode length: 1762.40 +/- 2139.37\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.76e+03    |\n",
      "|    mean_reward          | -1.17e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1190000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009231659 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.95        |\n",
      "|    explained_variance   | 0.772       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 650         |\n",
      "|    n_updates            | 56670       |\n",
      "|    policy_gradient_loss | 0.00204     |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 4.55e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 981       |\n",
      "|    ep_rew_mean     | -2.82e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 695       |\n",
      "|    iterations      | 582       |\n",
      "|    time_elapsed    | 1714      |\n",
      "|    total_timesteps | 1191936   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -2.87e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 695         |\n",
      "|    iterations           | 583         |\n",
      "|    time_elapsed         | 1716        |\n",
      "|    total_timesteps      | 1193984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009099964 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.95        |\n",
      "|    explained_variance   | 0.498       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.57e+06    |\n",
      "|    n_updates            | 56680       |\n",
      "|    policy_gradient_loss | 0.00022     |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 1.38e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1195000, episode_reward=2854.00 +/- 18266.81\n",
      "Episode length: 1075.60 +/- 1809.82\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.08e+03     |\n",
      "|    mean_reward          | 2.85e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1195000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036450138 |\n",
      "|    clip_fraction        | 0.0541       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.658        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.05e+06     |\n",
      "|    n_updates            | 56690        |\n",
      "|    policy_gradient_loss | 0.00179      |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 9.11e+06     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -3.01e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 694       |\n",
      "|    iterations      | 584       |\n",
      "|    time_elapsed    | 1720      |\n",
      "|    total_timesteps | 1196032   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | -3.01e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 695          |\n",
      "|    iterations           | 585          |\n",
      "|    time_elapsed         | 1722         |\n",
      "|    total_timesteps      | 1198080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070115677 |\n",
      "|    clip_fraction        | 0.0433       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.527        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.94e+06     |\n",
      "|    n_updates            | 56700        |\n",
      "|    policy_gradient_loss | 0.000919     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 2.18e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1200000, episode_reward=23885.52 +/- 22253.49\n",
      "Episode length: 2649.00 +/- 2202.15\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.65e+03    |\n",
      "|    mean_reward          | 2.39e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1200000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018767694 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.94        |\n",
      "|    explained_variance   | 0.941       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 200         |\n",
      "|    n_updates            | 56710       |\n",
      "|    policy_gradient_loss | 0.00713     |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 1.39e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.03e+03  |\n",
      "|    ep_rew_mean     | -2.97e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 693       |\n",
      "|    iterations      | 586       |\n",
      "|    time_elapsed    | 1730      |\n",
      "|    total_timesteps | 1200128   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.03e+03    |\n",
      "|    ep_rew_mean          | -2.97e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 693         |\n",
      "|    iterations           | 587         |\n",
      "|    time_elapsed         | 1732        |\n",
      "|    total_timesteps      | 1202176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022959167 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.94        |\n",
      "|    explained_variance   | 0.881       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 418         |\n",
      "|    n_updates            | 56720       |\n",
      "|    policy_gradient_loss | 0.00074     |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 4.26e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.05e+03    |\n",
      "|    ep_rew_mean          | -2.95e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 694         |\n",
      "|    iterations           | 588         |\n",
      "|    time_elapsed         | 1734        |\n",
      "|    total_timesteps      | 1204224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007234295 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.94        |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 484         |\n",
      "|    n_updates            | 56730       |\n",
      "|    policy_gradient_loss | 0.00069     |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 6.62e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1205000, episode_reward=-4016.12 +/- 55815.43\n",
      "Episode length: 1937.20 +/- 2313.07\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.94e+03    |\n",
      "|    mean_reward          | -4.02e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1205000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020091735 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.94        |\n",
      "|    explained_variance   | 0.751       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 432         |\n",
      "|    n_updates            | 56740       |\n",
      "|    policy_gradient_loss | 0.00511     |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 2.79e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.07e+03  |\n",
      "|    ep_rew_mean     | -2.96e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 692       |\n",
      "|    iterations      | 589       |\n",
      "|    time_elapsed    | 1741      |\n",
      "|    total_timesteps | 1206272   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.07e+03     |\n",
      "|    ep_rew_mean          | -2.96e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 693          |\n",
      "|    iterations           | 590          |\n",
      "|    time_elapsed         | 1742         |\n",
      "|    total_timesteps      | 1208320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051507894 |\n",
      "|    clip_fraction        | 0.0957       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.93         |\n",
      "|    explained_variance   | 0.637        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.42e+03     |\n",
      "|    n_updates            | 56750        |\n",
      "|    policy_gradient_loss | 0.00125      |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 1.03e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1210000, episode_reward=-71938.53 +/- 95274.03\n",
      "Episode length: 2796.60 +/- 1599.43\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.8e+03     |\n",
      "|    mean_reward          | -7.19e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1210000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011788978 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.94        |\n",
      "|    explained_variance   | 0.94        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 292         |\n",
      "|    n_updates            | 56760       |\n",
      "|    policy_gradient_loss | -0.00094    |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 1.62e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.12e+03  |\n",
      "|    ep_rew_mean     | -3.13e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 691       |\n",
      "|    iterations      | 591       |\n",
      "|    time_elapsed    | 1751      |\n",
      "|    total_timesteps | 1210368   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.12e+03    |\n",
      "|    ep_rew_mean          | -3.13e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 691         |\n",
      "|    iterations           | 592         |\n",
      "|    time_elapsed         | 1753        |\n",
      "|    total_timesteps      | 1212416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021724638 |\n",
      "|    clip_fraction        | 0.464       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.94        |\n",
      "|    explained_variance   | 0.392       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.81e+07    |\n",
      "|    n_updates            | 56770       |\n",
      "|    policy_gradient_loss | 0.0313      |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 3.89e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.12e+03    |\n",
      "|    ep_rew_mean          | -3.13e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 691         |\n",
      "|    iterations           | 593         |\n",
      "|    time_elapsed         | 1755        |\n",
      "|    total_timesteps      | 1214464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009933357 |\n",
      "|    clip_fraction        | 0.0834      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.94        |\n",
      "|    explained_variance   | 0.946       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 418         |\n",
      "|    n_updates            | 56780       |\n",
      "|    policy_gradient_loss | -0.000518   |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 5.47e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1215000, episode_reward=-84173.58 +/- 107091.85\n",
      "Episode length: 780.20 +/- 1335.04\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 780         |\n",
      "|    mean_reward          | -8.42e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1215000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006341353 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.95        |\n",
      "|    explained_variance   | 0.83        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.65e+04    |\n",
      "|    n_updates            | 56790       |\n",
      "|    policy_gradient_loss | -0.00201    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 1.02e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.13e+03  |\n",
      "|    ep_rew_mean     | -2.95e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 691       |\n",
      "|    iterations      | 594       |\n",
      "|    time_elapsed    | 1758      |\n",
      "|    total_timesteps | 1216512   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.13e+03    |\n",
      "|    ep_rew_mean          | -2.95e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 692         |\n",
      "|    iterations           | 595         |\n",
      "|    time_elapsed         | 1760        |\n",
      "|    total_timesteps      | 1218560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005169631 |\n",
      "|    clip_fraction        | 0.0333      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.95        |\n",
      "|    explained_variance   | 0.913       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.65e+03    |\n",
      "|    n_updates            | 56800       |\n",
      "|    policy_gradient_loss | -0.00536    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 3.34e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1220000, episode_reward=-76738.52 +/- 70395.20\n",
      "Episode length: 1716.60 +/- 1750.28\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.72e+03    |\n",
      "|    mean_reward          | -7.67e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1220000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011572853 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.95        |\n",
      "|    explained_variance   | 0.924       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 551         |\n",
      "|    n_updates            | 56810       |\n",
      "|    policy_gradient_loss | -0.00276    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 3.39e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.16e+03  |\n",
      "|    ep_rew_mean     | -3.06e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 690       |\n",
      "|    iterations      | 596       |\n",
      "|    time_elapsed    | 1766      |\n",
      "|    total_timesteps | 1220608   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.16e+03    |\n",
      "|    ep_rew_mean          | -3.06e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 691         |\n",
      "|    iterations           | 597         |\n",
      "|    time_elapsed         | 1768        |\n",
      "|    total_timesteps      | 1222656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002672559 |\n",
      "|    clip_fraction        | 0.0253      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.95        |\n",
      "|    explained_variance   | 0.502       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.72e+06    |\n",
      "|    n_updates            | 56820       |\n",
      "|    policy_gradient_loss | 0.000205    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 2.56e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.16e+03    |\n",
      "|    ep_rew_mean          | -3.38e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 691         |\n",
      "|    iterations           | 598         |\n",
      "|    time_elapsed         | 1770        |\n",
      "|    total_timesteps      | 1224704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007998097 |\n",
      "|    clip_fraction        | 0.0585      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.95        |\n",
      "|    explained_variance   | 0.882       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.93e+04    |\n",
      "|    n_updates            | 56830       |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 1.53e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1225000, episode_reward=-50162.71 +/- 103189.47\n",
      "Episode length: 1169.80 +/- 1924.32\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.17e+03     |\n",
      "|    mean_reward          | -5.02e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1225000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009289847 |\n",
      "|    clip_fraction        | 0.000977     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.511        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.09e+07     |\n",
      "|    n_updates            | 56840        |\n",
      "|    policy_gradient_loss | -0.000603    |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 7.7e+07      |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.16e+03  |\n",
      "|    ep_rew_mean     | -3.38e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 690       |\n",
      "|    iterations      | 599       |\n",
      "|    time_elapsed    | 1775      |\n",
      "|    total_timesteps | 1226752   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.16e+03    |\n",
      "|    ep_rew_mean          | -3.38e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 691         |\n",
      "|    iterations           | 600         |\n",
      "|    time_elapsed         | 1777        |\n",
      "|    total_timesteps      | 1228800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013939395 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.95        |\n",
      "|    explained_variance   | 0.949       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 454         |\n",
      "|    n_updates            | 56850       |\n",
      "|    policy_gradient_loss | 0.00254     |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 2.2e+03     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1230000, episode_reward=-26827.69 +/- 73237.26\n",
      "Episode length: 1655.00 +/- 2037.69\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.66e+03    |\n",
      "|    mean_reward          | -2.68e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1230000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013089528 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.95        |\n",
      "|    explained_variance   | 0.933       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 686         |\n",
      "|    n_updates            | 56860       |\n",
      "|    policy_gradient_loss | -0.000765   |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 3.44e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.2e+03  |\n",
      "|    ep_rew_mean     | -3.6e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 690      |\n",
      "|    iterations      | 601      |\n",
      "|    time_elapsed    | 1783     |\n",
      "|    total_timesteps | 1230848  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.2e+03     |\n",
      "|    ep_rew_mean          | -3.6e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 690         |\n",
      "|    iterations           | 602         |\n",
      "|    time_elapsed         | 1785        |\n",
      "|    total_timesteps      | 1232896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012869036 |\n",
      "|    clip_fraction        | 0.08        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.96        |\n",
      "|    explained_variance   | 0.519       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.2e+07     |\n",
      "|    n_updates            | 56870       |\n",
      "|    policy_gradient_loss | 0.00731     |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 4.42e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.25e+03    |\n",
      "|    ep_rew_mean          | -3.58e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 691         |\n",
      "|    iterations           | 603         |\n",
      "|    time_elapsed         | 1786        |\n",
      "|    total_timesteps      | 1234944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012019384 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.96        |\n",
      "|    explained_variance   | 0.922       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 546         |\n",
      "|    n_updates            | 56880       |\n",
      "|    policy_gradient_loss | -0.0032     |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 2.81e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1235000, episode_reward=36812.55 +/- 29805.02\n",
      "Episode length: 3038.60 +/- 2402.22\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.04e+03    |\n",
      "|    mean_reward          | 3.68e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1235000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017088037 |\n",
      "|    clip_fraction        | 0.0971      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.96        |\n",
      "|    explained_variance   | 0.573       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7e+06       |\n",
      "|    n_updates            | 56890       |\n",
      "|    policy_gradient_loss | 0.00347     |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 9.1e+06     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.25e+03  |\n",
      "|    ep_rew_mean     | -3.58e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 688       |\n",
      "|    iterations      | 604       |\n",
      "|    time_elapsed    | 1796      |\n",
      "|    total_timesteps | 1236992   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.25e+03    |\n",
      "|    ep_rew_mean          | -3.58e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 689         |\n",
      "|    iterations           | 605         |\n",
      "|    time_elapsed         | 1798        |\n",
      "|    total_timesteps      | 1239040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019056937 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.97        |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 182         |\n",
      "|    n_updates            | 56900       |\n",
      "|    policy_gradient_loss | 0.00449     |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 700         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1240000, episode_reward=883.27 +/- 29396.07\n",
      "Episode length: 1178.40 +/- 1925.75\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.18e+03   |\n",
      "|    mean_reward          | 883        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1240000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02155669 |\n",
      "|    clip_fraction        | 0.218      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.98       |\n",
      "|    explained_variance   | 0.907      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 534        |\n",
      "|    n_updates            | 56910      |\n",
      "|    policy_gradient_loss | 0.0118     |\n",
      "|    std                  | 0.209      |\n",
      "|    value_loss           | 2.8e+03    |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.28e+03  |\n",
      "|    ep_rew_mean     | -3.58e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 688       |\n",
      "|    iterations      | 606       |\n",
      "|    time_elapsed    | 1802      |\n",
      "|    total_timesteps | 1241088   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.3e+03     |\n",
      "|    ep_rew_mean          | -3.63e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 688         |\n",
      "|    iterations           | 607         |\n",
      "|    time_elapsed         | 1804        |\n",
      "|    total_timesteps      | 1243136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008609043 |\n",
      "|    clip_fraction        | 0.0758      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.99        |\n",
      "|    explained_variance   | 0.736       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 787         |\n",
      "|    n_updates            | 56920       |\n",
      "|    policy_gradient_loss | -0.00334    |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 5.22e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1245000, episode_reward=25622.38 +/- 27828.06\n",
      "Episode length: 2733.00 +/- 2265.33\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.73e+03     |\n",
      "|    mean_reward          | 2.56e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1245000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0113815665 |\n",
      "|    clip_fraction        | 0.0671       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.99         |\n",
      "|    explained_variance   | 0.426        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.28e+06     |\n",
      "|    n_updates            | 56930        |\n",
      "|    policy_gradient_loss | -0.0034      |\n",
      "|    std                  | 0.209        |\n",
      "|    value_loss           | 3.84e+06     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.3e+03   |\n",
      "|    ep_rew_mean     | -3.85e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 686       |\n",
      "|    iterations      | 608       |\n",
      "|    time_elapsed    | 1812      |\n",
      "|    total_timesteps | 1245184   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.3e+03      |\n",
      "|    ep_rew_mean          | -3.84e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 687          |\n",
      "|    iterations           | 609          |\n",
      "|    time_elapsed         | 1814         |\n",
      "|    total_timesteps      | 1247232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038229427 |\n",
      "|    clip_fraction        | 0.0417       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.99         |\n",
      "|    explained_variance   | 0.508        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.6e+07      |\n",
      "|    n_updates            | 56940        |\n",
      "|    policy_gradient_loss | 0.000466     |\n",
      "|    std                  | 0.209        |\n",
      "|    value_loss           | 3.12e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.3e+03      |\n",
      "|    ep_rew_mean          | -3.84e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 687          |\n",
      "|    iterations           | 610          |\n",
      "|    time_elapsed         | 1816         |\n",
      "|    total_timesteps      | 1249280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062645865 |\n",
      "|    clip_fraction        | 0.0355       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.99         |\n",
      "|    explained_variance   | 0.718        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.66e+04     |\n",
      "|    n_updates            | 56950        |\n",
      "|    policy_gradient_loss | -0.00406     |\n",
      "|    std                  | 0.209        |\n",
      "|    value_loss           | 1.24e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1250000, episode_reward=15273.14 +/- 63550.52\n",
      "Episode length: 3011.80 +/- 2435.07\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.01e+03    |\n",
      "|    mean_reward          | 1.53e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1250000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010868644 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.99        |\n",
      "|    explained_variance   | 0.907       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 242         |\n",
      "|    n_updates            | 56960       |\n",
      "|    policy_gradient_loss | -4.13e-05   |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 3.69e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.3e+03   |\n",
      "|    ep_rew_mean     | -3.53e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 685       |\n",
      "|    iterations      | 611       |\n",
      "|    time_elapsed    | 1825      |\n",
      "|    total_timesteps | 1251328   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.3e+03     |\n",
      "|    ep_rew_mean          | -3.39e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 685         |\n",
      "|    iterations           | 612         |\n",
      "|    time_elapsed         | 1827        |\n",
      "|    total_timesteps      | 1253376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010753894 |\n",
      "|    clip_fraction        | 0.0921      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.99        |\n",
      "|    explained_variance   | 0.803       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.7e+04     |\n",
      "|    n_updates            | 56970       |\n",
      "|    policy_gradient_loss | 0.00174     |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 9.03e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1255000, episode_reward=-13825.95 +/- 89187.97\n",
      "Episode length: 3591.00 +/- 1912.04\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.59e+03    |\n",
      "|    mean_reward          | -1.38e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1255000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011232588 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.98        |\n",
      "|    explained_variance   | 0.537       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.1e+03     |\n",
      "|    n_updates            | 56980       |\n",
      "|    policy_gradient_loss | 0.0044      |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 4.63e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.3e+03   |\n",
      "|    ep_rew_mean     | -3.39e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 683       |\n",
      "|    iterations      | 613       |\n",
      "|    time_elapsed    | 1837      |\n",
      "|    total_timesteps | 1255424   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.3e+03     |\n",
      "|    ep_rew_mean          | -3.39e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 683         |\n",
      "|    iterations           | 614         |\n",
      "|    time_elapsed         | 1839        |\n",
      "|    total_timesteps      | 1257472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013381032 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.99        |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 238         |\n",
      "|    n_updates            | 56990       |\n",
      "|    policy_gradient_loss | 0.00681     |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 838         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.3e+03     |\n",
      "|    ep_rew_mean          | -3.07e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 683         |\n",
      "|    iterations           | 615         |\n",
      "|    time_elapsed         | 1841        |\n",
      "|    total_timesteps      | 1259520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010078328 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2           |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 333         |\n",
      "|    n_updates            | 57000       |\n",
      "|    policy_gradient_loss | 0.00286     |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 1.36e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1260000, episode_reward=-58517.55 +/- 84222.28\n",
      "Episode length: 2045.60 +/- 1859.10\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.05e+03    |\n",
      "|    mean_reward          | -5.85e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1260000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006228311 |\n",
      "|    clip_fraction        | 0.0436      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.01        |\n",
      "|    explained_variance   | 0.567       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.43e+06    |\n",
      "|    n_updates            | 57010       |\n",
      "|    policy_gradient_loss | -0.00251    |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 1.24e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.3e+03   |\n",
      "|    ep_rew_mean     | -3.07e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 682       |\n",
      "|    iterations      | 616       |\n",
      "|    time_elapsed    | 1848      |\n",
      "|    total_timesteps | 1261568   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.33e+03    |\n",
      "|    ep_rew_mean          | -3.17e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 682         |\n",
      "|    iterations           | 617         |\n",
      "|    time_elapsed         | 1850        |\n",
      "|    total_timesteps      | 1263616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026307724 |\n",
      "|    clip_fraction        | 0.27        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.02        |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 139         |\n",
      "|    n_updates            | 57020       |\n",
      "|    policy_gradient_loss | 0.00619     |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 614         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1265000, episode_reward=-149055.08 +/- 149332.76\n",
      "Episode length: 728.40 +/- 830.77\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 728        |\n",
      "|    mean_reward          | -1.49e+05  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1265000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09161258 |\n",
      "|    clip_fraction        | 0.536      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.02       |\n",
      "|    explained_variance   | 0.463      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.08e+07   |\n",
      "|    n_updates            | 57030      |\n",
      "|    policy_gradient_loss | 0.0433     |\n",
      "|    std                  | 0.208      |\n",
      "|    value_loss           | 4.47e+07   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.26e+03  |\n",
      "|    ep_rew_mean     | -3.34e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 682       |\n",
      "|    iterations      | 618       |\n",
      "|    time_elapsed    | 1853      |\n",
      "|    total_timesteps | 1265664   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.24e+03     |\n",
      "|    ep_rew_mean          | -3.48e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 683          |\n",
      "|    iterations           | 619          |\n",
      "|    time_elapsed         | 1855         |\n",
      "|    total_timesteps      | 1267712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016296844 |\n",
      "|    clip_fraction        | 0.00381      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.02         |\n",
      "|    explained_variance   | 0.502        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.93e+07     |\n",
      "|    n_updates            | 57040        |\n",
      "|    policy_gradient_loss | -0.00219     |\n",
      "|    std                  | 0.208        |\n",
      "|    value_loss           | 7.58e+07     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.24e+03    |\n",
      "|    ep_rew_mean          | -3.33e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 683         |\n",
      "|    iterations           | 620         |\n",
      "|    time_elapsed         | 1857        |\n",
      "|    total_timesteps      | 1269760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007324255 |\n",
      "|    clip_fraction        | 0.044       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.02        |\n",
      "|    explained_variance   | 0.533       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.87e+07    |\n",
      "|    n_updates            | 57050       |\n",
      "|    policy_gradient_loss | -0.00508    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 6.25e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1270000, episode_reward=-135663.82 +/- 162104.98\n",
      "Episode length: 789.60 +/- 851.96\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 790          |\n",
      "|    mean_reward          | -1.36e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1270000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071312115 |\n",
      "|    clip_fraction        | 0.0519       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.02         |\n",
      "|    explained_variance   | 0.848        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.32e+03     |\n",
      "|    n_updates            | 57060        |\n",
      "|    policy_gradient_loss | -0.00157     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 5.57e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.24e+03  |\n",
      "|    ep_rew_mean     | -3.31e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 683       |\n",
      "|    iterations      | 621       |\n",
      "|    time_elapsed    | 1861      |\n",
      "|    total_timesteps | 1271808   |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.24e+03  |\n",
      "|    ep_rew_mean          | -3.31e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 683       |\n",
      "|    iterations           | 622       |\n",
      "|    time_elapsed         | 1863      |\n",
      "|    total_timesteps      | 1273856   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.1976769 |\n",
      "|    clip_fraction        | 0.521     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 2.03      |\n",
      "|    explained_variance   | 0.951     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 161       |\n",
      "|    n_updates            | 57070     |\n",
      "|    policy_gradient_loss | 0.0101    |\n",
      "|    std                  | 0.207     |\n",
      "|    value_loss           | 1.36e+03  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=1275000, episode_reward=-61322.20 +/- 108010.20\n",
      "Episode length: 74.60 +/- 56.24\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 74.6        |\n",
      "|    mean_reward          | -6.13e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1275000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017016381 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.03        |\n",
      "|    explained_variance   | 0.919       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 581         |\n",
      "|    n_updates            | 57080       |\n",
      "|    policy_gradient_loss | 0.00168     |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 4.29e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.29e+03  |\n",
      "|    ep_rew_mean     | -3.23e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 684       |\n",
      "|    iterations      | 623       |\n",
      "|    time_elapsed    | 1865      |\n",
      "|    total_timesteps | 1275904   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.29e+03   |\n",
      "|    ep_rew_mean          | -3.23e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 684        |\n",
      "|    iterations           | 624        |\n",
      "|    time_elapsed         | 1866       |\n",
      "|    total_timesteps      | 1277952    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01684277 |\n",
      "|    clip_fraction        | 0.167      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.03       |\n",
      "|    explained_variance   | 0.963      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 267        |\n",
      "|    n_updates            | 57090      |\n",
      "|    policy_gradient_loss | 4.86e-05   |\n",
      "|    std                  | 0.207      |\n",
      "|    value_loss           | 4.35e+03   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1280000, episode_reward=15814.88 +/- 27651.21\n",
      "Episode length: 2040.60 +/- 2416.55\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.04e+03     |\n",
      "|    mean_reward          | 1.58e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1280000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068403054 |\n",
      "|    clip_fraction        | 0.132        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.02         |\n",
      "|    explained_variance   | 0.954        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 230          |\n",
      "|    n_updates            | 57100        |\n",
      "|    policy_gradient_loss | 0.000612     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 1.62e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.25e+03  |\n",
      "|    ep_rew_mean     | -3.01e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 683       |\n",
      "|    iterations      | 625       |\n",
      "|    time_elapsed    | 1873      |\n",
      "|    total_timesteps | 1280000   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.25e+03     |\n",
      "|    ep_rew_mean          | -3.01e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 683          |\n",
      "|    iterations           | 626          |\n",
      "|    time_elapsed         | 1875         |\n",
      "|    total_timesteps      | 1282048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061319964 |\n",
      "|    clip_fraction        | 0.0509       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.02         |\n",
      "|    explained_variance   | 0.639        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.25e+03     |\n",
      "|    n_updates            | 57110        |\n",
      "|    policy_gradient_loss | -0.00422     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 4.32e+06     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.25e+03     |\n",
      "|    ep_rew_mean          | -3.01e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 684          |\n",
      "|    iterations           | 627          |\n",
      "|    time_elapsed         | 1877         |\n",
      "|    total_timesteps      | 1284096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0151393395 |\n",
      "|    clip_fraction        | 0.164        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.02         |\n",
      "|    explained_variance   | 0.98         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 316          |\n",
      "|    n_updates            | 57120        |\n",
      "|    policy_gradient_loss | 0.000374     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 853          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1285000, episode_reward=35436.62 +/- 28383.93\n",
      "Episode length: 3046.00 +/- 2393.16\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.05e+03    |\n",
      "|    mean_reward          | 3.54e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1285000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009403083 |\n",
      "|    clip_fraction        | 0.388       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.03        |\n",
      "|    explained_variance   | 0.954       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.36e+03    |\n",
      "|    n_updates            | 57130       |\n",
      "|    policy_gradient_loss | 0.0214      |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 6.31e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.21e+03  |\n",
      "|    ep_rew_mean     | -2.97e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 681       |\n",
      "|    iterations      | 628       |\n",
      "|    time_elapsed    | 1886      |\n",
      "|    total_timesteps | 1286144   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.21e+03     |\n",
      "|    ep_rew_mean          | -2.95e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 682          |\n",
      "|    iterations           | 629          |\n",
      "|    time_elapsed         | 1888         |\n",
      "|    total_timesteps      | 1288192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042532473 |\n",
      "|    clip_fraction        | 0.0133       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.03         |\n",
      "|    explained_variance   | 0.775        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.76e+04     |\n",
      "|    n_updates            | 57140        |\n",
      "|    policy_gradient_loss | -0.00259     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 1.3e+06      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1290000, episode_reward=8944.99 +/- 24038.77\n",
      "Episode length: 1216.40 +/- 1911.31\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.22e+03    |\n",
      "|    mean_reward          | 8.94e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1290000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007358309 |\n",
      "|    clip_fraction        | 0.0964      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.03        |\n",
      "|    explained_variance   | 0.796       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.03e+03    |\n",
      "|    n_updates            | 57150       |\n",
      "|    policy_gradient_loss | -0.00513    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1.39e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.21e+03  |\n",
      "|    ep_rew_mean     | -2.95e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 681       |\n",
      "|    iterations      | 630       |\n",
      "|    time_elapsed    | 1892      |\n",
      "|    total_timesteps | 1290240   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.26e+03    |\n",
      "|    ep_rew_mean          | -2.89e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 682         |\n",
      "|    iterations           | 631         |\n",
      "|    time_elapsed         | 1894        |\n",
      "|    total_timesteps      | 1292288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010960296 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.02        |\n",
      "|    explained_variance   | 0.92        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.72e+03    |\n",
      "|    n_updates            | 57160       |\n",
      "|    policy_gradient_loss | -0.00931    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 3.74e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.26e+03    |\n",
      "|    ep_rew_mean          | -2.89e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 682         |\n",
      "|    iterations           | 632         |\n",
      "|    time_elapsed         | 1896        |\n",
      "|    total_timesteps      | 1294336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005800897 |\n",
      "|    clip_fraction        | 0.0505      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.02        |\n",
      "|    explained_variance   | 0.797       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.54e+04    |\n",
      "|    n_updates            | 57170       |\n",
      "|    policy_gradient_loss | -0.00347    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1.18e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1295000, episode_reward=-181.64 +/- 1485.57\n",
      "Episode length: 154.60 +/- 165.56\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 155         |\n",
      "|    mean_reward          | -182        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1295000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028960353 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.02        |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 385         |\n",
      "|    n_updates            | 57180       |\n",
      "|    policy_gradient_loss | 0.00269     |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1.3e+03     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.26e+03  |\n",
      "|    ep_rew_mean     | -2.89e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 682       |\n",
      "|    iterations      | 633       |\n",
      "|    time_elapsed    | 1898      |\n",
      "|    total_timesteps | 1296384   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.25e+03     |\n",
      "|    ep_rew_mean          | -2.56e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 683          |\n",
      "|    iterations           | 634          |\n",
      "|    time_elapsed         | 1900         |\n",
      "|    total_timesteps      | 1298432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0148016885 |\n",
      "|    clip_fraction        | 0.247        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.02         |\n",
      "|    explained_variance   | 0.964        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 112          |\n",
      "|    n_updates            | 57190        |\n",
      "|    policy_gradient_loss | 0.0102       |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 811          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1300000, episode_reward=-8647.04 +/- 9055.74\n",
      "Episode length: 331.00 +/- 462.54\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 331         |\n",
      "|    mean_reward          | -8.65e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1300000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011976128 |\n",
      "|    clip_fraction        | 0.0715      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.01        |\n",
      "|    explained_variance   | 0.814       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.15e+03    |\n",
      "|    n_updates            | 57200       |\n",
      "|    policy_gradient_loss | -0.00181    |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 6.9e+04     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.27e+03  |\n",
      "|    ep_rew_mean     | -2.56e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 683       |\n",
      "|    iterations      | 635       |\n",
      "|    time_elapsed    | 1903      |\n",
      "|    total_timesteps | 1300480   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.27e+03     |\n",
      "|    ep_rew_mean          | -2.7e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 683          |\n",
      "|    iterations           | 636          |\n",
      "|    time_elapsed         | 1905         |\n",
      "|    total_timesteps      | 1302528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0097066015 |\n",
      "|    clip_fraction        | 0.0693       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.01         |\n",
      "|    explained_variance   | 0.315        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.41e+05     |\n",
      "|    n_updates            | 57210        |\n",
      "|    policy_gradient_loss | 0.00363      |\n",
      "|    std                  | 0.208        |\n",
      "|    value_loss           | 1.14e+06     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.2e+03      |\n",
      "|    ep_rew_mean          | -2.72e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 684          |\n",
      "|    iterations           | 637          |\n",
      "|    time_elapsed         | 1906         |\n",
      "|    total_timesteps      | 1304576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052353917 |\n",
      "|    clip_fraction        | 0.0332       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.01         |\n",
      "|    explained_variance   | 0.522        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.76e+06     |\n",
      "|    n_updates            | 57220        |\n",
      "|    policy_gradient_loss | -0.00677     |\n",
      "|    std                  | 0.208        |\n",
      "|    value_loss           | 1.11e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1305000, episode_reward=-56415.87 +/- 109620.70\n",
      "Episode length: 363.80 +/- 552.04\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 364          |\n",
      "|    mean_reward          | -5.64e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1305000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028731003 |\n",
      "|    clip_fraction        | 0.0157       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.01         |\n",
      "|    explained_variance   | 0.529        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.63e+05     |\n",
      "|    n_updates            | 57230        |\n",
      "|    policy_gradient_loss | -0.000785    |\n",
      "|    std                  | 0.208        |\n",
      "|    value_loss           | 4.65e+06     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.18e+03  |\n",
      "|    ep_rew_mean     | -3.03e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 684       |\n",
      "|    iterations      | 638       |\n",
      "|    time_elapsed    | 1909      |\n",
      "|    total_timesteps | 1306624   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.12e+03     |\n",
      "|    ep_rew_mean          | -2.92e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 684          |\n",
      "|    iterations           | 639          |\n",
      "|    time_elapsed         | 1911         |\n",
      "|    total_timesteps      | 1308672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028435504 |\n",
      "|    clip_fraction        | 0.0041       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.01         |\n",
      "|    explained_variance   | 0.528        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.46e+07     |\n",
      "|    n_updates            | 57240        |\n",
      "|    policy_gradient_loss | -0.000638    |\n",
      "|    std                  | 0.208        |\n",
      "|    value_loss           | 4.82e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1310000, episode_reward=-19888.10 +/- 20411.12\n",
      "Episode length: 443.60 +/- 468.57\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 444         |\n",
      "|    mean_reward          | -1.99e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1310000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003850261 |\n",
      "|    clip_fraction        | 0.0254      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.01        |\n",
      "|    explained_variance   | 0.543       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.59e+07    |\n",
      "|    n_updates            | 57250       |\n",
      "|    policy_gradient_loss | 0.000792    |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 3.33e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 870       |\n",
      "|    ep_rew_mean     | -2.65e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 684       |\n",
      "|    iterations      | 640       |\n",
      "|    time_elapsed    | 1914      |\n",
      "|    total_timesteps | 1310720   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 782         |\n",
      "|    ep_rew_mean          | -2.29e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 685         |\n",
      "|    iterations           | 641         |\n",
      "|    time_elapsed         | 1916        |\n",
      "|    total_timesteps      | 1312768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005728727 |\n",
      "|    clip_fraction        | 0.0228      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.01        |\n",
      "|    explained_variance   | 0.636       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.13e+06    |\n",
      "|    n_updates            | 57260       |\n",
      "|    policy_gradient_loss | -0.00354    |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 3.6e+06     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 739          |\n",
      "|    ep_rew_mean          | -2.3e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 685          |\n",
      "|    iterations           | 642          |\n",
      "|    time_elapsed         | 1918         |\n",
      "|    total_timesteps      | 1314816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028841174 |\n",
      "|    clip_fraction        | 0.0228       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.01         |\n",
      "|    explained_variance   | 0.694        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.41e+05     |\n",
      "|    n_updates            | 57270        |\n",
      "|    policy_gradient_loss | -0.00252     |\n",
      "|    std                  | 0.208        |\n",
      "|    value_loss           | 5.22e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1315000, episode_reward=-14731.26 +/- 4886.14\n",
      "Episode length: 750.20 +/- 428.09\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 750         |\n",
      "|    mean_reward          | -1.47e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1315000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027592978 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.01        |\n",
      "|    explained_variance   | 0.581       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.9e+05     |\n",
      "|    n_updates            | 57280       |\n",
      "|    policy_gradient_loss | 0.00401     |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 5.25e+06    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 733       |\n",
      "|    ep_rew_mean     | -2.05e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 685       |\n",
      "|    iterations      | 643       |\n",
      "|    time_elapsed    | 1921      |\n",
      "|    total_timesteps | 1316864   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 714         |\n",
      "|    ep_rew_mean          | -2.07e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 685         |\n",
      "|    iterations           | 644         |\n",
      "|    time_elapsed         | 1923        |\n",
      "|    total_timesteps      | 1318912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011125155 |\n",
      "|    clip_fraction        | 0.0996      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.01        |\n",
      "|    explained_variance   | 0.815       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.03e+04    |\n",
      "|    n_updates            | 57290       |\n",
      "|    policy_gradient_loss | -0.00532    |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 1.58e+05    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1320000, episode_reward=-18100.58 +/- 15109.86\n",
      "Episode length: 462.20 +/- 811.15\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 462         |\n",
      "|    mean_reward          | -1.81e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1320000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012595214 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.01        |\n",
      "|    explained_variance   | 0.705       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.86e+04    |\n",
      "|    n_updates            | 57300       |\n",
      "|    policy_gradient_loss | -0.000527   |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 4.07e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 695       |\n",
      "|    ep_rew_mean     | -2.13e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 685       |\n",
      "|    iterations      | 645       |\n",
      "|    time_elapsed    | 1926      |\n",
      "|    total_timesteps | 1320960   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 697         |\n",
      "|    ep_rew_mean          | -2.15e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 685         |\n",
      "|    iterations           | 646         |\n",
      "|    time_elapsed         | 1928        |\n",
      "|    total_timesteps      | 1323008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009292852 |\n",
      "|    clip_fraction        | 0.0563      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.01        |\n",
      "|    explained_variance   | 0.66        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.39e+06    |\n",
      "|    n_updates            | 57310       |\n",
      "|    policy_gradient_loss | -0.00225    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 4.61e+06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1325000, episode_reward=-7817.14 +/- 21287.89\n",
      "Episode length: 1516.60 +/- 1968.10\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.52e+03    |\n",
      "|    mean_reward          | -7.82e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1325000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007764572 |\n",
      "|    clip_fraction        | 0.0732      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.02        |\n",
      "|    explained_variance   | 0.854       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.67e+05    |\n",
      "|    n_updates            | 57320       |\n",
      "|    policy_gradient_loss | -0.00269    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1.23e+06    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 662       |\n",
      "|    ep_rew_mean     | -2.17e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 685       |\n",
      "|    iterations      | 647       |\n",
      "|    time_elapsed    | 1934      |\n",
      "|    total_timesteps | 1325056   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 670         |\n",
      "|    ep_rew_mean          | -2.11e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 685         |\n",
      "|    iterations           | 648         |\n",
      "|    time_elapsed         | 1936        |\n",
      "|    total_timesteps      | 1327104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024513185 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.02        |\n",
      "|    explained_variance   | 0.846       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.12e+04    |\n",
      "|    n_updates            | 57330       |\n",
      "|    policy_gradient_loss | -0.00247    |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 5.72e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 670         |\n",
      "|    ep_rew_mean          | -2.11e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 685         |\n",
      "|    iterations           | 649         |\n",
      "|    time_elapsed         | 1937        |\n",
      "|    total_timesteps      | 1329152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025499212 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.01        |\n",
      "|    explained_variance   | 0.875       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 191         |\n",
      "|    n_updates            | 57340       |\n",
      "|    policy_gradient_loss | 0.00799     |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1.42e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1330000, episode_reward=-53887.23 +/- 129494.51\n",
      "Episode length: 1258.60 +/- 1896.34\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.26e+03    |\n",
      "|    mean_reward          | -5.39e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1330000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007954387 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.02        |\n",
      "|    explained_variance   | 0.91        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.26e+03    |\n",
      "|    n_updates            | 57350       |\n",
      "|    policy_gradient_loss | 0.000358    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 6.1e+03     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 658       |\n",
      "|    ep_rew_mean     | -1.87e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 685       |\n",
      "|    iterations      | 650       |\n",
      "|    time_elapsed    | 1942      |\n",
      "|    total_timesteps | 1331200   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 683         |\n",
      "|    ep_rew_mean          | -1.86e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 685         |\n",
      "|    iterations           | 651         |\n",
      "|    time_elapsed         | 1944        |\n",
      "|    total_timesteps      | 1333248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006258919 |\n",
      "|    clip_fraction        | 0.0578      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.01        |\n",
      "|    explained_variance   | 0.601       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.88e+06    |\n",
      "|    n_updates            | 57360       |\n",
      "|    policy_gradient_loss | -0.00453    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 6.03e+06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1335000, episode_reward=25120.05 +/- 27060.79\n",
      "Episode length: 3020.80 +/- 2424.15\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.02e+03    |\n",
      "|    mean_reward          | 2.51e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1335000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006806619 |\n",
      "|    clip_fraction        | 0.061       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.01        |\n",
      "|    explained_variance   | 0.901       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 974         |\n",
      "|    n_updates            | 57370       |\n",
      "|    policy_gradient_loss | -0.00156    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 3.8e+04     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 699       |\n",
      "|    ep_rew_mean     | -1.79e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 683       |\n",
      "|    iterations      | 652       |\n",
      "|    time_elapsed    | 1953      |\n",
      "|    total_timesteps | 1335296   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 699         |\n",
      "|    ep_rew_mean          | -1.79e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 683         |\n",
      "|    iterations           | 653         |\n",
      "|    time_elapsed         | 1955        |\n",
      "|    total_timesteps      | 1337344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025816865 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.01        |\n",
      "|    explained_variance   | 0.786       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 380         |\n",
      "|    n_updates            | 57380       |\n",
      "|    policy_gradient_loss | 0.00248     |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1e+05       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 699         |\n",
      "|    ep_rew_mean          | -1.79e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 684         |\n",
      "|    iterations           | 654         |\n",
      "|    time_elapsed         | 1957        |\n",
      "|    total_timesteps      | 1339392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008152951 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.02        |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.23e+03    |\n",
      "|    n_updates            | 57390       |\n",
      "|    policy_gradient_loss | -0.00348    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 9.25e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1340000, episode_reward=10015.33 +/- 20837.51\n",
      "Episode length: 1603.40 +/- 1975.69\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.6e+03      |\n",
      "|    mean_reward          | 1e+04        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1340000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055457796 |\n",
      "|    clip_fraction        | 0.0707       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.02         |\n",
      "|    explained_variance   | 0.93         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.38e+03     |\n",
      "|    n_updates            | 57400        |\n",
      "|    policy_gradient_loss | -0.00289     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 1.84e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 761       |\n",
      "|    ep_rew_mean     | -1.81e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 683       |\n",
      "|    iterations      | 655       |\n",
      "|    time_elapsed    | 1963      |\n",
      "|    total_timesteps | 1341440   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 775        |\n",
      "|    ep_rew_mean          | -1.51e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 683        |\n",
      "|    iterations           | 656        |\n",
      "|    time_elapsed         | 1964       |\n",
      "|    total_timesteps      | 1343488    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00267379 |\n",
      "|    clip_fraction        | 0.00791    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.02       |\n",
      "|    explained_variance   | 0.522      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 8.76e+05   |\n",
      "|    n_updates            | 57410      |\n",
      "|    policy_gradient_loss | -0.00213   |\n",
      "|    std                  | 0.207      |\n",
      "|    value_loss           | 3.2e+06    |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1345000, episode_reward=-94628.08 +/- 76372.71\n",
      "Episode length: 1982.60 +/- 2367.22\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.98e+03    |\n",
      "|    mean_reward          | -9.46e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1345000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019899037 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.01        |\n",
      "|    explained_variance   | 0.924       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 362         |\n",
      "|    n_updates            | 57420       |\n",
      "|    policy_gradient_loss | 5.99e-05    |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 2.62e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 754       |\n",
      "|    ep_rew_mean     | -1.29e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 682       |\n",
      "|    iterations      | 657       |\n",
      "|    time_elapsed    | 1971      |\n",
      "|    total_timesteps | 1345536   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 754          |\n",
      "|    ep_rew_mean          | -1.29e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 682          |\n",
      "|    iterations           | 658          |\n",
      "|    time_elapsed         | 1973         |\n",
      "|    total_timesteps      | 1347584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044146795 |\n",
      "|    clip_fraction        | 0.05         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.01         |\n",
      "|    explained_variance   | 0.662        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.71e+06     |\n",
      "|    n_updates            | 57430        |\n",
      "|    policy_gradient_loss | -9.45e-05    |\n",
      "|    std                  | 0.208        |\n",
      "|    value_loss           | 8.16e+06     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 699        |\n",
      "|    ep_rew_mean          | -1.64e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 683        |\n",
      "|    iterations           | 659        |\n",
      "|    time_elapsed         | 1975       |\n",
      "|    total_timesteps      | 1349632    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01055845 |\n",
      "|    clip_fraction        | 0.0655     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.01       |\n",
      "|    explained_variance   | 0.959      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 794        |\n",
      "|    n_updates            | 57440      |\n",
      "|    policy_gradient_loss | -0.000725  |\n",
      "|    std                  | 0.208      |\n",
      "|    value_loss           | 7.92e+03   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1350000, episode_reward=-90121.11 +/- 118303.01\n",
      "Episode length: 246.20 +/- 283.79\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 246          |\n",
      "|    mean_reward          | -9.01e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1350000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017478033 |\n",
      "|    clip_fraction        | 0.0311       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.01         |\n",
      "|    explained_variance   | 0.51         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.61e+07     |\n",
      "|    n_updates            | 57450        |\n",
      "|    policy_gradient_loss | -0.00159     |\n",
      "|    std                  | 0.208        |\n",
      "|    value_loss           | 5.14e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 712       |\n",
      "|    ep_rew_mean     | -1.63e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 683       |\n",
      "|    iterations      | 660       |\n",
      "|    time_elapsed    | 1977      |\n",
      "|    total_timesteps | 1351680   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 712          |\n",
      "|    ep_rew_mean          | -1.63e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 683          |\n",
      "|    iterations           | 661          |\n",
      "|    time_elapsed         | 1979         |\n",
      "|    total_timesteps      | 1353728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046678185 |\n",
      "|    clip_fraction        | 0.0327       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.01         |\n",
      "|    explained_variance   | 0.915        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.18e+04     |\n",
      "|    n_updates            | 57460        |\n",
      "|    policy_gradient_loss | -0.00488     |\n",
      "|    std                  | 0.208        |\n",
      "|    value_loss           | 1.55e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1355000, episode_reward=-89103.70 +/- 67276.00\n",
      "Episode length: 989.40 +/- 1153.64\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 989         |\n",
      "|    mean_reward          | -8.91e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1355000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011410978 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.01        |\n",
      "|    explained_variance   | 0.924       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.19e+03    |\n",
      "|    n_updates            | 57470       |\n",
      "|    policy_gradient_loss | -0.0063     |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 8.74e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 744       |\n",
      "|    ep_rew_mean     | -1.58e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 683       |\n",
      "|    iterations      | 662       |\n",
      "|    time_elapsed    | 1983      |\n",
      "|    total_timesteps | 1355776   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 744         |\n",
      "|    ep_rew_mean          | -1.58e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 683         |\n",
      "|    iterations           | 663         |\n",
      "|    time_elapsed         | 1985        |\n",
      "|    total_timesteps      | 1357824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009522829 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.02        |\n",
      "|    explained_variance   | 0.814       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.87e+05    |\n",
      "|    n_updates            | 57480       |\n",
      "|    policy_gradient_loss | 0.00443     |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 3.35e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 750         |\n",
      "|    ep_rew_mean          | -1.59e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 684         |\n",
      "|    iterations           | 664         |\n",
      "|    time_elapsed         | 1987        |\n",
      "|    total_timesteps      | 1359872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007158313 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.02        |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 917         |\n",
      "|    n_updates            | 57490       |\n",
      "|    policy_gradient_loss | -0.000515   |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 7.4e+03     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1360000, episode_reward=3727.25 +/- 88819.03\n",
      "Episode length: 3627.20 +/- 1838.24\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3.63e+03     |\n",
      "|    mean_reward          | 3.73e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1360000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010036284 |\n",
      "|    clip_fraction        | 0.0296       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.02         |\n",
      "|    explained_variance   | 0.437        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.79e+06     |\n",
      "|    n_updates            | 57500        |\n",
      "|    policy_gradient_loss | -0.000377    |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 2.04e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 758       |\n",
      "|    ep_rew_mean     | -2.11e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 681       |\n",
      "|    iterations      | 665       |\n",
      "|    time_elapsed    | 1997      |\n",
      "|    total_timesteps | 1361920   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 759        |\n",
      "|    ep_rew_mean          | -2.11e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 682        |\n",
      "|    iterations           | 666        |\n",
      "|    time_elapsed         | 1999       |\n",
      "|    total_timesteps      | 1363968    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00311486 |\n",
      "|    clip_fraction        | 0.00615    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.02       |\n",
      "|    explained_variance   | 0.512      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.4e+07    |\n",
      "|    n_updates            | 57510      |\n",
      "|    policy_gradient_loss | -0.004     |\n",
      "|    std                  | 0.207      |\n",
      "|    value_loss           | 7.08e+07   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1365000, episode_reward=27372.62 +/- 42823.91\n",
      "Episode length: 3030.60 +/- 2412.04\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3.03e+03     |\n",
      "|    mean_reward          | 2.74e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1365000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059814984 |\n",
      "|    clip_fraction        | 0.0695       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.02         |\n",
      "|    explained_variance   | 0.837        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.01e+04     |\n",
      "|    n_updates            | 57520        |\n",
      "|    policy_gradient_loss | -0.00324     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 3.83e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 759       |\n",
      "|    ep_rew_mean     | -2.11e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 680       |\n",
      "|    iterations      | 667       |\n",
      "|    time_elapsed    | 2008      |\n",
      "|    total_timesteps | 1366016   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 757         |\n",
      "|    ep_rew_mean          | -2.22e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 680         |\n",
      "|    iterations           | 668         |\n",
      "|    time_elapsed         | 2010        |\n",
      "|    total_timesteps      | 1368064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014900365 |\n",
      "|    clip_fraction        | 0.307       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.03        |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 353         |\n",
      "|    n_updates            | 57530       |\n",
      "|    policy_gradient_loss | 0.0244      |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1.68e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1370000, episode_reward=-101188.56 +/- 159405.29\n",
      "Episode length: 491.80 +/- 516.92\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 492        |\n",
      "|    mean_reward          | -1.01e+05  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1370000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.24847949 |\n",
      "|    clip_fraction        | 0.149      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.03       |\n",
      "|    explained_variance   | 0.604      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 232        |\n",
      "|    n_updates            | 57540      |\n",
      "|    policy_gradient_loss | 0.0358     |\n",
      "|    std                  | 0.206      |\n",
      "|    value_loss           | 7.34e+06   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 757       |\n",
      "|    ep_rew_mean     | -2.22e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 680       |\n",
      "|    iterations      | 669       |\n",
      "|    time_elapsed    | 2013      |\n",
      "|    total_timesteps | 1370112   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 757        |\n",
      "|    ep_rew_mean          | -2.19e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 680        |\n",
      "|    iterations           | 670        |\n",
      "|    time_elapsed         | 2015       |\n",
      "|    total_timesteps      | 1372160    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00885131 |\n",
      "|    clip_fraction        | 0.122      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.03       |\n",
      "|    explained_variance   | 0.951      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 286        |\n",
      "|    n_updates            | 57550      |\n",
      "|    policy_gradient_loss | 0.00337    |\n",
      "|    std                  | 0.207      |\n",
      "|    value_loss           | 1.59e+03   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 774        |\n",
      "|    ep_rew_mean          | -2.28e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 681        |\n",
      "|    iterations           | 671        |\n",
      "|    time_elapsed         | 2017       |\n",
      "|    total_timesteps      | 1374208    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01916358 |\n",
      "|    clip_fraction        | 0.193      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.03       |\n",
      "|    explained_variance   | 0.521      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 7.78e+04   |\n",
      "|    n_updates            | 57560      |\n",
      "|    policy_gradient_loss | -5.62e-05  |\n",
      "|    std                  | 0.207      |\n",
      "|    value_loss           | 5.54e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1375000, episode_reward=-86195.98 +/- 184011.83\n",
      "Episode length: 1071.80 +/- 858.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.07e+03     |\n",
      "|    mean_reward          | -8.62e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1375000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050775874 |\n",
      "|    clip_fraction        | 0.074        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.03         |\n",
      "|    explained_variance   | 0.608        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.97e+05     |\n",
      "|    n_updates            | 57570        |\n",
      "|    policy_gradient_loss | -0.00569     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 9.09e+06     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 774       |\n",
      "|    ep_rew_mean     | -2.28e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 680       |\n",
      "|    iterations      | 672       |\n",
      "|    time_elapsed    | 2021      |\n",
      "|    total_timesteps | 1376256   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 774         |\n",
      "|    ep_rew_mean          | -2.28e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 681         |\n",
      "|    iterations           | 673         |\n",
      "|    time_elapsed         | 2023        |\n",
      "|    total_timesteps      | 1378304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014023382 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.04        |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 294         |\n",
      "|    n_updates            | 57580       |\n",
      "|    policy_gradient_loss | -0.00132    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1.51e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1380000, episode_reward=-39410.70 +/- 32058.50\n",
      "Episode length: 757.40 +/- 516.42\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 757         |\n",
      "|    mean_reward          | -3.94e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1380000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034128096 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.04        |\n",
      "|    explained_variance   | 0.948       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 279         |\n",
      "|    n_updates            | 57590       |\n",
      "|    policy_gradient_loss | 0.00394     |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 3.32e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 803       |\n",
      "|    ep_rew_mean     | -2.37e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 680       |\n",
      "|    iterations      | 674       |\n",
      "|    time_elapsed    | 2027      |\n",
      "|    total_timesteps | 1380352   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 791         |\n",
      "|    ep_rew_mean          | -2.55e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 681         |\n",
      "|    iterations           | 675         |\n",
      "|    time_elapsed         | 2029        |\n",
      "|    total_timesteps      | 1382400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005423677 |\n",
      "|    clip_fraction        | 0.0695      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.04        |\n",
      "|    explained_variance   | 0.515       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.19e+06    |\n",
      "|    n_updates            | 57600       |\n",
      "|    policy_gradient_loss | -0.00623    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1.75e+07    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 788          |\n",
      "|    ep_rew_mean          | -2.46e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 681          |\n",
      "|    iterations           | 676          |\n",
      "|    time_elapsed         | 2031         |\n",
      "|    total_timesteps      | 1384448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053198095 |\n",
      "|    clip_fraction        | 0.017        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.04         |\n",
      "|    explained_variance   | 0.455        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.35e+07     |\n",
      "|    n_updates            | 57610        |\n",
      "|    policy_gradient_loss | 0.000606     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 5.31e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1385000, episode_reward=-124690.63 +/- 177900.23\n",
      "Episode length: 513.60 +/- 475.85\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 514         |\n",
      "|    mean_reward          | -1.25e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1385000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008947574 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.04        |\n",
      "|    explained_variance   | 0.798       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.27e+05    |\n",
      "|    n_updates            | 57620       |\n",
      "|    policy_gradient_loss | -0.0038     |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 2.22e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 791       |\n",
      "|    ep_rew_mean     | -2.31e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 681       |\n",
      "|    iterations      | 677       |\n",
      "|    time_elapsed    | 2034      |\n",
      "|    total_timesteps | 1386496   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 806          |\n",
      "|    ep_rew_mean          | -2.75e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 681          |\n",
      "|    iterations           | 678          |\n",
      "|    time_elapsed         | 2036         |\n",
      "|    total_timesteps      | 1388544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041976185 |\n",
      "|    clip_fraction        | 0.0503       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.04         |\n",
      "|    explained_variance   | 0.676        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.18e+06     |\n",
      "|    n_updates            | 57630        |\n",
      "|    policy_gradient_loss | -0.00286     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 6.19e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1390000, episode_reward=-143270.36 +/- 122076.73\n",
      "Episode length: 551.40 +/- 466.87\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 551         |\n",
      "|    mean_reward          | -1.43e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1390000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004473648 |\n",
      "|    clip_fraction        | 0.0253      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.04        |\n",
      "|    explained_variance   | 0.488       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.29e+07    |\n",
      "|    n_updates            | 57640       |\n",
      "|    policy_gradient_loss | -0.0019     |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1.13e+08    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 808       |\n",
      "|    ep_rew_mean     | -2.81e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 681       |\n",
      "|    iterations      | 679       |\n",
      "|    time_elapsed    | 2039      |\n",
      "|    total_timesteps | 1390592   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 833          |\n",
      "|    ep_rew_mean          | -2.83e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 682          |\n",
      "|    iterations           | 680          |\n",
      "|    time_elapsed         | 2041         |\n",
      "|    total_timesteps      | 1392640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036500741 |\n",
      "|    clip_fraction        | 0.0304       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.04         |\n",
      "|    explained_variance   | 0.617        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.94e+06     |\n",
      "|    n_updates            | 57650        |\n",
      "|    policy_gradient_loss | -0.000797    |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 9.47e+06     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 833        |\n",
      "|    ep_rew_mean          | -3.11e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 682        |\n",
      "|    iterations           | 681        |\n",
      "|    time_elapsed         | 2042       |\n",
      "|    total_timesteps      | 1394688    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00526675 |\n",
      "|    clip_fraction        | 0.0459     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.04       |\n",
      "|    explained_variance   | 0.901      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.02e+04   |\n",
      "|    n_updates            | 57660      |\n",
      "|    policy_gradient_loss | -0.00715   |\n",
      "|    std                  | 0.207      |\n",
      "|    value_loss           | 4.33e+05   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1395000, episode_reward=-134833.51 +/- 187002.91\n",
      "Episode length: 1099.20 +/- 1579.73\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.1e+03      |\n",
      "|    mean_reward          | -1.35e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1395000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031219306 |\n",
      "|    clip_fraction        | 0.0242       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.04         |\n",
      "|    explained_variance   | 0.487        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.23e+06     |\n",
      "|    n_updates            | 57670        |\n",
      "|    policy_gradient_loss | -0.00277     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 4.59e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 836       |\n",
      "|    ep_rew_mean     | -3.14e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 682       |\n",
      "|    iterations      | 682       |\n",
      "|    time_elapsed    | 2047      |\n",
      "|    total_timesteps | 1396736   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 863          |\n",
      "|    ep_rew_mean          | -3.39e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 682          |\n",
      "|    iterations           | 683          |\n",
      "|    time_elapsed         | 2049         |\n",
      "|    total_timesteps      | 1398784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029610163 |\n",
      "|    clip_fraction        | 0.0145       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.04         |\n",
      "|    explained_variance   | 0.645        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.03e+05     |\n",
      "|    n_updates            | 57680        |\n",
      "|    policy_gradient_loss | -0.00244     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 1.28e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1400000, episode_reward=-65112.61 +/- 98171.70\n",
      "Episode length: 202.80 +/- 178.29\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 203         |\n",
      "|    mean_reward          | -6.51e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1400000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003501397 |\n",
      "|    clip_fraction        | 0.0218      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.04        |\n",
      "|    explained_variance   | 0.456       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.48e+07    |\n",
      "|    n_updates            | 57690       |\n",
      "|    policy_gradient_loss | -0.00304    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 4.12e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 876       |\n",
      "|    ep_rew_mean     | -4.19e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 682       |\n",
      "|    iterations      | 684       |\n",
      "|    time_elapsed    | 2051      |\n",
      "|    total_timesteps | 1400832   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 861         |\n",
      "|    ep_rew_mean          | -4.55e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 683         |\n",
      "|    iterations           | 685         |\n",
      "|    time_elapsed         | 2053        |\n",
      "|    total_timesteps      | 1402880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008240599 |\n",
      "|    clip_fraction        | 0.0693      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.04        |\n",
      "|    explained_variance   | 0.499       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.46e+07    |\n",
      "|    n_updates            | 57700       |\n",
      "|    policy_gradient_loss | -0.00399    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1.47e+08    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 847         |\n",
      "|    ep_rew_mean          | -5.36e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 683         |\n",
      "|    iterations           | 686         |\n",
      "|    time_elapsed         | 2055        |\n",
      "|    total_timesteps      | 1404928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007848222 |\n",
      "|    clip_fraction        | 0.0961      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.04        |\n",
      "|    explained_variance   | 0.492       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.47e+07    |\n",
      "|    n_updates            | 57710       |\n",
      "|    policy_gradient_loss | 0.00607     |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1.33e+08    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1405000, episode_reward=-97199.45 +/- 133945.80\n",
      "Episode length: 2628.00 +/- 1999.05\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.63e+03    |\n",
      "|    mean_reward          | -9.72e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1405000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007737805 |\n",
      "|    clip_fraction        | 0.0705      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.04        |\n",
      "|    explained_variance   | 0.48        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.34e+07    |\n",
      "|    n_updates            | 57720       |\n",
      "|    policy_gradient_loss | 0.00159     |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1.13e+08    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 854       |\n",
      "|    ep_rew_mean     | -5.36e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 681       |\n",
      "|    iterations      | 687       |\n",
      "|    time_elapsed    | 2063      |\n",
      "|    total_timesteps | 1406976   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 866        |\n",
      "|    ep_rew_mean          | -5.57e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 682        |\n",
      "|    iterations           | 688        |\n",
      "|    time_elapsed         | 2065       |\n",
      "|    total_timesteps      | 1409024    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01362989 |\n",
      "|    clip_fraction        | 0.0874     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.04       |\n",
      "|    explained_variance   | 0.709      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.76e+03   |\n",
      "|    n_updates            | 57730      |\n",
      "|    policy_gradient_loss | -0.00152   |\n",
      "|    std                  | 0.207      |\n",
      "|    value_loss           | 1.47e+06   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1410000, episode_reward=2732.97 +/- 24001.79\n",
      "Episode length: 1416.80 +/- 1819.18\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.42e+03    |\n",
      "|    mean_reward          | 2.73e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1410000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002236811 |\n",
      "|    clip_fraction        | 0.0177      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.04        |\n",
      "|    explained_variance   | 0.515       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.37e+06    |\n",
      "|    n_updates            | 57740       |\n",
      "|    policy_gradient_loss | -0.00376    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 3.61e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 866       |\n",
      "|    ep_rew_mean     | -5.57e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 681       |\n",
      "|    iterations      | 689       |\n",
      "|    time_elapsed    | 2070      |\n",
      "|    total_timesteps | 1411072   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 915         |\n",
      "|    ep_rew_mean          | -5.51e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 681         |\n",
      "|    iterations           | 690         |\n",
      "|    time_elapsed         | 2072        |\n",
      "|    total_timesteps      | 1413120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020582061 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.04        |\n",
      "|    explained_variance   | 0.82        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.32e+03    |\n",
      "|    n_updates            | 57750       |\n",
      "|    policy_gradient_loss | 0.00229     |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 4.21e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1415000, episode_reward=-102779.53 +/- 189288.94\n",
      "Episode length: 170.00 +/- 132.46\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 170         |\n",
      "|    mean_reward          | -1.03e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1415000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010397487 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.04        |\n",
      "|    explained_variance   | 0.933       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 387         |\n",
      "|    n_updates            | 57760       |\n",
      "|    policy_gradient_loss | 0.00165     |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 1.86e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 926       |\n",
      "|    ep_rew_mean     | -5.57e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 682       |\n",
      "|    iterations      | 691       |\n",
      "|    time_elapsed    | 2074      |\n",
      "|    total_timesteps | 1415168   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 910          |\n",
      "|    ep_rew_mean          | -5.64e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 682          |\n",
      "|    iterations           | 692          |\n",
      "|    time_elapsed         | 2076         |\n",
      "|    total_timesteps      | 1417216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061271437 |\n",
      "|    clip_fraction        | 0.0276       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.05         |\n",
      "|    explained_variance   | 0.678        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.48e+05     |\n",
      "|    n_updates            | 57770        |\n",
      "|    policy_gradient_loss | -0.000318    |\n",
      "|    std                  | 0.206        |\n",
      "|    value_loss           | 7.72e+06     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 930         |\n",
      "|    ep_rew_mean          | -5.67e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 682         |\n",
      "|    iterations           | 693         |\n",
      "|    time_elapsed         | 2078        |\n",
      "|    total_timesteps      | 1419264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019303277 |\n",
      "|    clip_fraction        | 0.0688      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.05        |\n",
      "|    explained_variance   | 0.563       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.44e+06    |\n",
      "|    n_updates            | 57780       |\n",
      "|    policy_gradient_loss | -0.0012     |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 7.25e+06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1420000, episode_reward=-19188.56 +/- 28904.05\n",
      "Episode length: 223.80 +/- 305.24\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 224         |\n",
      "|    mean_reward          | -1.92e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1420000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008361815 |\n",
      "|    clip_fraction        | 0.0708      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.05        |\n",
      "|    explained_variance   | 0.765       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.97e+06    |\n",
      "|    n_updates            | 57790       |\n",
      "|    policy_gradient_loss | -0.00526    |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 3.98e+06    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 882       |\n",
      "|    ep_rew_mean     | -5.63e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 683       |\n",
      "|    iterations      | 694       |\n",
      "|    time_elapsed    | 2080      |\n",
      "|    total_timesteps | 1421312   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 884         |\n",
      "|    ep_rew_mean          | -6.1e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 683         |\n",
      "|    iterations           | 695         |\n",
      "|    time_elapsed         | 2082        |\n",
      "|    total_timesteps      | 1423360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014546277 |\n",
      "|    clip_fraction        | 0.0971      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.05        |\n",
      "|    explained_variance   | 0.629       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.29e+04    |\n",
      "|    n_updates            | 57800       |\n",
      "|    policy_gradient_loss | 0.00097     |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 4.51e+06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1425000, episode_reward=-20464.09 +/- 13918.94\n",
      "Episode length: 206.00 +/- 164.95\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 206       |\n",
      "|    mean_reward          | -2.05e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 1425000   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0110384 |\n",
      "|    clip_fraction        | 0.116     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 2.05      |\n",
      "|    explained_variance   | 0.505     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.47e+07  |\n",
      "|    n_updates            | 57810     |\n",
      "|    policy_gradient_loss | 0.00425   |\n",
      "|    std                  | 0.206     |\n",
      "|    value_loss           | 8.25e+07  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 838       |\n",
      "|    ep_rew_mean     | -6.07e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 683       |\n",
      "|    iterations      | 696       |\n",
      "|    time_elapsed    | 2084      |\n",
      "|    total_timesteps | 1425408   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 791         |\n",
      "|    ep_rew_mean          | -5.9e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 684         |\n",
      "|    iterations           | 697         |\n",
      "|    time_elapsed         | 2086        |\n",
      "|    total_timesteps      | 1427456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013599893 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.05        |\n",
      "|    explained_variance   | 0.792       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 759         |\n",
      "|    n_updates            | 57820       |\n",
      "|    policy_gradient_loss | -0.00294    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 8.47e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 802         |\n",
      "|    ep_rew_mean          | -5.93e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 684         |\n",
      "|    iterations           | 698         |\n",
      "|    time_elapsed         | 2088        |\n",
      "|    total_timesteps      | 1429504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005949182 |\n",
      "|    clip_fraction        | 0.0987      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.04        |\n",
      "|    explained_variance   | 0.538       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.96e+06    |\n",
      "|    n_updates            | 57830       |\n",
      "|    policy_gradient_loss | -0.00335    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1.59e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1430000, episode_reward=-6960.09 +/- 9441.72\n",
      "Episode length: 311.60 +/- 394.19\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 312         |\n",
      "|    mean_reward          | -6.96e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1430000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007987187 |\n",
      "|    clip_fraction        | 0.0885      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.04        |\n",
      "|    explained_variance   | 0.857       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.57e+03    |\n",
      "|    n_updates            | 57840       |\n",
      "|    policy_gradient_loss | -0.00468    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 2.3e+05     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 801       |\n",
      "|    ep_rew_mean     | -5.92e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 684       |\n",
      "|    iterations      | 699       |\n",
      "|    time_elapsed    | 2091      |\n",
      "|    total_timesteps | 1431552   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 801         |\n",
      "|    ep_rew_mean          | -5.92e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 684         |\n",
      "|    iterations           | 700         |\n",
      "|    time_elapsed         | 2093        |\n",
      "|    total_timesteps      | 1433600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012541655 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.04        |\n",
      "|    explained_variance   | 0.514       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.9e+03     |\n",
      "|    n_updates            | 57850       |\n",
      "|    policy_gradient_loss | -0.00332    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1.48e+05    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1435000, episode_reward=-50218.81 +/- 91115.60\n",
      "Episode length: 462.20 +/- 460.10\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 462         |\n",
      "|    mean_reward          | -5.02e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1435000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012377303 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.04        |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 664         |\n",
      "|    n_updates            | 57860       |\n",
      "|    policy_gradient_loss | -0.000897   |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 4.47e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 801       |\n",
      "|    ep_rew_mean     | -5.92e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 684       |\n",
      "|    iterations      | 701       |\n",
      "|    time_elapsed    | 2096      |\n",
      "|    total_timesteps | 1435648   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 831        |\n",
      "|    ep_rew_mean          | -5.95e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 685        |\n",
      "|    iterations           | 702        |\n",
      "|    time_elapsed         | 2097       |\n",
      "|    total_timesteps      | 1437696    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02418044 |\n",
      "|    clip_fraction        | 0.205      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.04       |\n",
      "|    explained_variance   | 0.946      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 477        |\n",
      "|    n_updates            | 57870      |\n",
      "|    policy_gradient_loss | -0.00121   |\n",
      "|    std                  | 0.207      |\n",
      "|    value_loss           | 4.42e+03   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 795          |\n",
      "|    ep_rew_mean          | -6.08e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 685          |\n",
      "|    iterations           | 703          |\n",
      "|    time_elapsed         | 2099         |\n",
      "|    total_timesteps      | 1439744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057191644 |\n",
      "|    clip_fraction        | 0.114        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.04         |\n",
      "|    explained_variance   | 0.676        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.87e+06     |\n",
      "|    n_updates            | 57880        |\n",
      "|    policy_gradient_loss | 0.00159      |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 9.38e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1440000, episode_reward=-9182.31 +/- 10840.06\n",
      "Episode length: 160.20 +/- 167.93\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 160        |\n",
      "|    mean_reward          | -9.18e+03  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1440000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00847703 |\n",
      "|    clip_fraction        | 0.0543     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.04       |\n",
      "|    explained_variance   | 0.675      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.64e+06   |\n",
      "|    n_updates            | 57890      |\n",
      "|    policy_gradient_loss | -0.0049    |\n",
      "|    std                  | 0.207      |\n",
      "|    value_loss           | 7.88e+06   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 799       |\n",
      "|    ep_rew_mean     | -5.62e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 685       |\n",
      "|    iterations      | 704       |\n",
      "|    time_elapsed    | 2102      |\n",
      "|    total_timesteps | 1441792   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 712          |\n",
      "|    ep_rew_mean          | -5.73e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 686          |\n",
      "|    iterations           | 705          |\n",
      "|    time_elapsed         | 2103         |\n",
      "|    total_timesteps      | 1443840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076622902 |\n",
      "|    clip_fraction        | 0.0453       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.04         |\n",
      "|    explained_variance   | 0.713        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.29e+06     |\n",
      "|    n_updates            | 57900        |\n",
      "|    policy_gradient_loss | -0.00171     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 9.05e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1445000, episode_reward=-92740.03 +/- 195218.49\n",
      "Episode length: 1376.20 +/- 1840.26\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.38e+03   |\n",
      "|    mean_reward          | -9.27e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1445000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00437847 |\n",
      "|    clip_fraction        | 0.0183     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.04       |\n",
      "|    explained_variance   | 0.638      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 6.04e+06   |\n",
      "|    n_updates            | 57910      |\n",
      "|    policy_gradient_loss | -0.00322   |\n",
      "|    std                  | 0.207      |\n",
      "|    value_loss           | 1.25e+07   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 665       |\n",
      "|    ep_rew_mean     | -5.81e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 685       |\n",
      "|    iterations      | 706       |\n",
      "|    time_elapsed    | 2109      |\n",
      "|    total_timesteps | 1445888   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 670          |\n",
      "|    ep_rew_mean          | -5.8e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 685          |\n",
      "|    iterations           | 707          |\n",
      "|    time_elapsed         | 2110         |\n",
      "|    total_timesteps      | 1447936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037669628 |\n",
      "|    clip_fraction        | 0.0305       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.04         |\n",
      "|    explained_variance   | 0.692        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.76e+06     |\n",
      "|    n_updates            | 57920        |\n",
      "|    policy_gradient_loss | -0.00313     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 9.15e+06     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 687         |\n",
      "|    ep_rew_mean          | -5.43e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 686         |\n",
      "|    iterations           | 708         |\n",
      "|    time_elapsed         | 2112        |\n",
      "|    total_timesteps      | 1449984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017152961 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.03        |\n",
      "|    explained_variance   | 0.923       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 761         |\n",
      "|    n_updates            | 57930       |\n",
      "|    policy_gradient_loss | 0.00318     |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 9.5e+04     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1450000, episode_reward=-7968.45 +/- 13218.51\n",
      "Episode length: 326.20 +/- 502.28\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 326         |\n",
      "|    mean_reward          | -7.97e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1450000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007557896 |\n",
      "|    clip_fraction        | 0.0695      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.03        |\n",
      "|    explained_variance   | 0.697       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.53e+06    |\n",
      "|    n_updates            | 57940       |\n",
      "|    policy_gradient_loss | -0.00365    |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 6.2e+06     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 697       |\n",
      "|    ep_rew_mean     | -5.46e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 686       |\n",
      "|    iterations      | 709       |\n",
      "|    time_elapsed    | 2115      |\n",
      "|    total_timesteps | 1452032   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 708         |\n",
      "|    ep_rew_mean          | -5.55e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 686         |\n",
      "|    iterations           | 710         |\n",
      "|    time_elapsed         | 2117        |\n",
      "|    total_timesteps      | 1454080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010775724 |\n",
      "|    clip_fraction        | 0.0634      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.03        |\n",
      "|    explained_variance   | 0.87        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.01e+04    |\n",
      "|    n_updates            | 57950       |\n",
      "|    policy_gradient_loss | 0.000387    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1.72e+06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1455000, episode_reward=-12913.27 +/- 12522.60\n",
      "Episode length: 457.40 +/- 374.55\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 457       |\n",
      "|    mean_reward          | -1.29e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 1455000   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0083698 |\n",
      "|    clip_fraction        | 0.069     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 2.03      |\n",
      "|    explained_variance   | 0.707     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.23e+03  |\n",
      "|    n_updates            | 57960     |\n",
      "|    policy_gradient_loss | -0.000418 |\n",
      "|    std                  | 0.207     |\n",
      "|    value_loss           | 5.79e+06  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 712       |\n",
      "|    ep_rew_mean     | -5.57e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 686       |\n",
      "|    iterations      | 711       |\n",
      "|    time_elapsed    | 2120      |\n",
      "|    total_timesteps | 1456128   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 707          |\n",
      "|    ep_rew_mean          | -5.34e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 687          |\n",
      "|    iterations           | 712          |\n",
      "|    time_elapsed         | 2121         |\n",
      "|    total_timesteps      | 1458176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0087351035 |\n",
      "|    clip_fraction        | 0.0682       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.03         |\n",
      "|    explained_variance   | 0.818        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.61e+03     |\n",
      "|    n_updates            | 57970        |\n",
      "|    policy_gradient_loss | -0.000337    |\n",
      "|    std                  | 0.208        |\n",
      "|    value_loss           | 2.53e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1460000, episode_reward=-3519.21 +/- 6047.84\n",
      "Episode length: 621.00 +/- 571.13\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 621         |\n",
      "|    mean_reward          | -3.52e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1460000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005363078 |\n",
      "|    clip_fraction        | 0.0323      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.03        |\n",
      "|    explained_variance   | 0.501       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.5e+07     |\n",
      "|    n_updates            | 57980       |\n",
      "|    policy_gradient_loss | 0.00147     |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 8.24e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 703       |\n",
      "|    ep_rew_mean     | -5.13e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 687       |\n",
      "|    iterations      | 713       |\n",
      "|    time_elapsed    | 2125      |\n",
      "|    total_timesteps | 1460224   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 710         |\n",
      "|    ep_rew_mean          | -5.15e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 687         |\n",
      "|    iterations           | 714         |\n",
      "|    time_elapsed         | 2127        |\n",
      "|    total_timesteps      | 1462272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032857746 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.03        |\n",
      "|    explained_variance   | 0.851       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1e+03       |\n",
      "|    n_updates            | 57990       |\n",
      "|    policy_gradient_loss | 0.00224     |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 1.37e+05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 710          |\n",
      "|    ep_rew_mean          | -5.15e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 687          |\n",
      "|    iterations           | 715          |\n",
      "|    time_elapsed         | 2128         |\n",
      "|    total_timesteps      | 1464320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025737395 |\n",
      "|    clip_fraction        | 0.0794       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.03         |\n",
      "|    explained_variance   | 0.756        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.92e+06     |\n",
      "|    n_updates            | 58000        |\n",
      "|    policy_gradient_loss | 0.00176      |\n",
      "|    std                  | 0.208        |\n",
      "|    value_loss           | 2.44e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1465000, episode_reward=311.68 +/- 7655.29\n",
      "Episode length: 1496.60 +/- 1817.92\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.5e+03     |\n",
      "|    mean_reward          | 312         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1465000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014528122 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.02        |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 978         |\n",
      "|    n_updates            | 58010       |\n",
      "|    policy_gradient_loss | -0.00494    |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 4.4e+03     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 710       |\n",
      "|    ep_rew_mean     | -5.15e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 687       |\n",
      "|    iterations      | 716       |\n",
      "|    time_elapsed    | 2134      |\n",
      "|    total_timesteps | 1466368   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 754         |\n",
      "|    ep_rew_mean          | -5.05e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 687         |\n",
      "|    iterations           | 717         |\n",
      "|    time_elapsed         | 2136        |\n",
      "|    total_timesteps      | 1468416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011240633 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.02        |\n",
      "|    explained_variance   | 0.871       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 952         |\n",
      "|    n_updates            | 58020       |\n",
      "|    policy_gradient_loss | -0.0031     |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 6.42e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1470000, episode_reward=932.33 +/- 7299.39\n",
      "Episode length: 1306.00 +/- 1355.98\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.31e+03    |\n",
      "|    mean_reward          | 932         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1470000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019159988 |\n",
      "|    clip_fraction        | 0.0868      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.02        |\n",
      "|    explained_variance   | 0.654       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.55e+05    |\n",
      "|    n_updates            | 58030       |\n",
      "|    policy_gradient_loss | -0.000453   |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 7.72e+06    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 770       |\n",
      "|    ep_rew_mean     | -4.97e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 686       |\n",
      "|    iterations      | 718       |\n",
      "|    time_elapsed    | 2141      |\n",
      "|    total_timesteps | 1470464   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 772        |\n",
      "|    ep_rew_mean          | -4.95e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 687        |\n",
      "|    iterations           | 719        |\n",
      "|    time_elapsed         | 2142       |\n",
      "|    total_timesteps      | 1472512    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03782237 |\n",
      "|    clip_fraction        | 0.19       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.02       |\n",
      "|    explained_variance   | 0.583      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 593        |\n",
      "|    n_updates            | 58040      |\n",
      "|    policy_gradient_loss | 0.00934    |\n",
      "|    std                  | 0.208      |\n",
      "|    value_loss           | 8.91e+04   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 738         |\n",
      "|    ep_rew_mean          | -3.89e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 687         |\n",
      "|    iterations           | 720         |\n",
      "|    time_elapsed         | 2144        |\n",
      "|    total_timesteps      | 1474560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016788162 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.02        |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 531         |\n",
      "|    n_updates            | 58050       |\n",
      "|    policy_gradient_loss | 0.00129     |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 2.05e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1475000, episode_reward=-15257.47 +/- 12153.30\n",
      "Episode length: 666.80 +/- 582.41\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 667         |\n",
      "|    mean_reward          | -1.53e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1475000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023668528 |\n",
      "|    clip_fraction        | 0.27        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.02        |\n",
      "|    explained_variance   | 0.622       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.82e+06    |\n",
      "|    n_updates            | 58060       |\n",
      "|    policy_gradient_loss | 0.0182      |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 2.88e+06    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 741      |\n",
      "|    ep_rew_mean     | -3.9e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 687      |\n",
      "|    iterations      | 721      |\n",
      "|    time_elapsed    | 2148     |\n",
      "|    total_timesteps | 1476608  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 741         |\n",
      "|    ep_rew_mean          | -3.9e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 687         |\n",
      "|    iterations           | 722         |\n",
      "|    time_elapsed         | 2150        |\n",
      "|    total_timesteps      | 1478656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013965745 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.02        |\n",
      "|    explained_variance   | 0.876       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 751         |\n",
      "|    n_updates            | 58070       |\n",
      "|    policy_gradient_loss | 0.00591     |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 1.77e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1480000, episode_reward=4760.75 +/- 25424.52\n",
      "Episode length: 1415.00 +/- 1863.76\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.42e+03    |\n",
      "|    mean_reward          | 4.76e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1480000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024390034 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.01        |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 406         |\n",
      "|    n_updates            | 58080       |\n",
      "|    policy_gradient_loss | 0.00588     |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 1.63e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 788       |\n",
      "|    ep_rew_mean     | -3.42e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 686       |\n",
      "|    iterations      | 723       |\n",
      "|    time_elapsed    | 2155      |\n",
      "|    total_timesteps | 1480704   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 788        |\n",
      "|    ep_rew_mean          | -3.42e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 687        |\n",
      "|    iterations           | 724        |\n",
      "|    time_elapsed         | 2157       |\n",
      "|    total_timesteps      | 1482752    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01842523 |\n",
      "|    clip_fraction        | 0.17       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2          |\n",
      "|    explained_variance   | 0.938      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 431        |\n",
      "|    n_updates            | 58090      |\n",
      "|    policy_gradient_loss | 0.00233    |\n",
      "|    std                  | 0.21       |\n",
      "|    value_loss           | 3.86e+03   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 806          |\n",
      "|    ep_rew_mean          | -3.62e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 687          |\n",
      "|    iterations           | 725          |\n",
      "|    time_elapsed         | 2158         |\n",
      "|    total_timesteps      | 1484800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0094747795 |\n",
      "|    clip_fraction        | 0.113        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2            |\n",
      "|    explained_variance   | 0.943        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 480          |\n",
      "|    n_updates            | 58100        |\n",
      "|    policy_gradient_loss | 0.00183      |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 2.75e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1485000, episode_reward=-31217.82 +/- 75340.69\n",
      "Episode length: 2459.80 +/- 2216.13\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2.46e+03   |\n",
      "|    mean_reward          | -3.12e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1485000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19551304 |\n",
      "|    clip_fraction        | 0.216      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2          |\n",
      "|    explained_variance   | 0.587      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.57e+06   |\n",
      "|    n_updates            | 58110      |\n",
      "|    policy_gradient_loss | 0.0155     |\n",
      "|    std                  | 0.21       |\n",
      "|    value_loss           | 1.69e+07   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 806       |\n",
      "|    ep_rew_mean     | -3.62e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 686       |\n",
      "|    iterations      | 726       |\n",
      "|    time_elapsed    | 2166      |\n",
      "|    total_timesteps | 1486848   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 838        |\n",
      "|    ep_rew_mean          | -3.15e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 686        |\n",
      "|    iterations           | 727        |\n",
      "|    time_elapsed         | 2168       |\n",
      "|    total_timesteps      | 1488896    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02775203 |\n",
      "|    clip_fraction        | 0.312      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2          |\n",
      "|    explained_variance   | 0.988      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 76         |\n",
      "|    n_updates            | 58120      |\n",
      "|    policy_gradient_loss | 0.0147     |\n",
      "|    std                  | 0.209      |\n",
      "|    value_loss           | 371        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1490000, episode_reward=-64974.73 +/- 94816.59\n",
      "Episode length: 1713.60 +/- 2069.07\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.71e+03   |\n",
      "|    mean_reward          | -6.5e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1490000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02303269 |\n",
      "|    clip_fraction        | 0.174      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.01       |\n",
      "|    explained_variance   | 0.898      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 207        |\n",
      "|    n_updates            | 58130      |\n",
      "|    policy_gradient_loss | 0.00326    |\n",
      "|    std                  | 0.209      |\n",
      "|    value_loss           | 3.02e+04   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 838       |\n",
      "|    ep_rew_mean     | -3.15e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 685       |\n",
      "|    iterations      | 728       |\n",
      "|    time_elapsed    | 2174      |\n",
      "|    total_timesteps | 1490944   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 838         |\n",
      "|    ep_rew_mean          | -3.15e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 686         |\n",
      "|    iterations           | 729         |\n",
      "|    time_elapsed         | 2176        |\n",
      "|    total_timesteps      | 1492992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026928186 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2           |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 128         |\n",
      "|    n_updates            | 58140       |\n",
      "|    policy_gradient_loss | 0.00433     |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 404         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1495000, episode_reward=23883.81 +/- 23172.98\n",
      "Episode length: 3045.00 +/- 2394.38\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.04e+03    |\n",
      "|    mean_reward          | 2.39e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1495000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019559963 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2           |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 93.6        |\n",
      "|    n_updates            | 58150       |\n",
      "|    policy_gradient_loss | 0.0139      |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 287         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 813       |\n",
      "|    ep_rew_mean     | -2.67e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 684       |\n",
      "|    iterations      | 730       |\n",
      "|    time_elapsed    | 2185      |\n",
      "|    total_timesteps | 1495040   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 813         |\n",
      "|    ep_rew_mean          | -2.67e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 684         |\n",
      "|    iterations           | 731         |\n",
      "|    time_elapsed         | 2187        |\n",
      "|    total_timesteps      | 1497088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022230929 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.01        |\n",
      "|    explained_variance   | 0.393       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.97e+06    |\n",
      "|    n_updates            | 58160       |\n",
      "|    policy_gradient_loss | -0.00463    |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 2.2e+07     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 842         |\n",
      "|    ep_rew_mean          | -2.55e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 684         |\n",
      "|    iterations           | 732         |\n",
      "|    time_elapsed         | 2188        |\n",
      "|    total_timesteps      | 1499136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015738668 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2           |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 51.2        |\n",
      "|    n_updates            | 58170       |\n",
      "|    policy_gradient_loss | 0.00234     |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 272         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1500000, episode_reward=-63791.36 +/- 67930.07\n",
      "Episode length: 1573.00 +/- 1643.04\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.57e+03    |\n",
      "|    mean_reward          | -6.38e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1500000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007243566 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.99        |\n",
      "|    explained_variance   | 0.839       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 327         |\n",
      "|    n_updates            | 58180       |\n",
      "|    policy_gradient_loss | 0.0154      |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 1.12e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 842       |\n",
      "|    ep_rew_mean     | -2.55e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 684       |\n",
      "|    iterations      | 733       |\n",
      "|    time_elapsed    | 2194      |\n",
      "|    total_timesteps | 1501184   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 874         |\n",
      "|    ep_rew_mean          | -2.64e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 684         |\n",
      "|    iterations           | 734         |\n",
      "|    time_elapsed         | 2196        |\n",
      "|    total_timesteps      | 1503232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017162368 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.99        |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 72.5        |\n",
      "|    n_updates            | 58190       |\n",
      "|    policy_gradient_loss | 0.0024      |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 432         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1505000, episode_reward=-42834.38 +/- 60811.95\n",
      "Episode length: 1969.80 +/- 1679.60\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.97e+03   |\n",
      "|    mean_reward          | -4.28e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1505000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01158314 |\n",
      "|    clip_fraction        | 0.216      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.99       |\n",
      "|    explained_variance   | 0.465      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.49e+07   |\n",
      "|    n_updates            | 58200      |\n",
      "|    policy_gradient_loss | 0.00259    |\n",
      "|    std                  | 0.209      |\n",
      "|    value_loss           | 3.53e+07   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 873       |\n",
      "|    ep_rew_mean     | -2.64e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 683       |\n",
      "|    iterations      | 735       |\n",
      "|    time_elapsed    | 2202      |\n",
      "|    total_timesteps | 1505280   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 873         |\n",
      "|    ep_rew_mean          | -2.64e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 683         |\n",
      "|    iterations           | 736         |\n",
      "|    time_elapsed         | 2204        |\n",
      "|    total_timesteps      | 1507328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009557486 |\n",
      "|    clip_fraction        | 0.0873      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.99        |\n",
      "|    explained_variance   | 0.693       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.01e+06    |\n",
      "|    n_updates            | 58210       |\n",
      "|    policy_gradient_loss | 0.000845    |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 1.69e+06    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 884          |\n",
      "|    ep_rew_mean          | -2.8e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 684          |\n",
      "|    iterations           | 737          |\n",
      "|    time_elapsed         | 2206         |\n",
      "|    total_timesteps      | 1509376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040089386 |\n",
      "|    clip_fraction        | 0.0329       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.99         |\n",
      "|    explained_variance   | 0.495        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.12e+07     |\n",
      "|    n_updates            | 58220        |\n",
      "|    policy_gradient_loss | -0.0025      |\n",
      "|    std                  | 0.209        |\n",
      "|    value_loss           | 3.14e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1510000, episode_reward=-75621.17 +/- 35214.43\n",
      "Episode length: 900.00 +/- 1063.91\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 900         |\n",
      "|    mean_reward          | -7.56e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1510000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018600585 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.98        |\n",
      "|    explained_variance   | 0.82        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 136         |\n",
      "|    n_updates            | 58230       |\n",
      "|    policy_gradient_loss | -0.00167    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 6.74e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 894       |\n",
      "|    ep_rew_mean     | -3.01e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 683       |\n",
      "|    iterations      | 738       |\n",
      "|    time_elapsed    | 2210      |\n",
      "|    total_timesteps | 1511424   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 919          |\n",
      "|    ep_rew_mean          | -3.18e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 684          |\n",
      "|    iterations           | 739          |\n",
      "|    time_elapsed         | 2212         |\n",
      "|    total_timesteps      | 1513472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073546274 |\n",
      "|    clip_fraction        | 0.164        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.98         |\n",
      "|    explained_variance   | 0.51         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.16e+07     |\n",
      "|    n_updates            | 58240        |\n",
      "|    policy_gradient_loss | 0.00194      |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 4.2e+07      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1515000, episode_reward=-91057.72 +/- 76191.69\n",
      "Episode length: 1624.60 +/- 1278.34\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.62e+03     |\n",
      "|    mean_reward          | -9.11e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1515000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011472316 |\n",
      "|    clip_fraction        | 0.00537      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.98         |\n",
      "|    explained_variance   | 0.481        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.8e+07      |\n",
      "|    n_updates            | 58250        |\n",
      "|    policy_gradient_loss | -0.00196     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 4.08e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 919       |\n",
      "|    ep_rew_mean     | -3.18e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 683       |\n",
      "|    iterations      | 740       |\n",
      "|    time_elapsed    | 2218      |\n",
      "|    total_timesteps | 1515520   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 919         |\n",
      "|    ep_rew_mean          | -3.18e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 683         |\n",
      "|    iterations           | 741         |\n",
      "|    time_elapsed         | 2220        |\n",
      "|    total_timesteps      | 1517568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008347193 |\n",
      "|    clip_fraction        | 0.0587      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.98        |\n",
      "|    explained_variance   | 0.904       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.98e+03    |\n",
      "|    n_updates            | 58260       |\n",
      "|    policy_gradient_loss | -0.00833    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 3.22e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 964         |\n",
      "|    ep_rew_mean          | -3.14e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 683         |\n",
      "|    iterations           | 742         |\n",
      "|    time_elapsed         | 2221        |\n",
      "|    total_timesteps      | 1519616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011429748 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.98        |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 367         |\n",
      "|    n_updates            | 58270       |\n",
      "|    policy_gradient_loss | 0.000459    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 1.96e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1520000, episode_reward=25946.44 +/- 72926.75\n",
      "Episode length: 4833.20 +/- 333.60\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4.83e+03     |\n",
      "|    mean_reward          | 2.59e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1520000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0127987545 |\n",
      "|    clip_fraction        | 0.179        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.98         |\n",
      "|    explained_variance   | 0.799        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 134          |\n",
      "|    n_updates            | 58280        |\n",
      "|    policy_gradient_loss | 0.00973      |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 1.13e+05     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 964       |\n",
      "|    ep_rew_mean     | -3.14e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 680       |\n",
      "|    iterations      | 743       |\n",
      "|    time_elapsed    | 2235      |\n",
      "|    total_timesteps | 1521664   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | -2.62e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 681        |\n",
      "|    iterations           | 744        |\n",
      "|    time_elapsed         | 2236       |\n",
      "|    total_timesteps      | 1523712    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04087002 |\n",
      "|    clip_fraction        | 0.243      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.99       |\n",
      "|    explained_variance   | 0.957      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 194        |\n",
      "|    n_updates            | 58290      |\n",
      "|    policy_gradient_loss | 0.012      |\n",
      "|    std                  | 0.21       |\n",
      "|    value_loss           | 1.83e+03   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1525000, episode_reward=65824.68 +/- 4987.40\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 6.58e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1525000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007736991 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.99        |\n",
      "|    explained_variance   | 0.802       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.65e+03    |\n",
      "|    n_updates            | 58300       |\n",
      "|    policy_gradient_loss | 1.28e-05    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 1.04e+05    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -2.62e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 677       |\n",
      "|    iterations      | 745       |\n",
      "|    time_elapsed    | 2250      |\n",
      "|    total_timesteps | 1525760   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -2.62e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 678         |\n",
      "|    iterations           | 746         |\n",
      "|    time_elapsed         | 2252        |\n",
      "|    total_timesteps      | 1527808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037967846 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.99        |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 139         |\n",
      "|    n_updates            | 58310       |\n",
      "|    policy_gradient_loss | 0.00526     |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 572         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.05e+03    |\n",
      "|    ep_rew_mean          | -2.56e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 678         |\n",
      "|    iterations           | 747         |\n",
      "|    time_elapsed         | 2254        |\n",
      "|    total_timesteps      | 1529856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037874915 |\n",
      "|    clip_fraction        | 0.326       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.99        |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 40.3        |\n",
      "|    n_updates            | 58320       |\n",
      "|    policy_gradient_loss | 0.021       |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 240         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1530000, episode_reward=63695.46 +/- 4582.23\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5e+03        |\n",
      "|    mean_reward          | 6.37e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1530000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074465913 |\n",
      "|    clip_fraction        | 0.122        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.99         |\n",
      "|    explained_variance   | 0.956        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.13e+03     |\n",
      "|    n_updates            | 58330        |\n",
      "|    policy_gradient_loss | -0.00115     |\n",
      "|    std                  | 0.209        |\n",
      "|    value_loss           | 5.9e+03      |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.05e+03  |\n",
      "|    ep_rew_mean     | -2.56e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 675       |\n",
      "|    iterations      | 748       |\n",
      "|    time_elapsed    | 2267      |\n",
      "|    total_timesteps | 1531904   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.08e+03    |\n",
      "|    ep_rew_mean          | -2.51e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 675         |\n",
      "|    iterations           | 749         |\n",
      "|    time_elapsed         | 2269        |\n",
      "|    total_timesteps      | 1533952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041682288 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2           |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 212         |\n",
      "|    n_updates            | 58340       |\n",
      "|    policy_gradient_loss | 0.00469     |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 1.18e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1535000, episode_reward=53485.43 +/- 28239.77\n",
      "Episode length: 4002.00 +/- 1996.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4e+03       |\n",
      "|    mean_reward          | 5.35e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1535000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012818355 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.01        |\n",
      "|    explained_variance   | 0.939       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.14e+03    |\n",
      "|    n_updates            | 58350       |\n",
      "|    policy_gradient_loss | 0.00227     |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 3.37e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.08e+03  |\n",
      "|    ep_rew_mean     | -2.51e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 673       |\n",
      "|    iterations      | 750       |\n",
      "|    time_elapsed    | 2281      |\n",
      "|    total_timesteps | 1536000   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.08e+03   |\n",
      "|    ep_rew_mean          | -2.51e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 673        |\n",
      "|    iterations           | 751        |\n",
      "|    time_elapsed         | 2282       |\n",
      "|    total_timesteps      | 1538048    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01338627 |\n",
      "|    clip_fraction        | 0.157      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.01       |\n",
      "|    explained_variance   | 0.96       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 363        |\n",
      "|    n_updates            | 58360      |\n",
      "|    policy_gradient_loss | -0.00489   |\n",
      "|    std                  | 0.208      |\n",
      "|    value_loss           | 1.43e+03   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1540000, episode_reward=-26232.56 +/- 199468.30\n",
      "Episode length: 4047.80 +/- 1904.40\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.05e+03    |\n",
      "|    mean_reward          | -2.62e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1540000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023524981 |\n",
      "|    clip_fraction        | 0.385       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.01        |\n",
      "|    explained_variance   | 0.584       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 128         |\n",
      "|    n_updates            | 58370       |\n",
      "|    policy_gradient_loss | 0.0165      |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 719         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.13e+03  |\n",
      "|    ep_rew_mean     | -2.77e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 671       |\n",
      "|    iterations      | 752       |\n",
      "|    time_elapsed    | 2294      |\n",
      "|    total_timesteps | 1540096   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.13e+03    |\n",
      "|    ep_rew_mean          | -2.77e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 671         |\n",
      "|    iterations           | 753         |\n",
      "|    time_elapsed         | 2296        |\n",
      "|    total_timesteps      | 1542144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004851383 |\n",
      "|    clip_fraction        | 0.0451      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.01        |\n",
      "|    explained_variance   | 0.513       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.55e+07    |\n",
      "|    n_updates            | 58380       |\n",
      "|    policy_gradient_loss | 0.00286     |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 6.46e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.17e+03    |\n",
      "|    ep_rew_mean          | -2.64e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 671         |\n",
      "|    iterations           | 754         |\n",
      "|    time_elapsed         | 2298        |\n",
      "|    total_timesteps      | 1544192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017619116 |\n",
      "|    clip_fraction        | 0.297       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.01        |\n",
      "|    explained_variance   | 0.948       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 41.2        |\n",
      "|    n_updates            | 58390       |\n",
      "|    policy_gradient_loss | 0.0119      |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 249         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1545000, episode_reward=-12538.09 +/- 80391.43\n",
      "Episode length: 2246.60 +/- 2281.74\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.25e+03    |\n",
      "|    mean_reward          | -1.25e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1545000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010309186 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.02        |\n",
      "|    explained_variance   | 0.595       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.28e+03    |\n",
      "|    n_updates            | 58400       |\n",
      "|    policy_gradient_loss | -0.00161    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 6.99e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.17e+03  |\n",
      "|    ep_rew_mean     | -2.64e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 670       |\n",
      "|    iterations      | 755       |\n",
      "|    time_elapsed    | 2305      |\n",
      "|    total_timesteps | 1546240   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.17e+03    |\n",
      "|    ep_rew_mean          | -2.64e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 671         |\n",
      "|    iterations           | 756         |\n",
      "|    time_elapsed         | 2307        |\n",
      "|    total_timesteps      | 1548288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012004346 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.03        |\n",
      "|    explained_variance   | 0.741       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 192         |\n",
      "|    n_updates            | 58410       |\n",
      "|    policy_gradient_loss | -0.00921    |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 799         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1550000, episode_reward=-527.82 +/- 28229.96\n",
      "Episode length: 1602.00 +/- 2050.32\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.6e+03    |\n",
      "|    mean_reward          | -528       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1550000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07120546 |\n",
      "|    clip_fraction        | 0.369      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.04       |\n",
      "|    explained_variance   | 0.934      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 43.7       |\n",
      "|    n_updates            | 58420      |\n",
      "|    policy_gradient_loss | 0.0159     |\n",
      "|    std                  | 0.206      |\n",
      "|    value_loss           | 128        |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.22e+03  |\n",
      "|    ep_rew_mean     | -2.57e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 670       |\n",
      "|    iterations      | 757       |\n",
      "|    time_elapsed    | 2312      |\n",
      "|    total_timesteps | 1550336   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.22e+03   |\n",
      "|    ep_rew_mean          | -2.57e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 670        |\n",
      "|    iterations           | 758        |\n",
      "|    time_elapsed         | 2314       |\n",
      "|    total_timesteps      | 1552384    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01028699 |\n",
      "|    clip_fraction        | 0.141      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.04       |\n",
      "|    explained_variance   | 0.9        |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 522        |\n",
      "|    n_updates            | 58430      |\n",
      "|    policy_gradient_loss | -0.00301   |\n",
      "|    std                  | 0.207      |\n",
      "|    value_loss           | 6.14e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.27e+03    |\n",
      "|    ep_rew_mean          | -2.5e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 671         |\n",
      "|    iterations           | 759         |\n",
      "|    time_elapsed         | 2316        |\n",
      "|    total_timesteps      | 1554432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009660555 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.03        |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 134         |\n",
      "|    n_updates            | 58440       |\n",
      "|    policy_gradient_loss | 0.00314     |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 381         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1555000, episode_reward=64027.38 +/- 3025.14\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5e+03        |\n",
      "|    mean_reward          | 6.4e+04      |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1555000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0102841575 |\n",
      "|    clip_fraction        | 0.141        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.03         |\n",
      "|    explained_variance   | -0.0286      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 329          |\n",
      "|    n_updates            | 58450        |\n",
      "|    policy_gradient_loss | -0.00435     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 8.61e+04     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.27e+03 |\n",
      "|    ep_rew_mean     | -2.5e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 667      |\n",
      "|    iterations      | 760      |\n",
      "|    time_elapsed    | 2330     |\n",
      "|    total_timesteps | 1556480  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.32e+03    |\n",
      "|    ep_rew_mean          | -2.34e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 668         |\n",
      "|    iterations           | 761         |\n",
      "|    time_elapsed         | 2332        |\n",
      "|    total_timesteps      | 1558528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028999865 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.04        |\n",
      "|    explained_variance   | 0.953       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 39          |\n",
      "|    n_updates            | 58460       |\n",
      "|    policy_gradient_loss | -0.00176    |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 201         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1560000, episode_reward=18471.45 +/- 47143.01\n",
      "Episode length: 3686.20 +/- 1888.60\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.69e+03    |\n",
      "|    mean_reward          | 1.85e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1560000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010180775 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.04        |\n",
      "|    explained_variance   | 0.504       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.07e+07    |\n",
      "|    n_updates            | 58470       |\n",
      "|    policy_gradient_loss | 0.00197     |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 3.68e+07    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.31e+03 |\n",
      "|    ep_rew_mean     | -2.8e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 666      |\n",
      "|    iterations      | 762      |\n",
      "|    time_elapsed    | 2342     |\n",
      "|    total_timesteps | 1560576  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.31e+03   |\n",
      "|    ep_rew_mean          | -2.8e+04   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 666        |\n",
      "|    iterations           | 763        |\n",
      "|    time_elapsed         | 2344       |\n",
      "|    total_timesteps      | 1562624    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01692135 |\n",
      "|    clip_fraction        | 0.0701     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.04       |\n",
      "|    explained_variance   | 0.561      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.72e+07   |\n",
      "|    n_updates            | 58480      |\n",
      "|    policy_gradient_loss | 0.00813    |\n",
      "|    std                  | 0.206      |\n",
      "|    value_loss           | 3.8e+07    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.36e+03    |\n",
      "|    ep_rew_mean          | -2.8e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 666         |\n",
      "|    iterations           | 764         |\n",
      "|    time_elapsed         | 2346        |\n",
      "|    total_timesteps      | 1564672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023067575 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.05        |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 66.7        |\n",
      "|    n_updates            | 58490       |\n",
      "|    policy_gradient_loss | -0.000468   |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 240         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1565000, episode_reward=65389.72 +/- 12414.38\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 6.54e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1565000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021299263 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.06        |\n",
      "|    explained_variance   | 0.591       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.97e+05    |\n",
      "|    n_updates            | 58500       |\n",
      "|    policy_gradient_loss | 0.0127      |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 8.14e+06    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.36e+03  |\n",
      "|    ep_rew_mean     | -2.78e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 663       |\n",
      "|    iterations      | 765       |\n",
      "|    time_elapsed    | 2360      |\n",
      "|    total_timesteps | 1566720   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.36e+03    |\n",
      "|    ep_rew_mean          | -2.78e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 664         |\n",
      "|    iterations           | 766         |\n",
      "|    time_elapsed         | 2362        |\n",
      "|    total_timesteps      | 1568768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007953871 |\n",
      "|    clip_fraction        | 0.0927      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.06        |\n",
      "|    explained_variance   | 0.823       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 323         |\n",
      "|    n_updates            | 58510       |\n",
      "|    policy_gradient_loss | -0.00515    |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 8.58e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1570000, episode_reward=77387.34 +/- 1561.75\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 7.74e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1570000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015728172 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.06        |\n",
      "|    explained_variance   | 0.943       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 121         |\n",
      "|    n_updates            | 58520       |\n",
      "|    policy_gradient_loss | -0.00142    |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 332         |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.36e+03  |\n",
      "|    ep_rew_mean     | -2.78e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 661       |\n",
      "|    iterations      | 767       |\n",
      "|    time_elapsed    | 2375      |\n",
      "|    total_timesteps | 1570816   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.41e+03   |\n",
      "|    ep_rew_mean          | -2.71e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 661        |\n",
      "|    iterations           | 768        |\n",
      "|    time_elapsed         | 2377       |\n",
      "|    total_timesteps      | 1572864    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01600539 |\n",
      "|    clip_fraction        | 0.254      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.04       |\n",
      "|    explained_variance   | 0.986      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 50.2       |\n",
      "|    n_updates            | 58530      |\n",
      "|    policy_gradient_loss | 0.00149    |\n",
      "|    std                  | 0.208      |\n",
      "|    value_loss           | 142        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.44e+03    |\n",
      "|    ep_rew_mean          | -2.67e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 661         |\n",
      "|    iterations           | 769         |\n",
      "|    time_elapsed         | 2379        |\n",
      "|    total_timesteps      | 1574912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017163029 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.02        |\n",
      "|    explained_variance   | 0.901       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 220         |\n",
      "|    n_updates            | 58540       |\n",
      "|    policy_gradient_loss | 5.77e-05    |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 6.33e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1575000, episode_reward=34292.01 +/- 21378.69\n",
      "Episode length: 4390.60 +/- 1160.22\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.39e+03    |\n",
      "|    mean_reward          | 3.43e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1575000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006450168 |\n",
      "|    clip_fraction        | 0.0923      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.01        |\n",
      "|    explained_variance   | 0.838       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 297         |\n",
      "|    n_updates            | 58550       |\n",
      "|    policy_gradient_loss | -0.0025     |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 1.79e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.44e+03  |\n",
      "|    ep_rew_mean     | -2.67e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 659       |\n",
      "|    iterations      | 770       |\n",
      "|    time_elapsed    | 2391      |\n",
      "|    total_timesteps | 1576960   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.44e+03    |\n",
      "|    ep_rew_mean          | -2.67e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 659         |\n",
      "|    iterations           | 771         |\n",
      "|    time_elapsed         | 2393        |\n",
      "|    total_timesteps      | 1579008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021007117 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.02        |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 57.9        |\n",
      "|    n_updates            | 58560       |\n",
      "|    policy_gradient_loss | 0.00129     |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 284         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1580000, episode_reward=73908.88 +/- 2195.33\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 7.39e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1580000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011002973 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.03        |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 97          |\n",
      "|    n_updates            | 58570       |\n",
      "|    policy_gradient_loss | 0.00467     |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 341         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.49e+03  |\n",
      "|    ep_rew_mean     | -2.62e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 656       |\n",
      "|    iterations      | 772       |\n",
      "|    time_elapsed    | 2407      |\n",
      "|    total_timesteps | 1581056   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.49e+03    |\n",
      "|    ep_rew_mean          | -2.62e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 657         |\n",
      "|    iterations           | 773         |\n",
      "|    time_elapsed         | 2409        |\n",
      "|    total_timesteps      | 1583104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011580668 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.03        |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 180         |\n",
      "|    n_updates            | 58580       |\n",
      "|    policy_gradient_loss | -0.000186   |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 854         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1585000, episode_reward=35522.21 +/- 37380.82\n",
      "Episode length: 3006.40 +/- 2441.66\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.01e+03    |\n",
      "|    mean_reward          | 3.55e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1585000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022317976 |\n",
      "|    clip_fraction        | 0.355       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.03        |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 67.5        |\n",
      "|    n_updates            | 58590       |\n",
      "|    policy_gradient_loss | 0.0147      |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 339         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.54e+03  |\n",
      "|    ep_rew_mean     | -2.55e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 655       |\n",
      "|    iterations      | 774       |\n",
      "|    time_elapsed    | 2418      |\n",
      "|    total_timesteps | 1585152   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.54e+03    |\n",
      "|    ep_rew_mean          | -2.55e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 655         |\n",
      "|    iterations           | 775         |\n",
      "|    time_elapsed         | 2420        |\n",
      "|    total_timesteps      | 1587200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015218169 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.03        |\n",
      "|    explained_variance   | 0.869       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 189         |\n",
      "|    n_updates            | 58600       |\n",
      "|    policy_gradient_loss | 0.00732     |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 4.13e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.54e+03    |\n",
      "|    ep_rew_mean          | -2.55e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 656         |\n",
      "|    iterations           | 776         |\n",
      "|    time_elapsed         | 2422        |\n",
      "|    total_timesteps      | 1589248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009405022 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.03        |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 147         |\n",
      "|    n_updates            | 58610       |\n",
      "|    policy_gradient_loss | -0.0044     |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 959         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1590000, episode_reward=-59811.16 +/- 192062.93\n",
      "Episode length: 3898.40 +/- 1842.93\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 3.9e+03    |\n",
      "|    mean_reward          | -5.98e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1590000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01846018 |\n",
      "|    clip_fraction        | 0.211      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.04       |\n",
      "|    explained_variance   | 0.979      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 45.1       |\n",
      "|    n_updates            | 58620      |\n",
      "|    policy_gradient_loss | 0.00146    |\n",
      "|    std                  | 0.208      |\n",
      "|    value_loss           | 389        |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.54e+03  |\n",
      "|    ep_rew_mean     | -2.44e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 653       |\n",
      "|    iterations      | 777       |\n",
      "|    time_elapsed    | 2433      |\n",
      "|    total_timesteps | 1591296   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.54e+03    |\n",
      "|    ep_rew_mean          | -2.44e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 654         |\n",
      "|    iterations           | 778         |\n",
      "|    time_elapsed         | 2435        |\n",
      "|    total_timesteps      | 1593344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005788327 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.05        |\n",
      "|    explained_variance   | 0.882       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.79e+03    |\n",
      "|    n_updates            | 58630       |\n",
      "|    policy_gradient_loss | 0.0114      |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 5.43e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1595000, episode_reward=23718.54 +/- 21752.13\n",
      "Episode length: 4054.80 +/- 1117.10\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 4.05e+03   |\n",
      "|    mean_reward          | 2.37e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1595000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01354237 |\n",
      "|    clip_fraction        | 0.136      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.06       |\n",
      "|    explained_variance   | 0.983      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 116        |\n",
      "|    n_updates            | 58640      |\n",
      "|    policy_gradient_loss | 0.00195    |\n",
      "|    std                  | 0.208      |\n",
      "|    value_loss           | 670        |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.57e+03 |\n",
      "|    ep_rew_mean     | -2.4e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 652      |\n",
      "|    iterations      | 779      |\n",
      "|    time_elapsed    | 2446     |\n",
      "|    total_timesteps | 1595392  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.58e+03    |\n",
      "|    ep_rew_mean          | -2.35e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 652         |\n",
      "|    iterations           | 780         |\n",
      "|    time_elapsed         | 2448        |\n",
      "|    total_timesteps      | 1597440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008403219 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.06        |\n",
      "|    explained_variance   | 0.107       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 365         |\n",
      "|    n_updates            | 58650       |\n",
      "|    policy_gradient_loss | -0.00123    |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 1.74e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.58e+03    |\n",
      "|    ep_rew_mean          | -2.35e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 652         |\n",
      "|    iterations           | 781         |\n",
      "|    time_elapsed         | 2450        |\n",
      "|    total_timesteps      | 1599488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004487425 |\n",
      "|    clip_fraction        | 0.0485      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.06        |\n",
      "|    explained_variance   | 0.516       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.09e+03    |\n",
      "|    n_updates            | 58660       |\n",
      "|    policy_gradient_loss | -0.00216    |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 1.06e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1600000, episode_reward=-17250.31 +/- 43079.67\n",
      "Episode length: 2560.00 +/- 1194.34\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2.56e+03   |\n",
      "|    mean_reward          | -1.73e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1600000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02018023 |\n",
      "|    clip_fraction        | 0.124      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.06       |\n",
      "|    explained_variance   | 0.981      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 115        |\n",
      "|    n_updates            | 58670      |\n",
      "|    policy_gradient_loss | 0.000664   |\n",
      "|    std                  | 0.208      |\n",
      "|    value_loss           | 820        |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.6e+03   |\n",
      "|    ep_rew_mean     | -2.42e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 651       |\n",
      "|    iterations      | 782       |\n",
      "|    time_elapsed    | 2458      |\n",
      "|    total_timesteps | 1601536   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.6e+03      |\n",
      "|    ep_rew_mean          | -2.42e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 651          |\n",
      "|    iterations           | 783          |\n",
      "|    time_elapsed         | 2460         |\n",
      "|    total_timesteps      | 1603584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0154697085 |\n",
      "|    clip_fraction        | 0.222        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.06         |\n",
      "|    explained_variance   | 0.534        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.42e+07     |\n",
      "|    n_updates            | 58680        |\n",
      "|    policy_gradient_loss | 0.00193      |\n",
      "|    std                  | 0.208        |\n",
      "|    value_loss           | 2.24e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1605000, episode_reward=-75534.35 +/- 65504.10\n",
      "Episode length: 2501.60 +/- 1249.10\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.5e+03     |\n",
      "|    mean_reward          | -7.55e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1605000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012641303 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.07        |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 126         |\n",
      "|    n_updates            | 58690       |\n",
      "|    policy_gradient_loss | -0.000384   |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 407         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.63e+03  |\n",
      "|    ep_rew_mean     | -2.44e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 650       |\n",
      "|    iterations      | 784       |\n",
      "|    time_elapsed    | 2467      |\n",
      "|    total_timesteps | 1605632   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.65e+03    |\n",
      "|    ep_rew_mean          | -2.37e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 650         |\n",
      "|    iterations           | 785         |\n",
      "|    time_elapsed         | 2469        |\n",
      "|    total_timesteps      | 1607680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.062238142 |\n",
      "|    clip_fraction        | 0.388       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.07        |\n",
      "|    explained_variance   | 0.598       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.91e+06    |\n",
      "|    n_updates            | 58700       |\n",
      "|    policy_gradient_loss | 0.0251      |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 1.58e+07    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.65e+03     |\n",
      "|    ep_rew_mean          | -2.37e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 651          |\n",
      "|    iterations           | 786          |\n",
      "|    time_elapsed         | 2471         |\n",
      "|    total_timesteps      | 1609728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0086879525 |\n",
      "|    clip_fraction        | 0.106        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.07         |\n",
      "|    explained_variance   | 0.957        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 380          |\n",
      "|    n_updates            | 58710        |\n",
      "|    policy_gradient_loss | -0.00496     |\n",
      "|    std                  | 0.208        |\n",
      "|    value_loss           | 3.41e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1610000, episode_reward=-98070.02 +/- 53284.29\n",
      "Episode length: 1680.60 +/- 780.26\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.68e+03    |\n",
      "|    mean_reward          | -9.81e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1610000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015138963 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.07        |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 117         |\n",
      "|    n_updates            | 58720       |\n",
      "|    policy_gradient_loss | -0.00175    |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 447         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.68e+03  |\n",
      "|    ep_rew_mean     | -2.44e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 650       |\n",
      "|    iterations      | 787       |\n",
      "|    time_elapsed    | 2477      |\n",
      "|    total_timesteps | 1611776   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.68e+03     |\n",
      "|    ep_rew_mean          | -2.45e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 650          |\n",
      "|    iterations           | 788          |\n",
      "|    time_elapsed         | 2479         |\n",
      "|    total_timesteps      | 1613824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061041373 |\n",
      "|    clip_fraction        | 0.11         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.07         |\n",
      "|    explained_variance   | 0.548        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.7e+07      |\n",
      "|    n_updates            | 58730        |\n",
      "|    policy_gradient_loss | 0.000585     |\n",
      "|    std                  | 0.208        |\n",
      "|    value_loss           | 2.64e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1615000, episode_reward=-88607.61 +/- 43444.73\n",
      "Episode length: 1679.40 +/- 831.22\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.68e+03     |\n",
      "|    mean_reward          | -8.86e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1615000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021818213 |\n",
      "|    clip_fraction        | 0.00669      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.07         |\n",
      "|    explained_variance   | 0.607        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.36e+07     |\n",
      "|    n_updates            | 58740        |\n",
      "|    policy_gradient_loss | -0.00314     |\n",
      "|    std                  | 0.208        |\n",
      "|    value_loss           | 1.72e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.7e+03   |\n",
      "|    ep_rew_mean     | -2.57e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 650       |\n",
      "|    iterations      | 789       |\n",
      "|    time_elapsed    | 2485      |\n",
      "|    total_timesteps | 1615872   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.72e+03    |\n",
      "|    ep_rew_mean          | -2.67e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 650         |\n",
      "|    iterations           | 790         |\n",
      "|    time_elapsed         | 2486        |\n",
      "|    total_timesteps      | 1617920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011436369 |\n",
      "|    clip_fraction        | 0.0475      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.07        |\n",
      "|    explained_variance   | 0.568       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.03e+05    |\n",
      "|    n_updates            | 58750       |\n",
      "|    policy_gradient_loss | 0.000978    |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 2.5e+07     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.7e+03      |\n",
      "|    ep_rew_mean          | -2.62e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 650          |\n",
      "|    iterations           | 791          |\n",
      "|    time_elapsed         | 2488         |\n",
      "|    total_timesteps      | 1619968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016273367 |\n",
      "|    clip_fraction        | 0.00732      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.08         |\n",
      "|    explained_variance   | 0.553        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.2e+06      |\n",
      "|    n_updates            | 58760        |\n",
      "|    policy_gradient_loss | -0.00114     |\n",
      "|    std                  | 0.208        |\n",
      "|    value_loss           | 1.97e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1620000, episode_reward=-108550.09 +/- 2093.72\n",
      "Episode length: 2015.40 +/- 84.01\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2.02e+03   |\n",
      "|    mean_reward          | -1.09e+05  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1620000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01750244 |\n",
      "|    clip_fraction        | 0.151      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.08       |\n",
      "|    explained_variance   | 0.976      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 207        |\n",
      "|    n_updates            | 58770      |\n",
      "|    policy_gradient_loss | -0.00844   |\n",
      "|    std                  | 0.207      |\n",
      "|    value_loss           | 1.75e+03   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.72e+03  |\n",
      "|    ep_rew_mean     | -2.68e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 649       |\n",
      "|    iterations      | 792       |\n",
      "|    time_elapsed    | 2495      |\n",
      "|    total_timesteps | 1622016   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.74e+03     |\n",
      "|    ep_rew_mean          | -2.76e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 650          |\n",
      "|    iterations           | 793          |\n",
      "|    time_elapsed         | 2497         |\n",
      "|    total_timesteps      | 1624064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058360775 |\n",
      "|    clip_fraction        | 0.0888       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.08         |\n",
      "|    explained_variance   | 0.6          |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.09e+06     |\n",
      "|    n_updates            | 58780        |\n",
      "|    policy_gradient_loss | -0.00381     |\n",
      "|    std                  | 0.208        |\n",
      "|    value_loss           | 1.48e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1625000, episode_reward=-114002.83 +/- 15696.83\n",
      "Episode length: 2130.60 +/- 27.66\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.13e+03     |\n",
      "|    mean_reward          | -1.14e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1625000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042849244 |\n",
      "|    clip_fraction        | 0.0277       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.08         |\n",
      "|    explained_variance   | 0.614        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.62e+05     |\n",
      "|    n_updates            | 58790        |\n",
      "|    policy_gradient_loss | -0.00393     |\n",
      "|    std                  | 0.208        |\n",
      "|    value_loss           | 1.56e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.76e+03  |\n",
      "|    ep_rew_mean     | -2.81e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 649       |\n",
      "|    iterations      | 794       |\n",
      "|    time_elapsed    | 2504      |\n",
      "|    total_timesteps | 1626112   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.78e+03     |\n",
      "|    ep_rew_mean          | -2.93e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 649          |\n",
      "|    iterations           | 795          |\n",
      "|    time_elapsed         | 2506         |\n",
      "|    total_timesteps      | 1628160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034591756 |\n",
      "|    clip_fraction        | 0.0185       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.08         |\n",
      "|    explained_variance   | 0.461        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.71e+05     |\n",
      "|    n_updates            | 58800        |\n",
      "|    policy_gradient_loss | -0.00188     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 7.6e+06      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1630000, episode_reward=-108192.68 +/- 84601.45\n",
      "Episode length: 1887.40 +/- 933.44\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.89e+03     |\n",
      "|    mean_reward          | -1.08e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1630000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029058256 |\n",
      "|    clip_fraction        | 0.0183       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.08         |\n",
      "|    explained_variance   | 0.574        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.49e+06     |\n",
      "|    n_updates            | 58810        |\n",
      "|    policy_gradient_loss | -0.000433    |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 2.25e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.78e+03  |\n",
      "|    ep_rew_mean     | -3.01e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 648       |\n",
      "|    iterations      | 796       |\n",
      "|    time_elapsed    | 2512      |\n",
      "|    total_timesteps | 1630208   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.78e+03    |\n",
      "|    ep_rew_mean          | -3.02e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 649         |\n",
      "|    iterations           | 797         |\n",
      "|    time_elapsed         | 2514        |\n",
      "|    total_timesteps      | 1632256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004393233 |\n",
      "|    clip_fraction        | 0.0262      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.08        |\n",
      "|    explained_variance   | 0.582       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.02e+07    |\n",
      "|    n_updates            | 58820       |\n",
      "|    policy_gradient_loss | -0.00363    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 2.06e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.79e+03    |\n",
      "|    ep_rew_mean          | -3.09e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 649         |\n",
      "|    iterations           | 798         |\n",
      "|    time_elapsed         | 2516        |\n",
      "|    total_timesteps      | 1634304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013780199 |\n",
      "|    clip_fraction        | 0.09        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.08        |\n",
      "|    explained_variance   | 0.901       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 490         |\n",
      "|    n_updates            | 58830       |\n",
      "|    policy_gradient_loss | -0.00273    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 5.7e+03     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1635000, episode_reward=59885.57 +/- 32204.26\n",
      "Episode length: 4004.00 +/- 1992.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4e+03        |\n",
      "|    mean_reward          | 5.99e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1635000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043076873 |\n",
      "|    clip_fraction        | 0.136        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.08         |\n",
      "|    explained_variance   | 0.588        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.34e+07     |\n",
      "|    n_updates            | 58840        |\n",
      "|    policy_gradient_loss | 0.0011       |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 1.99e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.79e+03  |\n",
      "|    ep_rew_mean     | -3.09e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 647       |\n",
      "|    iterations      | 799       |\n",
      "|    time_elapsed    | 2527      |\n",
      "|    total_timesteps | 1636352   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.83e+03     |\n",
      "|    ep_rew_mean          | -3.11e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 647          |\n",
      "|    iterations           | 800          |\n",
      "|    time_elapsed         | 2529         |\n",
      "|    total_timesteps      | 1638400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062716673 |\n",
      "|    clip_fraction        | 0.0303       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.08         |\n",
      "|    explained_variance   | 0.837        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.75e+06     |\n",
      "|    n_updates            | 58850        |\n",
      "|    policy_gradient_loss | -0.00577     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 2e+06        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1640000, episode_reward=61310.62 +/- 31743.60\n",
      "Episode length: 4003.40 +/- 1993.20\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 4e+03      |\n",
      "|    mean_reward          | 6.13e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1640000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.23951718 |\n",
      "|    clip_fraction        | 0.171      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.08       |\n",
      "|    explained_variance   | 0.565      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 372        |\n",
      "|    n_updates            | 58860      |\n",
      "|    policy_gradient_loss | -0.0123    |\n",
      "|    std                  | 0.207      |\n",
      "|    value_loss           | 1.44e+07   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.83e+03  |\n",
      "|    ep_rew_mean     | -3.11e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 645       |\n",
      "|    iterations      | 801       |\n",
      "|    time_elapsed    | 2540      |\n",
      "|    total_timesteps | 1640448   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.85e+03    |\n",
      "|    ep_rew_mean          | -3.02e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 646         |\n",
      "|    iterations           | 802         |\n",
      "|    time_elapsed         | 2542        |\n",
      "|    total_timesteps      | 1642496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016079698 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.08        |\n",
      "|    explained_variance   | 0.926       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 191         |\n",
      "|    n_updates            | 58870       |\n",
      "|    policy_gradient_loss | 0.013       |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 2.54e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.85e+03    |\n",
      "|    ep_rew_mean          | -3.02e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 646         |\n",
      "|    iterations           | 803         |\n",
      "|    time_elapsed         | 2544        |\n",
      "|    total_timesteps      | 1644544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013736652 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.08        |\n",
      "|    explained_variance   | 0.665       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 918         |\n",
      "|    n_updates            | 58880       |\n",
      "|    policy_gradient_loss | -0.00168    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 9.79e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1645000, episode_reward=80485.41 +/- 3729.62\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 8.05e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1645000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007227678 |\n",
      "|    clip_fraction        | 0.0875      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.08        |\n",
      "|    explained_variance   | 0.923       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 632         |\n",
      "|    n_updates            | 58890       |\n",
      "|    policy_gradient_loss | -0.00118    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 4.76e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.9e+03   |\n",
      "|    ep_rew_mean     | -2.94e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 643       |\n",
      "|    iterations      | 804       |\n",
      "|    time_elapsed    | 2558      |\n",
      "|    total_timesteps | 1646592   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.9e+03     |\n",
      "|    ep_rew_mean          | -2.94e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 644         |\n",
      "|    iterations           | 805         |\n",
      "|    time_elapsed         | 2559        |\n",
      "|    total_timesteps      | 1648640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009253729 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.08        |\n",
      "|    explained_variance   | 0.883       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.83e+03    |\n",
      "|    n_updates            | 58900       |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1.68e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1650000, episode_reward=-1845.94 +/- 65099.08\n",
      "Episode length: 2018.40 +/- 2434.47\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.02e+03    |\n",
      "|    mean_reward          | -1.85e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1650000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012857968 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.09        |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 144         |\n",
      "|    n_updates            | 58910       |\n",
      "|    policy_gradient_loss | 0.00169     |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 745         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.9e+03   |\n",
      "|    ep_rew_mean     | -2.94e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 643       |\n",
      "|    iterations      | 806       |\n",
      "|    time_elapsed    | 2566      |\n",
      "|    total_timesteps | 1650688   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.95e+03    |\n",
      "|    ep_rew_mean          | -2.46e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 643         |\n",
      "|    iterations           | 807         |\n",
      "|    time_elapsed         | 2568        |\n",
      "|    total_timesteps      | 1652736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025169676 |\n",
      "|    clip_fraction        | 0.325       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.1         |\n",
      "|    explained_variance   | 0.884       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 105         |\n",
      "|    n_updates            | 58920       |\n",
      "|    policy_gradient_loss | 0.00248     |\n",
      "|    std                  | 0.205       |\n",
      "|    value_loss           | 879         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.95e+03    |\n",
      "|    ep_rew_mean          | -2.46e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 643         |\n",
      "|    iterations           | 808         |\n",
      "|    time_elapsed         | 2570        |\n",
      "|    total_timesteps      | 1654784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011403693 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.11        |\n",
      "|    explained_variance   | 0.737       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 808         |\n",
      "|    n_updates            | 58930       |\n",
      "|    policy_gradient_loss | -0.00238    |\n",
      "|    std                  | 0.205       |\n",
      "|    value_loss           | 5.87e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1655000, episode_reward=-25753.99 +/- 112905.30\n",
      "Episode length: 2036.20 +/- 2420.35\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.04e+03    |\n",
      "|    mean_reward          | -2.58e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1655000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007791915 |\n",
      "|    clip_fraction        | 0.046       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.11        |\n",
      "|    explained_variance   | 0.798       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.61e+03    |\n",
      "|    n_updates            | 58940       |\n",
      "|    policy_gradient_loss | -0.00299    |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 9.52e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.99e+03  |\n",
      "|    ep_rew_mean     | -2.39e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 642       |\n",
      "|    iterations      | 809       |\n",
      "|    time_elapsed    | 2577      |\n",
      "|    total_timesteps | 1656832   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.99e+03     |\n",
      "|    ep_rew_mean          | -2.5e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 643          |\n",
      "|    iterations           | 810          |\n",
      "|    time_elapsed         | 2578         |\n",
      "|    total_timesteps      | 1658880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035090037 |\n",
      "|    clip_fraction        | 0.0273       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.11         |\n",
      "|    explained_variance   | 0.632        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 403          |\n",
      "|    n_updates            | 58950        |\n",
      "|    policy_gradient_loss | 0.0016       |\n",
      "|    std                  | 0.206        |\n",
      "|    value_loss           | 1.66e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1660000, episode_reward=10147.19 +/- 94201.02\n",
      "Episode length: 3138.80 +/- 2289.50\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3.14e+03     |\n",
      "|    mean_reward          | 1.01e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1660000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009827701 |\n",
      "|    clip_fraction        | 0.00879      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.11         |\n",
      "|    explained_variance   | 0.476        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.27e+07     |\n",
      "|    n_updates            | 58960        |\n",
      "|    policy_gradient_loss | -0.00201     |\n",
      "|    std                  | 0.206        |\n",
      "|    value_loss           | 1.68e+07     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.99e+03 |\n",
      "|    ep_rew_mean     | -2.5e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 641      |\n",
      "|    iterations      | 811      |\n",
      "|    time_elapsed    | 2588     |\n",
      "|    total_timesteps | 1660928  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.03e+03    |\n",
      "|    ep_rew_mean          | -2.41e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 642         |\n",
      "|    iterations           | 812         |\n",
      "|    time_elapsed         | 2590        |\n",
      "|    total_timesteps      | 1662976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009357198 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.11        |\n",
      "|    explained_variance   | 0.941       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 329         |\n",
      "|    n_updates            | 58970       |\n",
      "|    policy_gradient_loss | -0.000765   |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 1.68e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1665000, episode_reward=32740.82 +/- 54635.48\n",
      "Episode length: 3008.40 +/- 2439.21\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.01e+03    |\n",
      "|    mean_reward          | 3.27e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1665000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010801109 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.1         |\n",
      "|    explained_variance   | 0.107       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.03e+03    |\n",
      "|    n_updates            | 58980       |\n",
      "|    policy_gradient_loss | -0.00212    |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 4.42e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.03e+03  |\n",
      "|    ep_rew_mean     | -2.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 640       |\n",
      "|    iterations      | 813       |\n",
      "|    time_elapsed    | 2599      |\n",
      "|    total_timesteps | 1665024   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.03e+03     |\n",
      "|    ep_rew_mean          | -2.41e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 640          |\n",
      "|    iterations           | 814          |\n",
      "|    time_elapsed         | 2601         |\n",
      "|    total_timesteps      | 1667072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054084766 |\n",
      "|    clip_fraction        | 0.0632       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.1          |\n",
      "|    explained_variance   | 0.827        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.76e+03     |\n",
      "|    n_updates            | 58990        |\n",
      "|    policy_gradient_loss | -0.00332     |\n",
      "|    std                  | 0.206        |\n",
      "|    value_loss           | 1.02e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.08e+03    |\n",
      "|    ep_rew_mean          | -2.33e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 641         |\n",
      "|    iterations           | 815         |\n",
      "|    time_elapsed         | 2602        |\n",
      "|    total_timesteps      | 1669120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024886325 |\n",
      "|    clip_fraction        | 0.356       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.1         |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 80          |\n",
      "|    n_updates            | 59000       |\n",
      "|    policy_gradient_loss | 0.022       |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 418         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1670000, episode_reward=40359.85 +/- 15372.01\n",
      "Episode length: 4571.80 +/- 856.40\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4.57e+03     |\n",
      "|    mean_reward          | 4.04e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1670000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064887125 |\n",
      "|    clip_fraction        | 0.0722       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.09         |\n",
      "|    explained_variance   | 0.813        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.49e+04     |\n",
      "|    n_updates            | 59010        |\n",
      "|    policy_gradient_loss | -0.00374     |\n",
      "|    std                  | 0.206        |\n",
      "|    value_loss           | 4.15e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.08e+03  |\n",
      "|    ep_rew_mean     | -2.33e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 638       |\n",
      "|    iterations      | 816       |\n",
      "|    time_elapsed    | 2615      |\n",
      "|    total_timesteps | 1671168   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.12e+03    |\n",
      "|    ep_rew_mean          | -2.26e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 639         |\n",
      "|    iterations           | 817         |\n",
      "|    time_elapsed         | 2617        |\n",
      "|    total_timesteps      | 1673216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021383291 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.09        |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 68.6        |\n",
      "|    n_updates            | 59020       |\n",
      "|    policy_gradient_loss | 0.00299     |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 392         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1675000, episode_reward=-4443.22 +/- 11764.82\n",
      "Episode length: 1063.60 +/- 563.69\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.06e+03   |\n",
      "|    mean_reward          | -4.44e+03  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1675000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01507216 |\n",
      "|    clip_fraction        | 0.237      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.09       |\n",
      "|    explained_variance   | -0.345     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 431        |\n",
      "|    n_updates            | 59030      |\n",
      "|    policy_gradient_loss | -0.00279   |\n",
      "|    std                  | 0.207      |\n",
      "|    value_loss           | 1.02e+04   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.13e+03  |\n",
      "|    ep_rew_mean     | -2.23e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 638       |\n",
      "|    iterations      | 818       |\n",
      "|    time_elapsed    | 2621      |\n",
      "|    total_timesteps | 1675264   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.08e+03     |\n",
      "|    ep_rew_mean          | -2.31e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 639          |\n",
      "|    iterations           | 819          |\n",
      "|    time_elapsed         | 2623         |\n",
      "|    total_timesteps      | 1677312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063047716 |\n",
      "|    clip_fraction        | 0.0824       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.09         |\n",
      "|    explained_variance   | 0.839        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.46e+03     |\n",
      "|    n_updates            | 59040        |\n",
      "|    policy_gradient_loss | -0.00392     |\n",
      "|    std                  | 0.206        |\n",
      "|    value_loss           | 2.5e+05      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.08e+03    |\n",
      "|    ep_rew_mean          | -2.24e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 639         |\n",
      "|    iterations           | 820         |\n",
      "|    time_elapsed         | 2625        |\n",
      "|    total_timesteps      | 1679360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.049009558 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.09        |\n",
      "|    explained_variance   | 0.584       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.55e+06    |\n",
      "|    n_updates            | 59050       |\n",
      "|    policy_gradient_loss | -0.00484    |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 1.07e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1680000, episode_reward=-3655.94 +/- 15286.76\n",
      "Episode length: 1776.80 +/- 1726.75\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.78e+03    |\n",
      "|    mean_reward          | -3.66e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1680000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007784224 |\n",
      "|    clip_fraction        | 0.0541      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.09        |\n",
      "|    explained_variance   | 0.618       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.67e+04    |\n",
      "|    n_updates            | 59060       |\n",
      "|    policy_gradient_loss | -0.00688    |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 4.9e+05     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.1e+03   |\n",
      "|    ep_rew_mean     | -2.23e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 638       |\n",
      "|    iterations      | 821       |\n",
      "|    time_elapsed    | 2631      |\n",
      "|    total_timesteps | 1681408   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.12e+03    |\n",
      "|    ep_rew_mean          | -2.2e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 639         |\n",
      "|    iterations           | 822         |\n",
      "|    time_elapsed         | 2633        |\n",
      "|    total_timesteps      | 1683456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013489128 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.09        |\n",
      "|    explained_variance   | 0.956       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 481         |\n",
      "|    n_updates            | 59070       |\n",
      "|    policy_gradient_loss | 0.00191     |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 4.42e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1685000, episode_reward=28134.28 +/- 52019.03\n",
      "Episode length: 3289.20 +/- 2140.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3.29e+03     |\n",
      "|    mean_reward          | 2.81e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1685000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067325127 |\n",
      "|    clip_fraction        | 0.103        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.09         |\n",
      "|    explained_variance   | 0.855        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.27e+03     |\n",
      "|    n_updates            | 59080        |\n",
      "|    policy_gradient_loss | -0.00035     |\n",
      "|    std                  | 0.206        |\n",
      "|    value_loss           | 1.14e+04     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.12e+03 |\n",
      "|    ep_rew_mean     | -2.2e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 637      |\n",
      "|    iterations      | 823      |\n",
      "|    time_elapsed    | 2643     |\n",
      "|    total_timesteps | 1685504  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.14e+03   |\n",
      "|    ep_rew_mean          | -2.22e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 638        |\n",
      "|    iterations           | 824        |\n",
      "|    time_elapsed         | 2644       |\n",
      "|    total_timesteps      | 1687552    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04127932 |\n",
      "|    clip_fraction        | 0.208      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.1        |\n",
      "|    explained_variance   | 0.782      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 699        |\n",
      "|    n_updates            | 59090      |\n",
      "|    policy_gradient_loss | -0.000363  |\n",
      "|    std                  | 0.206      |\n",
      "|    value_loss           | 2.21e+03   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.16e+03     |\n",
      "|    ep_rew_mean          | -2.19e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 638          |\n",
      "|    iterations           | 825          |\n",
      "|    time_elapsed         | 2646         |\n",
      "|    total_timesteps      | 1689600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030863825 |\n",
      "|    clip_fraction        | 0.094        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.1          |\n",
      "|    explained_variance   | 0.384        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.39e+05     |\n",
      "|    n_updates            | 59100        |\n",
      "|    policy_gradient_loss | 0.000206     |\n",
      "|    std                  | 0.206        |\n",
      "|    value_loss           | 1.28e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1690000, episode_reward=-31567.59 +/- 197237.96\n",
      "Episode length: 4049.20 +/- 1901.60\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.05e+03    |\n",
      "|    mean_reward          | -3.16e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1690000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013522052 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.1         |\n",
      "|    explained_variance   | 0.668       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 540         |\n",
      "|    n_updates            | 59110       |\n",
      "|    policy_gradient_loss | -0.000912   |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 1e+05       |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.16e+03  |\n",
      "|    ep_rew_mean     | -2.19e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 636       |\n",
      "|    iterations      | 826       |\n",
      "|    time_elapsed    | 2658      |\n",
      "|    total_timesteps | 1691648   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.16e+03    |\n",
      "|    ep_rew_mean          | -2.19e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 636         |\n",
      "|    iterations           | 827         |\n",
      "|    time_elapsed         | 2660        |\n",
      "|    total_timesteps      | 1693696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012962088 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.1         |\n",
      "|    explained_variance   | 0.893       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 286         |\n",
      "|    n_updates            | 59120       |\n",
      "|    policy_gradient_loss | -0.00159    |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 1.49e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1695000, episode_reward=12345.86 +/- 6848.88\n",
      "Episode length: 1696.60 +/- 986.01\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.7e+03     |\n",
      "|    mean_reward          | 1.23e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1695000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030134864 |\n",
      "|    clip_fraction        | 0.358       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.09        |\n",
      "|    explained_variance   | 0.807       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 115         |\n",
      "|    n_updates            | 59130       |\n",
      "|    policy_gradient_loss | 0.0209      |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1.28e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.22e+03  |\n",
      "|    ep_rew_mean     | -2.09e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 636       |\n",
      "|    iterations      | 828       |\n",
      "|    time_elapsed    | 2665      |\n",
      "|    total_timesteps | 1695744   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.23e+03     |\n",
      "|    ep_rew_mean          | -2.07e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 636          |\n",
      "|    iterations           | 829          |\n",
      "|    time_elapsed         | 2667         |\n",
      "|    total_timesteps      | 1697792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065592793 |\n",
      "|    clip_fraction        | 0.0862       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.08         |\n",
      "|    explained_variance   | 0.552        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.03e+03     |\n",
      "|    n_updates            | 59140        |\n",
      "|    policy_gradient_loss | 0.00134      |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 2.03e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.23e+03    |\n",
      "|    ep_rew_mean          | -2.07e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 636         |\n",
      "|    iterations           | 830         |\n",
      "|    time_elapsed         | 2669        |\n",
      "|    total_timesteps      | 1699840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008524895 |\n",
      "|    clip_fraction        | 0.0895      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.09        |\n",
      "|    explained_variance   | 0.902       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 544         |\n",
      "|    n_updates            | 59150       |\n",
      "|    policy_gradient_loss | -0.0013     |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 3.38e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1700000, episode_reward=42909.61 +/- 21832.99\n",
      "Episode length: 4004.00 +/- 1992.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4e+03       |\n",
      "|    mean_reward          | 4.29e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1700000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024883516 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.08        |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 61.9        |\n",
      "|    n_updates            | 59160       |\n",
      "|    policy_gradient_loss | 0.00304     |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 271         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.28e+03  |\n",
      "|    ep_rew_mean     | -2.05e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 634       |\n",
      "|    iterations      | 831       |\n",
      "|    time_elapsed    | 2681      |\n",
      "|    total_timesteps | 1701888   |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 2.28e+03  |\n",
      "|    ep_rew_mean          | -2.05e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 635       |\n",
      "|    iterations           | 832       |\n",
      "|    time_elapsed         | 2682      |\n",
      "|    total_timesteps      | 1703936   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0086808 |\n",
      "|    clip_fraction        | 0.0813    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 2.07      |\n",
      "|    explained_variance   | 0.838     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 553       |\n",
      "|    n_updates            | 59170     |\n",
      "|    policy_gradient_loss | -0.00283  |\n",
      "|    std                  | 0.207     |\n",
      "|    value_loss           | 1.04e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=1705000, episode_reward=61082.31 +/- 3212.71\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 6.11e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1705000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010694067 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.08        |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 81.8        |\n",
      "|    n_updates            | 59180       |\n",
      "|    policy_gradient_loss | 0.00117     |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 397         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.28e+03  |\n",
      "|    ep_rew_mean     | -2.05e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 632       |\n",
      "|    iterations      | 833       |\n",
      "|    time_elapsed    | 2696      |\n",
      "|    total_timesteps | 1705984   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.27e+03    |\n",
      "|    ep_rew_mean          | -2.13e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 632         |\n",
      "|    iterations           | 834         |\n",
      "|    time_elapsed         | 2698        |\n",
      "|    total_timesteps      | 1708032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020893734 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.09        |\n",
      "|    explained_variance   | 0.912       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 73.9        |\n",
      "|    n_updates            | 59190       |\n",
      "|    policy_gradient_loss | 0.0036      |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 404         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1710000, episode_reward=60112.69 +/- 31305.10\n",
      "Episode length: 4003.60 +/- 1992.80\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4e+03       |\n",
      "|    mean_reward          | 6.01e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1710000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004789154 |\n",
      "|    clip_fraction        | 0.0635      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.09        |\n",
      "|    explained_variance   | 0.58        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.93e+03    |\n",
      "|    n_updates            | 59200       |\n",
      "|    policy_gradient_loss | -0.000845   |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 1.19e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.27e+03  |\n",
      "|    ep_rew_mean     | -2.13e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 631       |\n",
      "|    iterations      | 835       |\n",
      "|    time_elapsed    | 2709      |\n",
      "|    total_timesteps | 1710080   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.29e+03    |\n",
      "|    ep_rew_mean          | -2.07e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 631         |\n",
      "|    iterations           | 836         |\n",
      "|    time_elapsed         | 2711        |\n",
      "|    total_timesteps      | 1712128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016462693 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.09        |\n",
      "|    explained_variance   | 0.786       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 57.3        |\n",
      "|    n_updates            | 59210       |\n",
      "|    policy_gradient_loss | 0.00359     |\n",
      "|    std                  | 0.205       |\n",
      "|    value_loss           | 748         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.29e+03     |\n",
      "|    ep_rew_mean          | -2.07e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 631          |\n",
      "|    iterations           | 837          |\n",
      "|    time_elapsed         | 2713         |\n",
      "|    total_timesteps      | 1714176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071938327 |\n",
      "|    clip_fraction        | 0.243        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.09         |\n",
      "|    explained_variance   | 0.637        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.47e+04     |\n",
      "|    n_updates            | 59220        |\n",
      "|    policy_gradient_loss | 0.00525      |\n",
      "|    std                  | 0.205        |\n",
      "|    value_loss           | 1.26e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1715000, episode_reward=-7562.58 +/- 41931.42\n",
      "Episode length: 2932.20 +/- 2372.21\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.93e+03    |\n",
      "|    mean_reward          | -7.56e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1715000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013849432 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.09        |\n",
      "|    explained_variance   | 0.879       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 160         |\n",
      "|    n_updates            | 59230       |\n",
      "|    policy_gradient_loss | -0.00589    |\n",
      "|    std                  | 0.205       |\n",
      "|    value_loss           | 821         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.29e+03  |\n",
      "|    ep_rew_mean     | -2.07e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 630       |\n",
      "|    iterations      | 838       |\n",
      "|    time_elapsed    | 2722      |\n",
      "|    total_timesteps | 1716224   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.34e+03    |\n",
      "|    ep_rew_mean          | -1.99e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 630         |\n",
      "|    iterations           | 839         |\n",
      "|    time_elapsed         | 2724        |\n",
      "|    total_timesteps      | 1718272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029751189 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.09        |\n",
      "|    explained_variance   | 0.937       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 105         |\n",
      "|    n_updates            | 59240       |\n",
      "|    policy_gradient_loss | 0.00189     |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 461         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1720000, episode_reward=-97229.60 +/- 150296.07\n",
      "Episode length: 1354.60 +/- 984.93\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.35e+03    |\n",
      "|    mean_reward          | -9.72e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1720000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013702639 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.09        |\n",
      "|    explained_variance   | 0.76        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 162         |\n",
      "|    n_updates            | 59250       |\n",
      "|    policy_gradient_loss | 0.00802     |\n",
      "|    std                  | 0.205       |\n",
      "|    value_loss           | 1.46e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.36e+03  |\n",
      "|    ep_rew_mean     | -1.95e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 630       |\n",
      "|    iterations      | 840       |\n",
      "|    time_elapsed    | 2729      |\n",
      "|    total_timesteps | 1720320   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.33e+03     |\n",
      "|    ep_rew_mean          | -1.99e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 630          |\n",
      "|    iterations           | 841          |\n",
      "|    time_elapsed         | 2731         |\n",
      "|    total_timesteps      | 1722368      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047158315 |\n",
      "|    clip_fraction        | 0.051        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.09         |\n",
      "|    explained_variance   | 0.55         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.34e+07     |\n",
      "|    n_updates            | 59260        |\n",
      "|    policy_gradient_loss | -0.00374     |\n",
      "|    std                  | 0.205        |\n",
      "|    value_loss           | 1.68e+07     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.36e+03    |\n",
      "|    ep_rew_mean          | -1.96e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 630         |\n",
      "|    iterations           | 842         |\n",
      "|    time_elapsed         | 2733        |\n",
      "|    total_timesteps      | 1724416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013995413 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.09        |\n",
      "|    explained_variance   | 0.726       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 339         |\n",
      "|    n_updates            | 59270       |\n",
      "|    policy_gradient_loss | -0.00028    |\n",
      "|    std                  | 0.205       |\n",
      "|    value_loss           | 2.08e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1725000, episode_reward=15239.40 +/- 23207.82\n",
      "Episode length: 3207.60 +/- 1827.63\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.21e+03    |\n",
      "|    mean_reward          | 1.52e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1725000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018928308 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.09        |\n",
      "|    explained_variance   | 0.904       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 287         |\n",
      "|    n_updates            | 59280       |\n",
      "|    policy_gradient_loss | 0.00148     |\n",
      "|    std                  | 0.205       |\n",
      "|    value_loss           | 1.5e+03     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.36e+03  |\n",
      "|    ep_rew_mean     | -1.96e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 629       |\n",
      "|    iterations      | 843       |\n",
      "|    time_elapsed    | 2742      |\n",
      "|    total_timesteps | 1726464   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.34e+03    |\n",
      "|    ep_rew_mean          | -1.97e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 629         |\n",
      "|    iterations           | 844         |\n",
      "|    time_elapsed         | 2744        |\n",
      "|    total_timesteps      | 1728512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014596324 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.09        |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 132         |\n",
      "|    n_updates            | 59290       |\n",
      "|    policy_gradient_loss | -0.00131    |\n",
      "|    std                  | 0.205       |\n",
      "|    value_loss           | 417         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1730000, episode_reward=-10663.23 +/- 28594.25\n",
      "Episode length: 1730.60 +/- 2035.77\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.73e+03     |\n",
      "|    mean_reward          | -1.07e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1730000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074246917 |\n",
      "|    clip_fraction        | 0.0788       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.09         |\n",
      "|    explained_variance   | 0.731        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 613          |\n",
      "|    n_updates            | 59300        |\n",
      "|    policy_gradient_loss | -0.00562     |\n",
      "|    std                  | 0.205        |\n",
      "|    value_loss           | 1.67e+05     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.34e+03  |\n",
      "|    ep_rew_mean     | -1.97e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 629       |\n",
      "|    iterations      | 845       |\n",
      "|    time_elapsed    | 2750      |\n",
      "|    total_timesteps | 1730560   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.38e+03   |\n",
      "|    ep_rew_mean          | -1.76e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 629        |\n",
      "|    iterations           | 846        |\n",
      "|    time_elapsed         | 2752       |\n",
      "|    total_timesteps      | 1732608    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02697261 |\n",
      "|    clip_fraction        | 0.178      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.09       |\n",
      "|    explained_variance   | 0.974      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 139        |\n",
      "|    n_updates            | 59310      |\n",
      "|    policy_gradient_loss | -0.00125   |\n",
      "|    std                  | 0.206      |\n",
      "|    value_loss           | 575        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.39e+03    |\n",
      "|    ep_rew_mean          | -1.83e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 629         |\n",
      "|    iterations           | 847         |\n",
      "|    time_elapsed         | 2754        |\n",
      "|    total_timesteps      | 1734656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008808361 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.09        |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 473         |\n",
      "|    n_updates            | 59320       |\n",
      "|    policy_gradient_loss | -0.00183    |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 2.26e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1735000, episode_reward=60002.93 +/- 15919.46\n",
      "Episode length: 4663.40 +/- 673.20\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.66e+03    |\n",
      "|    mean_reward          | 6e+04       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1735000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036172505 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.09        |\n",
      "|    explained_variance   | 0.595       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.51e+06    |\n",
      "|    n_updates            | 59330       |\n",
      "|    policy_gradient_loss | -0.00232    |\n",
      "|    std                  | 0.205       |\n",
      "|    value_loss           | 5.51e+06    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.39e+03  |\n",
      "|    ep_rew_mean     | -1.83e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 627       |\n",
      "|    iterations      | 848       |\n",
      "|    time_elapsed    | 2767      |\n",
      "|    total_timesteps | 1736704   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.39e+03    |\n",
      "|    ep_rew_mean          | -1.8e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 627         |\n",
      "|    iterations           | 849         |\n",
      "|    time_elapsed         | 2769        |\n",
      "|    total_timesteps      | 1738752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032258812 |\n",
      "|    clip_fraction        | 0.257       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.09        |\n",
      "|    explained_variance   | 0.894       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 90.3        |\n",
      "|    n_updates            | 59340       |\n",
      "|    policy_gradient_loss | 0.00741     |\n",
      "|    std                  | 0.205       |\n",
      "|    value_loss           | 518         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1740000, episode_reward=-21736.28 +/- 118213.31\n",
      "Episode length: 3030.80 +/- 2412.09\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.03e+03    |\n",
      "|    mean_reward          | -2.17e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1740000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004585201 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.1         |\n",
      "|    explained_variance   | 0.698       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.44e+05    |\n",
      "|    n_updates            | 59350       |\n",
      "|    policy_gradient_loss | -0.000467   |\n",
      "|    std                  | 0.205       |\n",
      "|    value_loss           | 1.75e+05    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.39e+03 |\n",
      "|    ep_rew_mean     | -1.8e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 626      |\n",
      "|    iterations      | 850      |\n",
      "|    time_elapsed    | 2778     |\n",
      "|    total_timesteps | 1740800  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.44e+03    |\n",
      "|    ep_rew_mean          | -1.74e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 626         |\n",
      "|    iterations           | 851         |\n",
      "|    time_elapsed         | 2779        |\n",
      "|    total_timesteps      | 1742848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010258154 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.1         |\n",
      "|    explained_variance   | 0.873       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.15e+03    |\n",
      "|    n_updates            | 59360       |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    std                  | 0.205       |\n",
      "|    value_loss           | 1.33e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.44e+03    |\n",
      "|    ep_rew_mean          | -1.74e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 627         |\n",
      "|    iterations           | 852         |\n",
      "|    time_elapsed         | 2781        |\n",
      "|    total_timesteps      | 1744896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012223849 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.11        |\n",
      "|    explained_variance   | 0.476       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 309         |\n",
      "|    n_updates            | 59370       |\n",
      "|    policy_gradient_loss | 0.00222     |\n",
      "|    std                  | 0.205       |\n",
      "|    value_loss           | 5.25e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1745000, episode_reward=27980.14 +/- 25884.36\n",
      "Episode length: 3171.60 +/- 1588.69\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.17e+03    |\n",
      "|    mean_reward          | 2.8e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1745000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018017411 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.12        |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 59.3        |\n",
      "|    n_updates            | 59380       |\n",
      "|    policy_gradient_loss | -0.00146    |\n",
      "|    std                  | 0.204       |\n",
      "|    value_loss           | 337         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.43e+03  |\n",
      "|    ep_rew_mean     | -1.55e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 625       |\n",
      "|    iterations      | 853       |\n",
      "|    time_elapsed    | 2791      |\n",
      "|    total_timesteps | 1746944   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.43e+03    |\n",
      "|    ep_rew_mean          | -1.55e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 626         |\n",
      "|    iterations           | 854         |\n",
      "|    time_elapsed         | 2793        |\n",
      "|    total_timesteps      | 1748992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011299423 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.13        |\n",
      "|    explained_variance   | 0.932       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 131         |\n",
      "|    n_updates            | 59390       |\n",
      "|    policy_gradient_loss | 0.00292     |\n",
      "|    std                  | 0.204       |\n",
      "|    value_loss           | 959         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1750000, episode_reward=66210.47 +/- 5142.45\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5e+03     |\n",
      "|    mean_reward          | 6.62e+04  |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 1750000   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0216939 |\n",
      "|    clip_fraction        | 0.253     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 2.15      |\n",
      "|    explained_variance   | 0.948     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 81.2      |\n",
      "|    n_updates            | 59400     |\n",
      "|    policy_gradient_loss | -0.0109   |\n",
      "|    std                  | 0.203     |\n",
      "|    value_loss           | 755       |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.43e+03  |\n",
      "|    ep_rew_mean     | -1.55e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 623       |\n",
      "|    iterations      | 855       |\n",
      "|    time_elapsed    | 2806      |\n",
      "|    total_timesteps | 1751040   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.48e+03   |\n",
      "|    ep_rew_mean          | -1.45e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 624        |\n",
      "|    iterations           | 856        |\n",
      "|    time_elapsed         | 2808       |\n",
      "|    total_timesteps      | 1753088    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04352278 |\n",
      "|    clip_fraction        | 0.289      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.17       |\n",
      "|    explained_variance   | 0.957      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 173        |\n",
      "|    n_updates            | 59410      |\n",
      "|    policy_gradient_loss | 2.92e-05   |\n",
      "|    std                  | 0.202      |\n",
      "|    value_loss           | 597        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1755000, episode_reward=12613.16 +/- 55473.65\n",
      "Episode length: 2015.40 +/- 2436.93\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.02e+03    |\n",
      "|    mean_reward          | 1.26e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1755000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012612536 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.17        |\n",
      "|    explained_variance   | 0.424       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.09e+05    |\n",
      "|    n_updates            | 59420       |\n",
      "|    policy_gradient_loss | -0.00403    |\n",
      "|    std                  | 0.202       |\n",
      "|    value_loss           | 2.53e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.48e+03  |\n",
      "|    ep_rew_mean     | -1.45e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 623       |\n",
      "|    iterations      | 857       |\n",
      "|    time_elapsed    | 2815      |\n",
      "|    total_timesteps | 1755136   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.51e+03    |\n",
      "|    ep_rew_mean          | -1.39e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 623         |\n",
      "|    iterations           | 858         |\n",
      "|    time_elapsed         | 2816        |\n",
      "|    total_timesteps      | 1757184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025991395 |\n",
      "|    clip_fraction        | 0.368       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.17        |\n",
      "|    explained_variance   | 0.916       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 19.1        |\n",
      "|    n_updates            | 59430       |\n",
      "|    policy_gradient_loss | 0.0289      |\n",
      "|    std                  | 0.201       |\n",
      "|    value_loss           | 123         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.51e+03    |\n",
      "|    ep_rew_mean          | -1.39e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 624         |\n",
      "|    iterations           | 859         |\n",
      "|    time_elapsed         | 2818        |\n",
      "|    total_timesteps      | 1759232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009282926 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.17        |\n",
      "|    explained_variance   | -1.91       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.58e+04    |\n",
      "|    n_updates            | 59440       |\n",
      "|    policy_gradient_loss | 0.00281     |\n",
      "|    std                  | 0.202       |\n",
      "|    value_loss           | 4.61e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1760000, episode_reward=29046.78 +/- 59366.00\n",
      "Episode length: 3009.80 +/- 2437.51\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.01e+03    |\n",
      "|    mean_reward          | 2.9e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1760000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009622477 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.18        |\n",
      "|    explained_variance   | 0.782       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 284         |\n",
      "|    n_updates            | 59450       |\n",
      "|    policy_gradient_loss | -0.009      |\n",
      "|    std                  | 0.201       |\n",
      "|    value_loss           | 1.11e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.51e+03  |\n",
      "|    ep_rew_mean     | -1.39e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 622       |\n",
      "|    iterations      | 860       |\n",
      "|    time_elapsed    | 2827      |\n",
      "|    total_timesteps | 1761280   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.54e+03    |\n",
      "|    ep_rew_mean          | -1.12e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 623         |\n",
      "|    iterations           | 861         |\n",
      "|    time_elapsed         | 2829        |\n",
      "|    total_timesteps      | 1763328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027985025 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.18        |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 284         |\n",
      "|    n_updates            | 59460       |\n",
      "|    policy_gradient_loss | -0.00386    |\n",
      "|    std                  | 0.201       |\n",
      "|    value_loss           | 410         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1765000, episode_reward=76400.41 +/- 8485.10\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 7.64e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1765000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009694649 |\n",
      "|    clip_fraction        | 0.0908      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.18        |\n",
      "|    explained_variance   | 0.848       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 378         |\n",
      "|    n_updates            | 59470       |\n",
      "|    policy_gradient_loss | -0.00201    |\n",
      "|    std                  | 0.201       |\n",
      "|    value_loss           | 2.59e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.54e+03  |\n",
      "|    ep_rew_mean     | -1.12e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 620       |\n",
      "|    iterations      | 862       |\n",
      "|    time_elapsed    | 2843      |\n",
      "|    total_timesteps | 1765376   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.56e+03    |\n",
      "|    ep_rew_mean          | -8.46e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 621         |\n",
      "|    iterations           | 863         |\n",
      "|    time_elapsed         | 2845        |\n",
      "|    total_timesteps      | 1767424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013927329 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.18        |\n",
      "|    explained_variance   | 0.801       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 196         |\n",
      "|    n_updates            | 59480       |\n",
      "|    policy_gradient_loss | -0.00195    |\n",
      "|    std                  | 0.201       |\n",
      "|    value_loss           | 812         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.52e+03     |\n",
      "|    ep_rew_mean          | -9.33e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 621          |\n",
      "|    iterations           | 864          |\n",
      "|    time_elapsed         | 2846         |\n",
      "|    total_timesteps      | 1769472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056157606 |\n",
      "|    clip_fraction        | 0.0521       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.18         |\n",
      "|    explained_variance   | 0.524        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.48e+05     |\n",
      "|    n_updates            | 59490        |\n",
      "|    policy_gradient_loss | -0.00117     |\n",
      "|    std                  | 0.201        |\n",
      "|    value_loss           | 2.29e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1770000, episode_reward=-58793.80 +/- 65667.95\n",
      "Episode length: 3021.80 +/- 991.40\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3.02e+03     |\n",
      "|    mean_reward          | -5.88e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1770000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011657674 |\n",
      "|    clip_fraction        | 0.00635      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.19         |\n",
      "|    explained_variance   | 0.501        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.98e+07     |\n",
      "|    n_updates            | 59500        |\n",
      "|    policy_gradient_loss | -0.00168     |\n",
      "|    std                  | 0.201        |\n",
      "|    value_loss           | 4.5e+07      |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.48e+03  |\n",
      "|    ep_rew_mean     | -1.09e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 620       |\n",
      "|    iterations      | 865       |\n",
      "|    time_elapsed    | 2855      |\n",
      "|    total_timesteps | 1771520   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.5e+03      |\n",
      "|    ep_rew_mean          | -1.17e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 620          |\n",
      "|    iterations           | 866          |\n",
      "|    time_elapsed         | 2857         |\n",
      "|    total_timesteps      | 1773568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004264693 |\n",
      "|    clip_fraction        | 0.00498      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.19         |\n",
      "|    explained_variance   | 0.6          |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.48e+06     |\n",
      "|    n_updates            | 59510        |\n",
      "|    policy_gradient_loss | -0.0018      |\n",
      "|    std                  | 0.201        |\n",
      "|    value_loss           | 2.06e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1775000, episode_reward=13321.12 +/- 85855.06\n",
      "Episode length: 4135.60 +/- 1059.47\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4.14e+03     |\n",
      "|    mean_reward          | 1.33e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1775000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029647858 |\n",
      "|    clip_fraction        | 0.0129       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.19         |\n",
      "|    explained_variance   | 0.617        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.27e+06     |\n",
      "|    n_updates            | 59520        |\n",
      "|    policy_gradient_loss | -0.00396     |\n",
      "|    std                  | 0.201        |\n",
      "|    value_loss           | 1.75e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.5e+03   |\n",
      "|    ep_rew_mean     | -1.17e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 618       |\n",
      "|    iterations      | 867       |\n",
      "|    time_elapsed    | 2869      |\n",
      "|    total_timesteps | 1775616   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.5e+03      |\n",
      "|    ep_rew_mean          | -1.17e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 619          |\n",
      "|    iterations           | 868          |\n",
      "|    time_elapsed         | 2871         |\n",
      "|    total_timesteps      | 1777664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023978804 |\n",
      "|    clip_fraction        | 0.00127      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.19         |\n",
      "|    explained_variance   | 0.933        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.53e+05     |\n",
      "|    n_updates            | 59530        |\n",
      "|    policy_gradient_loss | -0.00326     |\n",
      "|    std                  | 0.201        |\n",
      "|    value_loss           | 3.86e+05     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.49e+03     |\n",
      "|    ep_rew_mean          | -1.15e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 619          |\n",
      "|    iterations           | 869          |\n",
      "|    time_elapsed         | 2873         |\n",
      "|    total_timesteps      | 1779712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055588745 |\n",
      "|    clip_fraction        | 0.0258       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.19         |\n",
      "|    explained_variance   | 0.928        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.44e+04     |\n",
      "|    n_updates            | 59540        |\n",
      "|    policy_gradient_loss | -0.00325     |\n",
      "|    std                  | 0.201        |\n",
      "|    value_loss           | 6.45e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1780000, episode_reward=11773.50 +/- 66095.08\n",
      "Episode length: 2017.20 +/- 2435.47\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.02e+03    |\n",
      "|    mean_reward          | 1.18e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1780000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008111472 |\n",
      "|    clip_fraction        | 0.0794      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.19        |\n",
      "|    explained_variance   | 0.782       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 751         |\n",
      "|    n_updates            | 59550       |\n",
      "|    policy_gradient_loss | -0.00104    |\n",
      "|    std                  | 0.201       |\n",
      "|    value_loss           | 5.3e+04     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.49e+03  |\n",
      "|    ep_rew_mean     | -1.15e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 618       |\n",
      "|    iterations      | 870       |\n",
      "|    time_elapsed    | 2879      |\n",
      "|    total_timesteps | 1781760   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.45e+03    |\n",
      "|    ep_rew_mean          | -1.62e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 619         |\n",
      "|    iterations           | 871         |\n",
      "|    time_elapsed         | 2881        |\n",
      "|    total_timesteps      | 1783808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017627517 |\n",
      "|    clip_fraction        | 0.267       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.2         |\n",
      "|    explained_variance   | 0.913       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 271         |\n",
      "|    n_updates            | 59560       |\n",
      "|    policy_gradient_loss | 0.0198      |\n",
      "|    std                  | 0.201       |\n",
      "|    value_loss           | 1.19e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1785000, episode_reward=54977.09 +/- 55088.71\n",
      "Episode length: 4009.00 +/- 1982.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.01e+03    |\n",
      "|    mean_reward          | 5.5e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1785000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014915039 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.2         |\n",
      "|    explained_variance   | 0.5         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.46e+07    |\n",
      "|    n_updates            | 59570       |\n",
      "|    policy_gradient_loss | 0.0118      |\n",
      "|    std                  | 0.201       |\n",
      "|    value_loss           | 7.18e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.45e+03  |\n",
      "|    ep_rew_mean     | -1.62e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 617       |\n",
      "|    iterations      | 872       |\n",
      "|    time_elapsed    | 2892      |\n",
      "|    total_timesteps | 1785856   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.45e+03     |\n",
      "|    ep_rew_mean          | -1.62e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 617          |\n",
      "|    iterations           | 873          |\n",
      "|    time_elapsed         | 2894         |\n",
      "|    total_timesteps      | 1787904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0121703455 |\n",
      "|    clip_fraction        | 0.155        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.2          |\n",
      "|    explained_variance   | 0.854        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 219          |\n",
      "|    n_updates            | 59580        |\n",
      "|    policy_gradient_loss | -0.00106     |\n",
      "|    std                  | 0.2          |\n",
      "|    value_loss           | 1.11e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.5e+03     |\n",
      "|    ep_rew_mean          | -1.2e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 617         |\n",
      "|    iterations           | 874         |\n",
      "|    time_elapsed         | 2896        |\n",
      "|    total_timesteps      | 1789952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015429244 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.21        |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 61.5        |\n",
      "|    n_updates            | 59590       |\n",
      "|    policy_gradient_loss | 0.00669     |\n",
      "|    std                  | 0.199       |\n",
      "|    value_loss           | 611         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1790000, episode_reward=87671.81 +/- 267.27\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 8.77e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1790000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012901466 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.21        |\n",
      "|    explained_variance   | 0.945       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 574         |\n",
      "|    n_updates            | 59600       |\n",
      "|    policy_gradient_loss | -0.00136    |\n",
      "|    std                  | 0.199       |\n",
      "|    value_loss           | 1.79e+03    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.5e+03  |\n",
      "|    ep_rew_mean     | -1.2e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 615      |\n",
      "|    iterations      | 875      |\n",
      "|    time_elapsed    | 2910     |\n",
      "|    total_timesteps | 1792000  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.4e+03     |\n",
      "|    ep_rew_mean          | -1.58e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 616         |\n",
      "|    iterations           | 876         |\n",
      "|    time_elapsed         | 2912        |\n",
      "|    total_timesteps      | 1794048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011771532 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.21        |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 114         |\n",
      "|    n_updates            | 59610       |\n",
      "|    policy_gradient_loss | 0.00422     |\n",
      "|    std                  | 0.199       |\n",
      "|    value_loss           | 655         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1795000, episode_reward=23480.29 +/- 71377.01\n",
      "Episode length: 3015.40 +/- 2430.63\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.02e+03    |\n",
      "|    mean_reward          | 2.35e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1795000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018261027 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.22        |\n",
      "|    explained_variance   | 0.524       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.65e+06    |\n",
      "|    n_updates            | 59620       |\n",
      "|    policy_gradient_loss | 0.0162      |\n",
      "|    std                  | 0.199       |\n",
      "|    value_loss           | 4.78e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.4e+03   |\n",
      "|    ep_rew_mean     | -1.58e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 614       |\n",
      "|    iterations      | 877       |\n",
      "|    time_elapsed    | 2921      |\n",
      "|    total_timesteps | 1796096   |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 2.4e+03   |\n",
      "|    ep_rew_mean          | -1.58e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 615       |\n",
      "|    iterations           | 878       |\n",
      "|    time_elapsed         | 2922      |\n",
      "|    total_timesteps      | 1798144   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.027268  |\n",
      "|    clip_fraction        | 0.275     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 2.22      |\n",
      "|    explained_variance   | 0.948     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 39.2      |\n",
      "|    n_updates            | 59630     |\n",
      "|    policy_gradient_loss | 0.0169    |\n",
      "|    std                  | 0.2       |\n",
      "|    value_loss           | 170       |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=1800000, episode_reward=81099.26 +/- 8051.81\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 8.11e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1800000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011525776 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.22        |\n",
      "|    explained_variance   | 0.665       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.2e+04     |\n",
      "|    n_updates            | 59640       |\n",
      "|    policy_gradient_loss | -0.00302    |\n",
      "|    std                  | 0.2         |\n",
      "|    value_loss           | 2.2e+05     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.4e+03   |\n",
      "|    ep_rew_mean     | -1.58e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 613       |\n",
      "|    iterations      | 879       |\n",
      "|    time_elapsed    | 2936      |\n",
      "|    total_timesteps | 1800192   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.4e+03    |\n",
      "|    ep_rew_mean          | -1.58e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 613        |\n",
      "|    iterations           | 880        |\n",
      "|    time_elapsed         | 2938       |\n",
      "|    total_timesteps      | 1802240    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01030683 |\n",
      "|    clip_fraction        | 0.0881     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.22       |\n",
      "|    explained_variance   | 0.138      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 135        |\n",
      "|    n_updates            | 59650      |\n",
      "|    policy_gradient_loss | -0.00396   |\n",
      "|    std                  | 0.2        |\n",
      "|    value_loss           | 7.5e+04    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.44e+03    |\n",
      "|    ep_rew_mean          | -1.08e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 613         |\n",
      "|    iterations           | 881         |\n",
      "|    time_elapsed         | 2940        |\n",
      "|    total_timesteps      | 1804288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010098009 |\n",
      "|    clip_fraction        | 0.0975      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.23        |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 135         |\n",
      "|    n_updates            | 59660       |\n",
      "|    policy_gradient_loss | 0.00258     |\n",
      "|    std                  | 0.199       |\n",
      "|    value_loss           | 473         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1805000, episode_reward=32338.61 +/- 34399.54\n",
      "Episode length: 3004.80 +/- 2443.61\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3e+03       |\n",
      "|    mean_reward          | 3.23e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1805000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007956958 |\n",
      "|    clip_fraction        | 0.0703      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.23        |\n",
      "|    explained_variance   | 0.764       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.7e+04     |\n",
      "|    n_updates            | 59670       |\n",
      "|    policy_gradient_loss | -0.00333    |\n",
      "|    std                  | 0.199       |\n",
      "|    value_loss           | 4.19e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.44e+03  |\n",
      "|    ep_rew_mean     | -1.08e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 612       |\n",
      "|    iterations      | 882       |\n",
      "|    time_elapsed    | 2949      |\n",
      "|    total_timesteps | 1806336   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.48e+03    |\n",
      "|    ep_rew_mean          | -1.01e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 612         |\n",
      "|    iterations           | 883         |\n",
      "|    time_elapsed         | 2950        |\n",
      "|    total_timesteps      | 1808384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010292649 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.23        |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 137         |\n",
      "|    n_updates            | 59680       |\n",
      "|    policy_gradient_loss | 1.69e-05    |\n",
      "|    std                  | 0.199       |\n",
      "|    value_loss           | 664         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1810000, episode_reward=43369.62 +/- 20750.31\n",
      "Episode length: 4863.00 +/- 172.38\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.86e+03    |\n",
      "|    mean_reward          | 4.34e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1810000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005266181 |\n",
      "|    clip_fraction        | 0.0624      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.23        |\n",
      "|    explained_variance   | 0.718       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 184         |\n",
      "|    n_updates            | 59690       |\n",
      "|    policy_gradient_loss | 0.000367    |\n",
      "|    std                  | 0.199       |\n",
      "|    value_loss           | 2.47e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.48e+03  |\n",
      "|    ep_rew_mean     | -1.01e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 610       |\n",
      "|    iterations      | 884       |\n",
      "|    time_elapsed    | 2964      |\n",
      "|    total_timesteps | 1810432   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.47e+03    |\n",
      "|    ep_rew_mean          | -1.04e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 611         |\n",
      "|    iterations           | 885         |\n",
      "|    time_elapsed         | 2966        |\n",
      "|    total_timesteps      | 1812480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008327469 |\n",
      "|    clip_fraction        | 0.0692      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.23        |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 287         |\n",
      "|    n_updates            | 59700       |\n",
      "|    policy_gradient_loss | 0.00193     |\n",
      "|    std                  | 0.199       |\n",
      "|    value_loss           | 940         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.47e+03    |\n",
      "|    ep_rew_mean          | -1.04e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 611         |\n",
      "|    iterations           | 886         |\n",
      "|    time_elapsed         | 2967        |\n",
      "|    total_timesteps      | 1814528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010127468 |\n",
      "|    clip_fraction        | 0.0646      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.24        |\n",
      "|    explained_variance   | 0.946       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 332         |\n",
      "|    n_updates            | 59710       |\n",
      "|    policy_gradient_loss | -0.000386   |\n",
      "|    std                  | 0.199       |\n",
      "|    value_loss           | 2.79e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1815000, episode_reward=10087.99 +/- 35609.02\n",
      "Episode length: 1822.00 +/- 2170.88\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.82e+03    |\n",
      "|    mean_reward          | 1.01e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1815000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020219037 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.24        |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 75.1        |\n",
      "|    n_updates            | 59720       |\n",
      "|    policy_gradient_loss | 0.00201     |\n",
      "|    std                  | 0.199       |\n",
      "|    value_loss           | 354         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.5e+03   |\n",
      "|    ep_rew_mean     | -9.13e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 610       |\n",
      "|    iterations      | 887       |\n",
      "|    time_elapsed    | 2974      |\n",
      "|    total_timesteps | 1816576   |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 2.51e+03  |\n",
      "|    ep_rew_mean          | -9.56e+03 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 611       |\n",
      "|    iterations           | 888       |\n",
      "|    time_elapsed         | 2975      |\n",
      "|    total_timesteps      | 1818624   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0095958 |\n",
      "|    clip_fraction        | 0.125     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 2.25      |\n",
      "|    explained_variance   | 0.673     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 317       |\n",
      "|    n_updates            | 59730     |\n",
      "|    policy_gradient_loss | -0.00939  |\n",
      "|    std                  | 0.198     |\n",
      "|    value_loss           | 3.48e+05  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=1820000, episode_reward=-68213.11 +/- 137427.56\n",
      "Episode length: 1994.60 +/- 1146.93\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.99e+03     |\n",
      "|    mean_reward          | -6.82e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1820000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039152857 |\n",
      "|    clip_fraction        | 0.0444       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.25         |\n",
      "|    explained_variance   | 0.493        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.11e+06     |\n",
      "|    n_updates            | 59740        |\n",
      "|    policy_gradient_loss | -0.00418     |\n",
      "|    std                  | 0.198        |\n",
      "|    value_loss           | 4.79e+06     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.48e+03 |\n",
      "|    ep_rew_mean     | -1e+04   |\n",
      "| time/              |          |\n",
      "|    fps             | 610      |\n",
      "|    iterations      | 889      |\n",
      "|    time_elapsed    | 2982     |\n",
      "|    total_timesteps | 1820672  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.42e+03    |\n",
      "|    ep_rew_mean          | -1.07e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 610         |\n",
      "|    iterations           | 890         |\n",
      "|    time_elapsed         | 2984        |\n",
      "|    total_timesteps      | 1822720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008579578 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.25        |\n",
      "|    explained_variance   | 0.911       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 514         |\n",
      "|    n_updates            | 59750       |\n",
      "|    policy_gradient_loss | 0.000147    |\n",
      "|    std                  | 0.198       |\n",
      "|    value_loss           | 7.32e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.42e+03    |\n",
      "|    ep_rew_mean          | -1.07e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 611         |\n",
      "|    iterations           | 891         |\n",
      "|    time_elapsed         | 2986        |\n",
      "|    total_timesteps      | 1824768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011959264 |\n",
      "|    clip_fraction        | 0.0615      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.25        |\n",
      "|    explained_variance   | 0.793       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.56e+03    |\n",
      "|    n_updates            | 59760       |\n",
      "|    policy_gradient_loss | -0.0013     |\n",
      "|    std                  | 0.198       |\n",
      "|    value_loss           | 1.24e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1825000, episode_reward=-55476.47 +/- 65194.11\n",
      "Episode length: 787.00 +/- 904.64\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 787          |\n",
      "|    mean_reward          | -5.55e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1825000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0080568865 |\n",
      "|    clip_fraction        | 0.079        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.25         |\n",
      "|    explained_variance   | 0.82         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.18e+03     |\n",
      "|    n_updates            | 59770        |\n",
      "|    policy_gradient_loss | -0.00565     |\n",
      "|    std                  | 0.198        |\n",
      "|    value_loss           | 8.68e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.4e+03   |\n",
      "|    ep_rew_mean     | -1.11e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 610       |\n",
      "|    iterations      | 892       |\n",
      "|    time_elapsed    | 2989      |\n",
      "|    total_timesteps | 1826816   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.37e+03   |\n",
      "|    ep_rew_mean          | -1.16e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 611        |\n",
      "|    iterations           | 893        |\n",
      "|    time_elapsed         | 2991       |\n",
      "|    total_timesteps      | 1828864    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08562634 |\n",
      "|    clip_fraction        | 0.255      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.24       |\n",
      "|    explained_variance   | 0.864      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 113        |\n",
      "|    n_updates            | 59780      |\n",
      "|    policy_gradient_loss | -0.00114   |\n",
      "|    std                  | 0.199      |\n",
      "|    value_loss           | 1.25e+03   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1830000, episode_reward=-88876.10 +/- 99588.07\n",
      "Episode length: 1045.00 +/- 757.57\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.04e+03   |\n",
      "|    mean_reward          | -8.89e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1830000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00955811 |\n",
      "|    clip_fraction        | 0.0776     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.23       |\n",
      "|    explained_variance   | 0.881      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.85e+04   |\n",
      "|    n_updates            | 59790      |\n",
      "|    policy_gradient_loss | -0.00364   |\n",
      "|    std                  | 0.199      |\n",
      "|    value_loss           | 4.93e+04   |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.35e+03 |\n",
      "|    ep_rew_mean     | -1.2e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 611      |\n",
      "|    iterations      | 894      |\n",
      "|    time_elapsed    | 2996     |\n",
      "|    total_timesteps | 1830912  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.35e+03     |\n",
      "|    ep_rew_mean          | -1.17e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 611          |\n",
      "|    iterations           | 895          |\n",
      "|    time_elapsed         | 2998         |\n",
      "|    total_timesteps      | 1832960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062123253 |\n",
      "|    clip_fraction        | 0.038        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.23         |\n",
      "|    explained_variance   | 0.674        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.57e+05     |\n",
      "|    n_updates            | 59800        |\n",
      "|    policy_gradient_loss | -0.00187     |\n",
      "|    std                  | 0.199        |\n",
      "|    value_loss           | 1.12e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1835000, episode_reward=-155910.29 +/- 45657.28\n",
      "Episode length: 546.60 +/- 251.53\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 547       |\n",
      "|    mean_reward          | -1.56e+05 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 1835000   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 6.911522  |\n",
      "|    clip_fraction        | 0.498     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 2.23      |\n",
      "|    explained_variance   | 0.945     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 102       |\n",
      "|    n_updates            | 59810     |\n",
      "|    policy_gradient_loss | 0.133     |\n",
      "|    std                  | 0.2       |\n",
      "|    value_loss           | 1.14e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.27e+03  |\n",
      "|    ep_rew_mean     | -1.21e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 611       |\n",
      "|    iterations      | 896       |\n",
      "|    time_elapsed    | 3001      |\n",
      "|    total_timesteps | 1835008   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.26e+03    |\n",
      "|    ep_rew_mean          | -1.37e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 611         |\n",
      "|    iterations           | 897         |\n",
      "|    time_elapsed         | 3003        |\n",
      "|    total_timesteps      | 1837056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002233717 |\n",
      "|    clip_fraction        | 0.00479     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.22        |\n",
      "|    explained_variance   | 0.535       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.24e+07    |\n",
      "|    n_updates            | 59820       |\n",
      "|    policy_gradient_loss | -0.0049     |\n",
      "|    std                  | 0.2         |\n",
      "|    value_loss           | 2.82e+07    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.25e+03     |\n",
      "|    ep_rew_mean          | -1.46e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 612          |\n",
      "|    iterations           | 898          |\n",
      "|    time_elapsed         | 3004         |\n",
      "|    total_timesteps      | 1839104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013156718 |\n",
      "|    clip_fraction        | 0.00322      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.22         |\n",
      "|    explained_variance   | 0.576        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.22e+07     |\n",
      "|    n_updates            | 59830        |\n",
      "|    policy_gradient_loss | -0.00184     |\n",
      "|    std                  | 0.2          |\n",
      "|    value_loss           | 4.56e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1840000, episode_reward=-21439.14 +/- 19158.39\n",
      "Episode length: 531.00 +/- 274.31\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 531          |\n",
      "|    mean_reward          | -2.14e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1840000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055975337 |\n",
      "|    clip_fraction        | 0.0244       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.22         |\n",
      "|    explained_variance   | 0.543        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.58e+04     |\n",
      "|    n_updates            | 59840        |\n",
      "|    policy_gradient_loss | -0.00247     |\n",
      "|    std                  | 0.2          |\n",
      "|    value_loss           | 2.39e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.25e+03  |\n",
      "|    ep_rew_mean     | -1.44e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 612       |\n",
      "|    iterations      | 899       |\n",
      "|    time_elapsed    | 3008      |\n",
      "|    total_timesteps | 1841152   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.17e+03     |\n",
      "|    ep_rew_mean          | -1.75e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 612          |\n",
      "|    iterations           | 900          |\n",
      "|    time_elapsed         | 3009         |\n",
      "|    total_timesteps      | 1843200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035327417 |\n",
      "|    clip_fraction        | 0.0196       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.22         |\n",
      "|    explained_variance   | 0.644        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.18e+07     |\n",
      "|    n_updates            | 59850        |\n",
      "|    policy_gradient_loss | -0.00187     |\n",
      "|    std                  | 0.2          |\n",
      "|    value_loss           | 1.32e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1845000, episode_reward=-23766.16 +/- 43604.17\n",
      "Episode length: 580.40 +/- 261.86\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 580          |\n",
      "|    mean_reward          | -2.38e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1845000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012719817 |\n",
      "|    clip_fraction        | 0.0102       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.22         |\n",
      "|    explained_variance   | 0.512        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.07e+07     |\n",
      "|    n_updates            | 59860        |\n",
      "|    policy_gradient_loss | 0.00217      |\n",
      "|    std                  | 0.2          |\n",
      "|    value_loss           | 1.03e+08     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.15e+03  |\n",
      "|    ep_rew_mean     | -1.74e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 612       |\n",
      "|    iterations      | 901       |\n",
      "|    time_elapsed    | 3013      |\n",
      "|    total_timesteps | 1845248   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.01e+03     |\n",
      "|    ep_rew_mean          | -2.19e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 612          |\n",
      "|    iterations           | 902          |\n",
      "|    time_elapsed         | 3014         |\n",
      "|    total_timesteps      | 1847296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035013368 |\n",
      "|    clip_fraction        | 0.0163       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.22         |\n",
      "|    explained_variance   | 0.608        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.06e+07     |\n",
      "|    n_updates            | 59870        |\n",
      "|    policy_gradient_loss | -0.00636     |\n",
      "|    std                  | 0.2          |\n",
      "|    value_loss           | 3.31e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.93e+03     |\n",
      "|    ep_rew_mean          | -2.49e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 613          |\n",
      "|    iterations           | 903          |\n",
      "|    time_elapsed         | 3016         |\n",
      "|    total_timesteps      | 1849344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061566858 |\n",
      "|    clip_fraction        | 0.0243       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.22         |\n",
      "|    explained_variance   | 0.572        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.38e+07     |\n",
      "|    n_updates            | 59880        |\n",
      "|    policy_gradient_loss | -0.00344     |\n",
      "|    std                  | 0.2          |\n",
      "|    value_loss           | 7.39e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1850000, episode_reward=-90479.75 +/- 72263.86\n",
      "Episode length: 664.80 +/- 79.51\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 665         |\n",
      "|    mean_reward          | -9.05e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1850000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004582245 |\n",
      "|    clip_fraction        | 0.033       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.22        |\n",
      "|    explained_variance   | 0.625       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.96e+06    |\n",
      "|    n_updates            | 59890       |\n",
      "|    policy_gradient_loss | -0.00437    |\n",
      "|    std                  | 0.2         |\n",
      "|    value_loss           | 2.7e+07     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.89e+03  |\n",
      "|    ep_rew_mean     | -2.83e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 612       |\n",
      "|    iterations      | 904       |\n",
      "|    time_elapsed    | 3020      |\n",
      "|    total_timesteps | 1851392   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.86e+03     |\n",
      "|    ep_rew_mean          | -2.98e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 613          |\n",
      "|    iterations           | 905          |\n",
      "|    time_elapsed         | 3022         |\n",
      "|    total_timesteps      | 1853440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047949776 |\n",
      "|    clip_fraction        | 0.021        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.22         |\n",
      "|    explained_variance   | 0.588        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.58e+07     |\n",
      "|    n_updates            | 59900        |\n",
      "|    policy_gradient_loss | -0.00355     |\n",
      "|    std                  | 0.2          |\n",
      "|    value_loss           | 5.1e+07      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1855000, episode_reward=-74668.89 +/- 54410.29\n",
      "Episode length: 740.80 +/- 178.44\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 741          |\n",
      "|    mean_reward          | -7.47e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1855000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057450607 |\n",
      "|    clip_fraction        | 0.0245       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.22         |\n",
      "|    explained_variance   | 0.627        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.02e+06     |\n",
      "|    n_updates            | 59910        |\n",
      "|    policy_gradient_loss | -0.00172     |\n",
      "|    std                  | 0.2          |\n",
      "|    value_loss           | 1.29e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.8e+03   |\n",
      "|    ep_rew_mean     | -3.21e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 613       |\n",
      "|    iterations      | 906       |\n",
      "|    time_elapsed    | 3025      |\n",
      "|    total_timesteps | 1855488   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.81e+03    |\n",
      "|    ep_rew_mean          | -3.32e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 613         |\n",
      "|    iterations           | 907         |\n",
      "|    time_elapsed         | 3027        |\n",
      "|    total_timesteps      | 1857536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002354525 |\n",
      "|    clip_fraction        | 0.0261      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.22        |\n",
      "|    explained_variance   | 0.644       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.71e+06    |\n",
      "|    n_updates            | 59920       |\n",
      "|    policy_gradient_loss | -0.000487   |\n",
      "|    std                  | 0.2         |\n",
      "|    value_loss           | 2.31e+07    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.8e+03      |\n",
      "|    ep_rew_mean          | -3.53e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 613          |\n",
      "|    iterations           | 908          |\n",
      "|    time_elapsed         | 3029         |\n",
      "|    total_timesteps      | 1859584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044175014 |\n",
      "|    clip_fraction        | 0.0396       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.22         |\n",
      "|    explained_variance   | 0.614        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.76e+07     |\n",
      "|    n_updates            | 59930        |\n",
      "|    policy_gradient_loss | -0.00331     |\n",
      "|    std                  | 0.2          |\n",
      "|    value_loss           | 2.99e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1860000, episode_reward=-70289.98 +/- 63287.13\n",
      "Episode length: 383.80 +/- 425.78\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 384         |\n",
      "|    mean_reward          | -7.03e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1860000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007989052 |\n",
      "|    clip_fraction        | 0.0813      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.22        |\n",
      "|    explained_variance   | 0.631       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1e+07       |\n",
      "|    n_updates            | 59940       |\n",
      "|    policy_gradient_loss | -0.00342    |\n",
      "|    std                  | 0.2         |\n",
      "|    value_loss           | 2.58e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.74e+03  |\n",
      "|    ep_rew_mean     | -3.79e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 613       |\n",
      "|    iterations      | 909       |\n",
      "|    time_elapsed    | 3032      |\n",
      "|    total_timesteps | 1861632   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.69e+03     |\n",
      "|    ep_rew_mean          | -3.9e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 614          |\n",
      "|    iterations           | 910          |\n",
      "|    time_elapsed         | 3033         |\n",
      "|    total_timesteps      | 1863680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054207174 |\n",
      "|    clip_fraction        | 0.0411       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.22         |\n",
      "|    explained_variance   | 0.632        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.66e+07     |\n",
      "|    n_updates            | 59950        |\n",
      "|    policy_gradient_loss | -0.00142     |\n",
      "|    std                  | 0.2          |\n",
      "|    value_loss           | 2.32e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1865000, episode_reward=-54227.81 +/- 46617.56\n",
      "Episode length: 710.00 +/- 321.98\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 710         |\n",
      "|    mean_reward          | -5.42e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1865000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004469445 |\n",
      "|    clip_fraction        | 0.024       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.22        |\n",
      "|    explained_variance   | 0.646       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.47e+07    |\n",
      "|    n_updates            | 59960       |\n",
      "|    policy_gradient_loss | -0.00194    |\n",
      "|    std                  | 0.2         |\n",
      "|    value_loss           | 2.29e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.59e+03  |\n",
      "|    ep_rew_mean     | -4.24e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 614       |\n",
      "|    iterations      | 911       |\n",
      "|    time_elapsed    | 3037      |\n",
      "|    total_timesteps | 1865728   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.5e+03     |\n",
      "|    ep_rew_mean          | -4.32e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 614         |\n",
      "|    iterations           | 912         |\n",
      "|    time_elapsed         | 3039        |\n",
      "|    total_timesteps      | 1867776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005205678 |\n",
      "|    clip_fraction        | 0.0225      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.22        |\n",
      "|    explained_variance   | 0.595       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.73e+07    |\n",
      "|    n_updates            | 59970       |\n",
      "|    policy_gradient_loss | -0.00239    |\n",
      "|    std                  | 0.2         |\n",
      "|    value_loss           | 2.99e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.48e+03    |\n",
      "|    ep_rew_mean          | -4.31e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 614         |\n",
      "|    iterations           | 913         |\n",
      "|    time_elapsed         | 3041        |\n",
      "|    total_timesteps      | 1869824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027207706 |\n",
      "|    clip_fraction        | 0.0655      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.21        |\n",
      "|    explained_variance   | 0.654       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.56e+07    |\n",
      "|    n_updates            | 59980       |\n",
      "|    policy_gradient_loss | 0.00234     |\n",
      "|    std                  | 0.2         |\n",
      "|    value_loss           | 9.08e+06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1870000, episode_reward=-78408.24 +/- 44382.37\n",
      "Episode length: 904.40 +/- 138.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 904         |\n",
      "|    mean_reward          | -7.84e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1870000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005878045 |\n",
      "|    clip_fraction        | 0.037       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.21        |\n",
      "|    explained_variance   | 0.637       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.91e+06    |\n",
      "|    n_updates            | 59990       |\n",
      "|    policy_gradient_loss | 0.000302    |\n",
      "|    std                  | 0.2         |\n",
      "|    value_loss           | 1.14e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.44e+03  |\n",
      "|    ep_rew_mean     | -4.53e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 614       |\n",
      "|    iterations      | 914       |\n",
      "|    time_elapsed    | 3045      |\n",
      "|    total_timesteps | 1871872   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.41e+03     |\n",
      "|    ep_rew_mean          | -4.72e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 614          |\n",
      "|    iterations           | 915          |\n",
      "|    time_elapsed         | 3047         |\n",
      "|    total_timesteps      | 1873920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043513332 |\n",
      "|    clip_fraction        | 0.0277       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.21         |\n",
      "|    explained_variance   | 0.64         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.01e+06     |\n",
      "|    n_updates            | 60000        |\n",
      "|    policy_gradient_loss | -0.00448     |\n",
      "|    std                  | 0.2          |\n",
      "|    value_loss           | 2.23e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1875000, episode_reward=-65077.82 +/- 35802.14\n",
      "Episode length: 1011.00 +/- 85.26\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.01e+03     |\n",
      "|    mean_reward          | -6.51e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1875000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028177015 |\n",
      "|    clip_fraction        | 0.01         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.21         |\n",
      "|    explained_variance   | 0.479        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.3e+07      |\n",
      "|    n_updates            | 60010        |\n",
      "|    policy_gradient_loss | -0.000355    |\n",
      "|    std                  | 0.2          |\n",
      "|    value_loss           | 2.73e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.33e+03 |\n",
      "|    ep_rew_mean     | -4.9e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 614      |\n",
      "|    iterations      | 916      |\n",
      "|    time_elapsed    | 3051     |\n",
      "|    total_timesteps | 1875968  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.11e+03   |\n",
      "|    ep_rew_mean          | -5.61e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 615        |\n",
      "|    iterations           | 917        |\n",
      "|    time_elapsed         | 3053       |\n",
      "|    total_timesteps      | 1878016    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00680306 |\n",
      "|    clip_fraction        | 0.0376     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.21       |\n",
      "|    explained_variance   | 0.659      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.03e+07   |\n",
      "|    n_updates            | 60020      |\n",
      "|    policy_gradient_loss | -0.00126   |\n",
      "|    std                  | 0.2        |\n",
      "|    value_loss           | 8.25e+06   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1880000, episode_reward=-51531.35 +/- 42195.49\n",
      "Episode length: 894.60 +/- 110.22\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 895          |\n",
      "|    mean_reward          | -5.15e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1880000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028102386 |\n",
      "|    clip_fraction        | 0.0177       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.22         |\n",
      "|    explained_variance   | 0.514        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.78e+07     |\n",
      "|    n_updates            | 60030        |\n",
      "|    policy_gradient_loss | -0.000783    |\n",
      "|    std                  | 0.2          |\n",
      "|    value_loss           | 5.65e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.12e+03  |\n",
      "|    ep_rew_mean     | -5.54e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 614       |\n",
      "|    iterations      | 918       |\n",
      "|    time_elapsed    | 3057      |\n",
      "|    total_timesteps | 1880064   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.11e+03    |\n",
      "|    ep_rew_mean          | -5.48e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 615         |\n",
      "|    iterations           | 919         |\n",
      "|    time_elapsed         | 3058        |\n",
      "|    total_timesteps      | 1882112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007003321 |\n",
      "|    clip_fraction        | 0.0442      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.22        |\n",
      "|    explained_variance   | 0.665       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.09e+07    |\n",
      "|    n_updates            | 60040       |\n",
      "|    policy_gradient_loss | 0.00136     |\n",
      "|    std                  | 0.2         |\n",
      "|    value_loss           | 1.09e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.06e+03    |\n",
      "|    ep_rew_mean          | -5.67e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 615         |\n",
      "|    iterations           | 920         |\n",
      "|    time_elapsed         | 3060        |\n",
      "|    total_timesteps      | 1884160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004768364 |\n",
      "|    clip_fraction        | 0.0474      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.21        |\n",
      "|    explained_variance   | 0.655       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.34e+07    |\n",
      "|    n_updates            | 60050       |\n",
      "|    policy_gradient_loss | 0.0014      |\n",
      "|    std                  | 0.2         |\n",
      "|    value_loss           | 2.05e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1885000, episode_reward=-69727.05 +/- 7679.40\n",
      "Episode length: 1107.80 +/- 66.97\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.11e+03     |\n",
      "|    mean_reward          | -6.97e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1885000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058290944 |\n",
      "|    clip_fraction        | 0.0465       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.21         |\n",
      "|    explained_variance   | 0.624        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.41e+06     |\n",
      "|    n_updates            | 60060        |\n",
      "|    policy_gradient_loss | -0.00115     |\n",
      "|    std                  | 0.2          |\n",
      "|    value_loss           | 2.48e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.03e+03  |\n",
      "|    ep_rew_mean     | -5.87e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 615       |\n",
      "|    iterations      | 921       |\n",
      "|    time_elapsed    | 3065      |\n",
      "|    total_timesteps | 1886208   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 947          |\n",
      "|    ep_rew_mean          | -5.57e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 615          |\n",
      "|    iterations           | 922          |\n",
      "|    time_elapsed         | 3067         |\n",
      "|    total_timesteps      | 1888256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048691686 |\n",
      "|    clip_fraction        | 0.0508       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.21         |\n",
      "|    explained_variance   | 0.656        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.09e+06     |\n",
      "|    n_updates            | 60070        |\n",
      "|    policy_gradient_loss | -0.00436     |\n",
      "|    std                  | 0.2          |\n",
      "|    value_loss           | 1.9e+07      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1890000, episode_reward=-58581.66 +/- 60061.85\n",
      "Episode length: 940.00 +/- 200.69\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 940         |\n",
      "|    mean_reward          | -5.86e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1890000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005470286 |\n",
      "|    clip_fraction        | 0.0398      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.21        |\n",
      "|    explained_variance   | 0.6         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.25e+06    |\n",
      "|    n_updates            | 60080       |\n",
      "|    policy_gradient_loss | -0.00315    |\n",
      "|    std                  | 0.2         |\n",
      "|    value_loss           | 2.35e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 870       |\n",
      "|    ep_rew_mean     | -5.82e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 615       |\n",
      "|    iterations      | 923       |\n",
      "|    time_elapsed    | 3071      |\n",
      "|    total_timesteps | 1890304   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 848          |\n",
      "|    ep_rew_mean          | -5.93e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 615          |\n",
      "|    iterations           | 924          |\n",
      "|    time_elapsed         | 3073         |\n",
      "|    total_timesteps      | 1892352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057799644 |\n",
      "|    clip_fraction        | 0.0331       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.21         |\n",
      "|    explained_variance   | 0.65         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.65e+06     |\n",
      "|    n_updates            | 60090        |\n",
      "|    policy_gradient_loss | -0.00442     |\n",
      "|    std                  | 0.2          |\n",
      "|    value_loss           | 1.93e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 782          |\n",
      "|    ep_rew_mean          | -6.16e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 616          |\n",
      "|    iterations           | 925          |\n",
      "|    time_elapsed         | 3074         |\n",
      "|    total_timesteps      | 1894400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024883025 |\n",
      "|    clip_fraction        | 0.037        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.21         |\n",
      "|    explained_variance   | 0.693        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.08e+03     |\n",
      "|    n_updates            | 60100        |\n",
      "|    policy_gradient_loss | 0.0021       |\n",
      "|    std                  | 0.2          |\n",
      "|    value_loss           | 1.09e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1895000, episode_reward=-63234.28 +/- 55397.07\n",
      "Episode length: 687.60 +/- 547.04\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 688          |\n",
      "|    mean_reward          | -6.32e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1895000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052741123 |\n",
      "|    clip_fraction        | 0.0412       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.21         |\n",
      "|    explained_variance   | 0.648        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.45e+07     |\n",
      "|    n_updates            | 60110        |\n",
      "|    policy_gradient_loss | -0.00304     |\n",
      "|    std                  | 0.2          |\n",
      "|    value_loss           | 1.93e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 783       |\n",
      "|    ep_rew_mean     | -6.34e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 616       |\n",
      "|    iterations      | 926       |\n",
      "|    time_elapsed    | 3078      |\n",
      "|    total_timesteps | 1896448   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 764          |\n",
      "|    ep_rew_mean          | -6.54e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 616          |\n",
      "|    iterations           | 927          |\n",
      "|    time_elapsed         | 3080         |\n",
      "|    total_timesteps      | 1898496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057558096 |\n",
      "|    clip_fraction        | 0.0259       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.21         |\n",
      "|    explained_variance   | 0.579        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.91e+07     |\n",
      "|    n_updates            | 60120        |\n",
      "|    policy_gradient_loss | -0.00354     |\n",
      "|    std                  | 0.2          |\n",
      "|    value_loss           | 3.24e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1900000, episode_reward=-61894.67 +/- 4315.36\n",
      "Episode length: 1219.00 +/- 114.68\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.22e+03     |\n",
      "|    mean_reward          | -6.19e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1900000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040128636 |\n",
      "|    clip_fraction        | 0.0212       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.21         |\n",
      "|    explained_variance   | 0.635        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.1e+07      |\n",
      "|    n_updates            | 60130        |\n",
      "|    policy_gradient_loss | -0.00416     |\n",
      "|    std                  | 0.2          |\n",
      "|    value_loss           | 2.08e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 730       |\n",
      "|    ep_rew_mean     | -6.82e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 616       |\n",
      "|    iterations      | 928       |\n",
      "|    time_elapsed    | 3085      |\n",
      "|    total_timesteps | 1900544   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 728         |\n",
      "|    ep_rew_mean          | -6.91e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 616         |\n",
      "|    iterations           | 929         |\n",
      "|    time_elapsed         | 3086        |\n",
      "|    total_timesteps      | 1902592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004633532 |\n",
      "|    clip_fraction        | 0.0291      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.21        |\n",
      "|    explained_variance   | 0.623       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.18e+07    |\n",
      "|    n_updates            | 60140       |\n",
      "|    policy_gradient_loss | -0.00334    |\n",
      "|    std                  | 0.2         |\n",
      "|    value_loss           | 2.36e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 712         |\n",
      "|    ep_rew_mean          | -6.88e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 616         |\n",
      "|    iterations           | 930         |\n",
      "|    time_elapsed         | 3088        |\n",
      "|    total_timesteps      | 1904640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009168665 |\n",
      "|    clip_fraction        | 0.0465      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.21        |\n",
      "|    explained_variance   | 0.694       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.5e+06     |\n",
      "|    n_updates            | 60150       |\n",
      "|    policy_gradient_loss | -0.00343    |\n",
      "|    std                  | 0.2         |\n",
      "|    value_loss           | 1.25e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1905000, episode_reward=-59666.51 +/- 19324.77\n",
      "Episode length: 1118.60 +/- 465.57\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.12e+03     |\n",
      "|    mean_reward          | -5.97e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1905000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0149055915 |\n",
      "|    clip_fraction        | 0.0572       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.21         |\n",
      "|    explained_variance   | 0.786        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.02e+06     |\n",
      "|    n_updates            | 60160        |\n",
      "|    policy_gradient_loss | -0.00436     |\n",
      "|    std                  | 0.2          |\n",
      "|    value_loss           | 3.54e+06     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 718       |\n",
      "|    ep_rew_mean     | -6.96e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 616       |\n",
      "|    iterations      | 931       |\n",
      "|    time_elapsed    | 3093      |\n",
      "|    total_timesteps | 1906688   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 726          |\n",
      "|    ep_rew_mean          | -6.92e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 616          |\n",
      "|    iterations           | 932          |\n",
      "|    time_elapsed         | 3095         |\n",
      "|    total_timesteps      | 1908736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025515223 |\n",
      "|    clip_fraction        | 0.0146       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.21         |\n",
      "|    explained_variance   | 0.541        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.49e+06     |\n",
      "|    n_updates            | 60170        |\n",
      "|    policy_gradient_loss | -0.00432     |\n",
      "|    std                  | 0.2          |\n",
      "|    value_loss           | 2.37e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1910000, episode_reward=-62632.07 +/- 32270.83\n",
      "Episode length: 1009.00 +/- 509.95\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.01e+03     |\n",
      "|    mean_reward          | -6.26e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1910000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061706705 |\n",
      "|    clip_fraction        | 0.0263       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.21         |\n",
      "|    explained_variance   | 0.638        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.37e+06     |\n",
      "|    n_updates            | 60180        |\n",
      "|    policy_gradient_loss | -0.0012      |\n",
      "|    std                  | 0.2          |\n",
      "|    value_loss           | 2.02e+07     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 732      |\n",
      "|    ep_rew_mean     | -6.9e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 616      |\n",
      "|    iterations      | 933      |\n",
      "|    time_elapsed    | 3099     |\n",
      "|    total_timesteps | 1910784  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 735         |\n",
      "|    ep_rew_mean          | -6.9e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 616         |\n",
      "|    iterations           | 934         |\n",
      "|    time_elapsed         | 3101        |\n",
      "|    total_timesteps      | 1912832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024208348 |\n",
      "|    clip_fraction        | 0.0892      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.21        |\n",
      "|    explained_variance   | 0.664       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.43e+07    |\n",
      "|    n_updates            | 60190       |\n",
      "|    policy_gradient_loss | 0.00502     |\n",
      "|    std                  | 0.2         |\n",
      "|    value_loss           | 1.16e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 749         |\n",
      "|    ep_rew_mean          | -6.98e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 617         |\n",
      "|    iterations           | 935         |\n",
      "|    time_elapsed         | 3103        |\n",
      "|    total_timesteps      | 1914880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005546071 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.21        |\n",
      "|    explained_variance   | 0.571       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.49e+07    |\n",
      "|    n_updates            | 60200       |\n",
      "|    policy_gradient_loss | 0.00517     |\n",
      "|    std                  | 0.2         |\n",
      "|    value_loss           | 3.07e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1915000, episode_reward=-91627.91 +/- 33682.57\n",
      "Episode length: 1193.00 +/- 563.19\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.19e+03    |\n",
      "|    mean_reward          | -9.16e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1915000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005848595 |\n",
      "|    clip_fraction        | 0.0244      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.21        |\n",
      "|    explained_variance   | 0.653       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.47e+07    |\n",
      "|    n_updates            | 60210       |\n",
      "|    policy_gradient_loss | -0.00157    |\n",
      "|    std                  | 0.2         |\n",
      "|    value_loss           | 2.13e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 758       |\n",
      "|    ep_rew_mean     | -7.02e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 616       |\n",
      "|    iterations      | 936       |\n",
      "|    time_elapsed    | 3107      |\n",
      "|    total_timesteps | 1916928   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 762          |\n",
      "|    ep_rew_mean          | -6.97e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 617          |\n",
      "|    iterations           | 937          |\n",
      "|    time_elapsed         | 3109         |\n",
      "|    total_timesteps      | 1918976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028567056 |\n",
      "|    clip_fraction        | 0.0163       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.21         |\n",
      "|    explained_variance   | 0.644        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.02e+07     |\n",
      "|    n_updates            | 60220        |\n",
      "|    policy_gradient_loss | -0.00359     |\n",
      "|    std                  | 0.2          |\n",
      "|    value_loss           | 1.5e+07      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1920000, episode_reward=-50843.86 +/- 20772.61\n",
      "Episode length: 1191.00 +/- 599.37\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.19e+03     |\n",
      "|    mean_reward          | -5.08e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1920000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056823064 |\n",
      "|    clip_fraction        | 0.0621       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.21         |\n",
      "|    explained_variance   | 0.695        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.21e+06     |\n",
      "|    n_updates            | 60230        |\n",
      "|    policy_gradient_loss | -0.0033      |\n",
      "|    std                  | 0.2          |\n",
      "|    value_loss           | 7.8e+06      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 785      |\n",
      "|    ep_rew_mean     | -7e+04   |\n",
      "| time/              |          |\n",
      "|    fps             | 616      |\n",
      "|    iterations      | 938      |\n",
      "|    time_elapsed    | 3114     |\n",
      "|    total_timesteps | 1921024  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 798          |\n",
      "|    ep_rew_mean          | -7.04e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 617          |\n",
      "|    iterations           | 939          |\n",
      "|    time_elapsed         | 3116         |\n",
      "|    total_timesteps      | 1923072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035595007 |\n",
      "|    clip_fraction        | 0.0201       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.21         |\n",
      "|    explained_variance   | 0.63         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.66e+06     |\n",
      "|    n_updates            | 60240        |\n",
      "|    policy_gradient_loss | -0.00256     |\n",
      "|    std                  | 0.2          |\n",
      "|    value_loss           | 2.37e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1925000, episode_reward=-60449.71 +/- 14988.62\n",
      "Episode length: 1613.00 +/- 85.19\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.61e+03    |\n",
      "|    mean_reward          | -6.04e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1925000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024287235 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.21        |\n",
      "|    explained_variance   | 0.707       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.89e+05    |\n",
      "|    n_updates            | 60250       |\n",
      "|    policy_gradient_loss | -0.00463    |\n",
      "|    std                  | 0.2         |\n",
      "|    value_loss           | 4.87e+06    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 803       |\n",
      "|    ep_rew_mean     | -6.66e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 616       |\n",
      "|    iterations      | 940       |\n",
      "|    time_elapsed    | 3121      |\n",
      "|    total_timesteps | 1925120   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 815        |\n",
      "|    ep_rew_mean          | -6.58e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 616        |\n",
      "|    iterations           | 941        |\n",
      "|    time_elapsed         | 3124       |\n",
      "|    total_timesteps      | 1927168    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00901814 |\n",
      "|    clip_fraction        | 0.0378     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.2        |\n",
      "|    explained_variance   | 0.654      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.02e+06   |\n",
      "|    n_updates            | 60260      |\n",
      "|    policy_gradient_loss | -0.00242   |\n",
      "|    std                  | 0.2        |\n",
      "|    value_loss           | 1.26e+07   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 828          |\n",
      "|    ep_rew_mean          | -6.62e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 616          |\n",
      "|    iterations           | 942          |\n",
      "|    time_elapsed         | 3127         |\n",
      "|    total_timesteps      | 1929216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071020424 |\n",
      "|    clip_fraction        | 0.0384       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.2          |\n",
      "|    explained_variance   | 0.668        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.46e+06     |\n",
      "|    n_updates            | 60270        |\n",
      "|    policy_gradient_loss | -0.00443     |\n",
      "|    std                  | 0.201        |\n",
      "|    value_loss           | 1.63e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1930000, episode_reward=-51484.29 +/- 12056.64\n",
      "Episode length: 1635.40 +/- 68.17\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.64e+03   |\n",
      "|    mean_reward          | -5.15e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1930000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03120083 |\n",
      "|    clip_fraction        | 0.155      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.2        |\n",
      "|    explained_variance   | 0.697      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 9.95e+06   |\n",
      "|    n_updates            | 60280      |\n",
      "|    policy_gradient_loss | 0.0103     |\n",
      "|    std                  | 0.201      |\n",
      "|    value_loss           | 7.06e+06   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 843       |\n",
      "|    ep_rew_mean     | -6.49e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 616       |\n",
      "|    iterations      | 943       |\n",
      "|    time_elapsed    | 3134      |\n",
      "|    total_timesteps | 1931264   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 856          |\n",
      "|    ep_rew_mean          | -6.31e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 616          |\n",
      "|    iterations           | 944          |\n",
      "|    time_elapsed         | 3136         |\n",
      "|    total_timesteps      | 1933312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022976315 |\n",
      "|    clip_fraction        | 0.0361       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.21         |\n",
      "|    explained_variance   | 0.793        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.38e+05     |\n",
      "|    n_updates            | 60290        |\n",
      "|    policy_gradient_loss | 0.000706     |\n",
      "|    std                  | 0.201        |\n",
      "|    value_loss           | 6.52e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1935000, episode_reward=-44409.49 +/- 54125.32\n",
      "Episode length: 964.80 +/- 751.84\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 965          |\n",
      "|    mean_reward          | -4.44e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1935000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0118903555 |\n",
      "|    clip_fraction        | 0.0865       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.2          |\n",
      "|    explained_variance   | 0.871        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.55e+03     |\n",
      "|    n_updates            | 60300        |\n",
      "|    policy_gradient_loss | -0.00382     |\n",
      "|    std                  | 0.201        |\n",
      "|    value_loss           | 1.93e+06     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 871       |\n",
      "|    ep_rew_mean     | -6.32e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 616       |\n",
      "|    iterations      | 945       |\n",
      "|    time_elapsed    | 3140      |\n",
      "|    total_timesteps | 1935360   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 882        |\n",
      "|    ep_rew_mean          | -6.25e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 616        |\n",
      "|    iterations           | 946        |\n",
      "|    time_elapsed         | 3143       |\n",
      "|    total_timesteps      | 1937408    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06756617 |\n",
      "|    clip_fraction        | 0.216      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.2        |\n",
      "|    explained_variance   | 0.776      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 336        |\n",
      "|    n_updates            | 60310      |\n",
      "|    policy_gradient_loss | 0.0176     |\n",
      "|    std                  | 0.201      |\n",
      "|    value_loss           | 3.55e+06   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 882          |\n",
      "|    ep_rew_mean          | -6.14e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 616          |\n",
      "|    iterations           | 947          |\n",
      "|    time_elapsed         | 3146         |\n",
      "|    total_timesteps      | 1939456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023746872 |\n",
      "|    clip_fraction        | 0.0458       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.2          |\n",
      "|    explained_variance   | 0.651        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.04e+06     |\n",
      "|    n_updates            | 60320        |\n",
      "|    policy_gradient_loss | -0.00171     |\n",
      "|    std                  | 0.201        |\n",
      "|    value_loss           | 1.68e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1940000, episode_reward=258.93 +/- 18724.41\n",
      "Episode length: 1417.00 +/- 681.72\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.42e+03     |\n",
      "|    mean_reward          | 259          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1940000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061360043 |\n",
      "|    clip_fraction        | 0.0481       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.2          |\n",
      "|    explained_variance   | 0.692        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.55e+03     |\n",
      "|    n_updates            | 60330        |\n",
      "|    policy_gradient_loss | -0.00418     |\n",
      "|    std                  | 0.201        |\n",
      "|    value_loss           | 6.95e+06     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 890       |\n",
      "|    ep_rew_mean     | -5.99e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 615       |\n",
      "|    iterations      | 948       |\n",
      "|    time_elapsed    | 3152      |\n",
      "|    total_timesteps | 1941504   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 912        |\n",
      "|    ep_rew_mean          | -5.97e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 616        |\n",
      "|    iterations           | 949        |\n",
      "|    time_elapsed         | 3154       |\n",
      "|    total_timesteps      | 1943552    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06996493 |\n",
      "|    clip_fraction        | 0.176      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.2        |\n",
      "|    explained_variance   | 0.966      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.18e+03   |\n",
      "|    n_updates            | 60340      |\n",
      "|    policy_gradient_loss | 0.00503    |\n",
      "|    std                  | 0.201      |\n",
      "|    value_loss           | 9.99e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1945000, episode_reward=-38683.52 +/- 122214.35\n",
      "Episode length: 1879.40 +/- 1670.68\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.88e+03   |\n",
      "|    mean_reward          | -3.87e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1945000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00994017 |\n",
      "|    clip_fraction        | 0.097      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.2        |\n",
      "|    explained_variance   | 0.769      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 597        |\n",
      "|    n_updates            | 60350      |\n",
      "|    policy_gradient_loss | -0.000208  |\n",
      "|    std                  | 0.201      |\n",
      "|    value_loss           | 1.24e+05   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 912       |\n",
      "|    ep_rew_mean     | -5.97e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 615       |\n",
      "|    iterations      | 950       |\n",
      "|    time_elapsed    | 3162      |\n",
      "|    total_timesteps | 1945600   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 912         |\n",
      "|    ep_rew_mean          | -5.97e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 615         |\n",
      "|    iterations           | 951         |\n",
      "|    time_elapsed         | 3164        |\n",
      "|    total_timesteps      | 1947648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012629279 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.2         |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 389         |\n",
      "|    n_updates            | 60360       |\n",
      "|    policy_gradient_loss | 0.00394     |\n",
      "|    std                  | 0.2         |\n",
      "|    value_loss           | 1.27e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 954         |\n",
      "|    ep_rew_mean          | -5.81e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 615         |\n",
      "|    iterations           | 952         |\n",
      "|    time_elapsed         | 3166        |\n",
      "|    total_timesteps      | 1949696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012062261 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.21        |\n",
      "|    explained_variance   | 0.708       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.01e+03    |\n",
      "|    n_updates            | 60370       |\n",
      "|    policy_gradient_loss | -0.00781    |\n",
      "|    std                  | 0.2         |\n",
      "|    value_loss           | 2.57e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1950000, episode_reward=26010.95 +/- 18846.28\n",
      "Episode length: 3403.80 +/- 1813.30\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.4e+03     |\n",
      "|    mean_reward          | 2.6e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1950000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018693808 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.21        |\n",
      "|    explained_variance   | 0.69        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 836         |\n",
      "|    n_updates            | 60380       |\n",
      "|    policy_gradient_loss | 0.00429     |\n",
      "|    std                  | 0.2         |\n",
      "|    value_loss           | 4.05e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 954       |\n",
      "|    ep_rew_mean     | -5.81e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 614       |\n",
      "|    iterations      | 953       |\n",
      "|    time_elapsed    | 3177      |\n",
      "|    total_timesteps | 1951744   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 984         |\n",
      "|    ep_rew_mean          | -5.79e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 614         |\n",
      "|    iterations           | 954         |\n",
      "|    time_elapsed         | 3179        |\n",
      "|    total_timesteps      | 1953792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006911793 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.21        |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 150         |\n",
      "|    n_updates            | 60390       |\n",
      "|    policy_gradient_loss | 0.00261     |\n",
      "|    std                  | 0.199       |\n",
      "|    value_loss           | 1.27e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1955000, episode_reward=-6667.52 +/- 42915.47\n",
      "Episode length: 2018.80 +/- 2434.21\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 2.02e+03  |\n",
      "|    mean_reward          | -6.67e+03 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 1955000   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0132946 |\n",
      "|    clip_fraction        | 0.117     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 2.22      |\n",
      "|    explained_variance   | 0.919     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 209       |\n",
      "|    n_updates            | 60400     |\n",
      "|    policy_gradient_loss | -0.00138  |\n",
      "|    std                  | 0.199     |\n",
      "|    value_loss           | 1.98e+03  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 984       |\n",
      "|    ep_rew_mean     | -5.79e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 613       |\n",
      "|    iterations      | 955       |\n",
      "|    time_elapsed    | 3188      |\n",
      "|    total_timesteps | 1955840   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.02e+03    |\n",
      "|    ep_rew_mean          | -5.68e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 613         |\n",
      "|    iterations           | 956         |\n",
      "|    time_elapsed         | 3190        |\n",
      "|    total_timesteps      | 1957888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009907713 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.21        |\n",
      "|    explained_variance   | 0.945       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 151         |\n",
      "|    n_updates            | 60410       |\n",
      "|    policy_gradient_loss | 0.004       |\n",
      "|    std                  | 0.2         |\n",
      "|    value_loss           | 1.42e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.02e+03     |\n",
      "|    ep_rew_mean          | -5.68e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 613          |\n",
      "|    iterations           | 957          |\n",
      "|    time_elapsed         | 3192         |\n",
      "|    total_timesteps      | 1959936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0086771455 |\n",
      "|    clip_fraction        | 0.0741       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.2          |\n",
      "|    explained_variance   | 0.39         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 366          |\n",
      "|    n_updates            | 60420        |\n",
      "|    policy_gradient_loss | 0.00265      |\n",
      "|    std                  | 0.2          |\n",
      "|    value_loss           | 1.46e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1960000, episode_reward=353.29 +/- 16255.17\n",
      "Episode length: 1210.60 +/- 1464.34\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.21e+03    |\n",
      "|    mean_reward          | 353         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1960000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024311941 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.2         |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 109         |\n",
      "|    n_updates            | 60430       |\n",
      "|    policy_gradient_loss | 0.0169      |\n",
      "|    std                  | 0.2         |\n",
      "|    value_loss           | 560         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.06e+03  |\n",
      "|    ep_rew_mean     | -5.56e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 613       |\n",
      "|    iterations      | 958       |\n",
      "|    time_elapsed    | 3199      |\n",
      "|    total_timesteps | 1961984   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.06e+03     |\n",
      "|    ep_rew_mean          | -5.56e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 613          |\n",
      "|    iterations           | 959          |\n",
      "|    time_elapsed         | 3201         |\n",
      "|    total_timesteps      | 1964032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074273087 |\n",
      "|    clip_fraction        | 0.0669       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.19         |\n",
      "|    explained_variance   | 0.747        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 484          |\n",
      "|    n_updates            | 60440        |\n",
      "|    policy_gradient_loss | -0.00215     |\n",
      "|    std                  | 0.2          |\n",
      "|    value_loss           | 1.34e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1965000, episode_reward=18847.72 +/- 20444.86\n",
      "Episode length: 3685.00 +/- 1917.57\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.68e+03    |\n",
      "|    mean_reward          | 1.88e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1965000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011159816 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.2         |\n",
      "|    explained_variance   | 0.931       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 73.5        |\n",
      "|    n_updates            | 60450       |\n",
      "|    policy_gradient_loss | 0.00406     |\n",
      "|    std                  | 0.2         |\n",
      "|    value_loss           | 444         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.09e+03  |\n",
      "|    ep_rew_mean     | -5.31e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 611       |\n",
      "|    iterations      | 960       |\n",
      "|    time_elapsed    | 3213      |\n",
      "|    total_timesteps | 1966080   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.09e+03    |\n",
      "|    ep_rew_mean          | -5.31e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 612         |\n",
      "|    iterations           | 961         |\n",
      "|    time_elapsed         | 3215        |\n",
      "|    total_timesteps      | 1968128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019268405 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.2         |\n",
      "|    explained_variance   | 0.699       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 126         |\n",
      "|    n_updates            | 60460       |\n",
      "|    policy_gradient_loss | -0.000331   |\n",
      "|    std                  | 0.2         |\n",
      "|    value_loss           | 2.19e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1970000, episode_reward=31853.34 +/- 23877.49\n",
      "Episode length: 3188.80 +/- 1829.70\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.19e+03    |\n",
      "|    mean_reward          | 3.19e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1970000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009302799 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.2         |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 147         |\n",
      "|    n_updates            | 60470       |\n",
      "|    policy_gradient_loss | 0.0014      |\n",
      "|    std                  | 0.2         |\n",
      "|    value_loss           | 421         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.11e+03  |\n",
      "|    ep_rew_mean     | -5.16e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 610       |\n",
      "|    iterations      | 962       |\n",
      "|    time_elapsed    | 3224      |\n",
      "|    total_timesteps | 1970176   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.11e+03     |\n",
      "|    ep_rew_mean          | -5.16e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 611          |\n",
      "|    iterations           | 963          |\n",
      "|    time_elapsed         | 3227         |\n",
      "|    total_timesteps      | 1972224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054762177 |\n",
      "|    clip_fraction        | 0.158        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.2          |\n",
      "|    explained_variance   | 0.877        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.56e+06     |\n",
      "|    n_updates            | 60480        |\n",
      "|    policy_gradient_loss | -0.00102     |\n",
      "|    std                  | 0.2          |\n",
      "|    value_loss           | 7.51e+05     |\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model.learn(total_timesteps = 5_000_000, callback = eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(save_path + '/ppo_jl_ramp_top_v4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "model = PPO.load(\"/home/bmsit/Ascento/jointed_limited/Training/models_ascento/best_model.zip\", env = env)\n",
    "\n",
    "# #JL_10 -> STAYS AT SET POINT BUT KEEPS ON SPININING VERY VERY FAST\n",
    "# #JL_10_Best -> spins a bit slowly\n",
    "\n",
    "# # JL_11 -> MOVES AROUND, ALSO BENDS 1 LEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes = 30, render = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating window glfw\n",
      "-0.008549251880140699\n",
      "-0.15823683660434212\n",
      "-0.13375401458465522\n",
      "-0.1112357182169366\n",
      "-0.08937624903881373\n",
      "-0.17682168426249606\n",
      "0.18086810849813875\n",
      "-0.07312229973014331\n",
      "-0.005616457094615848\n",
      "-0.19567698031933123\n",
      "-0.00826980432287798\n",
      "0.024573735577237747\n",
      "0.04215654555925982\n",
      "0.0875293292143151\n",
      "0.18700977873846086\n",
      "0.27414914081903063\n",
      "0.20875015005446979\n",
      "0.20798535505889149\n",
      "0.23606643000002728\n",
      "0.1958517032401634\n",
      "0.130069872441585\n",
      "0.18108863769426847\n",
      "0.23518777369222957\n",
      "0.1510893149639833\n",
      "0.048989623971701035\n",
      "0.03169598218084335\n",
      "0.08746663104904397\n",
      "0.10481229534536829\n",
      "0.14384879006630574\n",
      "0.10698936944830024\n",
      "0.08795443531593686\n",
      "0.17681904480022675\n",
      "0.14017345330086564\n",
      "0.09433522007266881\n",
      "0.08302144399291106\n",
      "0.06222913563010489\n",
      "0.05781555246560965\n",
      "0.0932407114761252\n",
      "0.09031751204473022\n",
      "0.09722068139895737\n",
      "0.09267489126574514\n",
      "0.18192136391460328\n",
      "0.18803959839852744\n",
      "0.17744060297245065\n",
      "0.1293253428215529\n",
      "0.15094789559232416\n",
      "0.12093260794933139\n",
      "0.1329794735252774\n",
      "0.0850378769417088\n",
      "0.11913080096278558\n",
      "0.12967778698242433\n",
      "0.21338722041248165\n",
      "0.2288464229608928\n",
      "0.20784544411628145\n",
      "0.12948083428017632\n",
      "0.12149392322058493\n",
      "0.07258886498585171\n",
      "0.07631298957434252\n",
      "0.04963622034806882\n",
      "0.07949416807967502\n",
      "0.034138449308871596\n",
      "0.035429490953096394\n",
      "0.007606040075043882\n",
      "0.053596064432619384\n",
      "0.010506061306530031\n",
      "-0.014772144901000867\n",
      "0.008218036880267527\n",
      "0.025388835430242104\n",
      "0.03869497257401738\n",
      "0.07742128560150376\n",
      "0.03530937165904434\n",
      "0.05450740289432743\n",
      "0.023404558697285912\n",
      "-0.022536973176019753\n",
      "0.01821861494754641\n",
      "0.0031464957098166248\n",
      "0.06119447591170775\n",
      "0.07109738217596763\n",
      "0.11780740358219645\n",
      "0.08082740090218579\n",
      "0.05438612252941067\n",
      "0.1312037881934268\n",
      "0.07519182219890208\n",
      "0.006297514741365022\n",
      "-0.04877291090901888\n",
      "-0.11375450559477022\n",
      "-0.04049148780216003\n",
      "-0.059771462940627865\n",
      "-0.11125789207329025\n",
      "-0.08058937036754617\n",
      "-0.14074518349211615\n",
      "-0.18051364546631776\n",
      "-0.21829293353923676\n",
      "-0.26111801718114297\n",
      "-0.199485541397949\n",
      "-0.2126802410872947\n",
      "-0.20020599154798008\n",
      "-0.2555614233838427\n",
      "-0.30908526131252745\n",
      "-0.3564831355248063\n",
      "-0.31999653701416075\n",
      "-0.2843476287469789\n",
      "-0.22641001552872175\n",
      "-0.19843067197077152\n",
      "-0.28282323822720257\n",
      "-0.2406773797661063\n",
      "-0.20391938893654532\n",
      "-0.2446085058300324\n",
      "-0.253809543266794\n",
      "-0.3721566316551052\n",
      "-0.34792773431341406\n",
      "-0.3342889688044443\n",
      "-0.4442218838266718\n",
      "-0.4728263487468388\n",
      "-0.46986713363272054\n",
      "-0.4461037264894246\n",
      "-0.4453430247248352\n",
      "-0.39700733462525634\n",
      "-0.3511166483414576\n",
      "-0.30583867866656367\n",
      "-0.3703437940605112\n",
      "-0.39087731281760596\n",
      "-0.3118182439187569\n",
      "-0.2879012212809972\n",
      "-0.22813767676566646\n",
      "-0.20282767880685365\n",
      "-0.23379119125201955\n",
      "-0.15355222179315753\n",
      "-0.11652390815270758\n",
      "-0.08520745663529679\n",
      "-0.02885352314122433\n",
      "-0.03676428310561387\n",
      "-0.03863348262828707\n",
      "-0.03281094813479331\n",
      "0.016205107879875287\n",
      "-0.03936909350676969\n",
      "-0.12716133652846728\n",
      "-0.13075246217802797\n",
      "-0.09870825644727246\n",
      "-0.09926527864131054\n",
      "-0.0955468330969992\n",
      "-0.11224227269208434\n",
      "-0.07623873026063135\n",
      "-0.0639126496656033\n",
      "-0.12573437043821994\n",
      "-0.16612373190728538\n",
      "-0.18159413541505492\n",
      "-0.17323499131470124\n",
      "-0.11581693593419588\n",
      "-0.13049996821861753\n",
      "-0.13488277815521704\n",
      "-0.09529270237144893\n",
      "-0.1464474146526144\n",
      "-0.17312252509114243\n",
      "-0.2336441088970318\n",
      "-0.18648043783589205\n",
      "-0.17924328495477307\n",
      "-0.18740755707185983\n",
      "-0.2112807275947423\n",
      "-0.17394689548569187\n",
      "-0.17183883494380675\n",
      "-0.11633937115821275\n",
      "-0.17854828123425676\n",
      "-0.1775362153486707\n",
      "-0.19831524409357526\n",
      "-0.1400570744217234\n",
      "-0.11130059303277581\n",
      "-0.10396552785475163\n",
      "-0.10581481192297322\n",
      "-0.11991410396732725\n",
      "-0.10327072801417314\n",
      "-0.13767293240965675\n",
      "-0.1876249789627218\n",
      "-0.17206970266060242\n",
      "-0.1431496434736288\n",
      "-0.12962015463324933\n",
      "-0.09366025783294976\n",
      "-0.07477159055819302\n",
      "-0.06914662912374539\n",
      "-0.025074243797529337\n",
      "-0.046119795205563974\n",
      "0.015184213984729834\n",
      "0.02725319418142506\n",
      "0.020424115530053116\n",
      "0.040328981567170186\n",
      "0.021094304761315394\n",
      "0.031848798172932125\n",
      "0.04315353909215715\n",
      "0.013618727812157245\n",
      "0.05045157266543941\n",
      "0.024085701825885635\n",
      "0.054090436897578614\n",
      "-0.0039589719744039555\n",
      "-0.023944524818418182\n",
      "-0.05639716771502459\n",
      "-0.08527467224500614\n",
      "-0.09546798152424428\n",
      "-0.07803931475633472\n",
      "-0.06384881616561645\n",
      "-0.042627863580223836\n",
      "-0.03364792404343813\n",
      "-0.05182999525306432\n",
      "-0.02916326424404287\n",
      "0.01762034627905052\n",
      "0.03583042915077614\n",
      "0.04352807542855857\n",
      "0.06471374730881597\n",
      "0.05219482233540812\n",
      "0.05387708209821814\n",
      "0.03798487472928166\n",
      "0.0304504856444123\n",
      "0.06995966662187653\n",
      "0.09634167828908613\n",
      "0.09164110743395146\n",
      "0.10766297910102822\n",
      "0.13519725331581892\n",
      "0.1434194587886206\n",
      "0.13533688848717706\n",
      "0.1239880036713395\n",
      "0.12946031677993536\n",
      "0.10753062396573149\n",
      "0.12841971851377235\n",
      "0.11428536818564192\n",
      "0.09906533567830232\n",
      "0.09607402378270372\n",
      "0.0962929914248216\n",
      "0.0993268680558943\n",
      "0.10226267635191107\n",
      "0.11846267460960704\n",
      "0.11292384591333157\n",
      "0.1266905990932857\n",
      "0.10065977874682719\n",
      "0.08229804325901406\n",
      "0.07581812808008541\n",
      "0.07828672840872598\n",
      "0.10125874832227934\n",
      "0.0945871165656676\n",
      "0.09393557949605072\n",
      "0.09085361568846718\n",
      "0.07950644409321089\n",
      "0.09713007387680897\n",
      "0.11399900474579913\n",
      "0.1357969207278633\n",
      "0.12255859815093063\n",
      "0.11381220634835687\n",
      "0.10903145569259487\n",
      "0.10933172463385005\n",
      "0.11410558063782619\n",
      "0.10962051472038556\n",
      "0.1066816242862409\n",
      "0.11909663052294944\n",
      "0.11656010410163217\n",
      "0.12988091610464228\n",
      "0.13169274855155916\n",
      "0.1339030767873922\n",
      "0.13169382411474742\n",
      "0.14498619782496172\n",
      "0.14889972721012018\n",
      "0.1457162193067802\n",
      "0.14417925501377574\n",
      "0.1568553076981189\n",
      "0.15967687292523478\n",
      "0.14948268744970744\n",
      "0.15191334768678927\n",
      "0.14746411108622795\n",
      "0.13990516488743457\n",
      "0.12427835967537834\n",
      "0.11017474320697875\n",
      "0.10089489084926254\n",
      "0.10323333349466561\n",
      "0.10313886485717771\n",
      "0.09302215798318941\n",
      "0.09769576442149941\n",
      "0.10725876561138875\n",
      "0.11096992327748052\n",
      "0.10827397891976907\n",
      "-0.008706360174102111\n",
      "0.30471999542599726\n",
      "-0.11707570935943878\n",
      "-0.22065375575067736\n",
      "-0.2290483950689225\n",
      "0.1665782551913575\n",
      "-0.06085240351649521\n",
      "-0.12235243876945764\n",
      "0.3630057588713158\n",
      "0.11833216663816425\n",
      "0.19792181076881857\n",
      "0.0692761391505399\n",
      "-0.2224155447857021\n",
      "-0.031093227171085563\n",
      "-0.1195746692356146\n",
      "0.36817813922199033\n",
      "-0.17767668130246636\n",
      "0.10256774947700431\n",
      "0.053170654948397775\n",
      "-0.016627767581264056\n",
      "0.057358818871179135\n",
      "0.015123440794829973\n",
      "0.02647811030349817\n",
      "0.19706068077832262\n",
      "0.15953894744319597\n",
      "0.25774435777244603\n",
      "0.04531679297423205\n",
      "0.20071829977685862\n",
      "-0.10172797458619358\n",
      "0.009677647434541872\n",
      "-0.10500348112218802\n",
      "0.07306834646639997\n",
      "-0.0610723339146636\n",
      "-0.022846779726926697\n",
      "-0.17677256553819526\n",
      "-0.2016784881272554\n",
      "-0.07744263283240903\n",
      "-0.3489224368703949\n",
      "-0.38214633844470286\n",
      "-0.26584615022986696\n",
      "-0.19275044756476128\n",
      "-0.17705519380149948\n",
      "-0.27323956463784893\n",
      "-0.08085610571589583\n",
      "-0.1278770727930962\n",
      "-0.44211812822812224\n",
      "-0.4008160352611537\n",
      "-0.18519154485977352\n",
      "-0.018705379279690917\n",
      "-0.2087935685700532\n",
      "-0.3967293695807891\n",
      "-0.34949748557557225\n",
      "-0.07634614913460032\n",
      "-0.4387454005660451\n",
      "-0.32549558287781705\n",
      "-0.04337764977418232\n",
      "-0.24259275888092224\n",
      "-0.06188703070808495\n",
      "-0.3755825428476653\n",
      "-0.2300556378872064\n",
      "-0.6196362270202204\n",
      "-0.260367184998491\n",
      "-0.33561415349598717\n",
      "-0.261068598526777\n",
      "-0.13349168027978228\n",
      "-0.40591456436352535\n",
      "-0.13055461750077413\n",
      "-0.36686759314592055\n",
      "-0.1680170055874141\n",
      "-0.30396033490921837\n",
      "-0.3741571844543008\n",
      "-0.29049585460559224\n",
      "-0.6610176068280209\n",
      "-0.43852259023282397\n",
      "-0.12814206616789148\n",
      "-0.33144215079128786\n",
      "-0.3898316391533942\n",
      "-0.1060112064376739\n",
      "-0.4326942845871908\n",
      "-0.4085385843310395\n",
      "-0.4324655326725516\n",
      "-0.47228958155634193\n",
      "-0.43647035123036665\n",
      "-0.4026201120366388\n",
      "-0.170631976035431\n",
      "-0.14537149905686278\n",
      "-0.18579154491138009\n",
      "-0.333262510778061\n",
      "-0.11161290798375822\n",
      "-0.12662556147217124\n",
      "-0.28661432585566066\n",
      "-0.7361688238237755\n",
      "-0.39253001839494017\n",
      "-0.21239141870698675\n",
      "-0.1806633187007842\n",
      "-0.3145627006079099\n",
      "-0.30186050188355884\n",
      "-0.6728013194929615\n",
      "-0.43248349775230766\n",
      "-0.557192275544794\n",
      "-0.5120122715339158\n",
      "-0.6163268674967589\n",
      "-0.35570324602193193\n",
      "-0.5865262157354321\n",
      "-0.9086699888258891\n",
      "-0.8239123551090252\n",
      "-0.5596818325982615\n",
      "-0.2805253853976332\n",
      "-0.279172228771449\n",
      "-0.4616961072420366\n",
      "-0.4880944271486402\n",
      "-0.5214864918423364\n",
      "-0.8110115089941131\n",
      "-0.784031963473565\n",
      "-0.5205969123677711\n",
      "-0.6765705494995627\n",
      "-0.6417674310792327\n",
      "-0.7123647378029102\n",
      "-0.5852315176937148\n",
      "-0.5588383796467943\n",
      "-0.469371834320053\n",
      "-0.3139278208557402\n",
      "-0.4544316266493343\n",
      "-0.2534750178393761\n",
      "-0.3092682635590456\n",
      "-0.5330155816078641\n",
      "-0.30717520716968366\n",
      "-0.4945681042872652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.40482959527544043\n",
      "-0.38167993219006197\n",
      "-0.7140706742848686\n",
      "-0.5296578896743437\n",
      "-0.5184175548021827\n",
      "-0.3301983969484767\n",
      "-0.6078153573889705\n",
      "-0.5343302923537437\n",
      "-0.3417957141397334\n",
      "-0.5941712239353295\n",
      "-0.4127147223583585\n",
      "-0.7939695425546075\n",
      "-0.42578575111249123\n",
      "-0.7292218783530147\n",
      "-0.5602479757714579\n",
      "-0.6026487383280988\n",
      "-0.6817022045961996\n",
      "-0.6096288479953068\n",
      "-0.6856695581487984\n",
      "-0.6078058837122848\n",
      "-0.4195100282445867\n",
      "-0.8191079101701814\n",
      "-0.5609169385072212\n",
      "-0.6849110547737794\n",
      "-0.815584947583038\n",
      "-0.6832945857294975\n",
      "-0.8089503934783625\n",
      "-0.5153584607165994\n",
      "-0.6822445924214633\n",
      "-0.37594584810369625\n",
      "-0.6628467550696149\n",
      "-0.9108706730529079\n",
      "-0.6694071718387156\n",
      "-0.6139321595135177\n",
      "-0.7435069102012203\n",
      "-0.4348273850390536\n",
      "-0.3570746931678864\n",
      "-0.3806595583714272\n",
      "-0.356499684523068\n",
      "-0.5575787809199129\n",
      "-0.4489382016226398\n",
      "-0.6824021257402945\n",
      "-0.4530302478558099\n",
      "-0.6659580949960862\n",
      "-0.6349549124375121\n",
      "-0.9597848785836323\n",
      "-0.6685927496205445\n",
      "-0.8108259987163708\n",
      "-0.7986628937066689\n",
      "-0.6518869845481498\n",
      "-0.768336247106753\n",
      "-0.8356036118017984\n",
      "-0.9077366424400604\n",
      "-0.6400963346192639\n",
      "-0.697345385752778\n",
      "-0.6853320938281681\n",
      "-0.9311060634956687\n",
      "-0.9441429663192119\n",
      "-0.9035485484086105\n",
      "-0.8028672278198615\n",
      "-0.51074271779484\n",
      "-0.7320868753237454\n",
      "-0.8822363945977889\n",
      "-0.5916826941401516\n",
      "-0.48443357600191034\n",
      "-0.5536752841603878\n",
      "-0.7990424294203421\n",
      "-0.862425649996978\n",
      "-1.0453398183368339\n",
      "-0.8991140787426096\n",
      "-1.0055363278823035\n",
      "-0.7399389845285973\n",
      "-0.841395844171428\n",
      "-0.6970232159376433\n",
      "-0.758209589031821\n",
      "-0.7696333330139868\n",
      "-0.5970129916334767\n",
      "-0.3542796804471163\n",
      "-0.6163506345506836\n",
      "-0.615199970807256\n",
      "-0.7051067019222518\n",
      "-0.7219033266120465\n",
      "-0.45527404630521173\n",
      "-0.6052824594055601\n",
      "-0.34467279923749283\n",
      "-0.8643022006729246\n",
      "-0.2783766623222771\n",
      "-0.4628243283595044\n",
      "-0.7057229183721647\n",
      "-0.2395600242092624\n",
      "-0.4195137346925676\n",
      "-0.6039215271777236\n",
      "-0.5840270399944631\n",
      "-0.4757779551885123\n",
      "-0.31837908802106446\n",
      "-0.41781586516407926\n",
      "-0.923395501062081\n",
      "-0.576462563827621\n",
      "-0.3773684490095359\n",
      "-0.6867926849218443\n",
      "-1.0203624252651684\n",
      "-1.0652157724347897\n",
      "-0.899301495712413\n",
      "-0.5798231989525624\n",
      "-0.7464792885275352\n",
      "-0.7221933234986004\n",
      "-0.6553358324939114\n",
      "-0.5785858258782597\n",
      "-0.343372982459802\n",
      "-0.6328729567864827\n",
      "-0.4629696513253717\n",
      "-0.675867954375391\n",
      "-0.6184150288225054\n",
      "-0.843032201328507\n",
      "-0.8734841965326777\n",
      "-0.8813312499373432\n",
      "-0.3983848010572259\n",
      "-0.37042870699968505\n",
      "-0.5806329481928516\n",
      "-0.7573850474750982\n",
      "-0.9515423702181437\n",
      "-0.6095467607500156\n",
      "-0.742554600241929\n",
      "-0.8925980337234594\n",
      "-0.6507438309698509\n",
      "-1.1189120896932074\n",
      "-0.9243509699257424\n",
      "-0.665714533442086\n",
      "-0.6251999203152769\n",
      "-1.0125354182362796\n",
      "-0.8463725786400692\n",
      "-0.8132604527551222\n",
      "-0.7227386027160616\n",
      "-0.6117984829990725\n",
      "-0.9023977341283962\n",
      "-0.8451811426599443\n",
      "-0.707301981785634\n",
      "-0.6085114786543027\n",
      "-0.6086156925153309\n",
      "-0.48127126248814645\n",
      "-0.6837460699548915\n",
      "-0.5483052193232716\n",
      "-1.0141177938367705\n",
      "-0.7584324290831467\n",
      "-0.6322928098534442\n",
      "-0.6163624696132658\n",
      "-0.9628970775719566\n",
      "-0.8850350671629388\n",
      "-1.0794887465858138\n",
      "-0.9571935379112563\n",
      "-0.7331787324590819\n",
      "-0.997143023506088\n",
      "-0.9167079559380124\n",
      "-0.9299321702626425\n",
      "-1.1732382844050164\n",
      "-0.9688979552778965\n",
      "-0.9621464328205994\n",
      "-1.0328843105271235\n",
      "-1.0167532208715986\n",
      "-0.9191379434921152\n",
      "-0.8313301998578562\n",
      "-0.8490130802317837\n",
      "-0.7551268293348593\n",
      "-1.040059438940557\n",
      "-0.9434431847103163\n",
      "-1.0036882250591896\n",
      "-0.9294006706522493\n",
      "-0.8149828149880187\n",
      "-1.0122358005167273\n",
      "-0.8165828302795594\n",
      "-0.9933960035906352\n",
      "-0.7082561060518943\n",
      "-0.8528693549945798\n",
      "-0.5710247866703535\n",
      "-0.6527929950397741\n",
      "-0.5240678809045721\n",
      "-0.9035325967690326\n",
      "-0.658318575047145\n",
      "-0.7587990032871682\n",
      "-0.7707076267059512\n",
      "-0.6259225530232351\n",
      "-0.6087684288029052\n",
      "-0.8632357192082886\n",
      "-0.8311697851947126\n",
      "-0.7882228895601749\n",
      "-0.9256880926261738\n",
      "-0.7957930654709342\n",
      "-0.8445748142798434\n",
      "-0.953500970425156\n",
      "-1.0876707195336384\n",
      "-1.0430521110176756\n",
      "-0.8691519131904454\n",
      "-0.6718172086833342\n",
      "-0.9682804136324725\n",
      "-0.9929548876829629\n",
      "-0.934390970789024\n",
      "-0.7218476600302287\n",
      "-0.7127336013462039\n",
      "-0.9304803864217784\n",
      "-0.9193483584087868\n",
      "-0.9733251942014289\n",
      "-0.977693565295606\n",
      "-0.9723575426251824\n",
      "-0.7677821746141263\n",
      "-0.8899504684354563\n",
      "-0.8369649604726698\n",
      "-0.7886589993260511\n",
      "-1.0599738699243701\n",
      "-0.7879241505150428\n",
      "-0.9755700073753484\n",
      "-0.8685841162321167\n",
      "-0.8859890530971946\n",
      "-1.121512334564239\n",
      "-0.6640641169056922\n",
      "-0.8767445643700718\n",
      "-0.6585675339921692\n",
      "-0.8806461845000644\n",
      "-0.793108789197843\n",
      "-0.5475382058339044\n",
      "-0.8153002816659223\n",
      "-0.774551362562986\n",
      "-0.5148521076639712\n",
      "-0.8111157058308716\n",
      "-0.7223129260783802\n",
      "-0.8001138528010738\n",
      "-0.8156668393448891\n",
      "-0.627740639248876\n",
      "-0.786179486352744\n",
      "-0.5434229696012486\n",
      "-0.738360575724143\n",
      "-0.8813673248418987\n",
      "-0.8662812701767285\n",
      "-0.901659937440581\n",
      "-0.9610081895918983\n",
      "-0.9772992188685561\n",
      "-0.9025304818825537\n",
      "-0.9998191212204189\n",
      "-0.9556490128383477\n",
      "-0.8827004549075879\n",
      "-0.8826894469669837\n",
      "-1.1049617860257603\n",
      "-0.8935603428785509\n",
      "-0.7817151213011622\n",
      "-0.9878143600546851\n",
      "-0.8865358580308678\n",
      "-0.6960224220601503\n",
      "-0.926172982574249\n",
      "-0.7612774182558789\n",
      "-0.8616265046561047\n",
      "-0.8920387005744405\n",
      "-0.853509929704705\n",
      "-1.0269985388619953\n",
      "-0.562201629539498\n",
      "-0.8513703751100028\n",
      "-0.9023869409336879\n",
      "-0.7008767924001189\n",
      "-0.9561573947047722\n",
      "-0.9556428486457574\n",
      "-0.9191518545036005\n",
      "-0.5651406221186855\n",
      "-0.7262523206214323\n",
      "-0.8079757672662066\n",
      "-0.6544864587199435\n",
      "-0.6407572892044348\n",
      "-0.6144211569144458\n",
      "-0.7591049895365989\n",
      "-0.8182844359244044\n",
      "-0.904366335398611\n",
      "-0.6589044943583664\n",
      "-0.6898965292923643\n",
      "-0.5240398871650126\n",
      "-0.9223806350540376\n",
      "-0.536799077009599\n",
      "-0.7782833483030681\n",
      "-0.8388114564412681\n",
      "-0.5548094082907172\n",
      "-0.5113537743267327\n",
      "-0.6397303899099249\n",
      "-0.6370450671516644\n",
      "-0.638015435081925\n",
      "-0.7324223080900474\n",
      "-0.803683673540625\n",
      "-0.769670191833246\n",
      "-0.8838218467570419\n",
      "-0.8278299825918642\n",
      "-1.1011907206296985\n",
      "-0.8975040088900577\n",
      "-0.7674036960914961\n",
      "-0.7014049598472542\n",
      "-0.3685015034785082\n",
      "-0.7102394895872041\n",
      "-0.660859606275871\n",
      "-0.6989188678941793\n",
      "-0.6831809555755113\n",
      "-0.763157438016863\n",
      "-0.6470966905230889\n",
      "-0.8075929917616869\n",
      "-0.6865293334151019\n",
      "-0.39628534706221197\n",
      "-0.652143849896222\n",
      "-0.6126419079225148\n",
      "-0.5025977096917513\n",
      "-0.5549824098829528\n",
      "-0.5487939836661061\n",
      "-0.4262128844083732\n",
      "-0.50382439803847\n",
      "-0.3592092305974272\n",
      "-0.6050114699085581\n",
      "-0.6626963736775721\n",
      "-0.5288710268804356\n",
      "-0.33533224269531076\n",
      "-0.6660092279160845\n",
      "-0.6265941988329652\n",
      "-0.3642122016437655\n",
      "-0.45574477814865716\n",
      "-0.2719206120385445\n",
      "-0.34125987261972185\n",
      "-0.38880641061405763\n",
      "-0.4999258050285528\n",
      "-0.7258183434249107\n",
      "-0.7426535429521557\n",
      "-0.6981145218665422\n",
      "-0.41082589585718154\n",
      "-0.2943173046251667\n",
      "-0.3208143904073921\n",
      "-0.1701333018359628\n",
      "-0.1380876083261368\n",
      "-0.33295091247261654\n",
      "-0.02741352518690876\n",
      "-0.3091787918587095\n",
      "-0.4889089045114521\n",
      "-0.2654145786967678\n",
      "-0.32521980142460966\n",
      "-0.6274745524300611\n",
      "-0.7092776785976111\n",
      "-0.36193016962918356\n",
      "-0.7093314458425627\n",
      "-0.5729828978622876\n",
      "-0.4067119501830421\n",
      "-0.6822340648082568\n",
      "-0.7549725261728543\n",
      "-0.838953610040585\n",
      "-0.9143599094593511\n",
      "-1.0344990893347368\n",
      "-0.9481791859551437\n",
      "-0.8962639607962338\n",
      "-0.8758724564723324\n",
      "-0.9461976390614771\n",
      "-0.6605125283891452\n",
      "-1.0307857797473812\n",
      "-1.0214111781898603\n",
      "-1.0505156580273511\n",
      "-0.8530216524893619\n",
      "-0.8548549664648672\n",
      "-0.8702621705609566\n",
      "-0.6839734255475504\n",
      "-0.911209580577258\n",
      "-0.8809537985791236\n",
      "-0.932776282710356\n",
      "-1.0038932898852906\n",
      "-0.6582883768850593\n",
      "-0.6937675221746956\n",
      "-0.9309340898019489\n",
      "-1.1280101772596534\n",
      "-0.8647134435355341\n",
      "-0.5763944736705645\n",
      "-0.9291015153968498\n",
      "-0.792152308569681\n",
      "-0.6799120328561177\n",
      "-0.2783471626638945\n",
      "-0.616580939806944\n",
      "-0.5836880532652735\n",
      "-0.30015903030405916\n",
      "-0.4659736619826592\n",
      "-0.6905917022866433\n",
      "-0.607957963550742\n",
      "-0.7552223782620519\n",
      "-0.7674643291887362\n",
      "-0.42951157403768364\n",
      "-0.6070706176066282\n",
      "-0.5839499469925092\n",
      "-0.6089676600958336\n",
      "-0.6378736590072277\n",
      "-0.4488908519787293\n",
      "-0.6496240557699828\n",
      "-0.39821233121176447\n",
      "-0.5128643930014709\n",
      "-0.8892441493561751\n",
      "-0.38261559554237934\n",
      "-0.7703768940639206\n",
      "-0.4958163694759081\n",
      "-0.4623425517590835\n",
      "-0.5955083438335992\n",
      "-0.5978960554502064\n",
      "-0.8692851136235691\n",
      "-0.7788872403414947\n",
      "-0.8708268805053677\n",
      "-0.841704564000721\n",
      "-0.7295026315614835\n",
      "-0.6959516520887058\n",
      "-0.6367644729180457\n",
      "-0.4061874387516358\n",
      "-0.3851273369194223\n",
      "-0.4493705828034186\n",
      "-0.4259623530506038\n",
      "-0.7694306483283024\n",
      "-0.8283517855805363\n",
      "-0.8552164385676625\n",
      "-0.8411584468862271\n",
      "-0.4416812396656393\n",
      "-0.710096157020457\n",
      "-0.695554073447364\n",
      "-0.7431604829864371\n",
      "-0.899633333326593\n",
      "-0.45739933958266316\n",
      "-0.40098066912719843\n",
      "-0.6457279128404493\n",
      "-0.8084339257856049\n",
      "-0.518541037787243\n",
      "-0.7912274868287721\n",
      "-0.5239197119107869\n",
      "-0.6845426459494626\n",
      "-0.712301270939426\n",
      "-0.7361374163588911\n",
      "-0.7909433523107915\n",
      "-0.8036835536414538\n",
      "-0.4249138337851477\n",
      "-0.656679502688839\n",
      "-0.6774863970988924\n",
      "-0.7211510058555158\n",
      "-0.7560252489833638\n",
      "-0.6302853961791678\n",
      "-0.7358474293424774\n",
      "-0.7024567924847552\n",
      "-0.5263871821978294\n",
      "-0.8736850518032222\n",
      "-0.7774653512174771\n",
      "-0.5373875383082736\n",
      "-0.6047138577833866\n",
      "-0.46275878653800173\n",
      "-0.7671703388169275\n",
      "-0.8729660256622116\n",
      "-0.7453743058091415\n",
      "-0.9892566815065477\n",
      "-1.1646313241739112\n",
      "-0.9093023857206091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.8045250921555351\n",
      "-0.7529768092661094\n",
      "-0.5048755213021041\n",
      "-0.7308337136189083\n",
      "-0.7670986019150751\n",
      "-0.8387249119157645\n",
      "-0.8427574549431542\n",
      "-0.7891571827501088\n",
      "-0.9809610258574907\n",
      "-0.9409818906748828\n",
      "-0.7110188429938248\n",
      "-0.9134591714059613\n",
      "-1.1311716840355013\n",
      "-1.0129178069764366\n",
      "-0.7367147120071905\n",
      "-1.0098131017475165\n",
      "-1.0940168155414485\n",
      "-0.8527672791052552\n",
      "-1.1109552339065407\n",
      "-1.1597708434166818\n",
      "-1.1073863633943937\n",
      "-0.9021431603208826\n",
      "-0.7572435959853027\n",
      "-1.115123466260186\n",
      "-1.290438749424792\n",
      "-1.224912665382957\n",
      "-1.3898774516159942\n",
      "-1.206993879739755\n",
      "-1.2429799572662275\n",
      "-1.4407352700384544\n",
      "-1.3585156193986523\n",
      "-1.1786987310682697\n",
      "-1.337260205591847\n",
      "-1.2001178634417735\n",
      "-1.451878601405709\n",
      "-1.3364177197521432\n",
      "0.008053822035139413\n",
      "0.18326086338778136\n",
      "0.10191337549950902\n",
      "0.10050877019669277\n",
      "0.02351244310199386\n",
      "0.29164426792858034\n",
      "-0.026582568583651572\n",
      "-0.04971954732556705\n",
      "0.23513298050778808\n",
      "0.07829200502967339\n",
      "0.23007448477781078\n",
      "-0.3384045648427594\n",
      "-0.3958928294720366\n",
      "-0.03450504839210071\n",
      "-0.053935172833217526\n",
      "0.006634743901337139\n",
      "0.3093168766895499\n",
      "0.17925735872770965\n",
      "0.26124818589097054\n",
      "0.09664366750884322\n",
      "0.18090181167978825\n",
      "0.03523097385390621\n",
      "0.2494306804788506\n",
      "-0.26963488619969356\n",
      "-0.014788097404473705\n",
      "-0.0006576089547600666\n",
      "0.011040847291790053\n",
      "0.08134284324513849\n",
      "-0.29130872111500644\n",
      "-0.05101413137102972\n",
      "-0.2656137848697096\n",
      "-0.6226915956429276\n",
      "-0.3098006145600345\n",
      "-0.23420829336568688\n",
      "-0.3399739609234195\n",
      "-0.31889635440880365\n",
      "-0.391836555412417\n",
      "-0.17167441538854825\n",
      "-0.12996258753144185\n",
      "-0.2270120172765889\n",
      "-0.28418766653501365\n",
      "-0.38130617237304165\n",
      "-0.3699649525198989\n",
      "0.05906051953956522\n",
      "-0.11535164500710483\n",
      "-0.19154755051653602\n",
      "-0.10937938859492269\n",
      "-0.3028218293733518\n",
      "-0.1332494896551373\n",
      "0.057095762237046974\n",
      "-0.08504908091843918\n",
      "-0.27648563553285305\n",
      "-0.011990722566164382\n",
      "0.0062347882922453805\n",
      "-0.0035740056577066434\n",
      "-0.019871448077563626\n",
      "-0.0955376945713936\n",
      "-0.08767620494679831\n",
      "-0.25191517793139917\n",
      "-0.3456015247417534\n",
      "-0.08758393061321491\n",
      "-0.6058377866949071\n",
      "-0.2439126321211365\n",
      "-0.4560861178474679\n",
      "-0.15974713898959989\n",
      "-0.14248336890820182\n",
      "-0.2003260178207152\n",
      "-0.07825473509241948\n",
      "-0.17388667793985046\n",
      "-0.10973123223159859\n",
      "-0.2563596514418569\n",
      "-0.3164092540928849\n",
      "-0.3356937321046976\n",
      "-0.21999162186008211\n",
      "-0.23039954040142543\n",
      "-0.25719860790876775\n",
      "-0.4376832358922625\n",
      "-0.7004684406275167\n",
      "-0.5936374457590824\n",
      "-0.34150729072396896\n",
      "-0.3264793152819976\n",
      "-0.27897915846471\n",
      "-0.16846825201184149\n",
      "-0.4785520013315237\n",
      "-0.39909189824637553\n",
      "-0.446474669004833\n",
      "-0.4068986857080312\n",
      "-0.32963443020444316\n",
      "-0.49244931190574787\n",
      "-0.35116219652287467\n",
      "-0.50173912010514\n",
      "-0.41599154700923496\n",
      "-0.42626929621355836\n",
      "-0.35942463250681483\n",
      "-0.33146468203119694\n",
      "-0.43371014323067997\n",
      "-0.41542790982375966\n",
      "-0.5286335256684697\n",
      "-0.573101539498385\n",
      "-0.4238984488227097\n",
      "-0.14410410551053465\n",
      "-0.39668722585009764\n",
      "-0.6121946596820027\n",
      "-0.43256217293006016\n",
      "-0.40858409266294055\n",
      "-0.4598872487213892\n",
      "-0.40924829394180484\n",
      "-0.14249431085664882\n",
      "-0.45036784277459546\n",
      "-0.1916036831014003\n",
      "-0.2061295664837298\n",
      "-0.56876624120421\n",
      "-0.32594779577997873\n",
      "-0.198608987539403\n",
      "-0.16074014837675815\n",
      "-0.55324516100137\n",
      "-0.20073122142426164\n",
      "-0.2990218759786937\n",
      "-0.46300107005902036\n",
      "-0.6762361315713588\n",
      "-0.42945698203087646\n",
      "-0.3574139485469523\n",
      "-0.6307469808867381\n",
      "-0.48787693251360953\n",
      "-0.46903671167141664\n",
      "-0.43164625152468605\n",
      "-0.6212770134349297\n",
      "-0.6451057428062926\n",
      "-0.33629572427242055\n",
      "-0.11425587971520343\n",
      "-0.16879117181499342\n",
      "-0.3728786345641334\n",
      "-0.7254658573777005\n",
      "-0.27399182076120643\n",
      "-0.15454901429509568\n",
      "-0.38460924566324695\n",
      "-0.3598455703550463\n",
      "-0.23824110458060954\n",
      "-0.596017168117908\n",
      "-0.1616765482700488\n",
      "-0.3630581339684821\n",
      "-0.427803208620761\n",
      "-0.27803415751161376\n",
      "-0.4792535740655219\n",
      "-0.24394174854945352\n",
      "-0.5778120682187068\n",
      "-0.3747158333268127\n",
      "-0.3181922597208496\n",
      "-0.5081411623052933\n",
      "-0.4606798364416799\n",
      "-0.5972224662767761\n",
      "-0.5350123979846726\n",
      "-0.7647351611872937\n",
      "-0.6160669046398285\n",
      "-0.9613586987206437\n",
      "-0.8580283217467204\n",
      "-0.9781310570290038\n",
      "-0.6953839810601781\n",
      "-0.7145032945466161\n",
      "-0.7091432296806374\n",
      "-0.7994169210765893\n",
      "-0.5820826099888154\n",
      "-0.7562636190338934\n",
      "-0.6752166577114977\n",
      "-0.9022549793615109\n",
      "-0.6439196603652597\n",
      "-0.7530935806595693\n",
      "-0.4551018755483441\n",
      "-0.49354011980838747\n",
      "-0.42403204462262895\n",
      "-0.5670210758699271\n",
      "-0.4757972849745989\n",
      "-0.6088573966257619\n",
      "-0.6861364292862066\n",
      "-0.7404978479439305\n",
      "-0.7462590514444414\n",
      "-0.7631112966292315\n",
      "-0.557063214617286\n",
      "-0.8211242239242854\n",
      "-0.6258779846182557\n",
      "-0.5183884822607998\n",
      "-0.551680398628835\n",
      "-0.5792517924561921\n",
      "-0.6752505810032923\n",
      "-0.7817549173997157\n",
      "-0.5570710659178184\n",
      "-0.8235419431658101\n",
      "-0.9638378275557233\n",
      "-0.9975813764534041\n",
      "-0.6336468363299271\n",
      "-0.663028046381538\n",
      "-0.7680610355651218\n",
      "-0.6804155939178205\n",
      "-0.5334048640459511\n",
      "-0.4800740545896936\n",
      "-0.4520087266649333\n",
      "-0.4218937298668523\n",
      "-0.8082584402465378\n",
      "-0.28416675456658325\n",
      "-0.45403043687524525\n",
      "-0.5048442512561889\n",
      "-0.4440214202558972\n",
      "-0.7626763284891654\n",
      "-0.6982020081285708\n",
      "-0.5188482319776154\n",
      "-0.45966244387155825\n",
      "-0.45742274285340456\n",
      "-0.41215006010282723\n",
      "-0.6582389614915124\n",
      "-0.4209226553151838\n",
      "-0.2965268937380514\n",
      "-0.538230941744539\n",
      "-0.5001947463277062\n",
      "-0.6187757799534532\n",
      "-0.4848953186032785\n",
      "-0.5259593914128853\n",
      "-0.8049354718948714\n",
      "-0.6663901338504603\n",
      "-0.4176873796539055\n",
      "-0.34463387335218204\n",
      "-0.4467591821684201\n",
      "-0.44547797906600617\n",
      "-0.31341597059186327\n",
      "-0.32230598403141547\n",
      "-0.37270353532754874\n",
      "-0.3569491946348133\n",
      "-0.6200871273583385\n",
      "-0.653906748682506\n",
      "-0.6727775265844778\n",
      "-0.44950976809039644\n",
      "-0.4599310554478348\n",
      "-0.4270636798182817\n",
      "-0.7008063203247133\n",
      "-0.5849131145318851\n",
      "-0.5858433930616691\n",
      "-0.6801830311014998\n",
      "-0.752310274657474\n",
      "-0.5068495979495763\n",
      "-0.7161967220666385\n",
      "-0.6023155180157197\n",
      "-0.6052589808638347\n",
      "-0.6747101201109549\n",
      "-0.7676048802058889\n",
      "-0.6924165343253723\n",
      "-0.8208507470598981\n",
      "-0.6305568623368158\n",
      "-0.743161369880166\n",
      "-0.7233398596910262\n",
      "-0.7629400232610162\n",
      "-0.7988393823882217\n",
      "-0.9712632890116393\n",
      "-0.7952765545246079\n",
      "-0.6672249469475195\n",
      "-0.6618448376359376\n",
      "-0.5513682275276297\n",
      "-0.40244914271618726\n",
      "-0.550435194178563\n",
      "-0.6882875793019781\n",
      "-0.6799727740383312\n",
      "-0.6154497154461211\n",
      "-0.5733914280108812\n",
      "-0.6381642705896672\n",
      "-0.5103734028273683\n",
      "-0.42532987245394843\n",
      "-0.3096160066396108\n",
      "-0.44545703292700906\n",
      "-0.257141485488418\n",
      "-0.40430812468841126\n",
      "-0.3325153249268773\n",
      "-0.784086820397003\n",
      "-0.5850450795004142\n",
      "-0.514771659946552\n",
      "-0.31105656111651403\n",
      "-0.6043964423080547\n",
      "-0.6961181453957294\n",
      "-0.3968160444428534\n",
      "-0.3802560819413816\n",
      "-0.6294902368351838\n",
      "-0.7508112480618696\n",
      "-0.7496503877812771\n",
      "-0.5174509607252054\n",
      "-0.748483874537314\n",
      "-0.7137086581717254\n",
      "-0.3648616052532687\n",
      "-0.5266812300978788\n",
      "-0.6251736428708781\n",
      "-0.6415489287226493\n",
      "-0.5973448388735305\n",
      "-0.44694942652652464\n",
      "-0.6625863721759868\n",
      "-0.4979751638707969\n",
      "-0.7182664550374261\n",
      "-0.7152325205043437\n",
      "-0.7621208448796782\n",
      "-0.7907375392289118\n",
      "-0.8382660791142297\n",
      "-0.8954963601731732\n",
      "-0.8893022160719156\n",
      "-0.9403115857636577\n",
      "-0.8933740624983675\n",
      "-0.5760594779077204\n",
      "-0.8726685560494344\n",
      "-0.8015722031543835\n",
      "-0.7236321224817535\n",
      "-0.7800989163067006\n",
      "-1.0917089160438924\n",
      "-0.6247369769948045\n",
      "-0.6108967364398427\n",
      "-0.9456777021270483\n",
      "-0.8270622238521045\n",
      "-0.7020762451511641\n",
      "-0.7579975159007163\n",
      "-1.009339789458773\n",
      "-1.0257945876276389\n",
      "-0.9867259463655262\n",
      "-0.6042478132288007\n",
      "-0.3899763872839518\n",
      "-0.5709853009560547\n",
      "-0.18505603656993924\n",
      "-0.5067372862499456\n",
      "-0.3602877897170904\n",
      "-0.40518447604312924\n",
      "-0.2456303172798809\n",
      "-0.17984088635498516\n",
      "-0.38064589515591846\n",
      "-0.541256004374658\n",
      "-0.41198459767464535\n",
      "-0.421176822065837\n",
      "-0.6921593654560054\n",
      "-0.4197751348607097\n",
      "-0.4622566157027493\n",
      "-0.46836599024580006\n",
      "-0.3290828179603516\n",
      "-0.798504249610187\n",
      "-0.48043453357248106\n",
      "-0.43993227491473685\n",
      "-0.5041554289202392\n",
      "-0.538227898635969\n",
      "-0.3389047031197382\n",
      "-0.46880318478227756\n",
      "-0.4723361594478267\n",
      "-0.2666252613715805\n",
      "-0.41917857037416617\n",
      "-0.17821287286482348\n",
      "-0.30347306183471734\n",
      "-0.05011303531591792\n",
      "-0.29025143313943635\n",
      "-0.15053991191766136\n",
      "-0.3481400562653366\n",
      "-0.30082367294729734\n",
      "-0.16572080669831413\n",
      "0.05005072422648432\n",
      "-0.13180323662903515\n",
      "-0.29320331556388807\n",
      "-0.25154539312629354\n",
      "-0.6591903185258159\n",
      "-0.704254275118442\n",
      "-0.6003557407167094\n",
      "-0.7423893459840301\n",
      "-0.7525562373319803\n",
      "-0.6932447060073086\n",
      "-0.7185079127715507\n",
      "-0.5428042457138369\n",
      "-0.7287044818653843\n",
      "-0.8881542724111606\n",
      "-0.6993618648561937\n",
      "-0.7781978488989698\n",
      "-0.39369806028046705\n",
      "-0.5831486376275153\n",
      "-0.659738297655298\n",
      "-0.6742209571483289\n",
      "-0.4040432310612524\n",
      "-0.42019843904785587\n",
      "-0.40895972348826354\n",
      "-0.15616269709227915\n",
      "-0.1270568881407098\n",
      "-0.11446716569284614\n",
      "-0.5203612564836722\n",
      "-0.07710663705462856\n",
      "-0.046788166704424844\n",
      "-0.252872793152326\n",
      "-0.22485155829515244\n",
      "-0.3350363355249357\n",
      "-0.23383170969098707\n",
      "-0.5183778068030923\n",
      "-0.42304812812317183\n",
      "-0.277756357229664\n",
      "-0.3075277237757693\n",
      "-0.07006800516268966\n",
      "-0.27849541170376696\n",
      "-0.19655910669276502\n",
      "-0.2266471557396681\n",
      "-0.0027238609225714097\n",
      "-0.20303012022678654\n",
      "-0.5680020664955069\n",
      "-0.4477742796132008\n",
      "-0.39332518648006537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.38494310952025707\n",
      "-0.41818153198581953\n",
      "-0.24209779423287053\n",
      "-0.5134110579643697\n",
      "-0.6009073498351984\n",
      "-0.5167450965934459\n",
      "-0.37777477952789834\n",
      "-0.2599486466206407\n",
      "-0.26657469796660443\n",
      "-0.17126116179362147\n",
      "-0.14105089131339066\n",
      "-0.3871347986474241\n",
      "-0.3706446920184617\n",
      "-0.21970579288086672\n",
      "-0.18303606286552632\n",
      "-0.38411405576749563\n",
      "-0.13755469863071268\n",
      "-0.03682645369326005\n",
      "-0.10246429961196057\n",
      "-0.2713372889408062\n",
      "-0.39127121945116405\n",
      "-0.37837148135212695\n",
      "0.03941516372291401\n",
      "-0.08517572437738577\n",
      "-0.09526172453075861\n",
      "-0.05295214648773952\n",
      "0.14274694590201728\n",
      "0.010423999294766333\n",
      "-0.010342739536774557\n",
      "0.02565643230413871\n",
      "-0.020413497865116644\n",
      "-0.19424628345354003\n",
      "0.151439721102873\n",
      "0.05397735545589434\n",
      "0.1870586108219784\n",
      "0.19493996998698648\n",
      "0.1936682644019195\n",
      "-0.10276103107428826\n",
      "-0.10582619204961921\n",
      "-0.24276049339991923\n",
      "0.1396507286300579\n",
      "0.08591932254769455\n",
      "-0.18250275280963502\n",
      "0.04146301489050847\n",
      "-0.24092501173765762\n",
      "-0.3687256466982846\n",
      "-0.07320595631178003\n",
      "0.0748698114604858\n",
      "-0.012120771905202617\n",
      "-0.09541895402706793\n",
      "-0.1339900501166761\n",
      "-0.12027112664673159\n",
      "0.0825882409056536\n",
      "-0.1455556225405275\n",
      "-0.20724174773976975\n",
      "-0.2023029971179156\n",
      "0.10149530786384808\n",
      "-0.23275865483109723\n",
      "-0.14851092444914726\n",
      "-0.19714085554389896\n",
      "-0.3002576523709385\n",
      "-0.3860619475652233\n",
      "-0.3961860032567241\n",
      "-0.15413046708777567\n",
      "-0.481312874732406\n",
      "-0.39127380171845544\n",
      "0.006935962144310748\n",
      "-0.07436263628096111\n",
      "-0.31963628961505997\n",
      "-0.4232314324620436\n",
      "-0.14491423961365746\n",
      "-0.41322245893873966\n",
      "0.00391500002006144\n",
      "-0.21163654448291097\n",
      "-0.21735311373384605\n",
      "-0.09613775089888683\n",
      "-0.15624136305829842\n",
      "-0.11198296858547234\n",
      "-0.04688749003010414\n",
      "-0.009348566594548184\n",
      "-0.06786903992445381\n",
      "0.16890375274550423\n",
      "0.07270945216479274\n",
      "-0.1635325943831481\n",
      "-0.12839858424771475\n",
      "-0.05143731133267722\n",
      "-0.04300454948644739\n",
      "0.15194475420101364\n",
      "-0.05943879254390464\n",
      "-0.01167297303834742\n",
      "-0.09103361955739298\n",
      "-0.22348472248762524\n",
      "-0.1493096336800401\n",
      "-0.045256895034947606\n",
      "0.05004274394950507\n",
      "-0.002015533152185899\n",
      "0.13326676057378845\n",
      "0.12031258373947681\n",
      "-0.21006049224012\n",
      "-0.28533982475778713\n",
      "-0.23347271176103415\n",
      "-0.05136604947743508\n",
      "-0.04152777158429543\n",
      "0.03735958257042363\n",
      "-0.15325489188947522\n",
      "-0.27075781671805593\n",
      "-0.2724421112842004\n",
      "-0.24381977056148238\n",
      "-0.1159635363409476\n",
      "-0.3483350151495707\n",
      "-0.5568834529193547\n",
      "-0.37619302325271664\n",
      "-0.0914582338592771\n",
      "-0.03719011962923989\n",
      "-0.3796201568450568\n",
      "-0.15535930771723844\n",
      "-0.21819327845374856\n",
      "0.03222790651208848\n",
      "-0.2987011526951587\n",
      "-0.2797943955330027\n",
      "-0.2495345885006644\n",
      "-0.06020881608083494\n",
      "-0.3896805977169326\n",
      "-0.31748969650473025\n",
      "-0.14075099015016027\n",
      "0.014059742121356963\n",
      "-0.3143251558441206\n",
      "-0.2347193890186118\n",
      "-0.3544869994007364\n",
      "-0.388819245083079\n",
      "-0.22102398500946363\n",
      "-0.1800362342351804\n",
      "-0.22169784251815572\n",
      "-0.35725884614036296\n",
      "-0.07970154871401298\n",
      "-0.08931214517716896\n",
      "-0.3887793901475012\n",
      "-0.03455872871588432\n",
      "0.09851685142468536\n",
      "-0.24018014508268937\n",
      "-0.1587481415346776\n",
      "-0.11583776162687393\n",
      "-0.11283310412123057\n",
      "0.1951242800132752\n",
      "0.14479742160173117\n",
      "-0.3752004549389382\n",
      "-0.19678233485744728\n",
      "-0.19522990472749185\n",
      "-0.5911459952727439\n",
      "-0.2831554951812557\n",
      "-0.4476864325922574\n",
      "-0.05101816809191227\n",
      "-0.1845886417204542\n",
      "-0.41890018206034285\n",
      "-0.20897737014150108\n",
      "-0.16751139991598568\n",
      "-0.3228958830260117\n",
      "-0.601663417594847\n",
      "-0.5653496139970036\n",
      "-0.4070639682981123\n",
      "-0.6146059027945117\n",
      "-0.7828912252330894\n",
      "-0.4651831886642349\n",
      "-0.4175227452547607\n",
      "-0.5091776872246297\n",
      "-0.3357492448224807\n",
      "-0.5132277285229246\n",
      "-0.4489307579472608\n",
      "-0.6547701570116401\n",
      "-0.7082140170823042\n",
      "-0.7295691594369136\n",
      "-0.3618400509515758\n",
      "-0.5693072768715337\n",
      "-0.6233072521549095\n",
      "-0.7022663959881598\n",
      "-0.33722012992486955\n",
      "-0.6897452649713208\n",
      "-0.7096239687650786\n",
      "-0.668224608614311\n",
      "-0.5197909150959104\n",
      "-0.9256344812815389\n",
      "-0.6886879015179577\n",
      "-0.7404040857856253\n",
      "-0.5761280817018003\n",
      "-0.7079251860106727\n",
      "-0.8511282153271051\n",
      "-0.8691232298127783\n",
      "-0.8531499312923096\n",
      "-0.8411619472220578\n",
      "-0.7192294176351716\n",
      "-0.5099042270913094\n",
      "-0.8473619919001956\n",
      "-0.5392275577408346\n",
      "-0.8513669036929533\n",
      "-0.8382009173939867\n",
      "-0.9095706998878266\n",
      "-0.7536330368504739\n",
      "-0.7550559114227965\n",
      "-0.8620991231237011\n",
      "-0.414178359138497\n",
      "-0.6467811483995142\n",
      "-0.9336708246355648\n",
      "-0.479388428427455\n",
      "-0.8103614980612475\n",
      "-0.521960547702848\n",
      "-0.68463804810618\n",
      "-0.34223645872710345\n",
      "-0.6311832747758932\n",
      "-0.7970985725198132\n",
      "-0.8617547646589337\n",
      "-0.557555349023039\n",
      "-0.6589453710373714\n",
      "-0.8156408010919504\n",
      "-0.5107187234057562\n",
      "-0.7795650553988787\n",
      "-0.49626193131948354\n",
      "-0.468307521719545\n",
      "-0.902484966328731\n",
      "-0.9836566522194233\n",
      "-0.7314328766059219\n",
      "-0.8902132768227012\n",
      "-0.6528075278981772\n",
      "-0.680885323774865\n",
      "-0.7488696615358539\n",
      "-0.7628761447329047\n",
      "-0.7155980218818563\n",
      "-0.5299506263863999\n",
      "-0.5712368829509613\n",
      "-0.71663022662543\n",
      "-0.6554094730964798\n",
      "-0.8117743548358161\n",
      "-0.6736906274027182\n",
      "-0.8277674997427643\n",
      "-0.8699846365793569\n",
      "-0.9834795178366819\n",
      "-0.7970889063286115\n",
      "-0.5192574928329883\n",
      "-0.8181712323291411\n",
      "-0.7157802062563006\n",
      "-0.8650136356381968\n",
      "-0.796787026266794\n",
      "-0.8907248307279959\n",
      "-0.8320565989425973\n",
      "-0.888696872811931\n",
      "-0.9400920191105971\n",
      "-0.9268860184473857\n",
      "-0.8638198936607953\n",
      "-0.7990134566041932\n",
      "-0.6922030334568089\n",
      "-0.4297567260161167\n",
      "-0.7836746817496449\n",
      "-0.8622139502482266\n",
      "-1.0197402723870974\n",
      "-0.9692235906003018\n",
      "-1.0892037531381078\n",
      "-0.9444778726800779\n",
      "-1.083482621203614\n",
      "-0.5905825660766438\n",
      "-0.49449530215689685\n",
      "-0.8229641755151995\n",
      "-0.5796990579357357\n",
      "-0.678773143351777\n",
      "-0.7832765203256021\n",
      "-1.063046808975415\n",
      "-0.8575103576319227\n",
      "-1.0106306986300235\n",
      "-0.8920279711867318\n",
      "-0.8215503048072824\n",
      "-0.7847703658355192\n",
      "-0.8210967565069436\n",
      "-1.0161571570400172\n",
      "-0.957700201208321\n",
      "-0.8897111544031823\n",
      "-1.0636087308767748\n",
      "-1.1270516169660285\n",
      "-0.7841866500049537\n",
      "-0.7773435103784746\n",
      "-0.8417804683483182\n",
      "-0.8948443799734518\n",
      "-0.9953341491338504\n",
      "-0.9612783508064614\n",
      "-0.9860385575513739\n",
      "-0.864186343346538\n",
      "-0.9054976642728014\n",
      "-0.8934621996449134\n",
      "-1.0133736001876157\n",
      "-0.715253967501936\n",
      "-0.6839979095670505\n",
      "-0.9843149566209942\n",
      "-0.7890095941049062\n",
      "-0.9036441840992657\n",
      "-0.7350814904806997\n",
      "-0.7943953194182244\n",
      "-0.898487570142402\n",
      "-0.8823235384956329\n",
      "-0.8587140898846279\n",
      "-1.2393434553956875\n",
      "-1.0315838151130494\n",
      "-1.114611835600921\n",
      "-1.120145581719649\n",
      "-1.0490659390908257\n",
      "-1.1762162073784022\n",
      "-0.9808108656045484\n",
      "-0.9475413409095332\n",
      "-0.8329036663238875\n",
      "-1.1895617492560475\n",
      "-1.3004416832543566\n",
      "-1.381104080864095\n",
      "-1.1260467394677582\n",
      "-1.132029181055523\n",
      "-1.4045097435002576\n",
      "-1.3570828660883334\n",
      "-1.5079366564984718\n",
      "-1.4289964442939447\n",
      "-1.4644543908416496\n",
      "-1.3802498751540215\n",
      "-1.3051116670290936\n",
      "-1.2146214924257763\n",
      "-1.1074847623088104\n",
      "-0.9359670659195961\n",
      "-1.1899379422810066\n",
      "-1.213035381284287\n",
      "-0.9723474736781804\n",
      "-1.2541108255221805\n",
      "-1.3208674045065925\n",
      "-1.2982723435377381\n",
      "-1.1367846457968704\n",
      "-1.1674456334342262\n",
      "-1.183382275033301\n",
      "-1.1905937870576373\n",
      "-1.1765945923789227\n",
      "-1.389618552340219\n",
      "-1.1926532927764062\n",
      "-1.350977979610472\n",
      "-1.5742356064763119\n",
      "-1.3965716477205532\n",
      "-1.4132151900364713\n",
      "-1.4692045930886886\n",
      "-1.3561461167212505\n",
      "-1.3788991790978868\n",
      "-1.3399635543071737\n",
      "-1.2298928535238887\n",
      "-1.6012848259993975\n",
      "-1.291392820865177\n",
      "-1.5878310887601583\n",
      "-1.6628921320906156\n",
      "-1.7540987710708031\n",
      "-1.7889937896866628\n",
      "-1.7777355190503652\n",
      "-1.7898520418908364\n",
      "-1.626828931862956\n",
      "-1.3806534084804998\n",
      "-1.46706028772178\n",
      "-1.4555048946584117\n",
      "-1.4197614423052132\n",
      "-1.7118483585954627\n",
      "-1.9385128446643585\n",
      "-1.8088042899605066\n",
      "-1.4954701436368174\n",
      "-1.7721713909540542\n",
      "-1.8072853464704268\n",
      "-1.7722004274521008\n",
      "-1.5733899147728785\n",
      "-1.7701197786280574\n",
      "-1.7340527649688482\n",
      "-1.8546632919041002\n",
      "-1.8331913635941737\n",
      "-1.8618511063183905\n",
      "-1.7244016312929562\n",
      "-1.704532382230696\n",
      "-1.939503981530301\n",
      "-2.049226658359541\n",
      "0.001895317874202638\n",
      "-0.2300884360474736\n",
      "-0.16829386786368306\n",
      "-0.10221902755212242\n",
      "-0.1622716749410537\n",
      "-0.03549453631597535\n",
      "-0.06669554326031069\n",
      "0.008323815009445935\n",
      "-0.0009914553551735508\n",
      "0.31009448244428867\n",
      "0.3274980654901448\n",
      "-0.20383898929257133\n",
      "0.1940993647023044\n",
      "0.06732210932386973\n",
      "0.22046639537029597\n",
      "-0.04382675596427113\n",
      "-0.0975387821244857\n",
      "0.28692322576717966\n",
      "0.05256719048216443\n",
      "-0.006384941352079348\n",
      "-0.027164835794574974\n",
      "0.004533779984940145\n",
      "-0.06583484673893751\n",
      "0.2986270927494354\n",
      "0.11062541664471587\n",
      "-0.034833459190794835\n",
      "0.11259506086905083\n",
      "-0.2321201945841917\n",
      "-0.09132638409869233\n",
      "-0.26549914374150024\n",
      "-0.15419458708613137\n",
      "0.11297278647419227\n",
      "0.156090975877964\n",
      "-0.3107841833284742\n",
      "-0.18857196236232315\n",
      "0.06710880344436909\n",
      "-0.26195331442742387\n",
      "-0.12079843787774557\n",
      "-0.11125963109734276\n",
      "-0.40683203396073747\n",
      "-0.5193354812703717\n",
      "-0.06178511038755857\n",
      "-0.3569655727398029\n",
      "-0.34747768987045463\n",
      "-0.28145744694047403\n",
      "-0.15815767234744896\n",
      "-0.48613141210442157\n",
      "0.024818013007422896\n",
      "0.024284828704385322\n",
      "-0.32634652779331613\n",
      "-0.6376269672228309\n",
      "-0.5749378764564843\n",
      "-0.2825702051263136\n",
      "-0.32889631658485213\n",
      "-0.4800777923918759\n",
      "-0.16406094395915902\n",
      "0.07650287797463469\n",
      "0.0846538461173284\n",
      "-0.07521527737036472\n",
      "-0.006648110348206384\n",
      "-0.03571526875545135\n",
      "0.06526170948147514\n",
      "-0.1668489711315303\n",
      "-0.03918554090006685\n",
      "0.04368665404681841\n",
      "0.017526165109343655\n",
      "-0.4209225018768704\n",
      "-0.43422887127113485\n",
      "-0.2631907243615492\n",
      "-0.4352127702792103\n",
      "-0.21312054339092268\n",
      "-0.12237054556524087\n",
      "-0.3817560708278185\n",
      "-0.41069022923598714\n",
      "-0.3317908230186092\n",
      "0.005752296652306692\n",
      "-0.010092159886702694\n",
      "-0.09884181362385114\n",
      "-0.1140100792950501\n",
      "-0.4477953664296884\n",
      "-0.46551863085136913\n",
      "-0.4896540697642138\n",
      "-0.43526006580906385\n",
      "-0.09986661954618538\n",
      "-0.22049645733724957\n",
      "-0.3765624937193299\n",
      "-0.4898474997565015\n",
      "-0.31872191299607133\n",
      "-0.43497435210659213\n",
      "-0.21612786689092925\n",
      "-0.5098909628613764\n",
      "-0.5184101386529051\n",
      "-0.5642235518083538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.4816378910584346\n",
      "-0.2915391538019193\n",
      "-0.5489441542678922\n",
      "-0.5187562923657492\n",
      "-0.3117966481474036\n",
      "-0.4150397179313421\n",
      "-0.34516856510570965\n",
      "-0.1774460597031795\n",
      "-0.3344633586243088\n",
      "-0.1709452861966499\n",
      "-0.4469557103027859\n",
      "-0.2599889145483073\n",
      "-0.3026209656133401\n",
      "-0.6954772049353355\n",
      "-0.5113293702988237\n",
      "-0.19302003772036885\n",
      "-0.3928537422182028\n",
      "-0.4817246852609679\n",
      "-0.48106441505259234\n",
      "-0.6351882402792454\n",
      "-0.5758126750111601\n",
      "-0.7694837591130583\n",
      "-0.6248886646774309\n",
      "-0.9064366740442047\n",
      "-0.5431086028112284\n",
      "-1.0489065747285589\n",
      "-0.749511957382921\n",
      "-0.5574139370685699\n",
      "-0.9242114476875574\n",
      "-0.5546306460294803\n",
      "-0.6524155565221947\n",
      "-0.7271536825990771\n",
      "-0.28552611093964075\n",
      "-0.34878374057467737\n",
      "-0.4954878761871283\n",
      "-0.8706958578094416\n",
      "-0.6477930861526766\n",
      "-0.5175348461018379\n",
      "-0.47883322821040303\n",
      "-0.4903968316551094\n",
      "-1.0565848077647026\n",
      "-1.0656580518627323\n",
      "-0.7405125082925796\n",
      "-0.6856889665852717\n",
      "-0.5682259478156091\n",
      "-0.6309192249531812\n",
      "-0.6575260063098024\n",
      "-0.39395679477847995\n",
      "-0.6160339089344596\n",
      "-0.7264366703228603\n",
      "-0.5393467862877734\n",
      "-0.33416391163143366\n",
      "-0.5435114727463879\n",
      "-0.5643034280139025\n",
      "-0.5963535707742695\n",
      "-0.47761844311784596\n",
      "-0.4504430559867748\n",
      "-0.4577861862542212\n",
      "-0.6364636154124099\n",
      "-1.0284917654462835\n",
      "-1.0580928795324638\n",
      "-0.5941636466543034\n",
      "-0.34526085630386905\n",
      "-0.3512376134671722\n",
      "-0.3937332934572788\n",
      "-0.6170508826553852\n",
      "-0.6424657577275517\n",
      "-0.823049456225557\n",
      "-0.9750906736396385\n",
      "-0.7249808660604949\n",
      "-0.7665639894337668\n",
      "-0.5917324568178116\n",
      "-0.7847098346968168\n",
      "-0.866880029997661\n",
      "-0.7208829914006777\n",
      "-0.9663728064842247\n",
      "-0.7202865555767823\n",
      "-0.7344802836821985\n",
      "-0.9722165483352387\n",
      "-0.6618285149744232\n",
      "-0.8793964997850783\n",
      "-1.03858115060192\n",
      "-0.8572044669861445\n",
      "-0.7889703040399189\n",
      "-0.6918705188809139\n",
      "-0.4917046921124823\n",
      "-0.589061977461787\n",
      "-0.6533779109371477\n",
      "-0.8633818988757186\n",
      "-0.9494002775086705\n",
      "-0.9978843528658783\n",
      "-0.8462579357346007\n",
      "-0.9799798398352814\n",
      "-1.1748974184763894\n",
      "-0.9136098989902672\n",
      "-1.0841422420285727\n",
      "-1.0409447094376052\n",
      "-1.154706612617143\n",
      "-0.601422201652089\n",
      "-0.940425384104997\n",
      "-0.8678478130778499\n",
      "-0.7599102884611372\n",
      "-0.656158036518122\n",
      "-0.9354147143971776\n",
      "-0.5878104086972955\n",
      "-0.7052772771762934\n",
      "-0.6699682381170611\n",
      "-0.7353343392888878\n",
      "-1.0081823481028953\n",
      "-0.9316292087374488\n",
      "-0.7811994591885977\n",
      "-0.8059277291094457\n",
      "-1.1132468614696815\n",
      "-1.2138447106695551\n",
      "-1.0747050561674036\n",
      "-0.8518818201826646\n",
      "-1.1411267827304257\n",
      "-0.8105394559586168\n",
      "-0.8666767880040714\n",
      "-0.666643045052223\n",
      "-1.0373111506002386\n",
      "-1.0313984385900556\n",
      "-1.0076738023548637\n",
      "-1.097006582641804\n",
      "-1.0521219788875482\n",
      "-0.9335703258409805\n",
      "-1.227634411857335\n",
      "-1.0518315754145267\n",
      "-0.928806307239483\n",
      "-0.8275250088521556\n",
      "-0.8730980412860505\n",
      "-0.7210347082614661\n",
      "-0.6879978707204145\n",
      "-0.6939829853223136\n",
      "-0.9113805523467273\n",
      "-0.691587152380196\n",
      "-0.9175981465971135\n",
      "-0.7313533775088796\n",
      "-1.0251501654908326\n",
      "-1.0503064207552295\n",
      "-1.1417210636705233\n",
      "-0.9999764815769925\n",
      "-0.826832345918394\n",
      "-0.6848737628885354\n",
      "-0.8913481046143442\n",
      "-0.7383056112972886\n",
      "-0.7501509249313153\n",
      "-0.8504477907217224\n",
      "-0.9822009208045317\n",
      "-0.8513627056261336\n",
      "-0.792796328452175\n",
      "-0.9433582412106335\n",
      "-1.0490766230653679\n",
      "-0.997115486084929\n",
      "-0.7810480987432574\n",
      "-0.8289081187246258\n",
      "-0.7681724656775599\n",
      "-1.1749766607078547\n",
      "-0.9120574081543293\n",
      "-0.8451975185803383\n",
      "-0.8825200301675541\n",
      "-0.7799318356183574\n",
      "-0.7118579629488958\n",
      "-0.8645481631307956\n",
      "-0.8116081759237022\n",
      "-0.7673285772214602\n",
      "-0.50165213688763\n",
      "-0.5903122665701586\n",
      "-0.4499710500984401\n",
      "-0.35298564676015254\n",
      "-0.309220288161012\n",
      "-0.1434366559884156\n",
      "-0.5146091792018005\n",
      "-0.09026414165274309\n",
      "-0.3705836865077433\n",
      "-0.2631064590973261\n",
      "-0.33565292395263824\n",
      "-0.3853605516277609\n",
      "-0.467931311672869\n",
      "-0.21255475396465118\n",
      "-0.22853435924442211\n",
      "-0.28455851087020906\n",
      "-0.20249323922357979\n",
      "-0.32839104924274437\n",
      "-0.37396483360588273\n",
      "-0.17025449155370356\n",
      "-0.3690410964355121\n",
      "-0.4281170936252718\n",
      "-0.29014239754943044\n",
      "-0.11526441957612574\n",
      "-0.4060750116242621\n",
      "-0.4234703513987399\n",
      "-0.5816519876606205\n",
      "-0.48844074280870076\n",
      "-0.2553419326624235\n",
      "-0.19226418377474108\n",
      "-0.48300633493320144\n",
      "-0.2788601912625964\n",
      "-0.5270197162555719\n",
      "-0.45868818920495524\n",
      "-0.7504049087664728\n",
      "-0.7458361166871771\n",
      "-0.7662348204041387\n",
      "-0.7914837910202998\n",
      "-0.6256258664846491\n",
      "-0.5423275074101619\n",
      "-0.7884141363105691\n",
      "-0.5867956824444441\n",
      "-0.9871710592042073\n",
      "-1.0111076826171337\n",
      "-0.7797156201350158\n",
      "-0.6137141497563503\n",
      "-0.6330390228897663\n",
      "-0.514084081185249\n",
      "-0.7033099105166175\n",
      "-0.6687438390962764\n",
      "-0.5754060293503404\n",
      "-0.3702735525263446\n",
      "-0.37968832539624425\n",
      "-0.6536501579260465\n",
      "-0.7671369717526837\n",
      "-0.5986164133259568\n",
      "-0.48193721651108534\n",
      "-0.5037473754544327\n",
      "-0.6997370452999512\n",
      "-0.5757731811625825\n",
      "-0.5684025676449638\n",
      "-0.527002755456958\n",
      "-0.6133586785448254\n",
      "-0.26941217984981874\n",
      "-0.05552275338054857\n",
      "-0.25789626520342435\n",
      "-0.34543168230938526\n",
      "-0.14974064860723532\n",
      "-0.18318658371925145\n",
      "-0.3648257685265327\n",
      "-0.48821766841949316\n",
      "-0.4361610230949021\n",
      "-0.36424595356438927\n",
      "-0.36208431938165997\n",
      "-0.49361992067921767\n",
      "-0.3940086639397331\n",
      "-0.2876997009623777\n",
      "-0.32424958233403384\n",
      "-0.3138571584850052\n",
      "-0.2996071655958615\n",
      "-0.6880144608066987\n",
      "-0.39462756786436454\n",
      "-0.48314540891392754\n",
      "-0.30878094048708404\n",
      "-0.3702788114396276\n",
      "-0.43520252886685934\n",
      "-0.2532359778654473\n",
      "-0.527349918572921\n",
      "-0.5252988526969337\n",
      "-0.5456145532288349\n",
      "-0.475765701370897\n",
      "-0.39183977134474385\n",
      "-0.2762862600060813\n",
      "-0.21042316792244298\n",
      "-0.42540383200208104\n",
      "-0.37264406043277426\n",
      "-0.45193315815062374\n",
      "-0.16080159888233383\n",
      "-0.15993302477483556\n",
      "-0.5038999667512162\n",
      "-0.43617706629836034\n",
      "-0.17073257708107545\n",
      "-0.5354571482330912\n",
      "-0.48145645230860834\n",
      "-0.35357521095773253\n",
      "-0.6197240359001386\n",
      "-0.43907446118115945\n",
      "-0.6447466129200602\n",
      "-0.5738157603544022\n",
      "-0.6475858887624254\n",
      "-0.5558706555325733\n",
      "-0.48766524773846803\n",
      "-0.47222641050395026\n",
      "-0.7610137291295951\n",
      "-0.7246144259661877\n",
      "-0.5851766923968531\n",
      "-0.6006462085724703\n",
      "-0.5737115326852497\n",
      "-0.5409695156327593\n",
      "-0.6466328009739438\n",
      "-0.5703196545039078\n",
      "-0.5713951332685627\n",
      "-0.37357079436235296\n",
      "-0.21579468641677374\n",
      "-0.2240991594577569\n",
      "-0.252326961028217\n",
      "-0.48731454877866365\n",
      "-0.434569017148467\n",
      "-0.1989921862214461\n",
      "-0.3436009462673015\n",
      "-0.4070294532267413\n",
      "-0.6079528021530964\n",
      "-0.2956418869105494\n",
      "-0.22939902862595504\n",
      "-0.10090186295797798\n",
      "-0.3323748741619213\n",
      "-0.3732499672244788\n",
      "-0.5742177617291752\n",
      "-0.5487694556051853\n",
      "-0.3405231451277757\n",
      "-0.4160296433076784\n",
      "-0.3434313166666897\n",
      "-0.34152110176871603\n",
      "-0.4755818970013343\n",
      "-0.4946667663885108\n",
      "-0.37047597067255233\n",
      "-0.37873712519588804\n",
      "-0.43682167279270834\n",
      "-0.5945317675050926\n",
      "-0.48799422521615954\n",
      "-0.22471793449350722\n",
      "-0.5024025403130371\n",
      "-0.5143673484989739\n",
      "-0.8361929289341011\n",
      "-0.5924268083081131\n",
      "-0.5805888306403819\n",
      "-0.49489737348205254\n",
      "-0.6431164215753093\n",
      "-0.6194534870684165\n",
      "-0.38710368988918614\n",
      "0.01844829416322165\n",
      "-0.20913059096035747\n",
      "-0.3479927933000372\n",
      "-0.5078198621280055\n",
      "-0.7098942636138121\n",
      "-0.3814030333205667\n",
      "-0.22716338557987958\n",
      "-0.6867457677944884\n",
      "-0.6306277594429305\n",
      "-0.6017960787922236\n",
      "-0.5697390592510495\n",
      "-0.4321137427856627\n",
      "-0.6621658182520311\n",
      "-0.7205294370021048\n",
      "-0.5655332855229199\n",
      "-0.7279252139761226\n",
      "-0.6203813878134792\n",
      "-0.4669975448845042\n",
      "-0.4708614840586282\n",
      "-0.3215549008166298\n",
      "-0.4089632937817807\n",
      "-0.5291773055936575\n",
      "-0.9694670271344273\n",
      "-0.7937692175827277\n",
      "-0.702938356716707\n",
      "-0.5612390316957583\n",
      "-0.3668699131440275\n",
      "-0.6589128387606145\n",
      "-0.8186814403207917\n",
      "-0.8536796911712041\n",
      "-1.0558506917972017\n",
      "-0.784472144905017\n",
      "-0.5591588355267908\n",
      "-0.569356238643162\n",
      "-0.6799291604375017\n",
      "-1.0576193331275665\n",
      "-0.8038749546749405\n",
      "-0.670086131568695\n",
      "-0.8844212285911832\n",
      "-0.7563357270559721\n",
      "-0.6558101747645185\n",
      "-0.8756511551960994\n",
      "-0.6718252904884182\n",
      "-0.9900298078094236\n",
      "-0.9325748020838265\n",
      "-0.8148047171577979\n",
      "-0.5023787990277211\n",
      "-0.613089946518199\n",
      "-0.9617022380155282\n",
      "-0.9167225552393963\n",
      "-0.846716438879688\n",
      "-0.8606866132034132\n",
      "-1.0968894533462852\n",
      "-0.8888804079739293\n",
      "-0.9782730903675387\n",
      "-1.1290648863345596\n",
      "-0.9323492923317295\n",
      "-0.9791091030601161\n",
      "-0.8541620602305113\n",
      "-0.7033327663313678\n",
      "-1.0539127235199242\n",
      "-0.6158589019601421\n",
      "-0.765499721957424\n",
      "-0.8372399291726704\n",
      "-0.8880411836876904\n",
      "-0.9215668049023348\n",
      "-0.9326484022043515\n",
      "-1.1034876315371602\n",
      "-0.6412855358110393\n",
      "-0.7285051479379175\n",
      "-1.1532228917086225\n",
      "-0.9760808315332345\n",
      "-0.9684393626006987\n",
      "-0.7359968279259628\n",
      "-0.9845259709659929\n",
      "-1.0115076709649828\n",
      "-1.0042372183342227\n",
      "-1.0333768174327158\n",
      "-0.9281381934579911\n",
      "-0.9858415361360288\n",
      "-1.194672761387495\n",
      "-0.914285396776723\n",
      "-0.8410911986968127\n",
      "-0.6980351634388421\n",
      "-0.9954667522988837\n",
      "-0.5843925191379761\n",
      "-0.8975132584328546\n",
      "-0.9857003418010368\n",
      "-1.020208424888617\n",
      "-1.1951998192409368\n",
      "-1.0470857246729088\n",
      "-1.0472145122038807\n",
      "-1.1109705833607881\n",
      "-1.1507167497484387\n",
      "-1.1276515704703678\n",
      "-1.0607098423858488\n",
      "-1.1183153741755651\n",
      "-1.2521413677062239\n",
      "-1.1016845594316045\n",
      "-0.8158891434936401\n",
      "-0.7774607156500695\n",
      "-0.7722421987062504\n",
      "-0.8645197426742693\n",
      "-0.9217615904650636\n",
      "-0.994880272619593\n",
      "-1.0275968029540423\n",
      "-1.056110222070497\n",
      "-1.0024973811385731\n",
      "-0.9213076678358496\n",
      "-0.6200924394173982\n",
      "-1.178034795067458\n",
      "-0.9144455478064445\n",
      "-0.916871545758759\n",
      "-0.7661279352864179\n",
      "-1.1495960595696761\n",
      "-1.1093858081116856\n",
      "-0.8884897893381024\n",
      "-1.0880495801743213\n",
      "-1.1025704523633724\n",
      "-0.9883614372066786\n",
      "-1.0335137011649744\n",
      "-1.0389362683880503\n",
      "-0.9894304364920355\n",
      "-0.9839819820628579\n",
      "-0.640216311986982\n",
      "-0.8748451046165348\n",
      "-1.0172802773129601\n",
      "-0.7181756325129232\n",
      "-0.6359813412063379\n",
      "-0.646633824077196\n",
      "-0.8494367874314086\n",
      "-0.8742999064184412\n",
      "-0.8677449965775311\n",
      "-1.058745286560513\n",
      "-0.9445731799342055\n",
      "-0.9652704531975626\n",
      "-0.9438737789981352\n",
      "-0.8651997975193276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.8067904821251162\n",
      "-0.9159645333563154\n",
      "-0.7899521374837549\n",
      "-0.4627899348967616\n",
      "-0.6250811011552315\n",
      "-0.8229862984019044\n",
      "-0.8761837698738013\n",
      "-0.9807453794497399\n",
      "-0.8614185891405038\n",
      "-0.8533700928111122\n",
      "-0.8510510189456525\n",
      "-0.9068695585950969\n",
      "-1.024207120417628\n",
      "-0.9512438560978407\n",
      "-1.019468583465866\n",
      "-1.0484821096144525\n",
      "-0.9631051898337086\n",
      "-0.9394306851196407\n",
      "-1.0050524655602655\n",
      "-1.0330140439259485\n",
      "-0.9481504343175094\n",
      "-1.0399352923844047\n",
      "-1.0330628725466724\n",
      "-1.1008702708507196\n",
      "-0.8073635279167675\n",
      "-0.8760802514099931\n",
      "-1.2050246375863671\n",
      "-1.3050700773164914\n",
      "-1.3858393576119874\n",
      "-1.3641557594989124\n",
      "-1.4532152311162803\n",
      "-1.5022497541397797\n",
      "-1.143693789796561\n",
      "-1.3787899559370895\n",
      "-1.430838345033316\n",
      "-1.5574070902054828\n",
      "-1.65180800236664\n",
      "-1.577614898196151\n",
      "-1.3334026257011518\n",
      "-1.3565754902757519\n",
      "-1.658883704133364\n",
      "-1.7931686621830547\n",
      "-1.755521597892221\n",
      "-1.626135990718131\n",
      "-1.5646058332158284\n",
      "-1.1681706626682542\n",
      "-1.1300368529595801\n",
      "-1.1308741398697941\n",
      "-1.4432640449835759\n",
      "-1.2581331167259517\n",
      "-1.434288993915753\n",
      "-1.5940058196395552\n",
      "-1.6668028416336906\n",
      "-1.6753086469377427\n",
      "-1.3408566723462096\n",
      "-1.6831952901404863\n",
      "-1.392664276992255\n",
      "-1.6804392416899065\n",
      "-1.6769522987189713\n",
      "-1.6367418738407866\n",
      "-1.441745139393387\n",
      "-1.587070931729758\n",
      "-1.629548136592724\n",
      "-1.5894697006250376\n",
      "-1.6436933719692477\n",
      "-1.3971431574952107\n",
      "-1.547601962826378\n",
      "-1.702130304352081\n",
      "-1.673718906039749\n",
      "-1.5355760308835424\n",
      "-1.8622417596803054\n",
      "-1.8854026851443844\n",
      "-1.8869225008421575\n",
      "-1.9100589180615435\n",
      "-1.9890373495235498\n",
      "-1.8766007863161005\n",
      "-1.693890565045403\n",
      "-1.7527776766062513\n",
      "-1.70327285755307\n",
      "-1.7126036737573052\n",
      "-1.7334481279205005\n",
      "-1.4265272091757275\n",
      "-1.677352594661624\n",
      "-1.767008607429558\n",
      "-1.6987619940297347\n",
      "-1.74643596168717\n",
      "-1.9518991600245261\n",
      "-1.8068414328937679\n",
      "-1.8259896064334655\n",
      "-1.41762034491696\n",
      "-1.6183698561560562\n",
      "-1.8323087896269743\n",
      "-1.846601659673835\n",
      "-1.911170564208801\n",
      "-1.8913459195191027\n",
      "-1.8495854998868733\n",
      "-1.5984474239770206\n",
      "-1.5154678470674758\n",
      "-0.006398293228206147\n",
      "-0.43080393853746485\n",
      "-0.2224886589942226\n",
      "-0.01635657811254028\n",
      "0.16270061445845346\n",
      "-0.0028841248842140094\n",
      "-0.2599095247979629\n",
      "-0.058129056901940396\n",
      "0.21911947576529\n",
      "0.09548758063665286\n",
      "0.2364697347672923\n",
      "0.3540608568010922\n",
      "0.13853099105309813\n",
      "0.3161951115814251\n",
      "0.1475833201526034\n",
      "0.27639187473674487\n",
      "0.20142576013163066\n",
      "-0.10655261592089693\n",
      "-0.0863897119528815\n",
      "-0.2841053994029637\n",
      "-0.45762896129796443\n",
      "-0.030459196572452663\n",
      "0.04338050153338538\n",
      "0.23782127149381355\n",
      "-0.0982673204211328\n",
      "0.06743871905792286\n",
      "-0.12063209534073382\n",
      "-0.26196204118385724\n",
      "-0.029799987599747335\n",
      "-0.41322639791338195\n",
      "-0.17606871379228511\n",
      "-0.26073795253505744\n",
      "-0.17263865897230662\n",
      "-0.5264951402039386\n",
      "-0.12843646903069247\n",
      "0.010066646631838642\n",
      "-0.11263073582523127\n",
      "-0.029632122568546717\n",
      "0.15020089795381106\n",
      "0.26929531846095\n",
      "-0.06834983072917404\n",
      "0.00830944037508265\n",
      "-0.051055252589208\n",
      "-0.02970162460337528\n",
      "-0.11525213621602803\n",
      "0.06427129964813741\n",
      "-0.007857215007671736\n",
      "-0.18458630037433227\n",
      "-0.026516551191869856\n",
      "-0.247557605231289\n",
      "-0.2992838537590772\n",
      "-0.43683159582905035\n",
      "-0.31223154581885837\n",
      "-0.4000283982165466\n",
      "-0.028094491724467693\n",
      "-0.3574588319161131\n",
      "-0.15641899183675478\n",
      "-0.23095851574446963\n",
      "-0.6964353966506376\n",
      "-0.6575162993404133\n",
      "-0.23776514164594764\n",
      "-0.27402419696324715\n",
      "-0.5619525279906361\n",
      "-0.5087918991123158\n",
      "-0.3862933808262715\n",
      "-0.5804405419490627\n",
      "-0.4394804974283856\n",
      "-0.6000980362535525\n",
      "-0.5309666546599324\n",
      "-0.6014488325198415\n",
      "-0.42163494273282676\n",
      "-0.22296039348732002\n",
      "-0.3571574031398939\n",
      "-0.13680552924600714\n",
      "-0.0557823239752934\n",
      "-0.34402560380244135\n",
      "-0.41143714848960866\n",
      "-0.35923210318006077\n",
      "-0.3676010278994329\n",
      "-0.3065048238798246\n",
      "-0.21403737131791015\n",
      "-0.19964606491818598\n",
      "-0.09144566617621178\n",
      "-0.1171682449705029\n",
      "-0.3104147777897431\n",
      "-0.30220187942970334\n",
      "-0.41532929547264874\n",
      "-0.4740029434895612\n",
      "-0.5584892893025709\n",
      "-0.27735604454058466\n",
      "-0.400959305423857\n",
      "-0.4512276125193443\n",
      "-0.41508091374674116\n",
      "-0.18378182346222985\n",
      "-0.3057428226375438\n",
      "-0.290561130438164\n",
      "-0.44997821606774757\n",
      "-0.5482096384532281\n",
      "-0.1752714235105565\n",
      "-0.13040368461464974\n",
      "-0.2592510015928333\n",
      "-0.35343899089733977\n",
      "-0.473400892903676\n",
      "-0.4021960616354753\n",
      "-0.3644001775170322\n",
      "-0.7575490172778767\n",
      "-0.31688481787950035\n",
      "-0.4943625047329929\n",
      "-0.4471896182001032\n",
      "-0.24348153693060992\n",
      "-0.39248199897487684\n",
      "-0.4212088867071829\n",
      "-0.3790248374709377\n",
      "-0.5303706173228449\n",
      "-0.32137850811920915\n",
      "-0.5991209331592655\n",
      "-0.5832577078891718\n",
      "-0.5031723436623523\n",
      "-0.5257748069047288\n",
      "-0.4298892690080174\n",
      "-0.5452930611133721\n",
      "-0.7443305356612114\n",
      "-0.4506135226370965\n",
      "-0.377306452177759\n",
      "-0.6616665018167166\n",
      "-0.29330518534982175\n",
      "-0.4289705838640048\n",
      "-0.5602494690474339\n",
      "-0.735812457662536\n",
      "-0.47342384685228617\n",
      "-0.7282867919036082\n",
      "-0.6770186186484688\n",
      "-0.563233739271204\n",
      "-0.5031536724162156\n",
      "-0.8304116672979421\n",
      "-0.692155679832892\n",
      "-0.6126302957986695\n",
      "-0.7706430575977468\n",
      "-0.9882315703695675\n",
      "-0.7475127143047336\n",
      "-0.7434248767082093\n",
      "-0.4666325940860081\n",
      "-0.7946914155233644\n",
      "-0.427363777010286\n",
      "-0.32312019114078316\n",
      "-0.7093008047858634\n",
      "-0.5668494706082\n",
      "-0.3519172135090888\n",
      "-0.503148288312625\n",
      "-0.4266268698501035\n",
      "-0.5272009260298454\n",
      "-0.43464263894813787\n",
      "-0.7246974379118056\n",
      "-0.8435397688246837\n",
      "-0.38762596948973954\n",
      "-0.5003293925865818\n",
      "-0.6370330174884105\n",
      "-0.4950023331697739\n",
      "-0.46712245774909444\n",
      "-0.2246232592170068\n",
      "-0.4401943163915889\n",
      "-0.49622814226351625\n",
      "-0.46070947334223705\n",
      "-0.33639109923711374\n",
      "-0.5613936289482788\n",
      "-0.5081311840040958\n",
      "-0.43523414262095106\n",
      "-0.40104682753608945\n",
      "-0.34114636607584103\n",
      "-0.19954744348607803\n",
      "-0.36324002049665693\n",
      "-0.25858994655026424\n",
      "-0.530155077022614\n",
      "-0.8011814384388503\n",
      "-0.5707556403008011\n",
      "-0.45759579528875455\n",
      "-0.44925870082755753\n",
      "-0.7765807277737641\n",
      "-0.6835309330141175\n",
      "-0.5894234192779393\n",
      "-0.6390698397332912\n",
      "-0.6291363130426134\n",
      "-0.6259582104796146\n",
      "-0.6400824091326811\n",
      "-0.5311617799094166\n",
      "-0.826613890342442\n",
      "-0.9897251575397821\n",
      "-0.676319173892589\n",
      "-0.5108689289944573\n",
      "-0.8957569061051915\n",
      "-0.7108622759482577\n",
      "-0.4238463820151853\n",
      "-0.4663764618759216\n",
      "-0.8393561304427144\n",
      "-1.1327329694733093\n",
      "-0.6921835695258116\n",
      "-0.6273053478308442\n",
      "-0.8782504169843546\n",
      "-0.8548486538172619\n",
      "-0.7538818626099733\n",
      "-0.5312096084509603\n",
      "-0.45704922725584185\n",
      "-0.5208826326133426\n",
      "-0.27078913758433165\n",
      "-0.7650846588617726\n",
      "-0.6135332881141778\n",
      "-0.38788393942201993\n",
      "-0.7227154469494427\n",
      "-0.5735402758727695\n",
      "-0.7302158928600309\n",
      "-0.6043829760674876\n",
      "-0.7149566761534323\n",
      "-0.41598678009812834\n",
      "-0.19836406275689117\n",
      "-0.5268777986504132\n",
      "-0.5564845547193156\n",
      "-0.5456889411200162\n",
      "-0.6826536123559319\n",
      "-0.6901782594108861\n",
      "-0.2804967360865891\n",
      "-0.3068439849013176\n",
      "-0.5555045990478429\n",
      "-0.590239932584319\n",
      "-0.5670900635192789\n",
      "-0.3508053682554906\n",
      "-0.4463015109769085\n",
      "-0.40384206203329065\n",
      "-0.6014345895373957\n",
      "-0.3292954353613463\n",
      "-0.1594371187375012\n",
      "-0.34687875533354035\n",
      "-0.2142754083424419\n",
      "-0.2217522110714137\n",
      "-0.3405823933269434\n",
      "-0.2241862809121293\n",
      "-0.025263886087138122\n",
      "-0.26738198471485053\n",
      "-0.06775417908825168\n",
      "-0.35956054518767766\n",
      "-0.31608607548241285\n",
      "-0.3730671539156381\n",
      "-0.349270357751756\n",
      "-0.5331777765858815\n",
      "-0.09522133414289914\n",
      "-0.5446875518816288\n",
      "-0.5876377686505271\n",
      "-0.2866428996197372\n",
      "-0.21892200360146297\n",
      "0.008052848020899915\n",
      "-0.24108552684819629\n",
      "-0.06483087786473796\n",
      "-0.1199490974239971\n",
      "-0.3508491852180651\n",
      "-0.5785214978136092\n",
      "-0.24902588889428343\n",
      "-0.1545123242285963\n",
      "-0.05482153734042903\n",
      "-0.2904562732453487\n",
      "-0.09110002333354902\n",
      "-0.5749830692678441\n",
      "-0.19067646594888024\n",
      "0.003660543336602276\n",
      "-0.1015604089020512\n",
      "-0.11932589975126676\n",
      "-0.15619887333886792\n",
      "-0.18201284394747597\n",
      "-0.24152290201939358\n",
      "-0.29174474974393644\n",
      "-0.07957053550951791\n",
      "-0.25967135986255935\n",
      "-0.11136728513658192\n",
      "-0.3166615895036699\n",
      "-0.42687847100890336\n",
      "-0.6449348970264397\n",
      "-0.1607814037878954\n",
      "-0.12183285756602248\n",
      "-0.18142288968442394\n",
      "-0.4065317767852442\n",
      "-0.23981221428015032\n",
      "-0.4580782641933924\n",
      "-0.5973500140660307\n",
      "-0.7619315788943858\n",
      "-0.6137590036606438\n",
      "-0.5764985552032035\n",
      "-0.5296034493654744\n",
      "-0.5926696140248163\n",
      "-0.7184643358200552\n",
      "-0.6246011782701655\n",
      "-0.6104190613932334\n",
      "-0.29333291897348\n",
      "-0.6223380219171286\n",
      "-0.578519943257834\n",
      "-0.7112551733447915\n",
      "-0.524298474770514\n",
      "-0.5616218563524535\n",
      "-0.643185220967546\n",
      "-0.4830634057074063\n",
      "-0.6677034109484397\n",
      "-0.5859089089259247\n",
      "-0.3876351378640328\n",
      "-0.4416318533986315\n",
      "-0.46148737062389455\n",
      "-0.973289980673098\n",
      "-0.6557442510538776\n",
      "-0.44955544527744606\n",
      "-0.4775350515500187\n",
      "-0.6327723590524342\n",
      "-0.7693405199043575\n",
      "-1.002114549058126\n",
      "-0.7631745796096284\n",
      "-0.5353165612744157\n",
      "-0.5230742759374836\n",
      "-0.36107999710308114\n",
      "-0.2080263288775703\n",
      "-0.5147429305787206\n",
      "-0.2746449171205069\n",
      "-0.48038663118835656\n",
      "-0.7572377498818988\n",
      "-0.3167390563969154\n",
      "-0.33810499537566546\n",
      "-0.6158760788455192\n",
      "-0.1903713512147687\n",
      "-0.24010170587392354\n",
      "-0.4973876767801394\n",
      "-0.5084534336025366\n",
      "-0.19472469590643202\n",
      "-0.4386436571340813\n",
      "-0.5084842834911462\n",
      "-0.31995471661692676\n",
      "-0.4391158064426547\n",
      "-0.4746884812247772\n",
      "-0.5453857184941645\n",
      "-0.6542367245051341\n",
      "-0.3347300483377786\n",
      "-0.22375753300359494\n",
      "-0.5143764811313545\n",
      "-0.33661890610388673\n",
      "-0.619373062100457\n",
      "-0.5643775029086167\n",
      "-0.4880537383977651\n",
      "-0.40971635971158044\n",
      "-0.2994235029328635\n",
      "-0.41714263162016857\n",
      "-0.6719872633172274\n",
      "-0.5835032437089523\n",
      "-0.6078652480060696\n",
      "-0.2144026212336211\n",
      "-0.401630586085132\n",
      "-0.5636652568402457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.21945801529969355\n",
      "-0.6260560744413617\n",
      "-0.19176286633302514\n",
      "-0.2402089999383183\n",
      "-0.7097674688650242\n",
      "-0.5546832892992526\n",
      "-0.6820680442784085\n",
      "-0.3150687556591852\n",
      "-0.37337443826564504\n",
      "-0.43130568590484747\n",
      "-0.5351866577344848\n",
      "-0.37022755992978507\n",
      "-0.4267657860589239\n",
      "-0.47339322105768783\n",
      "-0.5718477849478503\n",
      "-0.5978234555270243\n",
      "-0.5675943452594666\n",
      "-0.5510632367772292\n",
      "-0.5597774879808879\n",
      "-0.6505523774234614\n",
      "-0.6347226998568731\n",
      "-0.8089891924002798\n",
      "-0.6652269615594367\n",
      "-0.5599807772013452\n",
      "-0.7818239171828132\n",
      "-0.6460298259478674\n",
      "-0.6205627471362379\n",
      "-0.51763491464582\n",
      "-0.8367253532308829\n",
      "-0.8460433997943227\n",
      "-0.4066660177660169\n",
      "-0.574142394359498\n",
      "-0.3887266682228166\n",
      "-0.5387262282327464\n",
      "-0.3270162510862205\n",
      "-0.36316452744269184\n",
      "-0.6296024974321436\n",
      "-0.5813382891065977\n",
      "-0.6157482511493958\n",
      "-0.39221657527033377\n",
      "-0.34050347692194904\n",
      "-0.5648486890226204\n",
      "-0.5191043482025692\n",
      "-0.7278144498124922\n",
      "-0.3969043679642854\n",
      "-0.6647568848344386\n",
      "-0.6281947023278187\n",
      "-0.32548846056505315\n",
      "-0.5918140118870048\n",
      "-0.37361692960121673\n",
      "-0.5416267622617817\n",
      "-0.5700626372350711\n",
      "-0.4745725402713803\n",
      "-0.3340683805157302\n",
      "-0.5877901256704239\n",
      "-0.6823169682918928\n",
      "-0.5835535182199809\n",
      "-0.5326389001900996\n",
      "-0.44127271406138624\n",
      "-0.18113790215021877\n",
      "-0.33894963214827867\n",
      "-0.4811923134929081\n",
      "-0.3408599462117765\n",
      "-0.36578098479487037\n",
      "-0.33374015329072354\n",
      "-0.6073450075730228\n",
      "-0.33090393871979146\n",
      "-0.25325956196204435\n",
      "-0.2976946429727499\n",
      "-0.39419876362727924\n",
      "-0.5462615358767978\n",
      "-0.4852902765415232\n",
      "-0.3505939487276465\n",
      "-0.3276579801463079\n",
      "-0.16292282361296898\n",
      "-0.4695006740553927\n",
      "-0.40349714340252074\n",
      "-0.3826677922667089\n",
      "-0.8112383375279969\n",
      "-0.6711146259633395\n",
      "-0.5796492029591673\n",
      "-0.5024568686806784\n",
      "-0.18197391806964663\n",
      "-0.6736147588592922\n",
      "-0.48605875920152075\n",
      "-0.5510021550622813\n",
      "-0.4178225329520281\n",
      "-0.3298202612989647\n",
      "-0.5439557306504811\n",
      "-0.4575757241991958\n",
      "-0.8000934550334388\n",
      "-0.36810841636400893\n",
      "-0.4197350548516605\n",
      "-0.6735710839241877\n",
      "-0.5755724935847419\n",
      "-0.32943217325498664\n",
      "-0.26820180937676424\n",
      "-0.4182487209824569\n",
      "-0.2607543789956783\n",
      "-0.528137037790654\n",
      "-0.7476003377424063\n",
      "-0.20515723095152444\n",
      "-0.41945265635258955\n",
      "-0.4629168580018126\n",
      "-0.39003804942479436\n",
      "-0.6187198790293901\n",
      "-0.37743535940275663\n",
      "-0.3172585698616537\n",
      "-0.2861223989203945\n",
      "-0.35451823511403335\n",
      "-0.24644038737566384\n",
      "-0.6017326001755446\n",
      "-0.4742738076381605\n",
      "-0.6013720093187127\n",
      "-0.28195161713891803\n",
      "-0.5846155138664472\n",
      "-0.260788886103992\n",
      "-0.26573766521158376\n",
      "-0.376524136941356\n",
      "-0.7471821096827395\n",
      "-0.6366108755847526\n",
      "-0.8045300752441747\n",
      "-0.832607983983793\n",
      "-0.4503699244223179\n",
      "-0.5856655652213247\n",
      "-0.6274147738323164\n",
      "-0.5234941093051259\n",
      "-0.27347256048472224\n",
      "-0.27994726205254145\n",
      "-0.4663153492988239\n",
      "-0.5611109661673953\n",
      "-0.4440892223762637\n",
      "-0.37802167168274564\n",
      "-0.14546857815551312\n",
      "-0.31587311244838256\n",
      "-0.37127597562531905\n",
      "-0.4038400445949498\n",
      "-0.3956521935926231\n",
      "-0.22733476305471578\n",
      "-0.30118583216311007\n",
      "-0.4257311554247827\n",
      "-0.18665486107059787\n",
      "-0.39609286670589594\n",
      "-0.46961027433715896\n",
      "-0.679110701208162\n",
      "-0.6673740458297365\n",
      "-0.7058339425758329\n",
      "-0.7357498067330438\n",
      "-0.8474369684642293\n",
      "-0.6679684394260712\n",
      "-0.7183981292769812\n",
      "-0.8061814445190664\n",
      "-0.382559429265801\n",
      "-0.462904082934362\n",
      "-0.35025972914606224\n",
      "-0.93569076087797\n",
      "-0.6953059029577175\n",
      "-0.6510156089941999\n",
      "-0.4863826753591874\n",
      "-0.6260162259791842\n",
      "-0.788543275844202\n",
      "-0.2784402946084238\n",
      "-0.36574679277878896\n",
      "-0.2657694230327043\n",
      "-0.5068787779855266\n",
      "-0.4833054129261264\n",
      "-0.45247288656218976\n",
      "-0.7623037480876448\n",
      "-0.5702033739150412\n",
      "-0.5080574788195306\n",
      "-0.4060345393777451\n",
      "-0.39491916947183836\n",
      "-0.2986540231223276\n",
      "-0.683317758946474\n",
      "-0.4255875344158582\n",
      "-0.2931709236897433\n",
      "-0.3438061199012651\n",
      "-0.5890902754951985\n",
      "-0.7625918206751179\n",
      "-0.5928527391657175\n",
      "-0.6653082513896383\n",
      "-0.6291452274525519\n",
      "-0.7560593283633805\n",
      "-0.9265538158046335\n",
      "-0.8409785394968572\n",
      "-0.5561565620178909\n",
      "-0.8581782068502137\n",
      "-0.9253516641968227\n",
      "-0.8915420307357544\n",
      "-0.7170162749009539\n",
      "-0.8861442793512446\n",
      "-0.5850600720100818\n",
      "-0.5393182146353342\n",
      "-0.7672522635065845\n",
      "-0.9603902022023807\n",
      "-1.0825148612491884\n",
      "-0.717094432869449\n",
      "-0.6339331022892258\n",
      "-0.8150689833771931\n",
      "-0.7121421531843282\n",
      "-0.6993115629947988\n",
      "-0.6542069623630975\n",
      "-0.9340077661342447\n",
      "-0.7021642445572474\n",
      "-0.9128721974140289\n",
      "-0.9799739746238759\n",
      "-0.781538605054839\n",
      "-0.8112346789915453\n",
      "-0.8191755159235674\n",
      "-0.676482387638222\n",
      "-0.7842991027377406\n",
      "-0.7726914371390552\n",
      "-0.99929054942784\n",
      "-0.6191522775176457\n",
      "-0.9665256117073225\n",
      "-1.0038159550962305\n",
      "-0.8599897958373943\n",
      "-1.1079156712101421\n",
      "-1.0468549929393356\n",
      "-1.049554626045826\n",
      "-0.7550941736192142\n",
      "-1.0397376468950934\n",
      "-1.1749633070822676\n",
      "-0.9865271737856708\n",
      "-0.9703562787656742\n",
      "-0.9997739325424807\n",
      "-0.9592706855964546\n",
      "-0.979498322232191\n",
      "-0.9737900310380428\n",
      "-1.1107858724250144\n",
      "-1.1547924045836249\n",
      "-1.239240025027087\n",
      "-1.3744211695778443\n",
      "-1.2653326618340937\n",
      "-1.3279865284297137\n",
      "-1.5584120592914883\n",
      "-1.3697281738629035\n",
      "-1.0384508547512519\n",
      "-1.3062032549113505\n",
      "-1.3782087668008483\n",
      "-1.4634071701644333\n",
      "-1.379020245188761\n",
      "-1.3311692256699044\n",
      "-1.545320366450268\n",
      "-1.1434702658504332\n",
      "-1.0896414578279716\n",
      "-1.1274882019816552\n",
      "-1.073252530512553\n",
      "-0.8094651330545647\n",
      "-1.1250567579847073\n",
      "-0.8544198802290863\n",
      "-1.126833606374839\n",
      "-0.9677910160410121\n",
      "-0.7769633087703642\n",
      "-1.0649456370769952\n",
      "-1.0857403757021782\n",
      "-1.097338175615959\n",
      "-1.027538829859308\n",
      "-0.9619650781621362\n",
      "-0.8169186530365243\n",
      "-0.9749965644118681\n",
      "-1.2781670688437696\n",
      "-1.2789798273609716\n",
      "-0.9144243015545537\n",
      "-0.8989316956896714\n",
      "-1.3133660121295965\n",
      "-0.9496435999467646\n",
      "-1.1200464275355309\n",
      "-1.1699919270742736\n",
      "-1.1094669813178772\n",
      "-1.0580964721287567\n",
      "-1.000458414936653\n",
      "-0.8723193263962215\n",
      "-0.9767092397948895\n",
      "-0.8294289861643684\n",
      "-1.0924889034107215\n",
      "-1.1178192339930564\n",
      "-0.786928689730572\n",
      "-0.9266436536121592\n",
      "-1.1646599436137872\n",
      "-1.2656743170823799\n",
      "-0.9966161392764209\n",
      "-1.0566168275358625\n",
      "-1.0761674366363232\n",
      "-1.2328009656260501\n",
      "-1.1141698776438076\n",
      "-1.1562356660225748\n",
      "-1.1510721825554873\n",
      "-1.2047829485543595\n",
      "-1.1446557928600005\n",
      "-1.2661682130907244\n",
      "-1.4763843103416656\n",
      "-1.2362829604445307\n",
      "-0.9630779823968102\n",
      "-1.2335381358145585\n",
      "-1.1931593270122203\n",
      "-0.9448224203831826\n",
      "-1.249834891754166\n",
      "-1.006529896607201\n",
      "-1.3439258240688317\n",
      "-1.1140543603555348\n",
      "-1.3141742928640756\n",
      "-1.4161957317152132\n",
      "-1.2783545855903924\n",
      "-1.3058022861833491\n",
      "-1.318225881714622\n",
      "-1.3750867971289902\n",
      "-1.1887728581677943\n",
      "-1.1908249403600262\n",
      "-1.3453210012382366\n",
      "-1.2967483552275396\n",
      "-1.3568789386787257\n",
      "-1.2539126671962026\n",
      "-1.2786356409042374\n",
      "-1.4953198507665653\n",
      "-1.2969779007190503\n",
      "-1.3779651926958267\n",
      "-1.3529105781319564\n",
      "-1.2966340372594445\n",
      "-1.3245226020217171\n",
      "-1.2656603826342527\n",
      "-1.5149681142889109\n",
      "-1.3583041868524526\n",
      "-1.362558215085914\n",
      "-1.5129357837795796\n",
      "-1.4751933197500808\n",
      "-1.1655813997562239\n",
      "-1.5062157328357708\n",
      "-1.5109966432539346\n",
      "-1.5432510602908887\n",
      "-1.5752680959295893\n",
      "-1.65459883747632\n",
      "-1.8382827134778326\n",
      "-1.6591112644985333\n",
      "-1.5825765192649757\n",
      "-1.5463288310900392\n",
      "-1.7226749850642162\n",
      "-1.4763259842484295\n",
      "-1.5913723166345832\n",
      "-1.5613149408348035\n",
      "-1.2033379753343019\n",
      "-1.4295249707084272\n",
      "-1.1173495540528966\n",
      "-1.3083291377292758\n",
      "-1.336866087040874\n",
      "-1.509533057677227\n",
      "-1.5009229084813775\n",
      "-1.6304576089615381\n",
      "-1.72306760151183\n",
      "-1.73760780391258\n",
      "-1.6523008630682414\n",
      "-1.6368583627704103\n",
      "-1.6739972576210043\n",
      "-1.5619430129837892\n",
      "-1.5313550750394054\n",
      "-1.285101027810653\n",
      "-1.596139226390033\n",
      "-1.381230137702044\n",
      "-1.6532280016613075\n",
      "-1.889844560591406\n",
      "-1.6238900863569876\n",
      "-1.709758287543231\n",
      "-1.4873236196333233\n",
      "-1.8126341907509294\n",
      "-1.9057788867233907\n",
      "-1.6871252861645054\n",
      "-1.920181751519296\n",
      "-1.8681763299636431\n",
      "-1.6411125711094634\n",
      "-1.832329260631481\n",
      "-1.9813800839268234\n",
      "-1.9092307707090916\n",
      "-1.9292625051230046\n",
      "-1.9482581804130592\n",
      "-1.7022724050527331\n",
      "-2.07491750838481\n",
      "-2.0553891894997496\n",
      "0.005388261081139227\n",
      "0.21586258584672127\n",
      "0.13955081679707437\n",
      "-0.03129038960606052\n",
      "-0.10800666470497973\n",
      "0.20298402258472548\n",
      "-0.030121671665468037\n",
      "-0.038351544188266556\n",
      "-0.21935281768601128\n",
      "0.3315564927972292\n",
      "0.2827208783468288\n",
      "0.25042614637993305\n",
      "0.16074829442678493\n",
      "0.23740795911397466\n",
      "0.2705463889150738\n",
      "0.30297980421577103\n",
      "0.056748647572618736\n",
      "0.4116385516284555\n",
      "0.09826665984763512\n",
      "0.06100042128882553\n",
      "0.22317436836793453\n",
      "-0.03332982617819315\n",
      "-0.15979555539748885\n",
      "0.19848951623384087\n",
      "0.11684655959883919\n",
      "0.19301213786307062\n",
      "0.17054544877468583\n",
      "0.23308355819550583\n",
      "-0.08070544258854795\n",
      "-0.009069330685686494\n",
      "0.3064137762188832\n",
      "0.22538270977887473\n",
      "0.082757925561468\n",
      "0.10909015547666831\n",
      "-0.0175836628134749\n",
      "-0.16912419106451948\n",
      "0.0380849610060306\n",
      "-0.07348853662582472\n",
      "-0.14554290023056343\n",
      "-0.34054180997602135\n",
      "-0.25992815714096035\n",
      "-0.15830643861795682\n",
      "0.006858191686043021\n",
      "-0.21816077452178406\n",
      "-0.09828405109366369\n",
      "-0.0802841658505137\n",
      "-0.09796819516871429\n",
      "-0.38552390177401297\n",
      "-0.02215216899024111\n",
      "0.020574329596686855\n",
      "-0.010277550844620578\n",
      "-0.05812858812961802\n",
      "-0.2667284284045629\n",
      "-0.04252012528766655\n",
      "-0.10775153813997679\n",
      "-0.27157951320029466\n",
      "-0.07410133186853723\n",
      "-0.23600241161564972\n",
      "-0.2642584634521493\n",
      "-0.2600961189563627\n",
      "-0.16610673058726794\n",
      "0.06047947750371128\n",
      "-0.10262890633796631\n",
      "-0.2873957453844174\n",
      "-0.1912435113781485\n",
      "-0.27640227551060337\n",
      "0.015882306532369203\n",
      "-0.06716247180644266\n",
      "-0.37829452344605624\n",
      "-0.5751999443329936\n",
      "-0.291083145034623\n",
      "-0.3399175771169827\n",
      "-0.15289200472415318\n",
      "-0.012892467518058406\n",
      "-0.3175060295200018\n",
      "-0.34848219109889483\n",
      "-0.10155495172762778\n",
      "-0.32558554478914664\n",
      "-0.5297397869799468\n",
      "-0.5520941197225105\n",
      "-0.7041133721544346\n",
      "-0.5098389073940798\n",
      "-0.4945521448157297\n",
      "-0.5633877818160844\n",
      "-0.3941311064414459\n",
      "-0.4886512258995999\n",
      "-0.3993263415056493\n",
      "-0.667634414549052\n",
      "-0.4187596605290959\n",
      "-0.5177870425399799\n",
      "-0.3963621662397016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.567785853034062\n",
      "-0.6952141619172599\n",
      "-0.4887989500243487\n",
      "-0.6818156386213858\n",
      "-0.6128568015067619\n",
      "-0.5016791887304016\n",
      "-0.37529656287419505\n",
      "-0.4853690520540842\n",
      "-0.297223598635716\n",
      "-0.4593255272660459\n",
      "-0.5887763859278266\n",
      "-0.3398327034036372\n",
      "-0.48232849374091935\n",
      "-0.41806001015174793\n",
      "-0.5359124318351535\n",
      "-0.5958611932578156\n",
      "-0.3105892008308659\n",
      "-0.6083582558088126\n",
      "-0.7613604826546468\n",
      "-0.7499485702445494\n",
      "-0.5891891772044952\n",
      "-0.7518505114202136\n",
      "-0.6380103479250003\n",
      "-0.6304890960820976\n",
      "-0.4335450990637225\n",
      "-0.4949782417329153\n",
      "-0.832649811605861\n",
      "-0.9837413108359031\n",
      "-0.9496899241587516\n",
      "-0.508959454894681\n",
      "-0.6068440317185334\n",
      "-0.6231182122955329\n",
      "-0.7372313653985718\n",
      "-0.6641819903676335\n",
      "-0.4236187720533061\n",
      "-0.633750822816169\n",
      "-0.7760594680566201\n",
      "-0.7697256605901567\n",
      "-0.8253672517321715\n",
      "-0.7483136139830979\n",
      "-0.5860146053908767\n",
      "-0.5885614360570657\n",
      "-0.6366851660160181\n",
      "-0.6531408436517028\n",
      "-0.7740178489034371\n",
      "-0.8996194296600735\n",
      "-0.7572419826077451\n",
      "-0.8088619484782761\n",
      "-0.5726866872712725\n",
      "-0.7649112098267047\n",
      "-0.6866225678929362\n",
      "-0.5421534478508281\n",
      "-0.575889864778802\n",
      "-0.9436342127887265\n",
      "-0.5594985774653886\n",
      "-0.6561510981042946\n",
      "-0.8597009660597461\n",
      "-0.8906970073902075\n",
      "-0.888551629104656\n",
      "-0.7906733528990009\n",
      "-0.5875314964071322\n",
      "-0.8617961552182296\n",
      "-0.8566979752051109\n",
      "-0.8696710199859057\n",
      "-0.6321908165533365\n",
      "-0.8069786918617095\n",
      "-0.9388721514396037\n",
      "-0.8349449831694159\n",
      "-0.749575706948782\n",
      "-0.7673987511154601\n",
      "-0.8046297838069085\n",
      "-0.9148723984060769\n",
      "-0.695426295766904\n",
      "-0.85182761245745\n",
      "-0.8598383478003407\n",
      "-0.7350488160772362\n",
      "-0.7668211835869971\n",
      "-0.9305656610524837\n",
      "-0.7887361662267169\n",
      "-0.9466579049305737\n",
      "-1.1040425681169748\n",
      "-1.0814977860981128\n",
      "-0.9292342069656104\n",
      "-1.0399603432834568\n",
      "-1.2313727540117898\n",
      "-0.9425722319644289\n",
      "-1.1165256163565938\n",
      "-1.0063154557248999\n",
      "-1.0883191013040214\n",
      "-1.06239510081042\n",
      "-1.1007097204864456\n",
      "-1.0100956662464524\n",
      "-0.8193712043980859\n",
      "-0.912312147803673\n",
      "-0.7108504867637372\n",
      "-0.9391145430161638\n",
      "-1.0398558866311498\n",
      "-0.8669360972316495\n",
      "-1.0651982844585064\n",
      "-1.0002178971309639\n",
      "-0.8741704176101015\n",
      "-0.740881072286852\n",
      "-0.6785527738977722\n",
      "-0.7046638428334981\n",
      "-0.71858902878698\n",
      "-0.712130841905265\n",
      "-0.6863949081534867\n",
      "-0.7125107349326883\n",
      "-0.5659126925114466\n",
      "-0.6861723758103315\n",
      "-0.5265860603009541\n",
      "-0.5298860447120041\n",
      "-0.740924615956916\n",
      "-0.7165104073972863\n",
      "-0.7158414710739265\n",
      "-0.5729875191498561\n",
      "-0.7457782693953621\n",
      "-0.5996015172814526\n",
      "-0.6041300606486496\n",
      "-0.572988673821892\n",
      "-0.6818105288635189\n",
      "-0.6398852349421167\n",
      "-0.7622591368458886\n",
      "-0.678309898964835\n",
      "-0.5455919566798034\n",
      "-0.5983176477582121\n",
      "-0.716011500009018\n",
      "-1.1018492548867742\n",
      "-0.607029988942436\n",
      "-0.6299897888996997\n",
      "-0.8647131127793733\n",
      "-0.776659482366351\n",
      "-0.8543720894911392\n",
      "-0.9392460649325092\n",
      "-1.1319258012145783\n",
      "-1.270782387371055\n",
      "-1.0415793093762957\n",
      "-1.027475782395093\n",
      "-0.8927881968156871\n",
      "-0.824116138272382\n",
      "-0.9355395370719222\n",
      "-0.9700335436812937\n",
      "-0.9589301971276163\n",
      "-1.0731739873307347\n",
      "-0.7990738218988566\n",
      "-0.7835434077164435\n",
      "-0.9181550141368302\n",
      "-0.8006715306299967\n",
      "-0.8089213019277748\n",
      "-0.6294799066674723\n",
      "-0.7765234033948902\n",
      "-0.6589188099941319\n",
      "-0.8187680063735948\n",
      "-1.208278121346523\n",
      "-0.9361629614818435\n",
      "-0.8594186399777987\n",
      "-0.816316709564482\n",
      "-0.9632908250665233\n",
      "-1.1598302706827748\n",
      "-1.125333141580967\n",
      "-1.217809942797764\n",
      "-0.7496552987755606\n",
      "-0.9143356196826188\n",
      "-0.9781045578927349\n",
      "-1.0195698699125972\n",
      "-0.7608131143647883\n",
      "-0.7307493775587529\n",
      "-0.9090311202585508\n",
      "-0.8762242985860348\n",
      "-0.6804098590308323\n",
      "-0.929509826803234\n",
      "-1.0230807297534665\n",
      "-0.9091627020932121\n",
      "-0.9088658353097636\n",
      "-0.6773320336463363\n",
      "-0.7948098474938271\n",
      "-0.5823357314973344\n",
      "-0.7905098957895191\n",
      "-0.7777409889730923\n",
      "-0.43970246817911174\n",
      "-0.3630337401838779\n",
      "-0.7787747379231347\n",
      "-0.6915629904416726\n",
      "-0.6854197562273608\n",
      "-0.5723809081900766\n",
      "-0.7470303136411771\n",
      "-0.7258185391906341\n",
      "-0.6869194559943517\n",
      "-0.7318693726934924\n",
      "-0.33559149829612905\n",
      "-0.32783699739498096\n",
      "-0.6471515308381367\n",
      "-0.8702152746889595\n",
      "-0.5574254228727304\n",
      "-0.745149216659712\n",
      "-0.5265306123827092\n",
      "-0.7758203726787645\n",
      "-0.78879574959706\n",
      "-0.8929767165292695\n",
      "-0.6663331858929195\n",
      "-0.5604719648441541\n",
      "-0.627957790938505\n",
      "-0.39315564778451184\n",
      "-0.6532541307878424\n",
      "-0.42932963788509837\n",
      "-0.5188173017536251\n",
      "-0.8903728188020413\n",
      "-0.5184837071392698\n",
      "-0.7297077875095832\n",
      "-0.7154365335599393\n",
      "-0.8781148359184074\n",
      "-0.7178542977990559\n",
      "-0.9554116725346561\n",
      "-0.6900852838428364\n",
      "-0.45611450567246964\n",
      "-0.785128159923044\n",
      "-1.022961821074918\n",
      "-1.0635476351075455\n",
      "-0.8369430729929674\n",
      "-0.9799383677064618\n",
      "-0.7283554228347449\n",
      "-0.4951520569886211\n",
      "-0.7377883480825688\n",
      "-0.8251815042854226\n",
      "-0.7333599050954243\n",
      "-0.4538916774807335\n",
      "-0.7048206723021271\n",
      "-0.7150488808701423\n",
      "-0.6571078838903168\n",
      "-0.31914964519070155\n",
      "-0.5808620234712375\n",
      "-0.8944823126248703\n",
      "-0.444617197167061\n",
      "-0.6482209382581293\n",
      "-0.5155371452157148\n",
      "-0.5388838619950533\n",
      "-0.5373008218260639\n",
      "-0.3176666430811205\n",
      "-0.07356735265076163\n",
      "-0.10380573612329061\n",
      "-0.10104649196961689\n",
      "0.04880317475599384\n",
      "-0.23274211094858654\n",
      "-0.09840540985380272\n",
      "-0.24537023535057068\n",
      "-0.39674812770961393\n",
      "-0.4605174968856247\n",
      "-0.15360677395808936\n",
      "-0.46141193113865087\n",
      "-0.44944420915295547\n",
      "-0.4357882265958232\n",
      "-0.4839910848413594\n",
      "-0.25040994072871403\n",
      "-0.5630303032706836\n",
      "-0.5268010512719891\n",
      "-0.43043785016635777\n",
      "-0.3296410206720353\n",
      "-0.44887378855272164\n",
      "-0.5582196853614076\n",
      "-0.47330708713220027\n",
      "-0.3354593798565795\n",
      "-0.5827363369969963\n",
      "-0.7002447362722196\n",
      "-0.5273078424341446\n",
      "-0.48603562116354143\n",
      "-0.4391665538570074\n",
      "-0.32187726622975005\n",
      "-0.4561132828602874\n",
      "-0.27598205899680855\n",
      "-0.3875634758745609\n",
      "-0.44057997104680247\n",
      "-0.6204315788628487\n",
      "-0.43493716315671804\n",
      "-0.34078015675060525\n",
      "-0.2632327674183639\n",
      "-0.22100495076154061\n",
      "0.030493020520000844\n",
      "-0.377921251981982\n",
      "-0.10063646092926329\n",
      "0.13189121198378118\n",
      "-0.16450665816139887\n",
      "-0.12153253393145641\n",
      "-0.2584640583460585\n",
      "-0.21894942928694994\n",
      "-0.30535504979189426\n",
      "-0.3190975088179115\n",
      "-0.35143749930752316\n",
      "-0.12221817802239492\n",
      "-0.429349271134787\n",
      "-0.46440464784699725\n",
      "-0.6868400765812094\n",
      "-0.32040377817259225\n",
      "-0.37215272818957645\n",
      "-0.08387652482998614\n",
      "-0.05236535853604719\n",
      "-0.3321855943388813\n",
      "-0.3139703278451386\n",
      "-0.2558292022099546\n",
      "0.015216122278783398\n",
      "-0.26996497354436044\n",
      "-0.10762661005811916\n",
      "-0.13095421559875314\n",
      "-0.44321118191584485\n",
      "-0.41742212153375075\n",
      "-0.2170138870539385\n",
      "-0.6578138506038529\n",
      "-0.678872234773283\n",
      "-0.5570727930661472\n",
      "-0.4764699675587335\n",
      "-0.581766716664362\n",
      "-0.5371708005506207\n",
      "-0.4303613441160008\n",
      "-0.32491528015267956\n",
      "-0.3906693305071091\n",
      "-0.3788492435071553\n",
      "-0.5047992360165384\n",
      "-0.5178635410674981\n",
      "-0.32894588994773344\n",
      "-0.5865887530966521\n",
      "-0.6167869441626168\n",
      "-0.6318849760903933\n",
      "-0.4662166033303309\n",
      "-0.7004950691729738\n",
      "-0.4890862137518848\n",
      "-0.15729076857036817\n",
      "-0.3582678823454254\n",
      "-0.34110741530498984\n",
      "-0.5598786448761907\n",
      "-0.23694275858838865\n",
      "-0.5102890028998845\n",
      "-0.29730518537772166\n",
      "-0.5015580798902346\n",
      "-0.1686865347596785\n",
      "-0.3709750293315971\n",
      "-0.09240476128365561\n",
      "-0.09670281945036102\n",
      "-0.06483823037712941\n",
      "-0.024564551960829663\n",
      "0.08796078095255552\n",
      "-0.10394791375437135\n",
      "-0.20903736598079656\n",
      "0.1536917466874389\n",
      "0.4267602422903733\n",
      "0.12894259230409275\n",
      "-0.10601164368543126\n",
      "0.015658925751820076\n",
      "-0.049005038186955244\n",
      "0.03443723321254625\n",
      "0.11004886480306426\n",
      "0.08093292177994697\n",
      "-0.004187601019528565\n",
      "-0.04202181490924521\n",
      "0.15025184716461362\n",
      "0.18071655195463077\n",
      "-0.004951608526908534\n",
      "0.11311341954792184\n",
      "0.15461925478849023\n",
      "-0.12071586762308215\n",
      "-0.25435026855953335\n",
      "-0.3499773659840639\n",
      "-0.11982081039684594\n",
      "-0.1239297549772621\n",
      "0.04655753290744684\n",
      "0.11427492933336254\n",
      "0.18354374208263002\n",
      "9.53257140694358e-05\n",
      "-0.09812349486833745\n",
      "-0.04615946707667772\n",
      "0.11777884855779383\n",
      "-0.1657008546452204\n",
      "-0.14123665119165035\n",
      "-0.12761706220192484\n",
      "-0.09321413094565184\n",
      "-0.14103170657934777\n",
      "0.15442537964084518\n",
      "0.048343465432739645\n",
      "0.017171208283448168\n",
      "-0.05853982589890921\n",
      "0.1824536494298003\n",
      "0.019786932307636982\n",
      "-0.08464959964255461\n",
      "-0.027625226105098915\n",
      "0.21816410378432205\n",
      "0.1433100575995568\n",
      "-0.20924318530816585\n",
      "-0.06450506559366971\n",
      "0.06325048196456444\n",
      "-0.24931384036460402\n",
      "-0.025914059566175443\n",
      "0.06305753929608632\n",
      "-0.00854472495118768\n",
      "0.23570726698292538\n",
      "-0.028822388601068574\n",
      "0.1429197016825386\n",
      "-0.20948799912032728\n",
      "-0.03449731614958125\n",
      "-0.26185883598015725\n",
      "-0.09170838922337016\n",
      "-0.22779283985462673\n",
      "-0.1336352606712265\n",
      "-0.06986412854257437\n",
      "-0.44440838573312047\n",
      "-0.20003039314031149\n",
      "-0.0867362286093501\n",
      "-0.13429755779867292\n",
      "-0.1386231535807797\n",
      "-0.09925246227023266\n",
      "0.11674736399557578\n",
      "-0.09357095716471826\n",
      "-0.10922749433584694\n",
      "0.032601195685341186\n",
      "0.09042672485815817\n",
      "0.09015419070967257\n",
      "-0.18934463070927404\n",
      "-0.12643239415539548\n",
      "-0.13481252362898674\n",
      "0.1529565819542765\n",
      "0.10998856575312288\n",
      "-0.02201730081159349\n",
      "-0.3225998127869748\n",
      "-0.15699908323879153\n",
      "-0.1446576250678195\n",
      "-0.3050749480477234\n",
      "-0.14178646154176772\n",
      "-0.4215629604520743\n",
      "-0.4605805833750736\n",
      "-0.576359031163006\n",
      "-0.27955209778589923\n",
      "-0.49605333079301395\n",
      "-0.34190338434233314\n",
      "-0.46398708903713193\n",
      "-0.4366326725111829\n",
      "-0.475281087262361\n",
      "-0.4126994336291284\n",
      "-0.3009339589942961\n",
      "-0.2683771624932384\n",
      "-0.15973661994270127\n",
      "-0.04031887554186528\n",
      "-0.22610614058895107\n",
      "-0.25177891753097476\n",
      "-0.23623865015795673\n",
      "-0.2732096931924673\n",
      "-0.15596302419265093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.15578287497387405\n",
      "-0.04766726137870568\n",
      "-0.1021549917120195\n",
      "-0.4767663132990061\n",
      "-0.1715837839642808\n",
      "-0.5000313881477828\n",
      "-0.29781550558076336\n",
      "-0.4165763209993019\n",
      "-0.46945901310448757\n",
      "-0.2661864196100915\n",
      "-0.11476933997951333\n",
      "-0.3222956165127737\n",
      "-0.2072496232846393\n",
      "-0.3315787295254858\n",
      "-0.3282836495466602\n",
      "-0.27335475574165724\n",
      "-0.20572955793660216\n",
      "0.008715624196230086\n",
      "-0.11725591577540546\n",
      "-0.33536701194997004\n",
      "-0.30899158780729236\n",
      "-0.12161332473054978\n",
      "-0.37060823840120416\n",
      "-0.27254833875428847\n",
      "-0.020373236700997485\n",
      "-0.2628384002296813\n",
      "-0.2428413121959844\n",
      "-0.31709625955463666\n",
      "-0.400806358622031\n",
      "-0.398630903953327\n",
      "-0.47204612817933067\n",
      "-0.45919136060548355\n",
      "-0.5119375419587766\n",
      "-0.4703293588306659\n",
      "-0.6688853675649751\n",
      "-0.5078371040240172\n",
      "-0.33012318498155546\n",
      "-0.5441274860927479\n",
      "-0.6665585977571022\n",
      "-0.6605628707390085\n",
      "-0.45948522026021965\n",
      "-0.4708152872447904\n",
      "-0.7793189280164664\n",
      "-1.033028786170237\n",
      "-0.631123307821575\n",
      "-0.40203109409699733\n",
      "-0.6065690027125143\n",
      "-0.5079964435489389\n",
      "-0.2881491584515094\n",
      "-0.6444310799324369\n",
      "-0.6351276028500843\n",
      "-0.6347525129499176\n",
      "-0.6076686549879061\n",
      "-0.3834753338616579\n",
      "-0.38773449401158044\n",
      "-0.4734596838457527\n",
      "-0.5926287763383541\n",
      "-0.4106986552462324\n",
      "-0.5288807607822406\n",
      "-0.4349051702411559\n",
      "-0.598627879067004\n",
      "-0.6406060626434068\n",
      "-0.512574282216865\n",
      "-0.6759075432687469\n",
      "-0.8588183122001998\n",
      "-0.6990881553597141\n",
      "-0.4424889473481502\n",
      "-0.728361572072758\n",
      "-0.38048574528757095\n",
      "-0.30548177451524094\n",
      "-0.44913555616462686\n",
      "-0.22834795650060113\n",
      "-0.07796137903253354\n",
      "0.005984038701716168\n",
      "-0.12635508390504377\n",
      "-0.5223452376276487\n",
      "-0.24325947980136922\n",
      "-0.4382165868000011\n",
      "-0.3618003068444194\n",
      "-0.3327607139163215\n",
      "-0.1868923012008818\n",
      "-0.3665794512872139\n",
      "-0.5670869478120565\n",
      "-0.6890224344347888\n",
      "-0.440610898846594\n",
      "-0.6534799718959716\n",
      "-0.5261445502058139\n",
      "-0.683553389937613\n",
      "-1.051974710643974\n",
      "-0.8011787364501246\n",
      "-0.9693681370675559\n",
      "-0.6789472502529886\n",
      "-1.0208480326888696\n",
      "-0.984147510178275\n",
      "-0.6118508686214488\n",
      "-0.5850845185858915\n",
      "-0.7538851344364124\n",
      "-0.8758147572165965\n",
      "-0.829214807567996\n",
      "-0.8290181892948192\n",
      "-0.7524527759266789\n",
      "-0.4503511518134942\n",
      "-0.5002521694537723\n",
      "-0.6262415230411201\n",
      "-0.6214623590782172\n",
      "-0.5256400840551492\n",
      "-0.5493818398840024\n",
      "-0.5298731067641242\n",
      "-0.4568494734560671\n",
      "-0.5206987382224652\n",
      "-0.47365315446600154\n",
      "-0.6170268170165132\n",
      "-0.6675742573389657\n",
      "-0.752359937853283\n",
      "-0.6748016385339649\n",
      "-0.8895129480730616\n",
      "-0.8210297215814131\n",
      "-0.9735126410306681\n",
      "-1.0171435281397374\n",
      "-0.9241709760394587\n",
      "-1.0194943777227232\n",
      "-0.8812614882199353\n",
      "-0.8107247204688758\n",
      "-0.995373346981875\n",
      "-1.2842134015566977\n",
      "-1.105125261037563\n",
      "-0.7952520415909559\n",
      "-1.018907101959394\n",
      "-1.1286086317519406\n",
      "-1.0881361126913958\n",
      "-1.2427496769905886\n",
      "-1.2895608521006976\n",
      "-1.5582050230237983\n",
      "-1.3535511515887373\n",
      "-1.071339080798616\n",
      "-1.3438008391633671\n",
      "-1.3152692327227797\n",
      "-1.5224611933561498\n",
      "-1.022364769394332\n",
      "-0.9066620193316582\n",
      "-0.9557333282805396\n",
      "-1.2903619248583291\n",
      "-1.1360127626856302\n",
      "-1.3831578359857695\n",
      "-1.3848834850002554\n",
      "-1.493261804317528\n",
      "-1.1789497184501865\n",
      "-1.263502644853973\n",
      "-1.6467002562664634\n",
      "-1.5042255404285467\n",
      "-1.1414147497840936\n",
      "-1.337361131815861\n",
      "-1.3046279511041303\n",
      "-1.229015729449985\n",
      "-1.2157077500070312\n",
      "-1.2459919898832272\n",
      "-1.300997753609245\n",
      "-1.0774236309788523\n",
      "-1.3756931826620855\n",
      "-1.5141241918975241\n",
      "-1.472184567155233\n",
      "-1.4037291679760253\n",
      "-1.1902535135498986\n",
      "-1.0313800571885947\n",
      "-1.317646360072918\n",
      "-1.3943894311929748\n",
      "-1.5869644243576955\n",
      "-1.1911637592971642\n",
      "-1.3274430902470622\n",
      "-1.3397276427335518\n",
      "-1.3630702975285331\n",
      "-1.304473732143494\n",
      "-1.288972374711977\n",
      "-1.2943029517367197\n",
      "-1.2173839444646342\n",
      "-1.5211585382264314\n",
      "-1.3653517267184068\n",
      "-1.2655469955047884\n",
      "-1.4779984820273027\n",
      "-0.9727831423658344\n",
      "-1.2598219713304373\n",
      "-1.3169960711587965\n",
      "-1.3824878109751304\n",
      "-1.4132034419537907\n",
      "-1.3073729612573244\n",
      "-1.4572677302719383\n",
      "-1.5560036418859933\n",
      "-1.2104768959395453\n",
      "-1.4220401170715578\n",
      "-1.280800858469434\n",
      "-1.139677244738979\n",
      "-1.4814375792922105\n",
      "-1.5957015975763156\n",
      "-1.6846534224324612\n",
      "-1.4892691305898844\n",
      "-1.5076493294981366\n",
      "-1.1652884358535671\n",
      "-1.6095410764245381\n",
      "-1.353841278308523\n",
      "-1.184108463747425\n",
      "-1.2706690824826887\n",
      "-0.005087350194552722\n",
      "0.0447555751181694\n",
      "-0.028365289930557654\n",
      "0.22085713380382055\n",
      "-0.029267991117414807\n",
      "-0.0969120585071268\n",
      "-0.08409690526056085\n",
      "-0.063368059245003\n",
      "-0.021643894140094683\n",
      "0.1497849433880385\n",
      "0.2880796662049604\n",
      "0.3063587749029525\n",
      "0.001233060714507822\n",
      "-0.06395549561312523\n",
      "-0.04508919113519755\n",
      "-0.024461416970856097\n",
      "0.005399246755723414\n",
      "0.03910309291133541\n",
      "-0.34524309737982906\n",
      "-0.18841835148606115\n",
      "-0.09960020461044275\n",
      "-0.002544997489055442\n",
      "-0.19954663259395813\n",
      "0.20455484424022963\n",
      "0.15894892367187557\n",
      "0.08726511697644436\n",
      "-0.2078038379017123\n",
      "0.11362110086258655\n",
      "0.1958053362048323\n",
      "-0.05010623193483152\n",
      "0.04082981178249591\n",
      "-0.19077906772622788\n",
      "-0.4191165415620233\n",
      "-0.30568939459392563\n",
      "-0.5220274453427314\n",
      "-0.5186472662046004\n",
      "-0.4999391122008605\n",
      "-0.31832529658344616\n",
      "-0.14725069139606298\n",
      "-0.21984095317798022\n",
      "-0.4763259290476025\n",
      "-0.5924809537182081\n",
      "-0.21976367356294663\n",
      "-0.20125460716330276\n",
      "-0.28805801799595243\n",
      "-0.5133692734984262\n",
      "-0.473927884567714\n",
      "-0.20511397698851244\n",
      "-0.020668830394460706\n",
      "-0.29967580118255316\n",
      "-0.48693734110049774\n",
      "-0.24078366816489014\n",
      "-0.38218425120971544\n",
      "-0.16524691953933654\n",
      "-0.12292642085704458\n",
      "-0.12380220796106167\n",
      "-0.44106178769900833\n",
      "-0.2684514046326715\n",
      "-0.5546466406619067\n",
      "-0.38629062463451874\n",
      "-0.32632504172240445\n",
      "-0.1259957817434309\n",
      "-0.4253587588569072\n",
      "-0.3659307896952988\n",
      "-0.16456423952537247\n",
      "-0.20842104770315165\n",
      "-0.45762701460145805\n",
      "-0.3158948872714439\n",
      "-0.3028667361409785\n",
      "-0.02092999754842062\n",
      "-0.28877089283550805\n",
      "-0.4007255242756087\n",
      "-0.13258185726242097\n",
      "-0.3339933778874483\n",
      "-0.2750904531754057\n",
      "-0.36738537567873336\n",
      "-0.37806331416547023\n",
      "-0.45774995481188924\n",
      "-0.5350685163022381\n",
      "-0.4085478088689646\n",
      "-0.41100365497522845\n",
      "-0.0744913425180924\n",
      "-0.30526484475425825\n",
      "-0.29194694744203936\n",
      "-0.21105420116478052\n",
      "-0.2673746321553877\n",
      "-0.1210490674453005\n",
      "-0.030763994740022928\n",
      "-0.19161218795413543\n",
      "0.03370285282895155\n",
      "-0.12337275454483501\n",
      "-0.05172661570718287\n",
      "-0.11671782970779747\n",
      "-0.6108386339381389\n",
      "-0.3841640007951486\n",
      "-0.5080550411259424\n",
      "-0.026745934751367467\n",
      "-0.05306129587100249\n",
      "-0.28458885081703156\n",
      "-0.08577771845300355\n",
      "-0.3859033214110793\n",
      "-0.323966343662394\n",
      "-0.25786333028685743\n",
      "-0.1504409692156046\n",
      "-0.46101082507119384\n",
      "-0.34325798016392\n",
      "-0.41706642800088733\n",
      "-0.49194157349087725\n",
      "-0.6724464636390179\n",
      "-0.4872846752144593\n",
      "-0.2934908916796043\n",
      "-0.42053071864969394\n",
      "-0.41326118554667834\n",
      "-0.45282079041957457\n",
      "-0.3032611291750171\n",
      "-0.13205464251826832\n",
      "-0.386694641596202\n",
      "-0.4470054651855254\n",
      "-0.2174387401123371\n",
      "-0.3064597703457685\n",
      "-0.3348933271795559\n",
      "-0.5863311955966932\n",
      "-0.20706790156702987\n",
      "-0.32699950960390756\n",
      "-0.20404123368892357\n",
      "-0.3162536452405514\n",
      "-0.2741205776710228\n",
      "-0.3331007012034246\n",
      "-0.06383465287676438\n",
      "-0.34809802562428677\n",
      "-0.15720691408177612\n",
      "-0.39947579178367704\n",
      "-0.3443543415827059\n",
      "-0.3927183595868571\n",
      "-0.24992329129131252\n",
      "-0.27889693555921435\n",
      "-0.3098991953550513\n",
      "-0.3154159022621339\n",
      "-0.3495131366572576\n",
      "-0.4135565699021209\n",
      "-0.5046097551089938\n",
      "-0.6382092779402342\n",
      "-0.5563403819854688\n",
      "-0.35185339489063583\n",
      "-0.5006947409951994\n",
      "-0.3386443031174757\n",
      "-0.2965022574495027\n",
      "-0.365815303308631\n",
      "-0.35556989570409364\n",
      "-0.5173971903172639\n",
      "-0.44216160262642656\n",
      "-0.4775373848477635\n",
      "-0.3274290000404897\n",
      "-0.3498163624865444\n",
      "-0.3849305073469925\n",
      "-0.35343732745568324\n",
      "-0.26170115587976833\n",
      "-0.26589490329847687\n",
      "-0.10910836915822025\n",
      "-0.13235453505291211\n",
      "-0.5758553577056921\n",
      "-0.15571257611916023\n",
      "-0.07655278786716846\n",
      "-0.08820109277113641\n",
      "-0.4029058875380002\n",
      "-0.2129865345171012\n",
      "-0.31748814120816843\n",
      "-0.3412916735381506\n",
      "-0.15649721026201086\n",
      "-0.34677417888260004\n",
      "-0.34479825805066905\n",
      "-0.19973456387924535\n",
      "-0.16565860168585425\n",
      "-0.6969218671629702\n",
      "-0.4401067221169003\n",
      "-0.16784658227052382\n",
      "-0.26091886435250494\n",
      "-0.4132110508493115\n",
      "-0.30473542258053044\n",
      "-0.4037582461855455\n",
      "-0.5629357404890741\n",
      "-0.5505775648374015\n",
      "-0.49924875519879985\n",
      "-0.5212508124344725\n",
      "-0.7676375448530741\n",
      "-0.6040795362125315\n",
      "-0.5553763389975495\n",
      "-0.5982698633809602\n",
      "-0.6097004666313541\n",
      "-0.35890390083004925\n",
      "-0.13783797863198602\n",
      "-0.3013693568809217\n",
      "-0.3030326303871143\n",
      "-0.47652794453001135\n",
      "-0.2921840740291371\n",
      "-0.4684367392965041\n",
      "-0.767947098235444\n",
      "-0.591264870982633\n",
      "-0.5578714726716464\n",
      "-0.38649058320413227\n",
      "-0.25929382489160385\n",
      "-0.586150469138238\n",
      "-0.42992163776708703\n",
      "-0.11051350431138836\n",
      "0.02438890469853\n",
      "-0.21317951589537246\n",
      "-0.2096374224382219\n",
      "-0.4014159137723316\n",
      "-0.4688409866709217\n",
      "-0.1251005264626143\n",
      "-0.27420814781591774\n",
      "-0.23321470179161058\n",
      "-0.19473940288861702\n",
      "0.04629904227589131\n",
      "0.01136450976278408\n",
      "-0.250327962183929\n",
      "-0.2857740106300186\n",
      "-0.06494865455619135\n",
      "-0.04580060209334227\n",
      "-0.1379144919916322\n",
      "-0.42283650847818616\n",
      "-0.45020603769837786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.17239672068429254\n",
      "-0.1166113805329317\n",
      "-0.36152352098435836\n",
      "-0.12097357888277545\n",
      "-0.036593288374158234\n",
      "0.009244327153858544\n",
      "-0.07263349745381628\n",
      "-0.39816108242375414\n",
      "-0.36821266067715713\n",
      "-0.2416684458508318\n",
      "-0.07626598749841335\n",
      "-0.15621447104089956\n",
      "-0.04195063865501686\n",
      "-0.2688480783187146\n",
      "-0.1019959282720464\n",
      "-0.32566263133781\n",
      "-0.3203897281381569\n",
      "-0.21612523113711077\n",
      "-0.4163124853388783\n",
      "-0.4702679215122808\n",
      "-0.5649530552966204\n",
      "-0.6333224541509824\n",
      "-0.37495115683429386\n",
      "-0.47706881913501487\n",
      "-0.47987452395391644\n",
      "-0.4640057989338575\n",
      "-0.6070256576476201\n",
      "-0.6473438851195198\n",
      "-0.6252422996603582\n",
      "-0.6561530780799595\n",
      "-0.33094901248355724\n",
      "-0.5509923568680432\n",
      "-0.3451567484991944\n",
      "-0.34145896094523936\n",
      "-0.26254942031362183\n",
      "-0.2965330541097311\n",
      "-0.42371135301295804\n",
      "-0.1419719479823772\n",
      "-0.09625233407865591\n",
      "-0.31284759442013815\n",
      "-0.1490605593768155\n",
      "-0.36626315473719673\n",
      "-0.2143142212128323\n",
      "-0.43157277223867097\n",
      "-0.265820238456771\n",
      "-0.41943444622191756\n",
      "-0.2630438021452676\n",
      "-0.49263199658252277\n",
      "-0.4134525537798127\n",
      "-0.221232504000424\n",
      "-0.1045868708883032\n",
      "-0.11830331871130655\n",
      "-0.40280834355905454\n",
      "-0.43434134387762935\n",
      "-0.30828774363685746\n",
      "0.054342119849486295\n",
      "-0.16319717860092897\n",
      "-0.1607414774796581\n",
      "0.017817851757616653\n",
      "-0.17646456487569012\n",
      "-0.25183668540714405\n",
      "-0.03766815195297844\n",
      "-0.2084358764324354\n",
      "-0.2066521991115376\n",
      "-0.39548826583337193\n",
      "0.02133526846619041\n",
      "-0.06396535595070152\n",
      "-0.19268631439304368\n",
      "-0.03795009713868941\n",
      "-0.013686909722887348\n",
      "-0.053389720044719625\n",
      "-0.3338307532019289\n",
      "-0.2807497833394512\n",
      "-0.03664398628878833\n",
      "-0.007970378964744404\n",
      "-0.2164309240477474\n",
      "-0.14505565058852335\n",
      "-0.2525146011938174\n",
      "-0.25288709143273397\n",
      "-0.4023047161554272\n",
      "-0.2612045068671064\n",
      "-0.20124375984744391\n",
      "-0.19469079509565837\n",
      "-0.05932823580270166\n",
      "-0.08763675555729168\n",
      "-0.06765688366831993\n",
      "0.01794447929560814\n",
      "0.19472458968735978\n",
      "-0.07364071411769774\n",
      "0.06346725074955752\n",
      "-0.12352902965773314\n",
      "-0.011117988654801951\n",
      "0.08737578695203055\n",
      "-0.08411325983713491\n",
      "-0.04567377463519746\n",
      "0.06621403947961914\n",
      "-0.08345425037980597\n",
      "-0.09537614422911565\n",
      "-0.021220034928253514\n",
      "0.0824734485920072\n",
      "0.15408350838968715\n",
      "0.26317719348784696\n",
      "0.19768253277525305\n",
      "-0.24375333699794668\n",
      "0.06784714127365836\n",
      "-0.06813762022352962\n",
      "0.0985172314115042\n",
      "0.0744131864585712\n",
      "-0.18367250637600357\n",
      "0.014210788918680523\n",
      "0.3183269891579689\n",
      "0.17629296678848017\n",
      "0.3064504782677669\n",
      "0.06048624660766772\n",
      "0.306784365008664\n",
      "0.16289407738266715\n",
      "0.3039169009453689\n",
      "0.04125009445086063\n",
      "0.3040584298451763\n",
      "0.2650637814057596\n",
      "0.010747154479432808\n",
      "0.20537736329536138\n",
      "0.2986861465198549\n",
      "0.10385461324399925\n",
      "0.16745873261978306\n",
      "0.19814163498087842\n",
      "0.18747300407430884\n",
      "0.05963850564221278\n",
      "0.22136938486114155\n",
      "0.135014187717801\n",
      "0.1083098558276903\n",
      "0.13533462153596526\n",
      "0.1230933562610028\n",
      "0.14246551997563406\n",
      "0.09465329195557803\n",
      "0.17160337534071657\n",
      "0.04287804846247864\n",
      "0.1439368090914303\n",
      "0.142875503485322\n",
      "0.3652226925361376\n",
      "0.08307197759848094\n",
      "0.32476929058502807\n",
      "0.16670416957649725\n",
      "0.2342099759792066\n",
      "-0.058318263922238815\n",
      "0.38360231352930474\n",
      "0.14914098482030475\n",
      "0.42128296887379213\n",
      "0.330663323450331\n",
      "0.3259242713249368\n",
      "0.17363911934187565\n",
      "0.20531050420699073\n",
      "0.14931570581706513\n",
      "0.02564673649733906\n",
      "0.18721917823087378\n",
      "-0.04308926989927438\n",
      "0.05615935683867262\n",
      "0.21817741692761872\n",
      "0.2540118519137913\n",
      "0.4866718146766216\n",
      "0.4674756001886727\n",
      "0.05380354935204833\n",
      "0.4438173922111394\n",
      "0.22061676912938977\n",
      "0.24176988415993536\n",
      "0.2239687528511421\n",
      "0.2613278161062913\n",
      "0.3969017473892629\n",
      "0.36717837186615804\n",
      "0.13516743613651327\n",
      "0.29859050461756986\n",
      "0.29268881402777674\n",
      "0.24769102722142405\n",
      "0.04651437196844265\n",
      "0.20741215864249138\n",
      "0.12348587509330683\n",
      "-0.010369955205828143\n",
      "0.01787117190700646\n",
      "0.1622084585166603\n",
      "0.12597325985313024\n",
      "0.15252115616811146\n",
      "0.27060602171871584\n",
      "0.44958007523721927\n",
      "0.42862529273177924\n",
      "0.3335344285477796\n",
      "0.4100139302660622\n",
      "0.4908776062718013\n",
      "0.4662471515514994\n",
      "0.5588000803373228\n",
      "0.6055071238526252\n",
      "0.30465918135834535\n",
      "0.18230943072415542\n",
      "0.4865830218060627\n",
      "0.30650953850442714\n",
      "0.454154461623764\n",
      "0.4100593812847769\n",
      "0.24466466178483126\n",
      "0.2250892225254887\n",
      "0.43469115973452477\n",
      "0.5413015324718147\n",
      "0.2646201702841259\n",
      "0.397446076014213\n",
      "0.371692366508483\n",
      "0.15666139895154085\n",
      "0.054187010978329335\n",
      "0.24947992900587065\n",
      "0.0019275760359936597\n",
      "-0.026301988909614583\n",
      "0.2572156028995035\n",
      "0.15632411894535536\n",
      "0.07990611649833268\n",
      "0.2950485351151707\n",
      "0.44378458621867173\n",
      "0.18262443326634395\n",
      "0.26597902319620714\n",
      "0.19811713160501201\n",
      "0.310615019235702\n",
      "0.5199209380405619\n",
      "0.5177671439698255\n",
      "0.3696825426402544\n",
      "0.37898661167683845\n",
      "0.5437636260738615\n",
      "0.4864126519941896\n",
      "0.3430962226809351\n",
      "0.2618291812172552\n",
      "0.17117296381296254\n",
      "0.6151973947774072\n",
      "0.5950664680464642\n",
      "0.338795404381683\n",
      "0.1720867631477872\n",
      "0.44609733175912786\n",
      "0.6615001075866075\n",
      "0.44843455352172784\n",
      "0.6548674325729844\n",
      "0.5996247568852926\n",
      "0.22573200839376661\n",
      "0.3040384835922635\n",
      "0.46536287804156506\n",
      "0.39366860793423614\n",
      "0.5449695544695895\n",
      "0.584526009504917\n",
      "0.43957881601726567\n",
      "0.7255295504145619\n",
      "0.6811198813167428\n",
      "0.5337399076126553\n",
      "0.4161183458119564\n",
      "0.6263382764111639\n",
      "0.6516924453836936\n",
      "0.6904736216654569\n",
      "0.7629194852541552\n",
      "0.7176957396798573\n",
      "0.6722177037435574\n",
      "0.6206347247176097\n",
      "0.2625571163235892\n",
      "0.3841593104014274\n",
      "0.3751490207466625\n",
      "0.7595582058901653\n",
      "0.5518879317918939\n",
      "0.5330790030676058\n",
      "0.4180391203522945\n",
      "0.6253646877638833\n",
      "0.755722085397516\n",
      "0.7061379978582246\n",
      "0.5464909301841215\n",
      "0.571434618066194\n",
      "0.5366912163549409\n",
      "0.39702711812090485\n",
      "0.483086578942446\n",
      "0.35199911841990866\n",
      "0.39906016074871653\n",
      "0.629529327632595\n",
      "0.589189780913488\n",
      "0.5778600380348097\n",
      "0.5136056843696313\n",
      "0.5207704702432528\n",
      "0.21921929197894577\n",
      "0.16989571456415106\n",
      "0.48816601596564957\n",
      "0.2230919937373334\n",
      "0.3876006481773122\n",
      "0.23121039404342641\n",
      "0.43293734886692214\n",
      "0.14076787402907548\n",
      "0.44708763285163633\n",
      "0.600745255647346\n",
      "0.46838681425398865\n",
      "0.4595469897509084\n",
      "0.21716993488356004\n",
      "0.5473536336616979\n",
      "0.28165584868642346\n",
      "0.3865960101881572\n",
      "0.3230719208175291\n",
      "0.12843391030764278\n",
      "0.0358717611351936\n",
      "0.2718793965746356\n",
      "0.28134189632978035\n",
      "0.2484106543274745\n",
      "-0.0008147978386639707\n",
      "0.05573730842082546\n",
      "0.11837857154260431\n",
      "0.14767091759812495\n",
      "0.36568797258736474\n",
      "-0.026141249114461335\n",
      "0.2010727734749997\n",
      "0.39417446700044617\n",
      "0.3975974359060453\n",
      "0.11255283444801338\n",
      "0.0830963945740292\n",
      "0.33159051397771255\n",
      "0.260186106249907\n",
      "0.237844616464207\n",
      "0.009398567116591539\n",
      "-0.06930412551941098\n",
      "0.07237447033074879\n",
      "0.07183650413885859\n",
      "0.38297902645824544\n",
      "0.5359918349332048\n",
      "0.6579810419515586\n",
      "0.5677890163162576\n",
      "0.6063776567789482\n",
      "0.3719302418345021\n",
      "0.24139206830876142\n",
      "0.48876022189191526\n",
      "0.4937537822433208\n",
      "0.3938422025685933\n",
      "0.3985683150118706\n",
      "0.6327699963150973\n",
      "0.5827058031231824\n",
      "0.37127764175294475\n",
      "0.1801170215540092\n",
      "0.4379564153961959\n",
      "0.3934801679533498\n",
      "0.37596683283965926\n",
      "0.04882544803319751\n",
      "0.1095750104764784\n",
      "0.31610353470749997\n",
      "0.13515473643906598\n",
      "0.07074253485382283\n",
      "0.1911918404129107\n",
      "0.3650497780947178\n",
      "0.1650371921396785\n",
      "0.22693649046005113\n",
      "0.32003871251887145\n",
      "0.2248405530249974\n",
      "0.3354918390149412\n",
      "0.643679642038253\n",
      "0.689028682630588\n",
      "0.34021608745337534\n",
      "0.24139097786953684\n",
      "0.11694070986393917\n",
      "0.4300750971989825\n",
      "0.5222850406307608\n",
      "0.513148962803222\n",
      "0.4833068737889916\n",
      "0.4837639965944579\n",
      "0.46296437515452327\n",
      "0.2744794336349542\n",
      "0.36665682756306545\n",
      "0.18929309486526266\n",
      "0.2922390524326645\n",
      "0.4473859518504497\n",
      "0.16584328992761949\n",
      "-0.08922493268642102\n",
      "0.2538040653564901\n",
      "0.6033127860011863\n",
      "0.3314256360428385\n",
      "0.31250523497489363\n",
      "0.18842074848296997\n",
      "-0.0011495285231459956\n",
      "0.11001544520817425\n",
      "0.13020126066635312\n",
      "0.34038999811662884\n",
      "0.33197089387980405\n",
      "0.39348377429611453\n",
      "0.219105052771123\n",
      "0.3521726483220526\n",
      "0.22384937654697828\n",
      "0.07134006411544169\n",
      "0.2983145742368089\n",
      "-0.03334960145360054\n",
      "0.0356074307492677\n",
      "0.08469360916085392\n",
      "0.08762553683600628\n",
      "0.1713115063218277\n",
      "-0.14697953966181682\n",
      "-0.030585436701620866\n",
      "0.11253287423371762\n",
      "0.24677917740617814\n",
      "-0.07157784014028869\n",
      "0.11636533331061534\n",
      "0.27178907115033024\n",
      "0.23658650510440138\n",
      "0.14724945492337116\n",
      "-0.16168706363798624\n",
      "-0.22292506026147874\n",
      "-0.2046413133976545\n",
      "-0.3006558908388902\n",
      "-0.11172259085080248\n",
      "-0.006313405496276701\n",
      "0.1325935023338566\n",
      "-0.07163188309639912\n",
      "-0.3063822939259123\n",
      "-0.10517913818217459\n",
      "-0.1235388949199328\n",
      "-0.06897612362214575\n",
      "-0.046096010089795275\n",
      "0.18889880207644952\n",
      "0.16012360440191167\n",
      "-0.1408989819156347\n",
      "-0.03985630214169112\n",
      "-0.25088731634311556\n",
      "-0.09485419234677063\n",
      "-0.15729874736740193\n",
      "-0.13894543782397312\n",
      "0.004038943230326761\n",
      "-0.00012174277531275257\n",
      "0.14890213501886312\n",
      "0.29289962488469323\n",
      "-0.1672251374901189\n",
      "-0.008405599446102557\n",
      "0.358066912852417\n",
      "0.24173183512783816\n",
      "0.2567983164955203\n",
      "0.3741551152923974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07076742492486794\n",
      "0.24924836193710653\n",
      "0.11172819855875521\n",
      "0.029646298456985132\n",
      "0.009558062458017179\n",
      "0.0576184921017297\n",
      "0.24236022922698466\n",
      "-0.03999335776995255\n",
      "0.027530412018776727\n",
      "-0.040823043794930035\n",
      "-0.06347954323202372\n",
      "0.178629755258794\n",
      "0.21437859099960307\n",
      "0.027563502232421523\n",
      "-0.13023391782822744\n",
      "-0.024822912083443338\n",
      "-0.006829029564326955\n",
      "0.2108766214602953\n",
      "0.2555856495304009\n",
      "0.2103618375755581\n",
      "-0.1448803932272133\n",
      "0.07361894636961572\n",
      "0.019479153903193484\n",
      "0.12240298537795621\n",
      "0.1256413586084837\n",
      "-0.12294818157887086\n",
      "-0.03395167169703007\n",
      "0.021041708719994806\n",
      "-0.17461573269678238\n",
      "-0.22100356338122545\n",
      "-0.05161263874579597\n",
      "0.034698513750799194\n",
      "0.0452046987708648\n",
      "-0.09344843438394174\n",
      "-0.3107943097117405\n",
      "-0.2996789278896418\n",
      "-0.15565701955296363\n",
      "0.04746145545465502\n",
      "-0.08994324404004649\n",
      "-0.06930633782990119\n",
      "0.09108508373854911\n",
      "-0.16032197010764898\n",
      "-0.21502168083925607\n",
      "0.010182216147531849\n",
      "-0.2710433410545283\n",
      "-0.31341750983600236\n",
      "-0.35180264249381615\n",
      "-0.19990793031051174\n",
      "-0.38930960704856327\n",
      "-0.07907126669876338\n",
      "-0.048404232533937636\n",
      "-0.39810897001025036\n",
      "-0.04748959748912361\n",
      "-0.024940226261549403\n",
      "-0.30798246703943877\n",
      "-0.07908387800511621\n",
      "-0.33991248691606224\n",
      "-0.19487971068655802\n",
      "-0.3466211974780494\n",
      "-0.436682176556219\n",
      "-0.4586652936836253\n",
      "-0.4770310539572359\n",
      "-0.21624558770085806\n",
      "-0.20015247997390626\n",
      "-0.4547459645133316\n",
      "-0.32460194256494845\n",
      "-0.32738321217778865\n",
      "-0.1886697846179165\n",
      "-0.44394276127415444\n",
      "-0.34813127535436283\n",
      "-0.41882557072848314\n",
      "-0.1128028393982895\n",
      "-0.08508486064693609\n",
      "-0.1864017467897854\n",
      "-0.060670332625299445\n",
      "-0.11284249710081588\n",
      "-0.14882992513903445\n",
      "-0.09022115319386519\n",
      "-0.22688144125769788\n",
      "-0.25559760039085927\n",
      "-0.06874531099992644\n",
      "0.10201482941271012\n",
      "-0.12878693631317056\n",
      "-0.06335096833362096\n",
      "-0.3633809854231179\n",
      "-0.2737435543378722\n",
      "-0.3555320780848917\n",
      "-0.4448815125932658\n",
      "-0.4467352243611652\n",
      "-0.41202374258952823\n",
      "-0.07657421167650029\n",
      "-0.09428723765939673\n",
      "-0.241659705893841\n",
      "-0.0917832393276578\n",
      "-0.07375766182892299\n",
      "-0.36263361348106044\n",
      "-0.40575300956998256\n",
      "-0.35986989124742097\n",
      "-0.1496731152038226\n",
      "-0.40969357593333144\n",
      "-0.48479637875011705\n",
      "-0.031627067775564704\n",
      "-0.31779983308181503\n",
      "-0.14831277934454448\n",
      "-0.17260645452414747\n",
      "-0.21409207086128887\n",
      "-0.5188290889067543\n",
      "-0.6227957183577555\n",
      "-0.20407790091815348\n",
      "-0.4297455880126891\n",
      "-0.3197080115898343\n",
      "-0.3861075323515549\n",
      "-0.6174107918976829\n",
      "-0.43081312554638757\n",
      "-0.17442313909455426\n",
      "-0.29504806750630047\n",
      "-0.19440868122421853\n",
      "-0.3194155174536663\n",
      "-0.18068667077286107\n",
      "-0.4539119838620996\n",
      "-0.4280928008814341\n",
      "-0.12618284557857495\n",
      "-0.2654060401679057\n",
      "-0.27273767005777844\n",
      "-0.5137145468471699\n",
      "-0.5440850749624961\n",
      "-0.12022617466723794\n",
      "-0.3211559622964124\n",
      "-0.16972952011509435\n",
      "-0.3817663313240437\n",
      "-0.29031644759658537\n",
      "-0.643302472855728\n",
      "-0.2728610315461439\n",
      "-0.5194961165286868\n",
      "-0.6171886904073682\n",
      "-0.3329535888612303\n",
      "-0.3566751187511259\n",
      "-0.2641663802686634\n",
      "-0.42693501903864245\n",
      "-0.6479935613044364\n",
      "-0.5851051268105498\n",
      "-0.6881972547977091\n",
      "-0.4266583882537239\n",
      "-0.49056668098659034\n",
      "-0.28435853768098873\n",
      "-0.38471271029256954\n",
      "-0.36590799898259907\n",
      "-0.21780611106610734\n",
      "-0.44444418802710783\n",
      "-0.31794748796768946\n",
      "-0.3623700690603125\n",
      "-0.47879007696647863\n",
      "-0.2729988592495203\n",
      "-0.3641894683029321\n",
      "-0.02230333528894153\n",
      "-0.20381423770768342\n",
      "-0.060083287467543385\n",
      "-0.1668826707361576\n",
      "-0.29566739801202097\n",
      "-0.1779166407047315\n",
      "-0.19906448884336242\n",
      "-0.24036706328807111\n",
      "-0.30158787696356004\n",
      "-0.5182212405814351\n",
      "-0.49335393603319755\n",
      "-0.5915081824753474\n",
      "-0.49833213021860817\n",
      "-0.31732599504780745\n",
      "-0.4674640686579983\n",
      "-0.5765521397565444\n",
      "-0.7093269383970643\n",
      "-0.6155382271816975\n",
      "-0.5681388595075315\n",
      "-0.5402837198192089\n",
      "-0.3813303302776413\n",
      "-0.5301588789856027\n",
      "-0.5673990130368298\n",
      "-0.41358182447566616\n",
      "-0.5691347243375396\n",
      "-0.2498377043491553\n",
      "-0.5518681702677981\n",
      "-0.09157212782185528\n",
      "-0.2937055132391328\n",
      "-0.2514454809329105\n",
      "-0.1881830629879788\n",
      "-0.011755625275810748\n",
      "-0.13047232183194923\n",
      "-0.07831591807960012\n",
      "-0.1557988166453418\n",
      "-0.2464136593754446\n",
      "-0.34817858572963717\n",
      "-0.12062664076610582\n",
      "-0.37485272736222985\n",
      "-0.196170024708545\n",
      "-0.18449889137194328\n",
      "-0.10612182608644795\n",
      "-0.28402367605080464\n",
      "-0.3372980834347474\n",
      "-0.36624155991228957\n",
      "-0.27116640413713966\n",
      "-0.09774942981417463\n",
      "-0.10645926756970661\n",
      "-0.19201181012892504\n",
      "-0.1946304987923042\n",
      "-0.5024895307500183\n",
      "-0.31030651445616725\n",
      "-0.2712599431664213\n",
      "-0.4184247092733667\n",
      "-0.28653577372742584\n",
      "-0.457058495748391\n",
      "-0.21084798803651156\n",
      "-0.1640169718993897\n",
      "-0.1585041124299981\n",
      "-0.2796739484412195\n",
      "-0.3454240788606802\n",
      "-0.161687989708367\n",
      "-0.13201893092937\n",
      "-0.27299630456706\n",
      "-0.2388729269017387\n",
      "-0.0726343138511171\n",
      "-0.10977870367763763\n",
      "-0.21983478794471847\n",
      "-0.039098792775585\n",
      "-0.2298238184318901\n",
      "-0.22806024084746515\n",
      "-0.42306961554443184\n",
      "-0.4400869494287521\n",
      "-0.3985506938369358\n",
      "-0.13713187697740592\n",
      "-0.19943161659970657\n",
      "-0.20173453378648426\n",
      "-0.15727030692073446\n",
      "-0.14288527698852585\n",
      "-0.18950191724216683\n",
      "-0.10470354799381916\n",
      "0.08269432075501981\n",
      "-0.18246250834217909\n",
      "-0.2108885224734372\n",
      "-0.12625722839100312\n",
      "0.03314482900405309\n",
      "-0.1798070199794869\n",
      "0.23820872125499043\n",
      "0.10481133892301628\n",
      "0.14941622522022363\n",
      "0.17959247999883884\n",
      "0.03556486622753993\n",
      "0.15994054856385956\n",
      "-0.16003218120536367\n",
      "0.09026953463368488\n",
      "0.0846583452174457\n",
      "0.2236897794164491\n",
      "0.1744121427110149\n",
      "0.05063955498869532\n",
      "0.16839252415502798\n",
      "-0.06747296901642623\n",
      "-0.06666642690804403\n",
      "-0.19517390975050938\n",
      "0.22019066013608501\n",
      "0.23493115715304944\n",
      "-0.03475484358561361\n",
      "0.015651877381015436\n",
      "-0.0570401673450717\n",
      "-0.29697414041368764\n",
      "-0.1103088852909909\n",
      "-0.2793328934078539\n",
      "-0.34569293885007624\n",
      "-0.017556925950640553\n",
      "-0.09153828672080716\n",
      "-0.02816589130080975\n",
      "0.13025695854476804\n",
      "-0.05583447962597263\n",
      "0.03984677278285703\n",
      "-0.09551717481339796\n",
      "-0.056564991803086086\n",
      "0.07547272030793016\n",
      "-0.01407121710613879\n",
      "-0.24545828839655975\n",
      "-0.3733810660015338\n",
      "-0.007952112571242023\n",
      "-0.05380339271315396\n",
      "0.031361497584754074\n",
      "-0.09327610998617351\n",
      "0.04947280674825816\n",
      "0.014587772707133337\n",
      "-0.05857482246688476\n",
      "-0.22149206889815043\n",
      "-0.14268354972645886\n",
      "0.12005099518493592\n",
      "-0.29991322508464935\n",
      "0.07699159493931161\n",
      "-0.10080578584813557\n",
      "-0.1173205689703427\n",
      "0.11474919854211112\n",
      "-0.09021168534814714\n",
      "0.21886206486546206\n",
      "-0.06313998933889084\n",
      "0.021005158693576484\n",
      "-0.004239355865454493\n",
      "-0.0271460713760812\n",
      "0.14148325391252697\n",
      "0.14313311834535494\n",
      "0.15548253916105886\n",
      "-0.16160306392140533\n",
      "-0.12639840536749322\n",
      "-0.025355929236135014\n",
      "0.0013484051551613668\n",
      "0.21071055819517998\n",
      "0.11492696840364539\n",
      "0.16852212100350078\n",
      "0.11116167418557243\n",
      "0.046252475218182675\n",
      "0.11476476020890822\n",
      "0.0722164720185002\n",
      "0.08602788417630032\n",
      "0.12759745105674064\n",
      "0.2222278449453059\n",
      "0.24288189893872444\n",
      "0.172451366938872\n",
      "0.18893603464817835\n",
      "0.23617942798196212\n",
      "0.41647755307601275\n",
      "0.17880995937864605\n",
      "0.09667741982021184\n",
      "0.3708075413387561\n",
      "0.35988639510398474\n",
      "0.29025923534324793\n",
      "0.1991475045122218\n",
      "-0.06570615897951695\n",
      "0.12508927677541992\n",
      "0.10450019129270421\n",
      "0.08178023045953975\n",
      "0.13553513472226503\n",
      "0.0786740727831248\n",
      "0.5020108488063367\n",
      "0.564750480009046\n",
      "0.3994861723308495\n",
      "0.542440768590951\n",
      "0.37148783210287134\n",
      "0.07211037193405771\n",
      "0.20283418747475362\n",
      "0.14000167259012453\n",
      "-0.04141770981362455\n",
      "-0.1041312628692227\n",
      "0.2657949927929056\n",
      "0.3080083518060729\n",
      "0.5109982228735248\n",
      "0.48517507904191354\n",
      "0.036166290538931375\n",
      "0.1240927725012152\n",
      "0.3519814712237008\n",
      "0.5094656904638986\n",
      "0.40618853604679706\n",
      "0.49442069645468223\n",
      "0.5093474776569316\n",
      "0.3476239812108022\n",
      "0.2665540320518367\n",
      "0.40549978485857\n",
      "0.4697141293288523\n",
      "0.35749230388990405\n",
      "0.3626931225315937\n",
      "0.40927169981491035\n",
      "0.35133319149902226\n",
      "0.15856797704248773\n",
      "0.22565719485706606\n",
      "0.37817979823058895\n",
      "0.05019635114386095\n",
      "0.2474556360166261\n",
      "0.24564399500189202\n",
      "0.265863052467758\n",
      "0.3260173736741657\n",
      "0.49602714772676315\n",
      "0.3009391771789376\n",
      "0.3001926313181391\n",
      "0.16041267476034982\n",
      "0.23006326786961956\n",
      "0.40601082792016085\n",
      "0.37860679156457416\n",
      "0.40159402481102857\n",
      "0.5156894697019775\n",
      "0.5125563956246066\n",
      "0.5047362842933831\n",
      "0.40209824338983463\n",
      "0.49517520384201974\n",
      "0.4311657297618464\n",
      "0.5400571973381263\n",
      "0.4989212836787543\n",
      "0.16430677300205448\n",
      "0.1853457070326844\n",
      "0.48729037758216465\n",
      "0.3601685854279931\n",
      "0.33808686506031443\n",
      "0.2742814696217602\n",
      "0.3552815110500558\n",
      "0.31105041237560555\n",
      "0.39447770146994154\n",
      "0.20873261961077355\n",
      "0.18299400102366\n",
      "0.30582670637193327\n",
      "0.08591785193757097\n",
      "0.023500685612795905\n",
      "-0.13386717916186835\n",
      "-0.15703623679253242\n",
      "-0.37995576761877187\n",
      "-0.18413027006488863\n",
      "-0.22165941956846694\n",
      "-0.029195224022362097\n",
      "-0.004632820456947716\n",
      "-0.16976099739320397\n",
      "-0.21815362521617226\n",
      "-0.2938027247677872\n",
      "-0.29656897791921943\n",
      "-0.2794568890081962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.08924903884828632\n",
      "-0.27686301026665416\n",
      "-0.1872624546399289\n",
      "-0.08943800194481268\n",
      "0.09170206189205335\n",
      "-0.00974686029981095\n",
      "-0.030885376197358386\n",
      "-0.08697444396352166\n",
      "0.1640371707979833\n",
      "0.08067798629620615\n",
      "0.26344209772050275\n",
      "0.056657177374080464\n",
      "0.13156760418869531\n",
      "0.24360455631509798\n",
      "0.10378958683397084\n",
      "0.2983502336178006\n",
      "0.08996536954465893\n",
      "0.013203552145574941\n",
      "0.1451645564384391\n",
      "0.2200482471575349\n",
      "0.19924231251481703\n",
      "0.19169358148596063\n",
      "0.24760602190594408\n",
      "0.078711360063018\n",
      "0.23787584898435493\n",
      "0.23149117187479656\n",
      "0.2684517639892188\n",
      "-0.09548455085458286\n",
      "0.13817418371366746\n",
      "-0.030168955935514746\n",
      "0.038963664820834354\n",
      "0.18498353272414808\n",
      "0.12090895524735644\n",
      "-0.01684106428788519\n",
      "0.1382817710130596\n",
      "0.10577042895684902\n",
      "-0.22771924665574678\n",
      "0.12148367933894019\n",
      "-0.1352467705240466\n",
      "-0.13867208653754887\n",
      "0.11772574442550977\n",
      "0.14502229199371253\n",
      "0.10908276614999768\n",
      "-0.13752156753588263\n",
      "0.03498188626337537\n",
      "0.0654151553182721\n",
      "-0.1622545551086751\n",
      "-0.05503282220126958\n",
      "0.2178507565685466\n",
      "0.26893946731615487\n",
      "0.2669520257285345\n",
      "0.15284176304671737\n",
      "0.20565019615148497\n",
      "-0.11589984426285414\n",
      "0.02765189970355747\n",
      "0.19088828021886475\n",
      "0.25344449937855307\n",
      "0.2129861069663806\n",
      "0.11550619555338743\n",
      "-0.045116541453866295\n",
      "0.08675486478115943\n",
      "0.2124559838209759\n",
      "-0.012286974526583082\n",
      "0.25031019786489983\n",
      "0.2308871382313791\n",
      "0.02746355791781011\n",
      "-0.027299031279561847\n",
      "0.13127783723175696\n",
      "0.217760158523857\n",
      "0.054370891259643846\n",
      "0.19801631797820865\n",
      "0.12284873897818166\n",
      "0.31179533543752813\n",
      "0.37370459966620156\n",
      "0.3752075931731186\n",
      "0.3096542218546887\n",
      "0.19336855457771382\n",
      "0.18804368166842672\n",
      "0.2842568984566141\n",
      "0.3175731389392227\n",
      "0.29924259923760405\n",
      "0.12695503306887213\n",
      "0.14511056309742212\n",
      "-0.08381996051124355\n",
      "-0.3144331699153041\n",
      "-0.21426591064622047\n",
      "0.0070903911385194335\n",
      "-0.03187073083713245\n",
      "-0.16501404325032829\n",
      "-0.11061814351331081\n",
      "-0.11009361508889308\n",
      "-0.007431241030155047\n",
      "0.04153956496103628\n",
      "0.09042948236549793\n",
      "0.04099907706064783\n",
      "-0.020468874226665906\n",
      "-0.3196947581439318\n",
      "-0.37551187999650476\n",
      "-0.15970832903755008\n",
      "-0.18748774306815194\n",
      "-0.019590854264145998\n",
      "-0.1256354452371523\n",
      "-0.015209240059376919\n",
      "0.13102668879700685\n",
      "0.2118887799044756\n",
      "0.10908325324613431\n",
      "0.13682584421158672\n",
      "0.35406081416067803\n",
      "0.31557179097384425\n",
      "-0.02601827380116631\n",
      "0.07815955312881662\n",
      "-0.12076116749618494\n",
      "-0.19075358679168292\n",
      "-0.29108849604360704\n",
      "0.003910042792621471\n",
      "0.103194936510054\n",
      "0.18321440982400575\n",
      "0.08346637216732553\n",
      "0.24974632802427899\n",
      "0.21041490034646917\n",
      "0.006410225352443344\n",
      "-0.2500513560747034\n",
      "-0.19091334772907162\n",
      "-0.05494889016237522\n",
      "0.1368927880717011\n",
      "0.13145285734201398\n",
      "0.034331480905596665\n",
      "0.17119268253959152\n",
      "0.034161152555436655\n",
      "0.23390201559469598\n",
      "0.1282168408018458\n",
      "0.058824672186553524\n",
      "-0.2508073106563561\n",
      "-0.09824536343099224\n",
      "-0.3780860053859291\n",
      "-0.30283098053061414\n",
      "-0.19513045335903206\n",
      "-0.18371808642342585\n",
      "-0.34672978305280455\n",
      "-0.39088972692243906\n",
      "-0.021602985425872315\n",
      "-0.1241069562654735\n",
      "-0.2435679444150168\n",
      "-0.2781269114784223\n",
      "-0.12005103873799373\n",
      "-0.28564964575581664\n",
      "-0.03653023265800483\n",
      "-0.07175760142701965\n",
      "-0.17385597149409895\n",
      "0.04225113482627969\n",
      "0.0364350734209055\n",
      "0.34407238717402655\n",
      "0.46563842123943555\n",
      "0.193108842231563\n",
      "0.10736841377384314\n",
      "-0.17486856911409343\n",
      "0.11027480229693766\n",
      "-0.18425698759538572\n",
      "-0.07248677497382965\n",
      "-0.21657310715551267\n",
      "0.11931935003957854\n",
      "0.06544369193622832\n",
      "0.34184295826600875\n",
      "0.43698396966532027\n",
      "0.4107969381984447\n",
      "0.381162115966082\n",
      "0.3628346715624784\n",
      "0.35006208883401496\n",
      "0.3293768590410981\n",
      "0.02723084889123832\n",
      "0.26876481840371214\n",
      "-0.17900757681832202\n",
      "0.2584783140791941\n",
      "0.07716929794274656\n",
      "-0.0464456929647219\n",
      "-0.04996320120760917\n",
      "-0.044731551510906624\n",
      "-0.05030547812227677\n",
      "-0.2576299971154359\n",
      "-0.3626249500344376\n",
      "-0.2035473400787175\n",
      "-0.42338543391785033\n",
      "-0.5432503397706132\n",
      "-0.3953352063122391\n",
      "-0.36338177533587956\n",
      "-0.2617348355218516\n",
      "-0.32067157878667096\n",
      "-0.20061860982624596\n",
      "-0.10761654432292099\n",
      "-0.1351992204125107\n",
      "-0.12725300411808182\n",
      "-0.46431876849900017\n",
      "-0.34679017041132465\n",
      "-0.3448728788408902\n",
      "-0.1362296750811568\n",
      "-0.10674119689141384\n",
      "-0.231495273000551\n",
      "-0.0792632458057971\n",
      "-0.08658795930719274\n",
      "-0.09252194933971292\n",
      "-0.16243054269209836\n",
      "-0.11605814670845468\n",
      "0.13735357069162113\n",
      "0.2082900867240848\n",
      "0.045397769997053444\n",
      "0.13249491686052034\n",
      "-0.0022865515744006568\n",
      "-0.02698153244164722\n",
      "0.009177976529657864\n",
      "0.24005093931561494\n",
      "0.1115228949497192\n",
      "0.3601329061273854\n",
      "0.35953276399735584\n",
      "0.028002411104486286\n",
      "0.10245663504925373\n",
      "0.3467016276312053\n",
      "0.4353600611316686\n",
      "0.09397832958797155\n",
      "0.24540779948361388\n",
      "-0.06417276449351521\n",
      "0.10698024356868241\n",
      "-0.062365092222928076\n",
      "-0.11696660241026328\n",
      "-0.18471130709852576\n",
      "-0.05154591248917076\n",
      "-0.1452459490631337\n",
      "0.01378731928246579\n",
      "0.0021320439493041545\n",
      "-0.1154548637548384\n",
      "0.020201927424491117\n",
      "0.21479467403337263\n",
      "0.2662886677463014\n",
      "0.3338102940329528\n",
      "0.09932706060111796\n",
      "0.2158772087000234\n",
      "0.31183192769139334\n",
      "-0.014539536660416727\n",
      "0.20443761029516389\n",
      "-0.0838529214889796\n",
      "-0.13314571597956407\n",
      "0.16236793487399173\n",
      "0.06831173654691937\n",
      "0.18120497378448921\n",
      "0.16695011728903045\n",
      "0.00018700330422848077\n",
      "-0.1290864056120456\n",
      "0.18047279813385964\n",
      "0.11791573058228833\n",
      "-0.10951841928530726\n",
      "-0.008054012577256794\n",
      "0.02977244992877033\n",
      "0.023839415974817275\n",
      "-0.17876432458106148\n",
      "0.07512800628304452\n",
      "0.11429781201092189\n",
      "0.0042342671606262275\n",
      "-0.3284031966801678\n",
      "0.05567575955846624\n",
      "-0.26547064098803075\n",
      "0.1661351750824032\n",
      "0.15246925097626485\n",
      "-0.08516281748413367\n",
      "-0.12854170353535588\n",
      "-0.06546813760429623\n",
      "0.19355789064954326\n",
      "0.24049731803750937\n",
      "0.17680658305592342\n",
      "-0.1594426434804183\n",
      "0.07859664827237406\n",
      "-0.20195842267603908\n",
      "-0.011861810038468562\n",
      "-0.060371230356838015\n",
      "0.05741674963488226\n",
      "0.10969149962077136\n",
      "-0.04574470759256324\n",
      "-0.19378726559835793\n",
      "-0.1754097656294601\n",
      "0.03285558200074362\n",
      "0.05039410386734208\n",
      "0.1288015964854421\n",
      "0.033294946109898124\n",
      "0.17380618914065551\n",
      "0.3620441636444496\n",
      "0.26649098147393935\n",
      "0.4129493973053947\n",
      "0.2314000538296057\n",
      "0.07030668544505349\n",
      "0.306650031385981\n",
      "0.18419257993919722\n",
      "0.00908325440716052\n",
      "-0.007971350041333612\n",
      "0.29449130088325126\n",
      "0.35690612978539715\n",
      "0.1641131321723202\n",
      "0.014865695086229605\n",
      "0.02671809193528728\n",
      "0.19709501368767585\n",
      "0.13077086692778872\n",
      "0.03611448214845763\n",
      "-0.23560220757606554\n",
      "-0.22001257172289562\n",
      "-0.36322723026177595\n",
      "-0.0978794021476189\n",
      "0.14381053381202213\n",
      "0.11105664065785739\n",
      "0.1707372545914432\n",
      "0.3064262756602451\n",
      "0.2511376845114862\n",
      "-0.0051526436180276\n",
      "0.009593013410756466\n",
      "0.26774942443984573\n",
      "0.040334660698817464\n",
      "0.021386694252634134\n",
      "0.2952389480056856\n",
      "0.16844414785665585\n",
      "0.38043301369247007\n",
      "0.29776223833517335\n",
      "0.06627385084524923\n",
      "0.002078450881984273\n",
      "0.17216205215204697\n",
      "-0.024183654979146103\n",
      "0.03830675933590427\n",
      "0.1666859079620047\n",
      "-0.07816819149827445\n",
      "0.03399356464789974\n",
      "0.14845186842485583\n",
      "0.024154668767243943\n",
      "0.14685094416386818\n",
      "0.024685109109755785\n",
      "0.08345120462397074\n",
      "0.028101845265072516\n",
      "-0.012921572836773415\n",
      "0.10477109751614742\n",
      "0.1573070296402977\n",
      "-0.11207029470882923\n",
      "0.0024348279602297435\n",
      "0.05206612331011207\n",
      "0.11066542830252643\n",
      "0.1098745647048076\n",
      "-0.21439445125900125\n",
      "-0.07441609536453125\n",
      "0.02762622827068923\n",
      "-0.038113572459018454\n",
      "0.16986127727096034\n",
      "0.34757742952177484\n",
      "0.2742753177282628\n",
      "-0.017427999829658133\n",
      "0.21132989343259698\n",
      "0.07358856088460516\n",
      "0.21758057560917418\n",
      "0.20951625328643164\n",
      "-0.093834341425583\n",
      "0.15960832370989358\n",
      "0.1815758172955105\n",
      "-0.1316622297418492\n",
      "0.08521759684587756\n",
      "-0.03258346753210972\n",
      "0.27600085978180666\n",
      "0.20867632744504072\n",
      "-0.0062676840680885165\n",
      "-0.10181502613305927\n",
      "0.19509627190680373\n",
      "0.48106631058797134\n",
      "0.24351783668879176\n",
      "0.3099390509637004\n",
      "0.4385419675728475\n",
      "0.23077742881410962\n",
      "0.07684112407873928\n",
      "0.27130058705651966\n",
      "0.33863880581833306\n",
      "-0.02601545916458503\n",
      "0.1336514175749029\n",
      "0.08092861513721437\n",
      "0.16878500349151992\n",
      "0.20149667561344944\n",
      "0.36646869138124183\n",
      "0.39943632274924007\n",
      "0.3651783729507362\n",
      "0.051301214212168406\n",
      "0.1781147824968523\n",
      "0.36146367978595967\n",
      "0.21032652778377303\n",
      "0.13433591564947955\n",
      "0.08062080441391012\n",
      "0.20131866512957364\n",
      "0.3027454208603743\n",
      "0.25889823801328377\n",
      "0.2349345301181036\n",
      "-0.07237284168456327\n",
      "0.1634182962820887\n",
      "0.11260215967929402\n",
      "0.0714137814224472\n",
      "0.1894316864251344\n",
      "0.16525440380860745\n",
      "0.3036535488599892\n",
      "0.08435647291703674\n",
      "0.18842499473955554\n",
      "0.2896947608864475\n",
      "-0.05565428509322504\n",
      "0.042043459725806566\n",
      "0.06627695328872994\n",
      "0.2449926071874488\n",
      "0.00814041154203747\n",
      "0.13893912876591155\n",
      "0.08497269628143715\n",
      "0.14106196002433205\n",
      "0.07068003772807117\n",
      "0.10149345874187453\n",
      "0.04813760298856094\n",
      "-0.23700349568734008\n",
      "-0.21898119075129982\n",
      "-0.1455091400487309\n",
      "-0.016784176997011374\n",
      "0.11283970027758905\n",
      "0.12552528389454598\n",
      "0.2533648193449017\n",
      "0.10466930588735962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2133960872151801\n",
      "0.27681988899253135\n",
      "0.12377576458920413\n",
      "0.17587383534216644\n",
      "0.06325407040445735\n",
      "0.20235265804975572\n",
      "0.05087054262400931\n",
      "0.2508526858607499\n",
      "0.074994956765566\n",
      "0.1752961089263073\n",
      "0.08635536378227349\n",
      "0.10052458387051288\n",
      "-0.024974471745253683\n",
      "-0.13609280901766893\n",
      "0.020433725594630824\n",
      "0.14599328991982988\n",
      "0.10749556054632159\n",
      "0.13960283453323108\n",
      "0.056652094787437206\n",
      "0.045559170912900515\n",
      "0.17978626866783157\n",
      "-0.18113948454946022\n",
      "-0.02501867277714706\n",
      "0.25929471402019244\n",
      "0.1916278991714815\n",
      "-0.04821604822950182\n",
      "0.07899405873914328\n",
      "0.12526026328911696\n",
      "0.10575127024420429\n",
      "0.11220285591170488\n",
      "0.1273106206647312\n",
      "-0.1820856375590078\n",
      "-0.18212240324782208\n",
      "-0.031222844711862895\n",
      "-0.2247201686822508\n",
      "0.06730105114615553\n",
      "-0.2790959978580763\n",
      "-0.02762007825795551\n",
      "0.029373869362404416\n",
      "-0.08403968258232841\n",
      "-0.05043448771764369\n",
      "0.11161430515275879\n",
      "-0.0018879398624391877\n",
      "0.05837363231203522\n",
      "-0.020033635558954734\n",
      "0.05380532026144323\n",
      "0.2904803171874437\n",
      "0.10509484901379028\n",
      "0.16082920307746432\n",
      "0.4315709820570906\n",
      "0.22496823301415197\n",
      "-0.08385217379299344\n",
      "0.3159892066766374\n",
      "0.3185709805262882\n",
      "0.261407484910062\n",
      "-0.024084076805467827\n",
      "-0.06666996622606591\n",
      "-0.1365268812028325\n",
      "0.21609389941794457\n",
      "0.00967853857827318\n",
      "0.05965254916610531\n",
      "-0.1933957850749825\n",
      "-0.27220280030201127\n",
      "0.14083801109199906\n",
      "0.17392710351345134\n",
      "0.2549195845852551\n",
      "0.09853595928805547\n",
      "-0.12783949022198368\n",
      "0.12612593613482231\n",
      "-0.1171810856673435\n",
      "0.2762818325538574\n",
      "0.19666001543051362\n",
      "0.12140660034531252\n",
      "0.14659295051845828\n",
      "0.13034368614602232\n",
      "0.16352173829721006\n",
      "0.22198812973565438\n",
      "0.28082845714665317\n",
      "0.3976301965142882\n",
      "0.33406664796078145\n",
      "0.15150857615063684\n",
      "-0.03403458099319117\n",
      "0.030672643929651484\n",
      "-0.006898715279832129\n",
      "0.11780907571043846\n",
      "0.34357042566451723\n",
      "0.32689407633229794\n",
      "0.14558884281568252\n",
      "0.048758210340921114\n",
      "0.223969403679712\n",
      "0.1481926020912586\n",
      "-0.11923757444957213\n",
      "-0.1538700128468251\n",
      "0.25413144238598556\n",
      "0.20939119609954734\n",
      "0.13914382732133154\n",
      "0.04238631519007406\n",
      "-0.1531021640862073\n",
      "0.21388629303141304\n",
      "0.2441278232207107\n",
      "0.2516017501976963\n",
      "0.2926691624223271\n",
      "0.24593465433981188\n",
      "-0.05035727527325749\n",
      "0.17839689452748853\n",
      "0.027002412175207484\n",
      "-0.04080741860396142\n",
      "-0.09815037170485118\n",
      "0.1856804602620951\n",
      "0.18272698353900493\n",
      "-0.01963924991418875\n",
      "-0.14730220679379\n",
      "-0.21910694512948375\n",
      "-0.08100445763067796\n",
      "-0.013076094295054557\n",
      "0.052273581768711386\n",
      "0.3256902148639561\n",
      "0.02816758206794509\n",
      "-0.06750298655695958\n",
      "0.1418507844202984\n",
      "0.23710042798953973\n",
      "-0.03973653163432225\n",
      "0.3120527584375423\n",
      "0.3530037659576022\n",
      "0.25226147481066846\n",
      "-0.012318567240724346\n",
      "0.1732779892106156\n",
      "-0.12892879250140532\n",
      "-0.13471392666366538\n",
      "-0.06905346361942843\n",
      "-0.03628114281549731\n",
      "0.21887496522340438\n",
      "0.02530418230760978\n",
      "-0.11077476705494019\n",
      "-0.13972538816685048\n",
      "0.014980538483359375\n",
      "0.09201180323829516\n",
      "-0.06356079277450219\n",
      "0.13112581784766075\n",
      "0.10454185243664507\n",
      "-0.044434130482449506\n",
      "0.07942514384676717\n",
      "0.016322655801327014\n",
      "0.17302602745619602\n",
      "0.14579305517439942\n",
      "0.14535297644082196\n",
      "0.0862061681908774\n",
      "-0.18437314833849264\n",
      "0.10062690903524198\n",
      "0.015339025495436122\n",
      "-0.24883656684720618\n",
      "-0.09719906325863777\n",
      "0.18583188762689412\n",
      "0.0714352775838796\n",
      "0.18999415930118685\n",
      "-0.22492377799385335\n",
      "0.08958693061467092\n",
      "0.06851548634463851\n",
      "-0.06791278113072441\n",
      "-0.11831340655848663\n",
      "0.036364783261463265\n",
      "0.12709566004242812\n",
      "0.015852312107720028\n",
      "-0.28178276542551883\n",
      "-0.07839780395051459\n",
      "-0.11360784664517476\n",
      "-0.39249335951031045\n",
      "-0.3100588943031579\n",
      "-0.09456588735426819\n",
      "-0.1163839141331019\n",
      "0.2036496036557986\n",
      "0.18821496158094675\n",
      "0.10852080318903631\n",
      "0.3068656389959132\n",
      "0.09614006977309879\n",
      "-0.037754909577138306\n",
      "-0.0073316766115296104\n",
      "0.12851965759115952\n",
      "0.18013526045455666\n",
      "0.16012975991737663\n",
      "0.18971708562702957\n",
      "-0.08006458444262705\n",
      "0.07973963682275487\n",
      "0.15474902039952776\n",
      "0.21839395570394046\n",
      "0.09917128555486625\n",
      "0.0864801539311383\n",
      "0.10828384750765521\n",
      "-0.06752072480563501\n",
      "-0.1773480120672904\n",
      "-0.06008031477023776\n",
      "-0.029911613222113963\n",
      "-0.10747035120900071\n",
      "0.013196040456084454\n",
      "0.09650307912908636\n",
      "0.31186402908142935\n",
      "0.398163881666519\n",
      "0.12944973025696865\n",
      "0.16898150499608708\n",
      "-0.058879567319473206\n",
      "0.11350233817292255\n",
      "0.35945424641370893\n",
      "0.4060160099197804\n",
      "-0.004690844575401032\n",
      "0.09791660404711085\n",
      "0.27397636390847985\n",
      "0.04663274600411843\n",
      "0.20501304668544892\n",
      "0.3149289012112545\n",
      "-0.15321925881641452\n",
      "-0.033517781289826534\n",
      "0.07957072328989857\n",
      "0.2618700763620832\n",
      "-0.038941933644421375\n",
      "-0.14567295775896208\n",
      "-0.035886168958994095\n",
      "0.08281109559297814\n",
      "0.31893033293253414\n",
      "0.3069575198104446\n",
      "0.25871460541986513\n",
      "0.03346734510151758\n",
      "0.21153052811682227\n",
      "0.3306811318237026\n",
      "0.15905550407118357\n",
      "-0.06268676140978428\n",
      "-0.025205137508526543\n",
      "0.2364990354752587\n",
      "-0.0008188268796408757\n",
      "0.2830350404425175\n",
      "0.11471231555922257\n",
      "0.09479454894213506\n",
      "0.001529101148956373\n",
      "-0.2677304337689183\n",
      "-0.24118432679266877\n",
      "-0.2741572408793391\n",
      "-0.043455576379193464\n",
      "0.07220207288126539\n",
      "0.2644727399015606\n",
      "0.1843579200525272\n",
      "0.2715263762570282\n",
      "0.3909323932215833\n",
      "0.19842590625601822\n",
      "0.2810663948014124\n",
      "0.0909858058025626\n",
      "0.384293212004472\n",
      "0.3837289342352856\n",
      "0.32327153166012007\n",
      "0.2727873213511684\n",
      "0.003725282391575574\n",
      "0.28450656442763333\n",
      "0.298381170896514\n",
      "0.17077176304031733\n",
      "-0.050632161754219085\n",
      "0.07318175716126363\n",
      "-0.07508293191154655\n",
      "-0.16161537317155558\n",
      "-0.13334755059235454\n",
      "0.13843977511488842\n",
      "0.03909087537479249\n",
      "0.11362819199346177\n",
      "0.34926992678331303\n",
      "0.42320490119846094\n",
      "0.5422310094730461\n",
      "0.5033764867554489\n",
      "0.13129239974227727\n",
      "0.057521108319534026\n",
      "0.24257749586730531\n",
      "0.13033177082623854\n",
      "0.3448117344895121\n",
      "0.4379351161747747\n",
      "0.4868148052015324\n",
      "0.37849309285765054\n",
      "0.4779480649102459\n",
      "0.44498267829806804\n",
      "0.23374978533194718\n",
      "0.2824330538617873\n",
      "0.2891585364921001\n",
      "0.12034196527495686\n",
      "0.00822313638701739\n",
      "0.23988237394294906\n",
      "0.30807903228038674\n",
      "-0.02615156535040046\n",
      "-0.09045578608058878\n",
      "-0.09835440205544244\n",
      "0.1137169377890902\n",
      "-0.1169093583912829\n",
      "0.024727032410641094\n",
      "-0.056104973645287576\n",
      "-0.14958463546901182\n",
      "0.009333133439826669\n",
      "0.1108573764140384\n",
      "0.08208229709653123\n",
      "0.05261515372394125\n",
      "0.044688596396195414\n",
      "-0.03265331936907709\n",
      "0.17949658159509718\n",
      "-0.13757727829317168\n",
      "-0.12275224678552948\n",
      "-0.15456044435834723\n",
      "-0.05068210948409639\n",
      "-0.014908678372920245\n",
      "-0.07124245392310503\n",
      "-0.038587178306211826\n",
      "-0.09668033461135324\n",
      "-0.1543120060768295\n",
      "-0.04106030068487229\n",
      "-0.1071159858754766\n",
      "0.026845490753308186\n",
      "0.050514714571290795\n",
      "0.008891043735183075\n",
      "-0.04461640678365496\n",
      "0.012018124599732258\n",
      "-0.19620525673421801\n",
      "0.01865638688958469\n",
      "-0.21894590024148256\n",
      "0.15575976263158892\n",
      "0.148234757525141\n",
      "0.07810311805670653\n",
      "0.1990470472680046\n",
      "0.001281535648457191\n",
      "0.2468813654183297\n",
      "-0.029857406690270122\n",
      "0.1381602754002731\n",
      "-0.11713413024163338\n",
      "-0.050329319008788856\n",
      "-0.059273780841351834\n",
      "0.021577353827479065\n",
      "0.053469965819783555\n",
      "-0.20237239821846764\n",
      "-0.18075337905244743\n",
      "-0.22482271097435008\n",
      "-0.2064537975442893\n",
      "-0.3024065731298571\n",
      "-0.3347598198632078\n",
      "-0.3172243667453133\n",
      "-0.42085965045614093\n",
      "0.020452987374680598\n",
      "-0.16687067523879184\n",
      "-0.08969946275468571\n",
      "-0.12458878330405182\n",
      "0.012356354807398794\n",
      "-0.1854236589134947\n",
      "0.1477958857406773\n",
      "0.25702139816430525\n",
      "0.0944771818366156\n",
      "-0.1166603104701041\n",
      "-0.008538111564093509\n",
      "-0.14305868395719673\n",
      "0.0876593025122396\n",
      "-0.04627652358227896\n",
      "-0.11067091056343006\n",
      "-0.017495272606070103\n",
      "-0.10950992106757747\n",
      "-0.12634566657273213\n",
      "-0.12167104681871033\n",
      "-0.20173706994914123\n",
      "-0.07262996336844887\n",
      "-0.35586669842918445\n",
      "-0.292306455878657\n",
      "-0.12510499353247215\n",
      "-0.07925340382303464\n",
      "-0.021757698582593295\n",
      "-0.06631808134881076\n",
      "-0.005051889011045994\n",
      "-0.04034163997460464\n",
      "0.029602466922047578\n",
      "-0.22947718990121008\n",
      "-0.19929531757412525\n",
      "-0.20755176469663028\n",
      "0.14822770103411348\n",
      "-0.05143180085421922\n",
      "-0.10930304138714425\n",
      "-0.19486611487599453\n",
      "-0.023616184324611145\n",
      "-0.017110204087906207\n",
      "0.10079222605464562\n",
      "0.12238028866381044\n",
      "0.21918569544602215\n",
      "0.2833643617092247\n",
      "0.10003488205978296\n",
      "-0.07524122184857421\n",
      "-0.013619520160616714\n",
      "-0.06834383205937083\n",
      "0.09547294264216362\n",
      "0.04625227656045887\n",
      "0.32474939725869895\n",
      "0.2811627477837915\n",
      "0.20979834501889597\n",
      "0.014152106219541292\n",
      "-0.13689652826548476\n",
      "0.05612524225728278\n",
      "-0.24589441479418916\n",
      "-0.34251397117987065\n",
      "-0.3735703498711904\n",
      "-0.294507313857365\n",
      "-0.21713204965421676\n",
      "-0.11867556170628359\n",
      "-0.2888960630643872\n",
      "-0.2257545782051143\n",
      "-0.026723367287007103\n",
      "0.015478394664768887\n",
      "-0.3106620273453659\n",
      "-0.30188018711621967\n",
      "-0.2790762411554775\n",
      "-0.39930599072092826\n",
      "-0.21551971916955734\n",
      "-0.43856661127013286\n",
      "-0.4469633425935704\n",
      "-0.21201609509180835\n",
      "-0.23017732500382632\n",
      "-0.1841865883230737\n",
      "-0.08643633999722737\n",
      "-0.18977728696046017\n",
      "-0.18282276023721133\n",
      "-0.0764469926256327\n",
      "-0.2830926271086808\n",
      "-0.2899409920196386\n",
      "-0.16279353918154033\n",
      "-0.17777789628103072\n",
      "0.13867275414104233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.139486813816117\n",
      "-0.016935065847030542\n",
      "-0.0992463012997696\n",
      "0.15483317950243597\n",
      "0.03616917272804613\n",
      "-0.05560805063977362\n",
      "0.3085911403722784\n",
      "0.030024760157834465\n",
      "0.17067513217518165\n",
      "0.09149340657173527\n",
      "-0.07256514509065815\n",
      "-0.021466261252052532\n",
      "-0.07185388717757904\n",
      "0.2240207705877839\n",
      "0.28183970703829087\n",
      "0.14614646827817823\n",
      "0.155433359204959\n",
      "-0.06208025957379932\n",
      "-0.011132164258187298\n",
      "0.07579015543077963\n",
      "0.20011372956111023\n",
      "0.12719762250328487\n",
      "-0.03929725252460921\n",
      "-0.13441413881234257\n",
      "-0.0820449641445849\n",
      "0.003923774103479473\n",
      "-0.33208509240732687\n",
      "-0.25174186159352374\n",
      "-0.05896344071124339\n",
      "0.03426265979719525\n",
      "0.11021479179293195\n",
      "0.08550550712431931\n",
      "0.13220840405904152\n",
      "0.08814607022868656\n",
      "0.11268633572297648\n",
      "-0.14335098630960852\n",
      "-0.17474320703028867\n",
      "-0.19283154454148957\n",
      "0.11369731749422478\n",
      "-0.02675439363770276\n",
      "-0.08527169090562617\n",
      "-0.017549060557933576\n",
      "-0.17203153280845365\n",
      "-0.16696028143996447\n",
      "-0.08736138389139972\n",
      "0.03530628903614376\n",
      "-0.13332288996677774\n",
      "0.08999813177801644\n",
      "0.20025521105779162\n",
      "0.12975850298381303\n",
      "-0.02347998208065789\n",
      "-0.011052406360144823\n",
      "0.24227436975397992\n",
      "0.004928177419620594\n",
      "0.18606923889455457\n",
      "0.03330446864105102\n",
      "0.10068877531804324\n",
      "0.3699929165964362\n",
      "0.3774887343930349\n",
      "0.1473234935906132\n",
      "0.13736212785578766\n",
      "0.19628958888943326\n",
      "0.25437779127423354\n",
      "0.3444528997982373\n",
      "0.3225993126954601\n",
      "0.09125617760887514\n",
      "0.14530564475311053\n",
      "0.2871073980479728\n",
      "0.13566429785540177\n",
      "0.3863320363888497\n",
      "0.15473293902839547\n",
      "0.17872550285164943\n",
      "0.14853960053402449\n",
      "0.15411051287727764\n",
      "0.23549378642592178\n",
      "0.4264422103610334\n",
      "0.29373199293734903\n",
      "0.3857084586518037\n",
      "0.36579128369011893\n",
      "0.1379952423395123\n",
      "0.07937111084943434\n",
      "0.31520083882909755\n",
      "0.28557811912638575\n",
      "0.3868990342221351\n",
      "0.16694107144322773\n",
      "0.27121801136617124\n",
      "0.4219703915838314\n",
      "0.2044040339329753\n",
      "0.3901966149622512\n",
      "0.13597502734404307\n",
      "0.32682313997275353\n",
      "0.45914299540467274\n",
      "0.5027168798255979\n",
      "0.3007262765355329\n",
      "0.2522439439189817\n",
      "0.45455370673699047\n",
      "0.5980179565265382\n",
      "0.5596265761989034\n",
      "0.47905737479537536\n",
      "0.5909482385294698\n",
      "0.6048699195605494\n",
      "0.43724182178825305\n",
      "0.37791168715266477\n",
      "0.3969529405986977\n",
      "0.6079458775162696\n",
      "0.47613966726837015\n",
      "0.49650588897012005\n",
      "0.26156870467672694\n",
      "0.22028141582027855\n",
      "0.4042274257926461\n",
      "0.3234170454678159\n",
      "0.32315368713785897\n",
      "0.40788140046175797\n",
      "0.5030885506325772\n",
      "0.4184784589941446\n",
      "0.47895932400782276\n",
      "0.5995516575950403\n",
      "0.4559281800904015\n",
      "0.5438271612989624\n",
      "0.6132149284780951\n",
      "0.540277153550061\n",
      "0.5671585808809546\n",
      "0.6223547255411224\n",
      "0.7873309968444283\n",
      "0.8172782359575006\n",
      "0.8178776080910345\n",
      "0.6509611961338342\n",
      "0.7882339951880051\n",
      "0.4849786854826862\n",
      "0.5482913709506744\n",
      "0.5556380256412621\n",
      "0.5532075098707199\n",
      "0.4262727356777374\n",
      "0.4880699617963224\n",
      "0.5094515568976631\n",
      "0.5917585891204192\n",
      "0.44010432133483907\n",
      "0.5145255657526736\n",
      "0.5631743408070564\n",
      "0.6959582923550919\n",
      "0.8268555818043992\n",
      "0.8146539322228623\n",
      "0.5218300200186973\n",
      "0.44524603225720916\n",
      "0.6073457383986768\n",
      "0.513685428797286\n",
      "0.6526938677216394\n",
      "0.546396805875068\n",
      "0.5899615564439276\n",
      "0.743047234722327\n",
      "0.8445856332859497\n",
      "0.5797046034436836\n",
      "0.5380171740188538\n",
      "0.5493222083884385\n",
      "0.6025304259046717\n",
      "0.6533707357739489\n",
      "0.6974433616236874\n",
      "0.710361129622158\n",
      "0.5981592644999362\n",
      "0.616442163439026\n",
      "0.763411317984327\n",
      "0.7429953934104943\n",
      "0.7635948514785914\n",
      "0.8264713704435221\n",
      "0.7729699160802141\n",
      "0.8745805529940813\n",
      "1.028022737464402\n",
      "1.0191586061340137\n",
      "1.1562695014393793\n",
      "0.8678622718996645\n",
      "0.8200918388591971\n",
      "0.8374584550572346\n",
      "0.8951118534527088\n",
      "0.9155931964493966\n",
      "0.9516205751687468\n",
      "1.0578623198859116\n",
      "0.9285660185753382\n",
      "0.8255265630061931\n",
      "0.7160573463333425\n",
      "0.7846384005812219\n",
      "0.918700019940305\n",
      "0.851997481266534\n",
      "0.8618379979602819\n",
      "1.038056806721028\n",
      "0.8584935631394037\n",
      "0.9290456980081524\n",
      "0.8611635721457817\n",
      "0.8794854514648888\n",
      "0.8924613827181015\n",
      "1.1416546307742523\n",
      "0.9098936157301047\n",
      "0.8497503859457903\n",
      "0.9019480221834486\n",
      "0.9461068558514721\n",
      "0.9879599549798027\n",
      "1.0025931615354395\n",
      "0.9093868964243962\n",
      "0.8990381542264271\n",
      "1.0330258503627254\n",
      "0.9895328123407876\n",
      "1.163776908878033\n",
      "1.0192044687649369\n",
      "0.9444415935848286\n",
      "1.0820474477249868\n",
      "0.9442678827718638\n",
      "0.9483892740425802\n",
      "0.9811036846762895\n",
      "0.9857633046783362\n",
      "0.8965876529026418\n",
      "0.8668583382647854\n",
      "0.8712582331148508\n",
      "1.0727066440415958\n",
      "0.8693059595771232\n",
      "1.0741878128187003\n",
      "1.0604272633074687\n",
      "1.0194774224898098\n",
      "0.9552495852109707\n",
      "0.8931289186184863\n",
      "0.8845222717926741\n",
      "0.8346015242275898\n",
      "0.8539005338160397\n",
      "0.8883924480507299\n",
      "0.7902452205137223\n",
      "0.8292326636787317\n",
      "0.9334162483589084\n",
      "1.0214420456851079\n",
      "0.9611372590440244\n",
      "1.1039380571792545\n",
      "1.1020967783078355\n",
      "1.197384923474456\n",
      "1.1892239356061955\n",
      "0.9906659380543307\n",
      "0.9879929509889587\n",
      "1.1461110020608247\n",
      "0.9244813490970261\n",
      "1.0447382383802946\n",
      "0.9990549120517404\n",
      "1.0026415958473176\n",
      "0.9701154868744074\n",
      "1.083808527539888\n",
      "1.2350867000984747\n",
      "1.0763070916638229\n",
      "1.0314666641967352\n",
      "1.1767635699880465\n",
      "1.4076860820907644\n",
      "1.3597431751508766\n",
      "1.1927639733205406\n",
      "1.171244032688097\n",
      "1.3898077770473543\n",
      "1.244219014536948\n",
      "1.2464558369576726\n",
      "1.1516710672124904\n",
      "1.0919146891104672\n",
      "1.2415681506940617\n",
      "1.4575986371713454\n",
      "1.1877394199090359\n",
      "1.3767604736629784\n",
      "1.4488500831065385\n",
      "1.1804942997778105\n",
      "1.123141144738458\n",
      "1.0930452819917165\n",
      "1.063387316245747\n",
      "1.3101837879571905\n",
      "1.0140746631875497\n",
      "1.0984100553406215\n",
      "1.0940995286378683\n",
      "1.1935761072843527\n",
      "0.872488872607378\n",
      "0.9899776917982515\n",
      "0.9808580355346649\n",
      "0.9119887265469562\n",
      "1.1166929231076481\n",
      "0.9556850000250039\n",
      "0.9547893601044127\n",
      "1.10896657414223\n",
      "1.1691101779235933\n",
      "0.9006285202638551\n",
      "0.9251541159745642\n",
      "0.9241334305526809\n",
      "0.8740150231396862\n",
      "0.8494822616662485\n",
      "0.8759333460741751\n",
      "1.013538782211035\n",
      "0.9024809213273544\n",
      "0.8313082838033252\n",
      "0.8190181833318434\n",
      "0.9018977076500769\n",
      "0.9513389714955621\n",
      "0.9761368479258323\n",
      "0.9708196922561504\n",
      "0.9614477106967265\n",
      "0.9464421671142101\n",
      "0.8953566546986517\n",
      "0.875886445477705\n",
      "0.8885491997136942\n",
      "0.8766640985058339\n",
      "1.1072212593914612\n",
      "0.9502441713643014\n",
      "0.856195065513679\n",
      "0.8022780639168899\n",
      "0.8270937848472074\n",
      "0.7911947068956544\n",
      "0.7936639122844832\n",
      "0.8006813904216146\n",
      "1.0502228340876867\n",
      "0.9530753965077858\n",
      "0.9822600990630092\n",
      "0.9006649768824335\n",
      "0.8890283123514287\n",
      "0.8705263499420315\n",
      "0.8567654106257665\n",
      "0.845084297271837\n",
      "0.9070131197092485\n",
      "0.9565161143629418\n",
      "1.047621813227345\n",
      "1.0693732428161378\n",
      "1.0769598112518866\n",
      "1.030844765722405\n",
      "1.2027570687600317\n",
      "1.0651872764858705\n",
      "0.9946305914704988\n",
      "1.1573386874287384\n",
      "1.07707075424336\n",
      "1.0354577313401077\n",
      "1.029634565921712\n",
      "0.9919882031632983\n",
      "0.8696877694362282\n",
      "0.8144392198457953\n",
      "0.8043379226457533\n",
      "0.8024631147015239\n",
      "0.6564041620644989\n",
      "0.5927066046398197\n",
      "0.6217801644173074\n",
      "0.6704210034314886\n",
      "0.5100456082916422\n",
      "0.49949609023549607\n",
      "0.5010336868985213\n",
      "0.4974192504320451\n",
      "0.3475837171966774\n",
      "0.384316254278704\n",
      "0.34454457626009816\n",
      "0.43325689766170145\n",
      "0.40523918428525313\n",
      "0.39201851302923096\n",
      "0.43843538592950776\n",
      "0.3546220298588812\n",
      "0.26439464584763217\n",
      "0.2686604156078084\n",
      "0.2528051794581902\n",
      "0.09042194823251054\n",
      "0.03835906165080147\n",
      "0.20587661043335084\n",
      "0.18453997847611486\n",
      "0.13807342751029245\n",
      "0.15973523399779885\n",
      "0.04736210810854402\n",
      "0.07892024807751526\n",
      "0.1219545359103315\n",
      "0.23447227038818458\n",
      "0.17916275379933758\n",
      "0.18382492499483127\n",
      "0.18646818471396465\n",
      "-0.014173445382373556\n",
      "0.14440176562818074\n",
      "0.04702523551927695\n",
      "0.06652359682293507\n",
      "0.23314924370730034\n",
      "0.17506467562636274\n",
      "0.15959191347535992\n",
      "0.15202075030157267\n",
      "0.0039105103138130926\n",
      "-0.3507996808449405\n",
      "-0.5497935364146669\n",
      "-0.5522632259463418\n",
      "-0.49878116633595315\n",
      "-0.43683747290126246\n",
      "-0.4408949799149147\n",
      "-0.3611889495601629\n",
      "-0.22628347674229063\n",
      "0.00818251590016418\n",
      "-0.05411814037775816\n",
      "-0.27947137453139886\n",
      "-0.28429578962696056\n",
      "-0.2662682192408097\n",
      "-0.28700045447908035\n",
      "-0.28313899103610335\n",
      "-0.28181172917849967\n",
      "-0.2493145022708494\n",
      "0.0009968543848068098\n",
      "-0.08581333478613432\n",
      "-0.07120259373634844\n",
      "-0.09519590165191948\n",
      "-0.08456112463690378\n",
      "0.0033112374455568916\n",
      "0.20484316792976692\n",
      "-0.009311639125636637\n",
      "0.014606618308506153\n",
      "-0.023141221486642976\n",
      "0.033211442750607195\n",
      "0.15674795315942394\n",
      "0.14492577594557884\n",
      "-0.01436859231792454\n",
      "0.14819712835400314\n",
      "0.34008247419358856\n",
      "0.08380833865484687\n",
      "0.016828778037980052\n",
      "0.05541403156471209\n",
      "0.0036593137775883453\n",
      "-0.03755481406230897\n",
      "0.03527103767444362\n",
      "0.05494838867806052\n",
      "0.14179302552711204\n",
      "0.12770671439096742\n",
      "0.11624238208458094\n",
      "0.12705597442904498\n",
      "0.04577261981903713\n",
      "0.013716378272079862\n",
      "-0.013320721097501691\n",
      "0.008060977634308051\n",
      "0.06323755266001642\n",
      "0.15717641743796257\n",
      "0.21447280523742843\n",
      "0.30961393776655083\n",
      "0.37284615743218436\n",
      "0.4002914465640062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47032911052269366\n",
      "0.39050737948396985\n",
      "0.23104665734725255\n",
      "0.14100670921235353\n",
      "0.15186130784937804\n",
      "0.2013470416081396\n",
      "0.12962527836240403\n",
      "0.025907035329457394\n",
      "0.11297649182975902\n",
      "0.09071423232053742\n",
      "0.1274293382040957\n",
      "0.12650364605124936\n",
      "0.11387090215444146\n",
      "0.0659955327564856\n",
      "0.005858923524863245\n",
      "0.02552702870101844\n",
      "0.0023123920530475385\n",
      "0.09920943196103775\n",
      "0.07186466424620996\n",
      "0.1316898463839737\n",
      "0.23793626751394087\n",
      "0.30177541468978697\n",
      "0.3884532315385338\n",
      "0.48466233693498173\n",
      "0.5146360926615239\n",
      "0.8147219281659588\n",
      "0.5900235241746032\n",
      "0.5841635347431866\n",
      "0.49195231014359064\n",
      "0.4385075355470873\n",
      "0.38969214097442945\n",
      "0.41214458147057964\n",
      "0.40162976342496925\n",
      "0.4089127287826823\n",
      "0.4306938840942991\n",
      "0.40487065412983936\n",
      "0.43870105298195866\n",
      "0.3885008352869794\n",
      "0.38598621805880845\n",
      "0.3469115568999493\n",
      "0.2974321465823142\n",
      "0.32082772233228257\n",
      "0.28242812698188396\n",
      "0.22783359574168363\n",
      "0.19550575231567155\n",
      "0.19179089106654743\n",
      "0.15756695166685097\n",
      "0.14784497587164028\n",
      "0.19804048455253065\n",
      "0.17906255661830356\n",
      "0.17055426416917366\n",
      "0.20685640744527703\n",
      "0.24559076758677711\n",
      "0.16911725802974875\n",
      "0.08794253428280194\n",
      "0.02017814776187895\n",
      "0.008655027958836853\n",
      "0.03454358471784722\n",
      "-0.005095844982537758\n",
      "0.016701083949744483\n",
      "-0.048565166617933225\n",
      "-0.038621002614573116\n",
      "-0.06759850536624247\n",
      "-0.062282212487567705\n",
      "-0.009719949945275724\n",
      "-0.006941156560276388\n",
      "0.029181876532839653\n",
      "0.07748813786244774\n",
      "0.037776170750378466\n",
      "-0.0003316530461785379\n",
      "-0.043653359023279256\n",
      "-0.08179151370585694\n",
      "-0.09355630021900829\n",
      "-0.09449813471856307\n",
      "-0.08175822644662824\n",
      "-0.09731739736451968\n",
      "-0.14268276108885913\n",
      "-0.18687783101952213\n",
      "-0.10225999396438029\n",
      "-0.15809153671687157\n",
      "-0.11838285994322889\n",
      "-0.17494185971488302\n",
      "-0.20159646963106065\n",
      "-0.18629176384487153\n",
      "-0.14222218346915785\n",
      "-0.1826195079382536\n",
      "-0.2158954211981303\n",
      "-0.18438713141509946\n",
      "-0.21152698138008466\n",
      "-0.23853650687286101\n",
      "-0.2766129625928284\n",
      "-0.2725278871513747\n",
      "-0.234281997460155\n",
      "-0.2509214946645748\n",
      "-0.21435784644615932\n",
      "-0.23203342015283518\n",
      "-0.25787205776845185\n",
      "-0.24655393325575567\n",
      "-0.20562650492355092\n",
      "-0.2481284171863538\n",
      "-0.2940712609210665\n",
      "-0.2892436676854651\n",
      "-0.29500074924619263\n",
      "-0.09711306124645994\n",
      "-0.25747470375425285\n",
      "-0.24555214890753624\n",
      "-0.28550563528458506\n",
      "-0.29437674103853934\n",
      "-0.2440999148036525\n",
      "-0.25171964703968025\n",
      "-0.21827656195355402\n",
      "-0.20491851172264855\n",
      "-0.20810141888394265\n",
      "0.03702342878896604\n",
      "-0.04931155607098195\n",
      "-0.09628447748556623\n",
      "-0.10481539296187445\n",
      "-0.09292529428677929\n",
      "-0.12225288679584341\n",
      "-0.127657869761323\n",
      "-0.18237036418516842\n",
      "-0.19790049131048776\n",
      "-0.2182894459937973\n",
      "-0.21921194316225037\n",
      "-0.2533900510717012\n",
      "-0.19353509920831774\n",
      "-0.20128110537374178\n",
      "-0.3010594080755765\n",
      "-0.3096079918690239\n",
      "-0.3517681418305118\n",
      "-0.3854879880819745\n",
      "-0.4023595616075462\n",
      "-0.3834917200623676\n",
      "-0.363507150465553\n",
      "-0.35671730731523005\n",
      "-0.4899680724981349\n",
      "-0.5146673766524871\n",
      "-0.5111702076093838\n",
      "-0.48770468388573757\n",
      "-0.5273638427243162\n",
      "-0.5161570949626892\n",
      "-0.5123384281461295\n",
      "-0.521412332902736\n",
      "-0.4900794320611805\n",
      "-0.4388612529241017\n",
      "-0.3992501744748337\n",
      "-0.3219600590743638\n",
      "-0.3161567252017777\n",
      "-0.30574197586430246\n",
      "-0.31115830452421245\n",
      "-0.2824584177286044\n",
      "-0.27287104034588494\n",
      "-0.3176630931794931\n",
      "-0.2725605847459425\n",
      "-0.24860214577652753\n",
      "-0.2366413356240075\n",
      "-0.21329535317110526\n",
      "-0.2253328273222386\n",
      "-0.19401593369886638\n",
      "-0.1952485187411399\n",
      "-0.17568227608475567\n",
      "-0.13267854043900007\n",
      "-0.14671481657273575\n",
      "-0.17746443057508196\n",
      "-0.2082698388066599\n",
      "-0.22792183802026056\n",
      "-0.22805591347515955\n",
      "-0.19560219200721718\n",
      "-0.16597843049077987\n",
      "-0.14764180465262883\n",
      "-0.16346031413003492\n",
      "-0.12621859954733777\n",
      "-0.11353885527859789\n",
      "-0.06900565876537826\n",
      "-0.06491336973450605\n",
      "-0.08195304626256095\n",
      "-0.027414993282982306\n",
      "-0.04969960290040066\n",
      "-0.029992876720803474\n",
      "-0.025091738744693594\n",
      "0.0017481275438430647\n",
      "0.04685507404033516\n",
      "0.021541294330585548\n",
      "0.041476901630592436\n",
      "0.05350984497199728\n",
      "0.09300835332707462\n",
      "0.0777805746374402\n",
      "0.07082143353278099\n",
      "0.0788729718682535\n",
      "0.10065283654532353\n",
      "0.12292438912909563\n",
      "0.09978527040484686\n",
      "0.09097123065839807\n",
      "0.12017623800736636\n",
      "0.13600945082793106\n",
      "0.1491583262996866\n",
      "0.11989349070453886\n",
      "0.1474947096798074\n",
      "0.16789049348813373\n",
      "0.18439019387798233\n",
      "0.20091946292143856\n",
      "0.20808365581458882\n",
      "-0.003688275132736345\n",
      "-0.12088217652442589\n",
      "-0.2711307542189432\n",
      "0.08353875234564948\n",
      "-0.09031747691375278\n",
      "-0.09547507784066803\n",
      "-0.16546114396752118\n",
      "-0.05416537134980712\n",
      "0.26971883007519487\n",
      "0.2589087225704774\n",
      "-0.2363152368646975\n",
      "-0.3931714679865933\n",
      "-0.3177064214161441\n",
      "-0.0635968196600101\n",
      "-0.19147131202860848\n",
      "0.014063903220338153\n",
      "0.07148221322195362\n",
      "0.1677128815088833\n",
      "0.4232243605224\n",
      "0.1206302306394555\n",
      "0.2061517986686338\n",
      "0.4681378234119229\n",
      "0.09018331954501338\n",
      "0.38860703041616623\n",
      "0.10261670650040317\n",
      "0.25258763509544574\n",
      "-0.2525462850110891\n",
      "0.013535114560087241\n",
      "-0.09423887375643772\n",
      "-0.12075655119099679\n",
      "-0.3074406432090362\n",
      "-0.1102409021038469\n",
      "0.12794607642683423\n",
      "-0.13941779866536533\n",
      "-0.24316658344806516\n",
      "-0.17310289582339772\n",
      "-0.007462685834579361\n",
      "0.018390955797323992\n",
      "-0.06587430402371122\n",
      "-0.054609667952438955\n",
      "-0.30440266635567625\n",
      "-0.3046596812294857\n",
      "-0.42745035237058454\n",
      "-0.13068052304420044\n",
      "-0.13825711669561566\n",
      "-0.17254424837000165\n",
      "0.01763363731378819\n",
      "-0.28529378486249574\n",
      "-0.3908712839728538\n",
      "-0.06011460151953346\n",
      "0.0006907410017661514\n",
      "-0.013129043040196166\n",
      "-0.0005857112604661235\n",
      "-0.008201689886090314\n",
      "-0.02933382376719926\n",
      "-0.40959474554040504\n",
      "-0.33376905190952444\n",
      "-0.10365564422478696\n",
      "-0.4356673763930565\n",
      "-0.4365794234674697\n",
      "-0.2163849954738425\n",
      "-0.4886905923659178\n",
      "-0.4322187063876121\n",
      "-0.28469963070521653\n",
      "-0.47942848747047595\n",
      "-0.46283063863695767\n",
      "-0.33543923633362543\n",
      "-0.3707775075307731\n",
      "-0.7218024553829715\n",
      "-0.2061790760287633\n",
      "-0.5233593269207599\n",
      "-0.2149692306475044\n",
      "-0.322040297536212\n",
      "-0.4825163291350433\n",
      "-0.23076442234225422\n",
      "-0.39769309363222816\n",
      "-0.20558567333388966\n",
      "-0.21114559726577667\n",
      "-0.23546361851728034\n",
      "-0.4438070059235974\n",
      "-0.4981346051418372\n",
      "-0.5575863628280876\n",
      "-0.4252463875893193\n",
      "-0.4187877457213866\n",
      "-0.3652621308710094\n",
      "-0.049770719165248695\n",
      "-0.12105645871876188\n",
      "-0.028456983534861188\n",
      "-0.14655666291503727\n",
      "-0.12825649776201142\n",
      "-0.3418334223773366\n",
      "-0.20177105458861663\n",
      "-0.19853139071537457\n",
      "-0.10643403222959219\n",
      "-0.048608108499971825\n",
      "-0.4747956346588732\n",
      "-0.16162578636733807\n",
      "-0.14695126026670807\n",
      "-0.3882179650232715\n",
      "-0.5050094167067097\n",
      "-0.49335660604257836\n",
      "-0.3443718499264083\n",
      "-0.3522987973826927\n",
      "-0.32506982594555345\n",
      "-0.5734460109950302\n",
      "-0.1819495890824772\n",
      "-0.23667251380025378\n",
      "-0.5408203184980095\n",
      "-0.5650602838932054\n",
      "-0.4987216155597863\n",
      "-0.6235472094604018\n",
      "-0.5495004466716255\n",
      "-0.5376030693456934\n",
      "-0.8491916144999769\n",
      "-0.8496500949949167\n",
      "-0.5834670679200351\n",
      "-0.3963940957041163\n",
      "-0.5340567972936159\n",
      "-0.8476425658253334\n",
      "-0.690295213775195\n",
      "-0.7206883276857593\n",
      "-0.7422858079814788\n",
      "-0.8824188580587173\n",
      "-1.0124583423851006\n",
      "-1.0000114881818323\n",
      "-0.7528367564457088\n",
      "-0.6843694668207363\n",
      "-0.724518625427936\n",
      "-0.8460386689295902\n",
      "-0.7502635299285465\n",
      "-0.6108973274756188\n",
      "-0.5781199070839649\n",
      "-0.6161026368389096\n",
      "-0.6182352423806199\n",
      "-0.5793433186665219\n",
      "-0.39902823150054145\n",
      "-0.7652224622939818\n",
      "-0.7082782904167358\n",
      "-0.5226820374791218\n",
      "-0.614383570365644\n",
      "-0.5552270762574081\n",
      "-0.6525464849309073\n",
      "-0.5914060097934799\n",
      "-0.6173577142082073\n",
      "-0.585203292211251\n",
      "-0.4406043281419826\n",
      "-0.6112474614759041\n",
      "-0.5669877156035094\n",
      "-0.43173462242319455\n",
      "-0.41150926230515383\n",
      "-0.37419719074979885\n",
      "-0.42416658185096195\n",
      "-0.31670595965791026\n",
      "-0.566911195965571\n",
      "-0.7377471521540544\n",
      "-0.3824902631655775\n",
      "-0.35650280759949915\n",
      "-0.36642229478976346\n",
      "-0.3443097009190869\n",
      "-0.37529172014980755\n",
      "-0.42567452275508333\n",
      "-0.9532913470817933\n",
      "-0.7621567537268842\n",
      "-0.4614736490271313\n",
      "-0.8401621763659441\n",
      "-1.141923616576371\n",
      "-0.9936770750776812\n",
      "-0.8833908217875517\n",
      "-0.8942933858388553\n",
      "-0.9637299910516298\n",
      "-1.1852026223479653\n",
      "-1.1533461212067628\n",
      "-0.9916720872949863\n",
      "-1.0786994059718584\n",
      "-1.028449947831627\n",
      "-0.8633519107522309\n",
      "-1.008046158338326\n",
      "-0.7828788931156107\n",
      "-0.6519153845368446\n",
      "-0.4719772438964697\n",
      "-0.5497728255048687\n",
      "-0.6072745853603583\n",
      "-0.8851447224319872\n",
      "-0.7749098133151018\n",
      "-0.9702062278001562\n",
      "-0.7567688185395808\n",
      "-0.7464887116439975\n",
      "-1.133496205636396\n",
      "-0.9220970133395789\n",
      "-0.7594405050957382\n",
      "-0.999968391390824\n",
      "-0.8575354755618022\n",
      "-1.1247482478955504\n",
      "-1.2423576628342043\n",
      "-0.8961971424000248\n",
      "-1.0396166047298823\n",
      "-0.7717622392838328\n",
      "-0.6126265567981115\n",
      "-0.9448289384774279\n",
      "-0.8246089065180758\n",
      "-0.9273928202439733\n",
      "-0.6218607711669639\n",
      "-0.8192763760671222\n",
      "-0.705646423847882\n",
      "-0.44874947755269123\n",
      "-0.6058997592838264\n",
      "-0.7656382279154907\n",
      "-0.5595832350507111\n",
      "-0.6340147691904332\n",
      "-0.7747191906352626\n",
      "-0.9317307235349206\n",
      "-0.7878077633186044\n",
      "-0.6335052071378728\n",
      "-0.6577916654861015\n",
      "-0.6287084479159856\n",
      "-1.015837894373473\n",
      "-1.033482178654557\n",
      "-0.9439836693108032\n",
      "-0.6654732982500832\n",
      "-0.577331292275646\n",
      "-0.7486740259929568\n",
      "-0.6431319319073171\n",
      "-0.5368519153189388\n",
      "-0.49313751014961704\n",
      "-0.4158840242115998\n",
      "-0.597187592575081\n",
      "-0.5782698719329992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.9908443302205585\n",
      "-0.5694665803140123\n",
      "-0.7553467567172254\n",
      "-0.5136285090842764\n",
      "-0.926705670587756\n",
      "-0.6468706195078292\n",
      "-0.5521355314998824\n",
      "-0.8669234497060108\n",
      "-0.7579140680375496\n",
      "-1.0143533208465254\n",
      "-0.9172068475334675\n",
      "-0.9454770715956577\n",
      "-0.8699581399135196\n",
      "-0.7852736678271643\n",
      "-0.8178869773452665\n",
      "-1.01119933781843\n",
      "-1.069412772640161\n",
      "-1.064529042118996\n",
      "-1.1570447327708921\n",
      "-1.0345696045812383\n",
      "-0.9735422031198794\n",
      "-0.9273634166902934\n",
      "-0.7365155927300225\n",
      "-1.0687270115746081\n",
      "-1.000884534841193\n",
      "-0.9187233043923387\n",
      "-1.1088688798306112\n",
      "-0.7592670653926081\n",
      "-1.1360170527349247\n",
      "-0.9904952926320836\n",
      "-0.9290433026032132\n",
      "-0.8541084418634448\n",
      "-0.7211314767893032\n",
      "-0.9486380716580068\n",
      "-0.6845946775365991\n",
      "-0.9776584495265312\n",
      "-1.0825997983896287\n",
      "-0.9333504247215758\n",
      "-1.0393732238351374\n",
      "-0.8876764366532303\n",
      "-0.5234408198068323\n",
      "-0.6426543412015264\n",
      "-0.4238352586332659\n",
      "-0.5993575703706716\n",
      "-0.6074191643224349\n",
      "-0.395829470528278\n",
      "-0.6120224186862215\n",
      "-0.6557123275957635\n",
      "-0.44884986974239105\n",
      "-0.529494561205732\n",
      "-0.5524002185033383\n",
      "-0.6116554355269943\n",
      "-0.7227073111838547\n",
      "-0.7570983204874034\n",
      "-0.7583367191072028\n",
      "-0.7791726292381042\n",
      "-0.9413540001651661\n",
      "-1.0835472395893453\n",
      "-1.1551989351034775\n",
      "-1.0562468059694101\n",
      "-1.0059821637067725\n",
      "-0.7824139750652239\n",
      "-1.0446270862706806\n",
      "-0.8187432281890276\n",
      "-0.9920150371703842\n",
      "-1.1905815170765213\n",
      "-1.082819571208042\n",
      "-1.0633268926873043\n",
      "-1.0515089511886577\n",
      "-0.8421512140224443\n",
      "-0.9235760240271067\n",
      "-0.8625828602643377\n",
      "-0.6152881182940404\n",
      "-0.8742033789827807\n",
      "-0.8879991947164418\n",
      "-0.8646162064223373\n",
      "-0.8423423912135423\n",
      "-1.1007680764542236\n",
      "-0.6254119580902925\n",
      "-0.8801446593535946\n",
      "-0.7318903288549679\n",
      "-0.6803803121351224\n",
      "-0.8650691462289344\n",
      "-0.8351398656062341\n",
      "-0.9809103803658857\n",
      "-0.8379753695129092\n",
      "-0.820530721377532\n",
      "-0.6443506105854998\n",
      "-0.8997431935830607\n",
      "-0.7002272176392507\n",
      "-0.8836709218266818\n",
      "-0.8944719903812447\n",
      "-1.0980203651299953\n",
      "-0.9477427892540842\n",
      "-0.8988260471915485\n",
      "-0.9348912869534716\n",
      "-0.7513235635420602\n",
      "-0.9249436439784848\n",
      "-0.9617465013300937\n",
      "-0.9421096253489551\n",
      "-0.918066325069641\n",
      "-0.7949977862895691\n",
      "-1.069638658149726\n",
      "-1.182084809412218\n",
      "-1.040874031894893\n",
      "-0.8410688787045059\n",
      "-0.8374364562216704\n",
      "-0.7540000948979655\n",
      "-0.6324362827112232\n",
      "-0.6356745269211266\n",
      "-0.6286418241365276\n",
      "-0.7182539331775204\n",
      "-0.6444248066884364\n",
      "-0.8179710915772762\n",
      "-0.7717779678785702\n",
      "-0.6961432388888709\n",
      "-0.6169290519932104\n",
      "-0.7019222002236103\n",
      "-0.5137584176297249\n",
      "-0.602365147051795\n",
      "-1.013226739100911\n",
      "-0.8352194339203416\n",
      "-0.6859580858333674\n",
      "-0.7270369144834743\n",
      "-0.6601781535672151\n",
      "-0.5752971752314151\n",
      "-0.7525893219273662\n",
      "-0.7170615174708314\n",
      "-0.42037269804067434\n",
      "-0.45054208775668736\n",
      "-0.6068339409363058\n",
      "-0.7025053313823414\n",
      "-0.6213333814079354\n",
      "-0.4107019096544888\n",
      "-0.7962478292292061\n",
      "-0.6550319665376504\n",
      "-0.5069473200431398\n",
      "-0.43065797748005397\n",
      "-0.6599879852114849\n",
      "-0.6245135947949733\n",
      "-0.6790309924774726\n",
      "-0.6090059781562867\n",
      "-0.5275964409660658\n",
      "-0.4232733306222652\n",
      "-0.6408230939363202\n",
      "-0.6633464773869662\n",
      "-0.5859973788286061\n",
      "-0.6304822399343193\n",
      "-0.4225891820577178\n",
      "-0.43034841443784727\n",
      "-0.4958585797567988\n",
      "-0.31944677235282803\n",
      "-0.13242970519468428\n",
      "-0.3536166063497334\n",
      "-0.48500763764754773\n",
      "-0.538875844264617\n",
      "-0.47319931305278795\n",
      "-0.6860910580605405\n",
      "-0.5943819062112472\n",
      "-0.6091337696908644\n",
      "-0.6332094132997669\n",
      "-0.18025472656309863\n",
      "-0.146112471032569\n",
      "-0.3021796001419739\n",
      "-0.5332484618379525\n",
      "-0.5307382411909048\n",
      "-0.460708497199134\n",
      "-0.2569381433374067\n",
      "-0.2881463221881859\n",
      "-0.2682034839655668\n",
      "-0.34160034383178123\n",
      "-0.2577013852948342\n",
      "-0.29365932160149216\n",
      "-0.09070946382227857\n",
      "-0.12267111082105056\n",
      "-0.2066235760196697\n",
      "-0.2907374477514009\n",
      "-0.29309848860982446\n",
      "-0.4538802524869629\n",
      "-0.38474597814657574\n",
      "-0.060333283183113665\n",
      "-0.09808964288665764\n",
      "-0.24120284437180156\n",
      "-0.540294308490145\n",
      "-0.49452300803006977\n",
      "-0.2640530954769603\n",
      "-0.4818174759964905\n",
      "-0.46119027903432785\n",
      "-0.4729120241831407\n",
      "-0.21922277056488615\n",
      "-0.5399256741091223\n",
      "-0.46004869600462434\n",
      "-0.4065410511001215\n",
      "-0.5098146637404498\n",
      "-0.4644889501705576\n",
      "-0.4745522146339896\n",
      "-0.2658663688094536\n",
      "-0.4457172693194653\n",
      "-0.34099499074158257\n",
      "-0.2431438680219533\n",
      "-0.23831293459212727\n",
      "-0.012729861692753239\n",
      "-0.12675849214617954\n",
      "-0.28028747040321356\n",
      "-0.30582838943603\n",
      "-0.1907656611289909\n",
      "-0.0061794497322888164\n",
      "0.23995989672871204\n",
      "0.06933704179037123\n",
      "0.21766806536841155\n",
      "0.22853950908198245\n",
      "0.2728233056323\n",
      "-0.013772571849211337\n",
      "-0.1317355420003927\n",
      "-0.021970922893656396\n",
      "-0.13183357228702391\n",
      "-0.05456299587863685\n",
      "-0.060152252972727624\n",
      "-0.1387351842662369\n",
      "-0.08333196869831264\n",
      "-0.1308404252617451\n",
      "-0.22481866816649926\n",
      "-0.013643370478052794\n",
      "-0.2609383162163311\n",
      "-0.3314810579479371\n",
      "-0.30203648291710233\n",
      "-0.147392117748754\n",
      "-0.2115578385288031\n",
      "-0.11429018293568782\n",
      "-0.11054327265586578\n",
      "-0.1000341441395424\n",
      "-0.019365801799457537\n",
      "0.2841144304036578\n",
      "0.004048890383718834\n",
      "0.04999320227566262\n",
      "0.30193448738727097\n",
      "0.24523295244104462\n",
      "0.24065913162624122\n",
      "-0.21988988325972084\n",
      "0.028461239024338794\n",
      "0.2016133199590581\n",
      "0.0409658728114483\n",
      "-0.059548383942878105\n",
      "-0.017552054430060523\n",
      "0.027744542741863235\n",
      "-0.10056526511679528\n",
      "0.10186750891763816\n",
      "0.170360343278671\n",
      "0.22109482312207193\n",
      "0.18647936423890374\n",
      "0.07528035989723647\n",
      "0.29725282441933476\n",
      "-0.028663967615268765\n",
      "-0.05369388879534524\n",
      "0.1466324039446134\n",
      "-0.05897937173483223\n",
      "-0.07288268077704868\n",
      "0.010221354891790733\n",
      "0.01729335739702236\n",
      "0.2632323126236711\n",
      "0.18602596355664358\n",
      "0.05487710972704297\n",
      "-0.19080705139207862\n",
      "0.0545373555598878\n",
      "0.2794682778257352\n",
      "0.19166657703779033\n",
      "0.13406404018415824\n",
      "0.22366151628036723\n",
      "0.34882623608066293\n",
      "0.2805000605140882\n",
      "0.3279145233639945\n",
      "0.4548991092565624\n",
      "0.10720337675392577\n",
      "0.04823785105165334\n",
      "-0.013101726071672749\n",
      "0.23016750680675302\n",
      "-0.09764942615003805\n",
      "0.20751805701607728\n",
      "0.021481919684898952\n",
      "0.19398307298248055\n",
      "-0.00851620733254458\n",
      "0.14959697477349973\n",
      "0.21318866035986797\n",
      "0.5494420127433063\n",
      "0.49651551348351514\n",
      "0.22683540765109317\n",
      "0.25592229730519467\n",
      "0.3745007489886483\n",
      "0.16091866431064147\n",
      "-0.0154942018954898\n",
      "-0.1303014827297471\n",
      "0.07580505227572411\n",
      "0.1849857541391072\n",
      "0.2597568483418608\n",
      "0.06638468080551174\n",
      "0.12998697454103544\n",
      "-0.09238704454992282\n",
      "0.035224128448526376\n",
      "-0.07421500030828415\n",
      "0.058068237704886685\n",
      "0.4250931587781573\n",
      "0.41874195604611186\n",
      "0.3660678388192093\n",
      "0.22296778104116677\n",
      "0.14742587163138812\n",
      "0.4072867227232555\n",
      "0.180361948123966\n",
      "0.34315060372650297\n",
      "0.5028068339331485\n",
      "0.1615358015452511\n",
      "0.10468917840458028\n",
      "0.3871889041506414\n",
      "0.15235040716974385\n",
      "0.3046653000697997\n",
      "0.26238956795891577\n",
      "0.012033181040046165\n",
      "0.1656362755626669\n",
      "0.17086500136435934\n",
      "0.013852551243916184\n",
      "0.34748768635512517\n",
      "0.02370484185658296\n",
      "0.10026447625522082\n",
      "0.2218694324537761\n",
      "-0.06713726453546923\n",
      "-0.12764225824169015\n",
      "-0.1740572894161035\n",
      "0.13974676091690913\n",
      "0.00037783898827081774\n",
      "0.06387195247686916\n",
      "0.01742902302310757\n",
      "-0.3176675166988237\n",
      "-0.22829651321378483\n",
      "-0.3040704427590657\n",
      "0.0696015493252652\n",
      "-0.11723383523888216\n",
      "-0.10240765242252792\n",
      "0.17120799775235424\n",
      "-0.28489351793929235\n",
      "-0.24412742304153506\n",
      "-0.22670918112746616\n",
      "-0.13345386761389935\n",
      "-0.23306605170343433\n",
      "-0.12391631370818179\n",
      "-0.03462750515855475\n",
      "-0.0017763257941000878\n",
      "0.26063922021792313\n",
      "0.27376101332288316\n",
      "-0.06407423005779629\n",
      "-0.04843425280974626\n",
      "-0.12646719455496147\n",
      "-0.12264862483672102\n",
      "-0.056266810682479615\n",
      "-0.27128699084687785\n",
      "-0.03597689363178906\n",
      "-0.17300238764775383\n",
      "-0.24810004193960383\n",
      "-0.26162359997943396\n",
      "-0.32340351462094835\n",
      "-0.26054749368193364\n",
      "-0.04613998044910869\n",
      "-0.18801559816631702\n",
      "-0.1874409050717464\n",
      "-0.28695234134144665\n",
      "-0.25887642139649975\n",
      "-0.49791120294113134\n",
      "-0.4901371112945885\n",
      "-0.2226853826730539\n",
      "-0.01613102415205002\n",
      "-0.35736721583162484\n",
      "-0.32392454204985527\n",
      "-0.3689899240740239\n",
      "-0.5048388080726824\n",
      "-0.11523238497927765\n",
      "-0.38726024949677135\n",
      "-0.23714319750820545\n",
      "-0.4311149783300692\n",
      "-0.34221589115033374\n",
      "-0.43049932195102\n",
      "-0.21992715568572957\n",
      "-0.43387497280782517\n",
      "-0.25269309033413745\n",
      "-0.1745436250239383\n",
      "-0.2585752762218344\n",
      "-0.25398047943394286\n",
      "-0.23851371856023976\n",
      "-0.452263052121099\n",
      "-0.5641469135333743\n",
      "-0.44754664397800464\n",
      "-0.3508347968948529\n",
      "-0.2734266720582804\n",
      "-0.5514193191619499\n",
      "-0.3246718800146399\n",
      "-0.1941808007681345\n",
      "-0.34460997052995623\n",
      "-0.3432895453671956\n",
      "-0.3095165490307658\n",
      "-0.32891650765535513\n",
      "-0.43218212195762823\n",
      "-0.4309402458520974\n",
      "-0.44318597757110045\n",
      "-0.3268482963124129\n",
      "-0.5384598775001843\n",
      "-0.3094149957541378\n",
      "-0.8120146795676826\n",
      "-0.3607100679454113\n",
      "-0.6333599321548954\n",
      "-0.387327681839554\n",
      "-0.676055178522742\n",
      "-0.4739744019910516\n",
      "-0.5657258887732295\n",
      "-0.45128302789930597\n",
      "-0.4698343319301059\n",
      "-0.6971413688214535\n",
      "-0.6112494002793074\n",
      "-0.4810952054992039\n",
      "-0.6028602021113233\n",
      "-0.7895127674074413\n",
      "-0.5114987216702527\n",
      "-0.67777710913259\n",
      "-0.8585342120739224\n",
      "-0.561388387661478\n",
      "-0.7934224742367664\n",
      "-0.942860953724745\n",
      "-0.8095679868403025\n",
      "-1.1401453510830128\n",
      "-1.0040489849683458\n",
      "-1.061792963848386\n",
      "-1.0119685505247433\n",
      "-1.1861201897163554\n",
      "-1.3197518913263853\n",
      "-1.3779739108923623\n",
      "-1.120298195191929\n",
      "-1.1811172483689867\n",
      "-1.1694937409690205\n",
      "-1.1347812185142918\n",
      "-1.5263010461681559\n",
      "-1.393192706700731\n",
      "-1.4025299736074528\n",
      "-1.378305214623565\n",
      "-1.546506117886292\n",
      "-1.3788043381499557\n",
      "-1.3230933797340219\n",
      "-1.3871552645802856\n",
      "-1.4036511611931175\n",
      "-1.464912750806232\n",
      "-1.3299879016812546\n",
      "-1.4600962040402317\n",
      "-1.497461284705632\n",
      "-1.3707550177467072\n",
      "-1.2749477763229022\n",
      "-1.4376750689158284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.2815056495297135\n",
      "-1.3643948045958214\n",
      "-1.2528958620550297\n",
      "-1.6861349014099685\n",
      "-1.893968913519561\n",
      "-1.7185268306397443\n",
      "-1.430286523611615\n",
      "-1.4133289135490958\n",
      "0.0005092932795203037\n",
      "-0.3402510019080558\n",
      "0.0403079383940112\n",
      "0.08633353751608969\n",
      "0.07953761561148752\n",
      "0.016256472298666107\n",
      "-0.14908121808386518\n",
      "0.12624274476708822\n",
      "0.11972343394961814\n",
      "0.020437817361796642\n",
      "0.13787180933755083\n",
      "0.06999753414140189\n",
      "-0.15359227326070488\n",
      "-0.19765178520999468\n",
      "-0.2274678286612924\n",
      "-0.21578144922675432\n",
      "-0.16876803283809558\n",
      "-0.30030581764538966\n",
      "-0.21926582188806631\n",
      "-0.1910931549310287\n",
      "-0.15110555699379094\n",
      "0.12044904388281132\n",
      "0.17799100192995632\n",
      "-0.08846340626829928\n",
      "-0.3299452146703902\n",
      "-6.205964304201173e-05\n",
      "0.17394616757541387\n",
      "0.18766393020371872\n",
      "0.04127397821058286\n",
      "-0.07654851010116351\n",
      "-0.1627099025367702\n",
      "0.08808781488268433\n",
      "0.08889195940730013\n",
      "-0.16072838663132794\n",
      "0.006883119361992096\n",
      "-0.09406417854360742\n",
      "-0.2581777674348482\n",
      "-0.1750446640337337\n",
      "-0.12350024899305934\n",
      "-0.433671179697919\n",
      "0.023092242608244856\n",
      "0.03396683706231107\n",
      "-0.34615291711383817\n",
      "-0.12400594256209568\n",
      "-0.10514479016141168\n",
      "-0.38832783536441756\n",
      "-0.025903206559292208\n",
      "0.09873046130864399\n",
      "0.01696625948417163\n",
      "-0.25765534376841337\n",
      "-0.0748778062946139\n",
      "-0.39092227420381864\n",
      "-0.6079899220769627\n",
      "-0.1371139737999923\n",
      "-0.30826153057472416\n",
      "-0.5372513248122052\n",
      "-0.23254482523737924\n",
      "-0.12648865040283186\n",
      "-0.04396267973842661\n",
      "-0.07087202021507946\n",
      "-0.2454407963863407\n",
      "-0.5373932780918976\n",
      "-0.3771911594613043\n",
      "-0.4163847823777209\n",
      "-0.6218127535886455\n",
      "-0.5862257180454505\n",
      "-0.4552735766222362\n",
      "-0.4149160924564269\n",
      "-0.5714609207001264\n",
      "-0.71870787218802\n",
      "-0.8660998112847498\n",
      "-0.46860348855470335\n",
      "-0.6361941713785118\n",
      "-0.6238972708517585\n",
      "-0.4500774345205396\n",
      "-0.3928028097535698\n",
      "-0.30219016991263686\n",
      "-0.22344211296912708\n",
      "-0.5206380546559112\n",
      "-0.40687387967597194\n",
      "-0.685214543596218\n",
      "-0.5957578354891251\n",
      "-0.8057725910234277\n",
      "-0.6055303001746895\n",
      "-0.46766845579913685\n",
      "-0.6698744959943805\n",
      "-0.38499779154283365\n",
      "-0.46848079476073845\n",
      "-0.2397272263493038\n",
      "-0.7215574821520376\n",
      "-0.5622305147320569\n",
      "-0.1980083139766505\n",
      "-0.2703795428395096\n",
      "-0.16022896081093688\n",
      "-0.07221080869635867\n",
      "0.02248456380697505\n",
      "-0.08840715140181198\n",
      "-0.24269855851997674\n",
      "-0.4724825042509153\n",
      "-0.2350226869644505\n",
      "-0.26919735368213493\n",
      "-0.2523172160215243\n",
      "-0.6830539895045816\n",
      "-0.5908864258656527\n",
      "-0.43614326228252615\n",
      "-0.25191861020757467\n",
      "-0.4410157187968141\n",
      "-0.6686425842236302\n",
      "-0.5953959226074311\n",
      "-0.4803802265024957\n",
      "-0.3976246140179334\n",
      "-0.3485674251242348\n",
      "-0.18257455344900303\n",
      "-0.20773368875975948\n",
      "-0.23382585832018377\n",
      "-0.6613844698786892\n",
      "-0.7382666467886851\n",
      "-0.5226538888463573\n",
      "-0.45758064863762316\n",
      "-0.37386413622846015\n",
      "-0.47587327065505336\n",
      "-0.6622596107225512\n",
      "-0.3489827427127958\n",
      "-0.5395580456521276\n",
      "-0.5490963214516783\n",
      "-0.549391103029414\n",
      "-0.3623649885390661\n",
      "-0.47239989344021627\n",
      "-0.4847927581316442\n",
      "-0.44303890480826824\n",
      "-0.7613134516623528\n",
      "-0.4845789892417955\n",
      "-0.47752700666431824\n",
      "-0.7431330525259287\n",
      "-0.4726389749010485\n",
      "-0.8600554724723162\n",
      "-1.016554895519516\n",
      "-0.8274629099456514\n",
      "-0.8125300392687532\n",
      "-0.9782919436375708\n",
      "-0.9939585373674601\n",
      "-0.886195969513903\n",
      "-0.5979677716585969\n",
      "-0.5539326636854861\n",
      "-0.33454236125223674\n",
      "-0.5129053237815386\n",
      "-0.5506451980403396\n",
      "-0.30116814489900817\n",
      "-0.34216313105526247\n",
      "-0.25236989273937527\n",
      "-0.25054096917471425\n",
      "-0.5498936539247123\n",
      "-0.4522990586210757\n",
      "-0.4231841304159832\n",
      "-0.5272662350324003\n",
      "-0.5312631020540027\n",
      "-0.46772136411666165\n",
      "-0.5773984230368523\n",
      "-0.6633549535017095\n",
      "-0.45356805551715995\n",
      "-0.4001550912897645\n",
      "-0.27864594306996593\n",
      "-0.6361073656912349\n",
      "-0.6214805698025762\n",
      "-0.504709047546833\n",
      "-0.4187450525016716\n",
      "-0.33692920861841874\n",
      "-0.5336570974256196\n",
      "-0.2850980227526003\n",
      "-0.489071563322413\n",
      "-0.4940126787680737\n",
      "-0.4426516272729988\n",
      "-0.5542806071922941\n",
      "-0.626736683736269\n",
      "-0.5551853354226125\n",
      "-0.3564691103109978\n",
      "-0.673360385333851\n",
      "-0.292558034733717\n",
      "-0.7297035627120656\n",
      "-0.595374580592527\n",
      "-0.4006715880522902\n",
      "-0.3654743708381588\n",
      "-0.5258166806591739\n",
      "-0.48561837055447166\n",
      "-0.660658469027288\n",
      "-0.760591347916385\n",
      "-0.5822106722717295\n",
      "-0.2867560911248847\n",
      "-0.05443308434466697\n",
      "0.041605610572876726\n",
      "-0.15260378032173408\n",
      "-0.30181641708183055\n",
      "-0.1320124186365309\n",
      "-0.15259799745910488\n",
      "-0.20548832114528018\n",
      "-0.4257231491878584\n",
      "-0.2955354437002623\n",
      "-0.5868456629194161\n",
      "-0.44366773637975365\n",
      "-0.3018123657458692\n",
      "-0.29205549423207006\n",
      "-0.3117189216318832\n",
      "-0.20412396496563961\n",
      "-0.46710484020161586\n",
      "-0.3507015615674326\n",
      "-0.29715277391070843\n",
      "-0.030806436961214677\n",
      "-0.07946232853434185\n",
      "-0.07948859034070171\n",
      "-0.3599109851797181\n",
      "-0.3923709739200757\n",
      "-0.1020817154582626\n",
      "-0.04790937459840648\n",
      "-0.2720287239094338\n",
      "-0.1729503431593157\n",
      "-0.3737467524691965\n",
      "-0.5896629050872689\n",
      "-0.17278838089387005\n",
      "-0.3853547743122738\n",
      "-0.489946852434046\n",
      "-0.41682510204446643\n",
      "-0.3517961143195217\n",
      "-0.48707481191523516\n",
      "-0.3943916783425912\n",
      "-0.5550915762739763\n",
      "-0.4565474254851795\n",
      "-0.43277494685874884\n",
      "-0.3910324964591159\n",
      "-0.17412906680454798\n",
      "-0.21547473323989955\n",
      "-0.34243693449172075\n",
      "-0.3075031090486502\n",
      "-0.2868178546870062\n",
      "-0.5631377558012108\n",
      "-0.3812360233584501\n",
      "-0.2679963692046463\n",
      "-0.13567380145475777\n",
      "-0.38769188338151156\n",
      "-0.31752883007414867\n",
      "-0.3315092508196708\n",
      "-0.10767340397587608\n",
      "-0.1488793863824316\n",
      "-0.23229974495211836\n",
      "-0.5483971014657488\n",
      "-0.17894748204621613\n",
      "-0.07105380071528611\n",
      "-0.03983068304338914\n",
      "-0.07564364303170963\n",
      "-0.11929423278899383\n",
      "-0.023690401962878648\n",
      "-0.15672113500255097\n",
      "-0.04665033462506018\n",
      "-0.08779164702942921\n",
      "-0.29937081248991193\n",
      "0.0517650341128606\n",
      "-0.27882247513874914\n",
      "-0.28510004261703775\n",
      "-0.47478595252214323\n",
      "-0.32841016391762035\n",
      "-0.23053602921533942\n",
      "-0.2578741049589879\n",
      "-0.014391160688686018\n",
      "-0.14675448373664363\n",
      "-0.23104700862163968\n",
      "-0.26905539311209387\n",
      "-0.2021692462645927\n",
      "-0.029849309892212586\n",
      "0.09773194196297202\n",
      "0.3146194491963433\n",
      "0.1773169160573565\n",
      "0.12368975964448084\n",
      "0.1669956865112309\n",
      "0.19264388837904575\n",
      "0.3178518508666478\n",
      "0.27374188292170715\n",
      "0.11389332064593904\n",
      "0.19370763749672332\n",
      "0.20849593552110407\n",
      "0.14983252491979246\n",
      "0.04507514805648011\n",
      "-0.11185073135352361\n",
      "0.27553362656197766\n",
      "0.16250080071984246\n",
      "0.11362033728875473\n",
      "-0.02837916022714913\n",
      "0.2554291730263368\n",
      "0.20107025329172545\n",
      "0.370381190886121\n",
      "0.07362660504374599\n",
      "0.323454761277976\n",
      "0.17511854190157278\n",
      "0.15794882299390425\n",
      "0.2874486430421877\n",
      "0.050720012364673245\n",
      "-0.31271655189138725\n",
      "0.005414808865434467\n",
      "0.14789975051084453\n",
      "0.15355822471415212\n",
      "-0.030572443325649092\n",
      "0.1675017446273343\n",
      "0.11736705245042726\n",
      "-0.26952958707918795\n",
      "-0.08536017705424725\n",
      "-0.0898711912780186\n",
      "0.05647273434835194\n",
      "0.06553895414131068\n",
      "0.2953191524869486\n",
      "0.1531744882208529\n",
      "0.09524325060792074\n",
      "0.04759676502475189\n",
      "0.4043909437177972\n",
      "0.1726941426229121\n",
      "0.3510868914509792\n",
      "0.3295610933223197\n",
      "0.19365765525357598\n",
      "0.10375044223214616\n",
      "0.28915191657951567\n",
      "0.27348946208846203\n",
      "0.2525718295919923\n",
      "-0.03233997051842864\n",
      "0.035039964676229135\n",
      "0.09448062515276873\n",
      "0.3480195854768012\n",
      "0.48231955468971593\n",
      "0.2697986358975101\n",
      "0.3386544969606674\n",
      "0.30582417315775506\n",
      "0.344369441660946\n",
      "0.34058971466124427\n",
      "0.4926326686943269\n",
      "0.14971911260333104\n",
      "0.46881181214796985\n",
      "0.43747321346049595\n",
      "0.3829378002743642\n",
      "0.23021381987984368\n",
      "0.3067615632960896\n",
      "0.4320660771373148\n",
      "0.42350635638861656\n",
      "0.279847461900683\n",
      "0.18263053925410738\n",
      "0.2067033320216988\n",
      "0.17130063549288355\n",
      "0.20991778048891535\n",
      "0.34448233797038436\n",
      "0.3902514223782091\n",
      "0.15679306076965283\n",
      "0.3791418962925923\n",
      "0.35769699846645764\n",
      "0.28918935721867206\n",
      "0.38661711676482796\n",
      "0.49286128989185296\n",
      "0.28743087845866944\n",
      "0.43818266742191253\n",
      "0.36974731367459807\n",
      "0.4656205082373952\n",
      "0.4651444786416158\n",
      "0.35959131687305484\n",
      "0.4761449227835648\n",
      "0.14344325295244176\n",
      "0.4711773870493107\n",
      "0.5427763063751373\n",
      "0.152900633783577\n",
      "0.31565286172131923\n",
      "0.33457196890112884\n",
      "0.31609946147399015\n",
      "0.5129859386626777\n",
      "0.3772327758380197\n",
      "0.2796264808457653\n",
      "0.37728174064363745\n",
      "0.3007747509242393\n",
      "0.38667738898544146\n",
      "0.6308209656839383\n",
      "0.2817140920842226\n",
      "0.5201366917215196\n",
      "0.6492480787085011\n",
      "0.6465843747215241\n",
      "0.716392192662273\n",
      "0.5997847950285388\n",
      "0.26613661245419545\n",
      "0.5527598716236107\n",
      "0.5835911578590375\n",
      "0.5546268847454665\n",
      "0.3856351248742498\n",
      "0.44871844420127893\n",
      "0.44252490275055584\n",
      "0.5882891976165435\n",
      "0.4609920563615073\n",
      "0.543028619536546\n",
      "0.4201087166344026\n",
      "0.4823680305025236\n",
      "0.383087084033711\n",
      "0.30516465900497564\n",
      "0.46855079170791625\n",
      "0.33078047503961244\n",
      "0.60132789156478\n",
      "0.4897906328587352\n",
      "0.4753754296232953\n",
      "0.3598953727724321\n",
      "0.468622518736066\n",
      "0.5402346982639163\n",
      "0.3668503291090445\n",
      "0.42896245317245235\n",
      "0.436087355387511\n",
      "0.4410678560901023\n",
      "0.6800465909361233\n",
      "0.6169924448337907\n",
      "0.5528181897144828\n",
      "0.7038679565685211\n",
      "0.6836451441887068\n",
      "0.4582429181858688\n",
      "0.6590797204085406\n",
      "0.5259716423448443\n",
      "0.4178463771382208\n",
      "0.5487133650461714\n",
      "0.6133617759930791\n",
      "0.5257994793667344\n",
      "0.6042332022305461\n",
      "0.5766087642342348\n",
      "0.7101507259648075\n",
      "0.7139831396647942\n",
      "0.7056214952162588\n",
      "0.8331924441387201\n",
      "0.7497799304666645\n",
      "0.8833657706543393\n",
      "0.7694586314918017\n",
      "1.0318271257247973\n",
      "0.9418018623243615\n",
      "0.9343896347708951\n",
      "0.833182052872605\n",
      "1.0559638155808382\n",
      "0.9509158230612716\n",
      "0.9828086130260721\n",
      "0.9594085882278781\n",
      "0.9904503720797458\n",
      "1.015659317625167\n",
      "1.0050878415096671\n",
      "1.005824487636869\n",
      "0.6355824874117962\n",
      "0.7623166451370422\n",
      "0.990442925951799\n",
      "0.6952728787734511\n",
      "0.5565901552440176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9112573810366844\n",
      "0.7627191243409763\n",
      "0.8860041790907188\n",
      "0.6233709418435136\n",
      "0.9807583816421135\n",
      "0.881222655335129\n",
      "1.025929685307573\n",
      "0.9943015962703486\n",
      "0.9008302201588478\n",
      "0.7961099273534206\n",
      "0.5403973761770402\n",
      "0.7965063921335899\n",
      "0.7138016236602528\n",
      "0.7325664397531\n",
      "0.8599792285591813\n",
      "0.8944758029229566\n",
      "0.7014662576666475\n",
      "0.8200717909480825\n",
      "0.9771162663700864\n",
      "0.7577728812545602\n",
      "0.8449102268118767\n",
      "0.5689051002835426\n",
      "0.5636460556815989\n",
      "0.5328877320402626\n",
      "0.7011109945972299\n",
      "0.584402987159321\n",
      "0.7939761666710277\n",
      "0.839335956778859\n",
      "0.6992559330672685\n",
      "0.8458654156957118\n",
      "0.6211618803023599\n",
      "0.7972625277460742\n",
      "0.6578456963461703\n",
      "0.779136590661743\n",
      "0.6636422272702349\n",
      "0.7894556861507854\n",
      "0.8517828604001331\n",
      "0.7630735511305361\n",
      "0.9465312070288\n",
      "0.9393618901824885\n",
      "0.7249340178084913\n",
      "0.8206401309397198\n",
      "0.6301981347934201\n",
      "0.676896574489762\n",
      "0.6793480426357318\n",
      "0.7481070856831832\n",
      "1.151246874980293\n",
      "1.1297033279096027\n",
      "0.8154381031043036\n",
      "0.7793797360649757\n",
      "0.7360366636412499\n",
      "0.8576956789420189\n",
      "0.8685563257679582\n",
      "0.9937185831304977\n",
      "1.2654448184576534\n",
      "1.13333791565059\n",
      "1.0384570609803943\n",
      "0.9106220615861899\n",
      "1.0508258607224104\n",
      "0.7337299354151048\n",
      "1.0819111475073118\n",
      "1.084681825973566\n",
      "0.7616178952209047\n",
      "0.9566528861654346\n",
      "0.7039955558138865\n",
      "0.7023612025399558\n",
      "0.9652524932919923\n",
      "0.7535031762249618\n",
      "0.8985475981324649\n",
      "1.2220328382742007\n",
      "1.2006297976584384\n",
      "0.9622774413653161\n",
      "0.8400718187241123\n",
      "0.8796911158304519\n",
      "1.1209753682486663\n",
      "1.0001443161990657\n",
      "0.824618101097777\n",
      "0.8189920786563352\n",
      "0.7706822998056407\n",
      "0.6482401656638769\n",
      "0.5397230091726597\n",
      "0.4924887131980771\n",
      "0.6162557220853541\n",
      "0.8219266963356846\n",
      "0.47537197119617747\n",
      "0.4739029310471233\n",
      "0.5095320884117528\n",
      "0.7132837237123799\n",
      "0.48749303295311697\n",
      "0.7763987806588679\n",
      "0.8268265044902093\n",
      "0.613383303298889\n",
      "0.5230652949779586\n",
      "0.4197811571586627\n",
      "0.4321133281682933\n",
      "0.5138418178780699\n",
      "0.6336667118421382\n",
      "0.8142004211734849\n",
      "0.7476601653413332\n",
      "0.8455231735419028\n",
      "0.5486227639435148\n",
      "0.7720067711286372\n",
      "0.5819504692198847\n",
      "0.7748739649942014\n",
      "0.5939382518854769\n",
      "0.6072000050485655\n",
      "0.6741869449669132\n",
      "0.46074473763968016\n",
      "0.30468252459340145\n",
      "0.31956194180404407\n",
      "0.4300232688548237\n",
      "0.641567429432723\n",
      "0.6157325570090635\n",
      "0.8491274073517312\n",
      "0.8255686987270134\n",
      "0.7630933900600074\n",
      "0.5690257597540026\n",
      "0.5637957431189594\n",
      "0.5521678889254115\n",
      "0.5079962143496314\n",
      "0.5288704177203533\n",
      "0.5175841490201398\n",
      "0.7158758192359047\n",
      "0.5518373393012304\n",
      "0.38379066175488513\n",
      "0.47956159471330045\n",
      "0.7028154551374917\n",
      "0.32370159117026215\n",
      "0.5249390159590288\n",
      "0.6760094889897732\n",
      "0.7722442192759356\n",
      "0.6332718536111583\n",
      "0.5131829048504876\n",
      "0.6646357513711283\n",
      "0.9019226051086259\n",
      "0.8309816373470745\n",
      "0.5606233784011618\n",
      "0.5368778646977815\n",
      "0.8959927569889472\n",
      "0.6159842917564037\n",
      "0.6225328990445924\n",
      "0.9215487274574681\n",
      "0.7841990433440205\n",
      "0.8020851481248638\n",
      "0.5120342118297244\n",
      "0.7949013434294318\n",
      "0.5421916971233498\n",
      "0.80011078756591\n",
      "0.5959172216616094\n",
      "0.5799790797157849\n",
      "0.6156922828893474\n",
      "0.6771702278866832\n",
      "0.7033422155458923\n",
      "0.8510003729381294\n",
      "0.7388991684431021\n",
      "0.5446925952957785\n",
      "0.6939869360625118\n",
      "0.3346888776371856\n",
      "0.3402160046301347\n",
      "0.39047814726256264\n",
      "0.42354621536000125\n",
      "0.5776870952933854\n",
      "0.44679287210727825\n",
      "0.4572946602068216\n",
      "0.45740063860719693\n",
      "0.6379170391919473\n",
      "0.7377867487189138\n",
      "0.731972321553558\n",
      "0.5782244220987275\n",
      "0.5048959606857921\n",
      "0.5551742832099125\n",
      "0.4970280456238731\n",
      "0.23898011802466346\n",
      "0.2896567938077019\n",
      "0.3079996120417177\n",
      "0.312607649676986\n",
      "0.20057142936716263\n",
      "0.5613494330143247\n",
      "0.44331521109959326\n",
      "0.349459744541704\n",
      "0.597969941588589\n",
      "0.2937977248020747\n",
      "0.2677091062345658\n",
      "0.49878246217239963\n",
      "0.22161969359627748\n",
      "0.0913061002706222\n",
      "0.18435207699396874\n",
      "0.21259690817609195\n",
      "0.3375840654329862\n",
      "0.4338520221981944\n",
      "0.5924215981670051\n",
      "0.7798021403816813\n",
      "0.43394022916879127\n",
      "0.40499364183992287\n",
      "0.4080417494963433\n",
      "0.6274762599421377\n",
      "0.46739254348690784\n",
      "0.7390103605607439\n",
      "0.4052606364418206\n",
      "0.28926911631720453\n",
      "0.36695415786297886\n",
      "0.30775646904173004\n",
      "0.2907311055865711\n",
      "0.3455265818922008\n",
      "0.6034723855321821\n",
      "0.4352055533875764\n",
      "0.20257859540295658\n",
      "0.18293002084873003\n",
      "0.24499476218348148\n",
      "0.2119344457542197\n",
      "0.34496788188914174\n",
      "0.45913408074036655\n",
      "0.29946847824824985\n",
      "0.29502246431128337\n",
      "0.19759132536067225\n",
      "0.1416754498308149\n",
      "0.2578970672553935\n",
      "0.6715688259807047\n",
      "0.659682970320496\n",
      "0.7117030695340083\n",
      "0.4224499163005623\n",
      "0.33414847718162916\n",
      "0.23513860496648026\n",
      "0.19853831128423782\n",
      "0.17341096633823735\n",
      "0.24818704111343662\n",
      "0.25993348907181196\n",
      "0.2555744766540692\n",
      "0.5663889955516196\n",
      "0.4069897029848236\n",
      "0.2593933465484125\n",
      "0.2826333083441468\n",
      "0.11041343302427102\n",
      "0.004899837126820336\n",
      "0.224466490101331\n",
      "-7.513470281557411e-06\n",
      "0.4151946877091699\n",
      "0.1272202340137358\n",
      "0.09493942166519849\n",
      "0.09965125441162517\n",
      "0.19896899042590005\n",
      "0.06561403818307213\n",
      "0.1443451815680184\n",
      "0.5048262499704433\n",
      "0.21106029961728562\n",
      "0.1867040824541851\n",
      "0.15474619988040517\n",
      "0.3395016873350414\n",
      "0.25030738119601453\n",
      "0.537268458460375\n",
      "0.24392379138459785\n",
      "0.26702703925000915\n",
      "0.16444907405117581\n",
      "0.48859436193967903\n",
      "0.20509959021487045\n",
      "0.22097877956038198\n",
      "0.23827650437503473\n",
      "0.27551786927027716\n",
      "0.3238884647897869\n",
      "0.2967475093299464\n",
      "0.10663641360591014\n",
      "0.17879049138869868\n",
      "0.0024456724783571623\n",
      "-0.004972152556680406\n",
      "0.1293953985835702\n",
      "0.2252601140753507\n",
      "0.13451627210869788\n",
      "0.1923993166743624\n",
      "0.16978847490030058\n",
      "0.1870912280298328\n",
      "0.10918810098443489\n",
      "0.17546955948743231\n",
      "0.16429483012836651\n",
      "0.2306916627225084\n",
      "0.4747321129404147\n",
      "0.25857131358677526\n",
      "0.17387184351254212\n",
      "0.22117898506120393\n",
      "0.5239200300610624\n",
      "0.4743836621284839\n",
      "0.5231570461107619\n",
      "0.2527944770443433\n",
      "0.19315747329691332\n",
      "0.45535860647696047\n",
      "0.42054104961190036\n",
      "0.3021315364322848\n",
      "0.43327444699271334\n",
      "0.12957508033415283\n",
      "0.0955985207668819\n",
      "0.06559872933547138\n",
      "0.00953296807426918\n",
      "0.06211060270509162\n",
      "0.051681520560751114\n",
      "0.2907942699174899\n",
      "0.01150638368068821\n",
      "0.024362176019882532\n",
      "0.11103637730164717\n",
      "0.24408282116610955\n",
      "0.2916491253752675\n",
      "0.1731106786133445\n",
      "-0.006031219096907389\n",
      "0.1851743282288512\n",
      "-0.08412918439720461\n",
      "-0.0908643158766703\n",
      "0.006326181126932957\n",
      "0.13943400292935457\n",
      "0.16756825951576515\n",
      "0.060210569862316224\n",
      "0.04223274996171402\n",
      "-0.051651040454688824\n",
      "-0.13651887044405075\n",
      "-0.07886048209092081\n",
      "0.04917952480646655\n",
      "0.03557805071451833\n",
      "0.1051902446027954\n",
      "0.11362588805487223\n",
      "0.1442484811347061\n",
      "0.45001570656007395\n",
      "0.39828878792576417\n",
      "0.04707438610783794\n",
      "-0.004391436417239918\n",
      "0.06401373926349302\n",
      "0.01778959911705343\n",
      "0.1916644888675605\n",
      "0.0011700888384969521\n",
      "0.22382815922971316\n",
      "0.07933083100135634\n",
      "-0.08950102056846124\n",
      "-0.01707711804892228\n",
      "0.3164489746058374\n",
      "0.05315678076144009\n",
      "-0.0022925980351283723\n",
      "0.29276399584298746\n",
      "-0.02680069767945943\n",
      "0.048578327109944745\n",
      "-0.11238904107928777\n",
      "-0.14588846530520977\n",
      "-0.0764616950158939\n",
      "-0.090446534916747\n",
      "-0.0872707564779771\n",
      "-0.02605086025687245\n",
      "-0.04188616456311564\n",
      "0.26205487807051087\n",
      "0.3227394707912516\n",
      "0.03486096197255001\n",
      "0.2858707697077935\n",
      "0.23834963453569272\n",
      "0.16045820108266742\n",
      "0.007876642469046125\n",
      "-0.06763645323584581\n",
      "-0.07461681792475632\n",
      "0.010939615816092256\n",
      "-0.03061074065894184\n",
      "-0.07709657064615695\n",
      "-0.07073650592579761\n",
      "-0.1290867641006404\n",
      "-0.156223329817337\n",
      "-0.15634813655900215\n",
      "0.11368257747956093\n",
      "0.01546306973833872\n",
      "0.23282100479662282\n",
      "0.2473766711681207\n",
      "-0.015716735926432968\n",
      "-0.09446220012486128\n",
      "-0.04848200589534348\n",
      "-0.054601984560185356\n",
      "0.13313449992124265\n",
      "-0.12805027185635715\n",
      "0.00012835566854035169\n",
      "-0.15099880509890384\n",
      "-0.18577950554040512\n",
      "0.03813713348529206\n",
      "-0.1507904300171036\n",
      "-0.1268871505010382\n",
      "-0.14572344358132147\n",
      "0.08660266155725801\n",
      "0.2880361127314662\n",
      "0.14013000191012398\n",
      "0.3887102661983846\n",
      "0.09978168736063722\n",
      "0.021730465391353173\n",
      "-0.028711914141401822\n",
      "0.05526548143148835\n",
      "0.08286394711117882\n",
      "0.25425232384216534\n",
      "0.10188928187021745\n",
      "0.11053523764194624\n",
      "0.33442385213206993\n",
      "0.16898922417326642\n",
      "0.13049593774319332\n",
      "0.10587152487848835\n",
      "0.2152841067412379\n",
      "0.18061023033953194\n",
      "0.3077962238279097\n",
      "0.27094457475446143\n",
      "0.2991741099288515\n",
      "0.08091216769768032\n",
      "0.22182791376219052\n",
      "0.054686472337044115\n",
      "0.08621367680366292\n",
      "0.1355070023987853\n",
      "0.2259787451106538\n",
      "0.2112722008369989\n",
      "0.227808921493358\n",
      "0.12429190528445508\n",
      "-0.0023869995920719513\n",
      "-0.04189179978826063\n",
      "-0.02340638554680098\n",
      "0.050953513349100324\n",
      "0.10592957199577306\n",
      "0.16921504001343046\n",
      "0.11536106100292474\n",
      "0.16131777241690803\n",
      "0.2644599685674141\n",
      "0.18928064577601822\n",
      "0.2060120792440409\n",
      "0.2033165617847734\n",
      "0.21032963713040806\n",
      "0.37848427298638826\n",
      "0.24664730278683172\n",
      "0.18402042409272013\n",
      "0.33993029141983544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09772657759829458\n",
      "0.10404223049923707\n",
      "0.10826724315060329\n",
      "0.21552924132063786\n",
      "0.28977002587154777\n",
      "0.2520076840700564\n",
      "0.27911893278158867\n",
      "0.27794764625017826\n",
      "0.29287855332860435\n",
      "0.261291365529987\n",
      "0.25496113996841885\n",
      "0.31149033581709784\n",
      "0.25205193266890863\n",
      "0.30573200027833025\n",
      "0.36301611319416294\n",
      "0.3168190154846421\n",
      "0.302647025195805\n",
      "0.4591095192112983\n",
      "0.2915027455895805\n",
      "0.41300963243210276\n",
      "0.3481131488377146\n",
      "0.5433803649674646\n",
      "0.48410194988644606\n",
      "0.33468037918834814\n",
      "0.3043097783241602\n",
      "0.31419196495832075\n",
      "0.5279529798605751\n",
      "0.35346475088235696\n",
      "0.3353360315530963\n",
      "0.37538925637677817\n",
      "0.37318030187030704\n",
      "0.22710702248472453\n",
      "0.22900496447526214\n",
      "0.2639419908387773\n",
      "0.3198562895692836\n",
      "0.2800048214508735\n",
      "0.43653107465128266\n",
      "0.23648576724754816\n",
      "0.31788823530334687\n",
      "0.2658746745650062\n",
      "0.29336511985257085\n",
      "0.3974359147320523\n",
      "0.38850893854484103\n",
      "0.3865239949424216\n",
      "0.4940633205327699\n",
      "0.40992802680345886\n",
      "0.38689949004697466\n",
      "0.42375292264835784\n",
      "0.3872681821761613\n",
      "0.42426258423240953\n",
      "0.42723652526658573\n",
      "0.6023998380574923\n",
      "0.4613047044981047\n",
      "0.47819280728779734\n",
      "0.4955773725282026\n",
      "0.5408562607762782\n",
      "0.618263555453174\n",
      "0.6406063643884082\n",
      "0.6839793010446114\n",
      "0.8145455489061108\n",
      "0.8867299305573781\n",
      "0.8803558882696706\n",
      "0.802178817412665\n",
      "0.7932612199326682\n",
      "0.761758927573822\n",
      "0.5613280332124853\n",
      "0.5115092187159015\n",
      "0.5033063430690394\n",
      "0.5517064971321699\n",
      "0.7536476912256446\n",
      "0.705357759273862\n",
      "0.58970811302735\n",
      "0.5545218551495428\n",
      "0.5743214586766417\n",
      "0.6188675673156798\n",
      "0.5902952575215784\n",
      "0.48629773645206065\n",
      "0.5106384292974486\n",
      "0.442607413456378\n",
      "0.3467153710323858\n",
      "0.33544903313080254\n",
      "0.38068682376304047\n",
      "0.4148322067140816\n",
      "0.4580683394459672\n",
      "0.5155417780025703\n",
      "0.5161652551388649\n",
      "0.691083806394893\n",
      "0.5864322943676442\n",
      "0.5688746127258737\n",
      "0.5725844405342823\n",
      "0.5586805560099\n",
      "0.5965930885005503\n",
      "0.618464305598813\n",
      "0.6722605062831692\n",
      "0.6996817163876115\n",
      "0.8219747555489818\n",
      "0.7675485138033393\n",
      "0.7437149597821238\n",
      "0.8281752890350559\n",
      "0.7327612212980144\n",
      "0.7158647496669842\n",
      "0.718786670163182\n",
      "0.6995584016691964\n",
      "0.7397014405808063\n",
      "0.6968749323783525\n",
      "0.790910372906165\n",
      "0.6903110294494997\n",
      "0.7079137990554064\n",
      "0.699287157490416\n",
      "0.7184397835791643\n",
      "0.7605726079774308\n",
      "0.8028547625117786\n",
      "0.8119339045697925\n",
      "0.8037916708826276\n",
      "0.7755927027214553\n",
      "0.7644081864335025\n",
      "0.7293414205746711\n",
      "0.7705831042420002\n",
      "0.7817088659017424\n",
      "0.7115320030460603\n",
      "0.5923825830701672\n",
      "0.5110551491373679\n",
      "0.46119592065039977\n",
      "0.47849928893803595\n",
      "0.40582773671536726\n",
      "0.35711270229256076\n",
      "0.3851143328944574\n",
      "0.40176560829884833\n",
      "0.4142879800289168\n",
      "0.3693531912189328\n",
      "0.4655014767817306\n",
      "0.37830112514617986\n",
      "0.412801399900233\n",
      "0.4685979571302951\n",
      "0.42829751533772276\n",
      "0.006853669730589455\n",
      "0.05613777783822869\n",
      "-0.15448064572482378\n",
      "-0.2247045890598904\n",
      "-0.1679151031420211\n",
      "-0.16763959215913177\n",
      "-0.07712861997233825\n",
      "0.30232223845586126\n",
      "-0.06187096344359552\n",
      "0.05261135945546889\n",
      "0.13012662123535867\n",
      "-0.27166011878268687\n",
      "-0.2705920905087185\n",
      "-0.01648164172184105\n",
      "0.4757107515007291\n",
      "0.3828931535511456\n",
      "0.34688433462077983\n",
      "0.13468537209835152\n",
      "-0.19723559250339684\n",
      "-0.040441940283384575\n",
      "-0.04461602114185416\n",
      "0.138566411893763\n",
      "-0.07711996650933398\n",
      "-0.08493429024915403\n",
      "0.11882847990977612\n",
      "-0.06633698994999648\n",
      "-0.15849824993059222\n",
      "0.06357557991967461\n",
      "0.004087609263868169\n",
      "-0.11477780408638236\n",
      "-0.20932999223356052\n",
      "-0.1071566078860309\n",
      "-0.048754219035792606\n",
      "0.16091967284312336\n",
      "0.2257081275213325\n",
      "-0.1332065989841921\n",
      "-0.06471608449571031\n",
      "-0.19560971085195308\n",
      "-0.06243230697383922\n",
      "-0.22091642997566058\n",
      "-0.004227014524138484\n",
      "-0.05527105355160781\n",
      "-0.14961656145180155\n",
      "0.29557884178274924\n",
      "0.18405779161557376\n",
      "0.283744503975982\n",
      "-0.2525599889090655\n",
      "-0.3129075035812732\n",
      "-0.0338602341824249\n",
      "0.11129922951440897\n",
      "0.04748055189981512\n",
      "0.2576121413687405\n",
      "0.20447452851727407\n",
      "0.05701935541884353\n",
      "0.2695056658098207\n",
      "0.22494494965825096\n",
      "0.15187695580846422\n",
      "-0.08329506475379389\n",
      "-0.24931006987061086\n",
      "0.05050361157867596\n",
      "-0.20473100551794965\n",
      "-0.2939413990159299\n",
      "-0.4985909080094213\n",
      "-0.2891033945526504\n",
      "-0.2837898344042661\n",
      "-0.27694189195303237\n",
      "-0.1583040476242191\n",
      "-0.5263715176030188\n",
      "-0.28220172732865434\n",
      "-0.5206652729875761\n",
      "-0.57027633421068\n",
      "-0.4953095930786291\n",
      "-0.4963518850011714\n",
      "-0.4900695878772473\n",
      "-0.2979050468052776\n",
      "-0.5897794557704109\n",
      "-0.182900588805968\n",
      "-0.19378554711358165\n",
      "-0.4683569855333771\n",
      "-0.5485023963507071\n",
      "-0.5671680353845058\n",
      "-0.3596799763025488\n",
      "-0.8029840677795097\n",
      "-0.6603092443739851\n",
      "-0.20246431527415662\n",
      "-0.21399700524537185\n",
      "-0.5195776165825832\n",
      "-0.24064848086017882\n",
      "-0.584821395418258\n",
      "-0.4715620223136386\n",
      "-0.5166185900006663\n",
      "-0.6598656141775571\n",
      "-0.43202171283383384\n",
      "-0.5178267901174265\n",
      "-0.17368127497719607\n",
      "-0.649059603762911\n",
      "-0.24943891863038956\n",
      "-0.40010288131748567\n",
      "-0.2902589450059836\n",
      "-0.3249509368241439\n",
      "-0.5696275817159957\n",
      "-0.9408139906698468\n",
      "-0.48477901254340655\n",
      "-0.715945259266604\n",
      "-0.5026751807285812\n",
      "-0.34592208582721545\n",
      "-0.6213897923504873\n",
      "-0.6012594814352034\n",
      "-0.7389198003283515\n",
      "-0.46417771279985376\n",
      "-0.4364035738794513\n",
      "-0.4697558609192627\n",
      "-0.548074658867394\n",
      "-0.6607448703152101\n",
      "-0.7226832343163212\n",
      "-0.7451196167647871\n",
      "-0.8113769194322079\n",
      "-0.5256676468006614\n",
      "-1.0737472381551072\n",
      "-0.5756410254318933\n",
      "-0.7379448025890566\n",
      "-0.6095032695228952\n",
      "-0.7268343476692508\n",
      "-0.9808682291171499\n",
      "-0.6159903276026869\n",
      "-0.7825219481829148\n",
      "-0.9256128032567428\n",
      "-0.9577070573701276\n",
      "-0.9854901576006168\n",
      "-0.8572094540160063\n",
      "-0.8538575130367518\n",
      "-0.7397384524351839\n",
      "-1.0315010566795353\n",
      "-0.9086763111570515\n",
      "-0.7297443135720812\n",
      "-0.6923763659843464\n",
      "-0.9848984535990343\n",
      "-0.9310189636014746\n",
      "-0.7385826397418661\n",
      "-0.7587446284959045\n",
      "-0.7719083319014515\n",
      "-0.661825537866295\n",
      "-0.3735116509976869\n",
      "-0.2293566884869676\n",
      "-0.20639357190780835\n",
      "-0.2859010328776606\n",
      "-0.5849754129082436\n",
      "-0.3944672936583214\n",
      "-0.4488330158985159\n",
      "-0.7190284080420373\n",
      "-0.4045394632546818\n",
      "-0.7348227936873012\n",
      "-0.5213899598208205\n",
      "-0.3470991157045928\n",
      "-0.27985469375309774\n",
      "-0.39503625473376097\n",
      "-0.6929676897277283\n",
      "-0.7547351630008062\n",
      "-0.7314224876107567\n",
      "-0.5751599604603721\n",
      "-0.5563455835013271\n",
      "-0.48575741817327467\n",
      "-0.7083546616174262\n",
      "-0.5392068202576759\n",
      "-0.7910319087207142\n",
      "-0.5647488337924758\n",
      "-0.9181604992379583\n",
      "-0.426906035381164\n",
      "-0.6451403933866391\n",
      "-0.5816500385261462\n",
      "-0.7113686735982518\n",
      "-0.6052887324839263\n",
      "-1.088704225717188\n",
      "-0.6490931102918241\n",
      "-0.6480358122662051\n",
      "-0.8593297928676852\n",
      "-0.5840414733303005\n",
      "-0.7672350581195958\n",
      "-0.7793112033444797\n",
      "-0.8039967614392896\n",
      "-0.900049789317693\n",
      "-0.8518807901364194\n",
      "-0.8441897360708319\n",
      "-0.6755097441214349\n",
      "-0.9359235577953583\n",
      "-0.6962053238186404\n",
      "-0.8868536221752394\n",
      "-1.135899702149894\n",
      "-1.0855555612556897\n",
      "-0.6586302213506944\n",
      "-0.6920717142355565\n",
      "-0.6199345914678659\n",
      "-0.7757293300243545\n",
      "-0.9660088614284985\n",
      "-0.965740107840214\n",
      "-1.1257113377149834\n",
      "-0.9289503712636845\n",
      "-0.7332050756353861\n",
      "-0.7772542704278468\n",
      "-0.7076418993176335\n",
      "-0.682492715262585\n",
      "-0.5320277921982952\n",
      "-0.5658311723423041\n",
      "-0.5213657924236117\n",
      "-0.581104092028685\n",
      "-0.7606624263775085\n",
      "-0.5926561885522024\n",
      "-0.44960809137860763\n",
      "-0.43387135111637215\n",
      "-0.6845383614993906\n",
      "-0.6721888242830317\n",
      "-0.6385919611140849\n",
      "-0.7660676087137462\n",
      "-1.0709619405437545\n",
      "-0.9177842537374832\n",
      "-0.8222473030534748\n",
      "-0.9711136200530778\n",
      "-0.7807324653864363\n",
      "-0.7935824990835215\n",
      "-0.733540934757284\n",
      "-0.6892150708546171\n",
      "-0.6963682024127523\n",
      "-0.6646236938750507\n",
      "-0.8239741996552484\n",
      "-0.4696485799264361\n",
      "-0.47503505716385036\n",
      "-0.569414242302762\n",
      "-0.5167455985709728\n",
      "-0.3290245690881095\n",
      "-0.18827811621215274\n",
      "-0.4369385968705588\n",
      "-0.19356684084976847\n",
      "-0.2668335445274052\n",
      "-0.2805632905151509\n",
      "-0.4943469090634611\n",
      "-0.6928828130064952\n",
      "-0.46403786045698736\n",
      "-0.45787689664421133\n",
      "-0.37749704049444904\n",
      "-0.532799578740528\n",
      "-0.7677619288062916\n",
      "-0.607797134196485\n",
      "-0.4594739526121301\n",
      "-0.7427416011243787\n",
      "-0.8062431300493548\n",
      "-0.7586767696960741\n",
      "-0.9097056838464719\n",
      "-0.5616149812548559\n",
      "-0.4968535244027686\n",
      "-0.5675969511776233\n",
      "-0.9035216006827832\n",
      "-0.7676278795892398\n",
      "-0.5737554004155174\n",
      "-0.8253802705247353\n",
      "-0.7773444754160462\n",
      "-0.5006769157667126\n",
      "-0.27731856021454915\n",
      "-0.4818185619872877\n",
      "-0.7791587351486935\n",
      "-0.4995755563415346\n",
      "-0.5046891055282556\n",
      "-0.5271318805686237\n",
      "-0.2729236213424316\n",
      "-0.3784183138804323\n",
      "-0.32527544232224787\n",
      "-0.405757008383069\n",
      "-0.5214079243818158\n",
      "-0.36092257606986683\n",
      "-0.3687712273442411\n",
      "-0.5723873987035512\n",
      "-0.41581234815694657\n",
      "-0.41702212462270016\n",
      "-0.43847138525448237\n",
      "-0.21380950097228968\n",
      "-0.4095431360650662\n",
      "-0.38293600828699365\n",
      "-0.7749747432286249\n",
      "-0.4500821138722969\n",
      "-0.546471271608028\n",
      "-0.5533537083141962\n",
      "-0.41827927703757023\n",
      "-0.629893797081133\n",
      "-0.8061477659149945\n",
      "-0.4064728123566222\n",
      "-0.7136316285774229\n",
      "-0.7360608292354665\n",
      "-0.7785051878369473\n",
      "-0.7973475028679412\n",
      "-0.7060012444742636\n",
      "-0.7220113941611206\n",
      "-0.6565830965005797\n",
      "-0.89350383083569\n",
      "-0.6937863337004534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.6325443049342097\n",
      "-0.6068972589117569\n",
      "-0.5775434073180271\n",
      "-0.47606782487503657\n",
      "-0.6620315528099256\n",
      "-0.5187721569051917\n",
      "-0.8640252331838706\n",
      "-0.6822108986548453\n",
      "-0.9047586000674513\n",
      "-0.6102078930404979\n",
      "-0.4379743660012002\n",
      "-0.4151875206670786\n",
      "-0.5482491888347656\n",
      "-0.5162376593027523\n",
      "-0.8211993649946348\n",
      "-0.9970147026769242\n",
      "-0.8242539136531367\n",
      "-0.5592101918442145\n",
      "-0.7660571679318965\n",
      "-0.6934971408384252\n",
      "-0.7487827293422143\n",
      "-0.6067999455203129\n",
      "-0.7538736060409975\n",
      "-0.6859382519188643\n",
      "-0.696949500076901\n",
      "-0.5981076731193335\n",
      "-0.29662812347129797\n",
      "-0.5703983085192456\n",
      "-0.19751616405334171\n",
      "-0.48402329799117105\n",
      "-0.350534503474085\n",
      "-0.41706538402885446\n",
      "-0.4735960124923365\n",
      "-0.9771211267310564\n",
      "-0.5485970175834612\n",
      "-0.730999559859077\n",
      "-0.5322189732307117\n",
      "-0.4650219595860177\n",
      "-0.5722177713220048\n",
      "-0.6587436374786164\n",
      "-0.6800786248059127\n",
      "-0.8689908511478327\n",
      "-0.6662554064909206\n",
      "-0.504329488079701\n",
      "-0.7159017477507491\n",
      "-0.7201748661417438\n",
      "-0.7250476765927011\n",
      "-0.5734838516080776\n",
      "-0.7033740404534872\n",
      "-0.5235662884454807\n",
      "-0.49614512361601815\n",
      "-0.7821597161398081\n",
      "-0.532370416539927\n",
      "-0.5776749252891824\n",
      "-0.41130554968147387\n",
      "-0.5789043190337109\n",
      "-0.8512663176835046\n",
      "-0.7912638133585457\n",
      "-0.7920700484093451\n",
      "-0.45995851598541915\n",
      "-0.43716183835345285\n",
      "-0.6073375565160487\n",
      "-0.7960596533149238\n",
      "-0.7102335859286344\n",
      "-0.5077303726336048\n",
      "-0.587714643043304\n",
      "-0.7510311071437268\n",
      "-0.7745191209373237\n",
      "-0.7300178901422565\n",
      "-0.5801973086709727\n",
      "-0.8026991777352721\n",
      "-0.7670409945040078\n",
      "-0.757061285819806\n",
      "-0.8317980642421416\n",
      "-0.8185729638340132\n",
      "-0.85766701389265\n",
      "-0.9269416326757858\n",
      "-0.7714274952395692\n",
      "-0.7709085023677705\n",
      "-0.5901196991938609\n",
      "-0.970252600781586\n",
      "-0.6604921187171623\n",
      "-0.8464194667557475\n",
      "-0.6269178326712644\n",
      "-0.868059175270012\n",
      "-0.8574092673884062\n",
      "-0.5682946534794123\n",
      "-1.0155810785823636\n",
      "-0.7359932415034893\n",
      "-0.8310249679228222\n",
      "-0.491126420124148\n",
      "-0.4902974098993435\n",
      "-0.6012008879245455\n",
      "-0.7209977720209947\n",
      "-0.4740178063083348\n",
      "-0.5137670093893579\n",
      "-0.24234737421588895\n",
      "-0.5729727529048324\n",
      "-0.43936697474386244\n",
      "-0.6934417679502213\n",
      "-0.4898635050912419\n",
      "-0.29808111759935274\n",
      "-0.25298656504683326\n",
      "-0.20020719071803839\n",
      "-0.28835819866247614\n",
      "-0.5029862774644531\n",
      "-0.5636723739147048\n",
      "-0.7867800496294802\n",
      "-0.6146432133997863\n",
      "-0.6093343036748483\n",
      "-0.7912941784576379\n",
      "-0.5480088471951268\n",
      "-0.667281582586211\n",
      "-0.6923792897344204\n",
      "-0.6444924337749225\n",
      "-0.4174569827048347\n",
      "-0.3737914433839258\n",
      "-0.8028766234184171\n",
      "-0.5946189076113162\n",
      "-0.5791751470618823\n",
      "-0.6122408066695252\n",
      "-0.5540676724820327\n",
      "-0.41908224920936854\n",
      "-0.5182841065328085\n",
      "-0.46815148399405726\n",
      "-0.5094011054706099\n",
      "-0.43403185938895184\n",
      "-0.6951522494494017\n",
      "-0.42923106268197436\n",
      "-0.21470265502078312\n",
      "-0.6514485162465543\n",
      "-0.593504297524019\n",
      "-0.5530461267401086\n",
      "-0.40301189753742866\n",
      "-0.46336375208494535\n",
      "-0.5041843224196633\n",
      "-0.3482722950318185\n",
      "-0.027661841981302934\n",
      "-0.26909709611088295\n",
      "0.08646208299293033\n",
      "-0.25442725499408103\n",
      "-0.38800821155262005\n",
      "-0.5080453791665513\n",
      "-0.16015100352855782\n",
      "-0.018673924023426092\n",
      "0.08709823854749194\n",
      "0.07901233283072491\n",
      "0.06717144512793875\n",
      "-0.27964205026730915\n",
      "-0.21852630653403768\n",
      "-0.3765776272771996\n",
      "0.05577621396916144\n",
      "-0.19355526977255058\n",
      "-0.2627143303468678\n",
      "-0.34991071631247334\n",
      "-0.4363194450629632\n",
      "-0.3453876665204563\n",
      "-0.12204937128772249\n",
      "-0.37610149959615724\n",
      "-0.43655141595890595\n",
      "-0.7038985719224633\n",
      "-0.3940288465479946\n",
      "-0.5785287705996823\n",
      "-0.35813706260380707\n",
      "-0.2728393103660687\n",
      "-0.5988269985003437\n",
      "-0.650118243373784\n",
      "-0.701619402759767\n",
      "-0.5379688346489202\n",
      "-0.5064124067901669\n",
      "-0.7677068611658214\n",
      "-0.777576687855765\n",
      "-0.45291702037115933\n",
      "-0.3970301076281174\n",
      "-0.6043978016568142\n",
      "-0.7549299714002693\n",
      "-0.9082120550744335\n",
      "-0.6862788857083597\n",
      "-0.34453173153334427\n",
      "-0.31058848075818263\n",
      "-0.2638544363764364\n",
      "-0.6347405236639135\n",
      "-0.501061295839461\n",
      "-0.5085975938944597\n",
      "-0.6761743233124129\n",
      "-0.7055917528951998\n",
      "-0.6376852359147417\n",
      "-0.6999321102333841\n",
      "-0.6425394904194616\n",
      "-0.7431099613680979\n",
      "-0.6119754429792073\n",
      "-0.6958282369154039\n",
      "-0.5838239926672874\n",
      "-0.6097547291443823\n",
      "-0.5479653524313877\n",
      "-0.628532686574231\n",
      "-0.5743541409472779\n",
      "-0.6640922953481208\n",
      "-0.7256965406774234\n",
      "-0.773823220962067\n",
      "-0.7899919484380666\n",
      "-0.6988241911610914\n",
      "-0.9280070756637192\n",
      "-0.6578124611059237\n",
      "-0.6279757333649675\n",
      "-0.7011404826465456\n",
      "-0.7462033984077845\n",
      "-0.7878138456939205\n",
      "-0.5205654881976443\n",
      "-0.8277015589302301\n",
      "-0.8674591228254549\n",
      "-0.9154833319052472\n",
      "-0.9095135541728049\n",
      "-0.9660450820984758\n",
      "-1.0785303689673413\n",
      "-0.757675358335379\n",
      "-1.0324391288044756\n",
      "-1.1362349140885402\n",
      "-1.3510681785558336\n",
      "-0.7385459086146264\n",
      "-0.8876037630155883\n",
      "-0.6361028476457509\n",
      "-0.766103884643982\n",
      "-0.9847013269324177\n",
      "-0.9933992632075324\n",
      "-1.0678872959264352\n",
      "-0.7071924509801726\n",
      "-0.7864893262768263\n",
      "-0.9668909382076664\n",
      "-0.7876888640348813\n",
      "-1.1819728279023753\n",
      "-0.9391983431332402\n",
      "-0.841940681817486\n",
      "-0.6379949625978251\n",
      "-0.6299697119956487\n",
      "-0.47439322070936135\n",
      "-0.7695924164445763\n",
      "-0.8623203586247655\n",
      "-0.8308761470436508\n",
      "-0.8689725288084044\n",
      "-0.7457259024613933\n",
      "-0.7493940018456752\n",
      "-0.7130626926243259\n",
      "-0.4469806347182635\n",
      "-0.8202190106506001\n",
      "-0.7775772478374494\n",
      "-0.7387164428560244\n",
      "-0.6139293137369423\n",
      "-0.4825735663656137\n",
      "-0.7750287505817305\n",
      "-0.8017487646243499\n",
      "-0.8920372348354113\n",
      "-0.7366497428863363\n",
      "-0.7773203367775805\n",
      "-0.7046813161017567\n",
      "-0.6630104709098819\n",
      "-0.7367949380067093\n",
      "-0.6445309156809468\n",
      "-0.8379111842756307\n",
      "-0.8630188250378965\n",
      "-0.9951928759025924\n",
      "-0.7454735638413396\n",
      "-0.8375072383916492\n",
      "-1.0053772446559281\n",
      "-0.8770238980643232\n",
      "-0.764443994471683\n",
      "-0.6613811807555737\n",
      "-1.054952344444932\n",
      "-0.7265539989233093\n",
      "-0.9485494750711352\n",
      "-1.1979450057706884\n",
      "-0.7764813278398704\n",
      "-1.0779471238187923\n",
      "-0.8529581674612337\n",
      "-1.1391737196279732\n",
      "-1.1250535822890946\n",
      "-1.2299493786122853\n",
      "-1.1761971330861338\n",
      "-1.139419667691489\n",
      "-0.8483272816503885\n",
      "-1.164436610157111\n",
      "-1.0564850741660627\n",
      "-1.1102647599525761\n",
      "-0.9838065460199676\n",
      "-0.9939621755654435\n",
      "-1.2215354093120612\n",
      "-1.3191315339452816\n",
      "-1.4081810020698484\n",
      "-1.3527127732648943\n",
      "-1.2078198029257523\n",
      "-1.211041223743484\n",
      "-1.1418443175255069\n",
      "-1.1345425695371931\n",
      "-1.0604949908983758\n",
      "-1.0076797133606583\n",
      "-1.0329913884732889\n",
      "-0.8445641124804799\n",
      "-1.1559730397787547\n",
      "-1.113952867864285\n",
      "-1.0282190290065187\n",
      "-0.9297247282284384\n",
      "-0.9743966968677252\n",
      "-1.0560255379375745\n",
      "-1.143900648273866\n",
      "-1.1976745545774423\n",
      "-0.9537221602659913\n",
      "-1.1981572356600332\n",
      "-1.2597078990099022\n",
      "-1.1628707294067924\n",
      "-0.907614472609649\n",
      "-0.9700773031335029\n",
      "-0.6577027940827103\n",
      "-0.9187467119686128\n",
      "-0.913371555577866\n",
      "-0.9307475905212315\n",
      "-0.5912611014548673\n",
      "-0.8039985633107324\n",
      "-0.6481016912346296\n",
      "-0.8680290520712738\n",
      "-1.1761368466812012\n",
      "-1.186895337397557\n",
      "-1.2695033263339939\n",
      "-1.064457981056685\n",
      "-1.3544030795326316\n",
      "-1.442980134435261\n",
      "-1.1878308994892333\n",
      "-1.547736506968099\n",
      "-1.5772859128172638\n",
      "-1.3009548564585656\n",
      "-1.2800050853431446\n",
      "-1.615351900661072\n",
      "-1.6732757744407394\n",
      "-1.6893563495961823\n",
      "-1.6558392341665717\n",
      "-1.2999229057824409\n",
      "-1.5045417855995535\n",
      "-1.1481103844346119\n",
      "-1.0653669156773329\n",
      "-1.4300069136895617\n",
      "-1.1928253032615819\n",
      "-1.5153619921977133\n",
      "-1.5647765436453416\n",
      "-1.6117721368737958\n",
      "-1.546349720220241\n",
      "-1.4933298525894798\n",
      "-1.6194316630286296\n",
      "-1.4795354690596536\n",
      "-1.4611024550183276\n",
      "-1.4779324221172616\n",
      "-1.5755826006351112\n",
      "-1.2019798845137997\n",
      "-1.2857260396790562\n",
      "-1.4472999462462912\n",
      "-1.7390840951113948\n",
      "-1.6414190637803039\n",
      "-1.589144773680724\n",
      "-1.7151835553671608\n",
      "-1.7261914832339011\n",
      "-1.7041030175206138\n",
      "-1.7015202735231438\n",
      "-1.6959406394549275\n",
      "-1.7236151511946851\n",
      "-1.8596081129653532\n",
      "-1.7258443934190755\n",
      "-1.7467149115378577\n",
      "-1.5025914159117495\n",
      "0.008841391138999526\n",
      "0.026746464726159724\n",
      "-0.0027994309034454143\n",
      "0.020647984581665467\n",
      "-0.001365890981380194\n",
      "0.0055338435916213215\n",
      "-0.01654864197487352\n",
      "0.2803785620938062\n",
      "0.24422750550330555\n",
      "-0.039619197675927684\n",
      "-0.015157389094501176\n",
      "-0.09381575955071818\n",
      "0.17885086731209315\n",
      "-0.053784926572356645\n",
      "0.08591785004483624\n",
      "0.13229611516165976\n",
      "0.14009156446839477\n",
      "0.1172836801584992\n",
      "0.3645244142914827\n",
      "0.19595416560356954\n",
      "0.16255258741333772\n",
      "-0.10496584079033952\n",
      "-0.04105294359299224\n",
      "-0.006965906950789618\n",
      "0.1218472768643634\n",
      "0.03328694183096049\n",
      "0.0008482490121210816\n",
      "0.059043259138637186\n",
      "0.08923423237562582\n",
      "0.027548864300046057\n",
      "-0.14008223268565548\n",
      "-0.03708071842816949\n",
      "-0.12559502765593622\n",
      "-0.17441505559562884\n",
      "-0.18225173557380647\n",
      "-0.28872529257510643\n",
      "-0.18455155845146953\n",
      "-0.34565952345155304\n",
      "0.11740845007007802\n",
      "0.07614795569833274\n",
      "-0.21195962035169935\n",
      "-0.18548322297411315\n",
      "-0.038910291764716075\n",
      "-0.11521529967413704\n",
      "-0.15364958314128027\n",
      "-0.1302539298039771\n",
      "-0.004651634815179405\n",
      "-0.09473392610763849\n",
      "-0.23164399258117918\n",
      "-0.14024888504607533\n",
      "-0.21861294737321835\n",
      "-0.4183521271607924\n",
      "-0.10640311452350551\n",
      "-0.1166339765407859\n",
      "-0.2049457923066607\n",
      "-0.3683954772314817\n",
      "-0.20392495374799727\n",
      "-0.13251600382559192\n",
      "-0.14414415485924453\n",
      "-0.2938611579729392\n",
      "-0.3201993338752148\n",
      "-0.3533844577437403\n",
      "-0.2793475089631173\n",
      "-0.29077368491816286\n",
      "-0.30175940779376603\n",
      "-0.31172835237766505\n",
      "-0.4681989007190678\n",
      "-0.6212824816462432\n",
      "-0.5225113917350535\n",
      "-0.2656720594382046\n",
      "-0.4330738924464198\n",
      "-0.4377894166980824\n",
      "-0.6381358788049776\n",
      "-0.7493949650899558\n",
      "-0.6915194624135523\n",
      "-0.48390113083123637\n",
      "-0.40856394969846466\n",
      "-0.2122432429768021\n",
      "-0.3584504925394314\n",
      "-0.21197071823710906\n",
      "-0.3371164811693343\n",
      "-0.7019738462112332\n",
      "-0.4796339446431132\n",
      "-0.4777537532409952\n",
      "-0.5565355134284858\n",
      "-0.6079177495462686\n",
      "-0.7821907409385415\n",
      "-0.6169146214120086\n",
      "-0.657468397342313\n",
      "-0.3527603099391203\n",
      "-0.5788259936439818\n",
      "-0.6877754835778287\n",
      "-0.6190586337228324\n",
      "-0.6169731015670927\n",
      "-0.5263919141360541\n",
      "-0.6222111193538196\n",
      "-0.545656673048392\n",
      "-0.5605464352563269\n",
      "-0.5610488643732924\n",
      "-0.48520050913396234\n",
      "-0.47453682089488264\n",
      "-0.5098364883527012\n",
      "-0.6665849013238373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.5309068976139799\n",
      "-0.39450373992660925\n",
      "-0.25585094918004603\n",
      "-0.6049775209247517\n",
      "-0.6659148241101873\n",
      "-0.4944174810521359\n",
      "-0.5379332003607612\n",
      "-0.6298470251229789\n",
      "-0.34443328426858416\n",
      "-0.6360859402773653\n",
      "-0.9970039353743154\n",
      "-0.7988371718058542\n",
      "-0.4568240096783967\n",
      "-0.566567977294057\n",
      "-0.5698465603101349\n",
      "-0.8443216905718549\n",
      "-1.174604670491986\n",
      "-0.917719764568477\n",
      "-1.0932531806399675\n",
      "-0.5582739294363691\n",
      "-0.7486246155304591\n",
      "-0.5458652686981713\n",
      "-0.720553873988586\n",
      "-0.773706319383776\n",
      "-0.4587562131705062\n",
      "-0.5776427697685298\n",
      "-1.0294494039258475\n",
      "-0.7597384852871953\n",
      "-0.5079344564548405\n",
      "-0.6872036519076054\n",
      "-0.4563135830015226\n",
      "-0.6973370614767631\n",
      "-0.8477376151763437\n",
      "-0.7237331986090215\n",
      "-0.3704594708940268\n",
      "-0.576406198773087\n",
      "-0.7513290127268194\n",
      "-0.5965887262683132\n",
      "-0.5493241480718505\n",
      "-0.9370349305890573\n",
      "-0.7572808393413898\n",
      "-0.6766035385562595\n",
      "-0.5388764026284208\n",
      "-0.5878413271489432\n",
      "-0.8304554615339927\n",
      "-0.949665216077613\n",
      "-0.9476690169208978\n",
      "-0.8633090545622296\n",
      "-0.5973903213920095\n",
      "-0.7741364795902014\n",
      "-0.7520751597576603\n",
      "-0.6979150510603948\n",
      "-0.4614719579646743\n",
      "-0.8279926387929013\n",
      "-0.7269988322338801\n",
      "-0.44233783267912846\n",
      "-0.9024253987603236\n",
      "-0.5253637854144276\n",
      "-0.4594180134709032\n",
      "-0.7857100262171723\n",
      "-0.7406696140845929\n",
      "-0.9293411032006736\n",
      "-0.6991736904875668\n",
      "-0.547767930037787\n",
      "-0.769457349375009\n",
      "-0.543218983003075\n",
      "-0.7116448101934337\n",
      "-0.7676234364569969\n",
      "-0.8004309497132567\n",
      "-0.7680489729630634\n",
      "-0.7385909583820535\n",
      "-0.7084114379950451\n",
      "-0.6507164646367191\n",
      "-0.7048204390905369\n",
      "-0.6816524146171287\n",
      "-0.7060020391914055\n",
      "-0.4586125090981092\n",
      "-0.4839029466828628\n",
      "-0.6763018131603379\n",
      "-0.501117634850297\n",
      "-0.7887283153591238\n",
      "-0.7973121985048144\n",
      "-0.7147833494434261\n",
      "-0.5971201232574999\n",
      "-0.6762336371220162\n",
      "-0.5835211516356925\n",
      "-0.5715713499146268\n",
      "-0.3297379522589223\n",
      "-0.5898341021510487\n",
      "-0.49129913378811235\n",
      "-0.6056686944514219\n",
      "-0.48453755984118785\n",
      "-0.6127948161403072\n",
      "-0.6783576863571513\n",
      "-0.49746086866761197\n",
      "-0.5989600284050663\n",
      "-0.4215638329867957\n",
      "-0.49311747567921743\n",
      "-0.7922882148845597\n",
      "-0.6275294370460414\n",
      "-0.5347827660637496\n",
      "-0.8279830794574417\n",
      "-0.8547618566770301\n",
      "-0.8863368501834596\n",
      "-1.1173996180735009\n",
      "-0.9402279106967972\n",
      "-0.8255752385018313\n",
      "-0.7041811277789004\n",
      "-0.783213560245178\n",
      "-0.8813202228705918\n",
      "-0.9018442169806302\n",
      "-0.6185027268307935\n",
      "-1.0476069062799365\n",
      "-0.888039620731717\n",
      "-0.7441588012050292\n",
      "-0.7234544619137373\n",
      "-0.7600758937713185\n",
      "-0.5856201816321155\n",
      "-0.6566252205795448\n",
      "-0.7549454195926648\n",
      "-0.5481033115247231\n",
      "-0.7238098663103257\n",
      "-0.5578447691531611\n",
      "-0.655450408167506\n",
      "-0.5894020085239018\n",
      "-0.37780114990174224\n",
      "-0.32976956019223985\n",
      "-0.6115071249693635\n",
      "-0.4265428165531727\n",
      "-0.4474290142438834\n",
      "-0.5930668524408367\n",
      "-0.5033283413610481\n",
      "-0.6576955981804501\n",
      "-0.7627368528314826\n",
      "-0.7084489597035353\n",
      "-0.42721073671630094\n",
      "-0.5894346389765424\n",
      "-0.7345671491044256\n",
      "-0.5737853055157328\n",
      "-0.4897859173478312\n",
      "-0.7313698448683561\n",
      "-0.5627835822505614\n",
      "-0.5644138737018359\n",
      "-0.3855697505748053\n",
      "-0.3521598912587851\n",
      "-0.4837392623348319\n",
      "-0.45889509828860064\n",
      "-0.24879327271956758\n",
      "-0.3848563835392888\n",
      "-0.34438118062716344\n",
      "-0.4554335439214513\n",
      "-0.1951900543054606\n",
      "-0.378370910267414\n",
      "-0.3674753852786293\n",
      "-0.26992132513363454\n",
      "-0.2501389342426981\n",
      "-0.18787218114458168\n",
      "-0.2854331589545829\n",
      "-0.5238883500285063\n",
      "-0.5179461891151037\n",
      "-0.5605342628950628\n",
      "-0.3851108930503712\n",
      "-0.4853194880902603\n",
      "-0.23587761624923254\n",
      "-0.3105330062108672\n",
      "-0.21904461359600838\n",
      "-0.1844374100418891\n",
      "-0.1544937499575291\n",
      "-0.390223388311768\n",
      "-0.2741470381219519\n",
      "-0.2893820077965557\n",
      "-0.1583203503656603\n",
      "-0.4553061509939457\n",
      "-0.42128886998578574\n",
      "-0.4169737732828258\n",
      "-0.3922495018420926\n",
      "-0.33086385949261105\n",
      "-0.10890456181345633\n",
      "0.055018131738671316\n",
      "-0.2364400358293517\n",
      "-0.18620838068583356\n",
      "-0.477156501881394\n",
      "-0.4176054861922661\n",
      "-0.22022898701374288\n",
      "0.1168119334844481\n",
      "0.2575297469653318\n",
      "-0.0015781759478731977\n",
      "0.20840300728857358\n",
      "0.09969789739597762\n",
      "0.03638933968913978\n",
      "-0.09696536212670752\n",
      "-0.049617801262004546\n",
      "-0.2812790511045731\n",
      "-0.2181875646560055\n",
      "-0.0031522475173858255\n",
      "0.05363536518568506\n",
      "0.06235378640529924\n",
      "0.0660496956810083\n",
      "0.048571056368611164\n",
      "0.08616111665604921\n",
      "0.18116287577222934\n",
      "0.004120261716307187\n",
      "0.18585307619783123\n",
      "0.23672288340812506\n",
      "0.23543580684606055\n",
      "0.2361908932381949\n",
      "0.20653824459074446\n",
      "-0.056287494892804615\n",
      "0.11325836427943287\n",
      "-0.13847911679270708\n",
      "0.028850110802288748\n",
      "-0.30413908616981433\n",
      "-0.22307226999241495\n",
      "-0.28804359485806064\n",
      "-0.16810834951802384\n",
      "-0.03549376022615623\n",
      "0.1183707090209235\n",
      "-0.010762102257023825\n",
      "0.15101869200464352\n",
      "0.07801336317818391\n",
      "0.2817288680383858\n",
      "0.039449822924262495\n",
      "0.1634449943280702\n",
      "0.1390578157837292\n",
      "0.07974728241190066\n",
      "-0.13692658484073694\n",
      "-0.07916048016784134\n",
      "-0.079703618557143\n",
      "-0.11801713839157053\n",
      "0.04630563291967096\n",
      "0.06662972289415008\n",
      "0.23065584477965692\n",
      "0.017978335297301258\n",
      "0.03141354386158376\n",
      "-0.1588087941895951\n",
      "-0.035903666617437505\n",
      "-0.13875373603859062\n",
      "-0.12512491489527974\n",
      "-0.22575115034114515\n",
      "-0.08354354490468183\n",
      "-0.3137276913083387\n",
      "-0.06861539066067426\n",
      "-0.1896760602987307\n",
      "-0.16438342679115656\n",
      "-0.3744412183372036\n",
      "-0.23160127241235354\n",
      "-0.16270589603022279\n",
      "-0.1543828453961294\n",
      "-0.07860391118360929\n",
      "0.017175610928593578\n",
      "0.3456894820898304\n",
      "0.09799439174023883\n",
      "0.13253287958162352\n",
      "0.09791359132688131\n",
      "0.16670063418409933\n",
      "0.07839186073003127\n",
      "0.035343953148292896\n",
      "0.461453420563419\n",
      "0.3948302009003714\n",
      "0.3877397554798195\n",
      "0.08703131362706629\n",
      "-0.25047590454188473\n",
      "0.031270347394853\n",
      "0.23936707563077997\n",
      "-0.2724812126290339\n",
      "-0.15979189038049613\n",
      "-0.21979507385321842\n",
      "-0.20167526197380115\n",
      "0.09633164843299641\n",
      "0.012125351353803944\n",
      "-0.11718930532503408\n",
      "-0.10897963425832978\n",
      "-0.022076864481567274\n",
      "-0.007811105824594994\n",
      "-0.09220736311051105\n",
      "-0.16805020967951698\n",
      "-0.06071192246498055\n",
      "-0.07878373058614518\n",
      "-0.12160225747444459\n",
      "0.08077212302575948\n",
      "0.11777500660631589\n",
      "-0.06141147545858738\n",
      "-0.21286276992513353\n",
      "-0.004244189658654925\n",
      "-0.011204927583432691\n",
      "-0.2070393619189875\n",
      "-0.02574880652971813\n",
      "0.09378413674771127\n",
      "0.11408281150600717\n",
      "0.09085565099689503\n",
      "-0.181973269925677\n",
      "-0.0902422613369414\n",
      "0.04555230041237908\n",
      "-0.16875790255452366\n",
      "-0.2620474581194133\n",
      "-0.0388332924611894\n",
      "-0.2061715108066244\n",
      "-0.08592213439667706\n",
      "-0.13502292148932837\n",
      "-0.4384897046700332\n",
      "-0.2700656628629619\n",
      "-0.07543645118019499\n",
      "-0.037250731495970225\n",
      "-0.24131668408584928\n",
      "-0.05092701446223945\n",
      "-0.11280563871137289\n",
      "-0.15169045605644624\n",
      "-0.17199456006941213\n",
      "-0.13938403249912934\n",
      "-0.06381864123651028\n",
      "-0.20506287461953743\n",
      "-0.026029698952335468\n",
      "-0.37784492946018805\n",
      "-0.5965646759702271\n",
      "-0.26787114836621706\n",
      "-0.10953570585660408\n",
      "-0.08551713190788032\n",
      "-0.36837287038101907\n",
      "-0.33929033072856885\n",
      "-0.2756296631416951\n",
      "-0.07992700897011012\n",
      "-0.3690733345900011\n",
      "-0.3071548321889154\n",
      "-0.1253453788222013\n",
      "-0.3228638036723707\n",
      "-0.30435193741435107\n",
      "-0.5225657526531254\n",
      "-0.24578353205310474\n",
      "-0.19460304564964911\n",
      "-0.4719238679399967\n",
      "-0.16631831394312196\n",
      "-0.3842769325479519\n",
      "-0.5108167686984761\n",
      "-0.48510167826621453\n",
      "-0.42847697518566075\n",
      "-0.5134987097863374\n",
      "-0.49480701013646494\n",
      "-0.4690896728878299\n",
      "-0.5820978380149282\n",
      "-0.4208459024668967\n",
      "-0.26835294408778076\n",
      "-0.48389386630269904\n",
      "-0.6546836835037384\n",
      "-0.4104444739157589\n",
      "-0.3778269608126344\n",
      "-0.5907972868625977\n",
      "-0.605582512674236\n",
      "-0.31894930157099355\n",
      "-0.38284575665391696\n",
      "-0.26151165297753887\n",
      "-0.22940659725449977\n",
      "-0.30447611362339555\n",
      "-0.5797480613814993\n",
      "-0.3524187710636193\n",
      "-0.5271612740363846\n",
      "-0.3887106786227664\n",
      "-0.45597739040063273\n",
      "-0.7427030697412373\n",
      "-0.6654320368218141\n",
      "-0.3523394349495457\n",
      "-0.3375503088478826\n",
      "-0.6680617140456275\n",
      "-0.7811805863071214\n",
      "-0.28936207703072214\n",
      "-0.204878307985073\n",
      "-0.2667494641253925\n",
      "-0.4639887589441516\n",
      "-0.19915847992291627\n",
      "-0.41437937630749133\n",
      "-0.40193788291059596\n",
      "-0.3399325638897658\n",
      "-0.4333182373544315\n",
      "-0.49190993845495395\n",
      "-0.3603238423720036\n",
      "-0.3858489829803489\n",
      "-0.46846579163690294\n",
      "-0.8272938086065813\n",
      "-0.7710951213911109\n",
      "-0.8944218495261497\n",
      "-0.46149746171510975\n",
      "-0.3949172606168805\n",
      "-0.6330365269099714\n",
      "-0.6671614372402677\n",
      "-0.6454320372145156\n",
      "-0.7102288035817703\n",
      "-0.5370967399563175\n",
      "-0.5040526899583865\n",
      "-0.285495669261562\n",
      "-0.34070351515036423\n",
      "-0.5866316065290171\n",
      "-0.7821404920523984\n",
      "-0.42932964744416785\n",
      "-0.33748885668823136\n",
      "-0.3842881090048018\n",
      "-0.3821506841170461\n",
      "-0.49418029191631957\n",
      "-0.5966108296538776\n",
      "-0.4607324754616598\n",
      "-0.3763586268289668\n",
      "-0.5371304324069386\n",
      "-0.6898933057461488\n",
      "-0.3042406526327223\n",
      "-0.2830743374207513\n",
      "-0.33773302332134353\n",
      "-0.5944468277166639\n",
      "-0.6071485258789303\n",
      "-0.3029822506671255\n",
      "-0.58972980350327\n",
      "-0.4965084614610449\n",
      "-0.23422866436419026\n",
      "-0.12656314902327043\n",
      "0.06420927766551696\n",
      "-0.18959819894119667\n",
      "-0.27420996220158284\n",
      "-0.19748828507565738\n",
      "-0.43186261649216595\n",
      "-0.4189002729964541\n",
      "-0.38362554044667835\n",
      "-0.20390905589394848\n",
      "-0.33295707987230894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.36808701797881777\n",
      "-0.5427069428442437\n",
      "-0.6315317369855582\n",
      "-0.3176372603908056\n",
      "-0.6938384652704725\n",
      "-0.5978120112177425\n",
      "-0.8188284893886695\n",
      "-0.41608001754732615\n",
      "-0.6428429543657606\n",
      "-0.6698124891036961\n",
      "-0.5979361294887563\n",
      "-0.44370579989160613\n",
      "-0.9684065123015481\n",
      "-0.6819098477312207\n",
      "-0.3818472078607926\n",
      "-0.6678315311643267\n",
      "-0.45394007901667577\n",
      "-0.6308534243560888\n",
      "-0.5167193117830233\n",
      "-0.8124093459717195\n",
      "-0.7288061819516827\n",
      "-0.5380553420416486\n",
      "-0.8351563281316232\n",
      "-0.9147192199721507\n",
      "-1.130569918680742\n",
      "-0.6128455225254097\n",
      "-0.5141381521550532\n",
      "-0.7669145703618925\n",
      "-0.5241425042350064\n",
      "-0.7867406704196946\n",
      "-0.78061789949995\n",
      "-0.5591551130732006\n",
      "-0.6856988850856474\n",
      "-0.5846118491097343\n",
      "-0.358747172959321\n",
      "-0.6996050972630316\n",
      "-0.7124972564570035\n",
      "-0.6997903070218674\n",
      "-0.7574438156665286\n",
      "-0.6185985742376785\n",
      "-0.8955692568599606\n",
      "-0.8432450130887669\n",
      "-0.871334292847139\n",
      "-0.9292426975582597\n",
      "-0.6761579722044889\n",
      "-0.9489205924955849\n",
      "-0.6772017262382068\n",
      "-1.0401785956546097\n",
      "-0.6209436601544657\n",
      "-1.1462834609060837\n",
      "-0.9245844433209702\n",
      "-0.8551581828976029\n",
      "-0.9628794723975675\n",
      "-0.7681799223473195\n",
      "-1.0120641433382656\n",
      "-1.0323742801715423\n",
      "-1.024171369861012\n",
      "-0.8690931689367614\n",
      "-1.1041118292706207\n",
      "-1.2093502839973551\n",
      "-1.226105468072447\n",
      "-1.1384585933128797\n",
      "-1.0888910747460723\n",
      "-0.8654186700655286\n",
      "-1.174289199935702\n",
      "-0.8828080958749518\n",
      "-1.0694485441358916\n",
      "-1.288513816341432\n",
      "-1.271453383174425\n",
      "-1.5203189890887798\n",
      "-1.1059664770865971\n",
      "-1.1505346729354073\n",
      "-0.9816421148108085\n",
      "-1.3273996682066158\n",
      "-1.0995604249372448\n",
      "-0.9097504681814447\n",
      "-1.2300183654903027\n",
      "-1.2009841314206133\n",
      "-1.5059325073113754\n",
      "-1.3090896419698141\n",
      "-1.1105761401745458\n",
      "-0.837077203660946\n",
      "-1.0828074308976858\n",
      "-1.0753658405789006\n",
      "-0.9542915022602871\n",
      "-1.2632108989296578\n",
      "-1.2965035751771852\n",
      "-1.3169546242919907\n",
      "-1.0280641797745178\n",
      "-1.5777722469525437\n",
      "-1.4051497943666564\n",
      "-1.0401729799300221\n",
      "-1.2839777876464171\n",
      "-1.231693698249407\n",
      "-1.3079129107418261\n",
      "-1.2974756122336306\n",
      "-1.1254929832863598\n",
      "-1.1928548506134253\n",
      "-1.280413018846931\n",
      "-1.7454334651318741\n",
      "-1.816200355442211\n",
      "-1.6555891613899956\n",
      "-1.643623070000882\n",
      "-1.5642031852478915\n",
      "-1.5683649490365525\n",
      "-1.5800542182732886\n",
      "-1.2798490954382908\n",
      "-1.6492080525809445\n",
      "-1.64757333504734\n",
      "-1.804704930632099\n",
      "-1.5896532544021875\n",
      "-1.57675140724161\n",
      "-1.638460138169863\n",
      "-1.4921932525370005\n",
      "-1.6383976696675515\n",
      "-1.7327147878887434\n",
      "-1.3592764493356435\n",
      "-1.8639758540786988\n",
      "-1.6726961543210703\n",
      "-1.7339723168091694\n",
      "-1.8969342435560466\n",
      "-1.7778400176471256\n",
      "-1.902466248574429\n",
      "-1.8673829967962126\n",
      "-1.812096838723001\n",
      "-1.6596343860301779\n",
      "-1.6256531485101113\n",
      "-1.6337157025363576\n",
      "-1.6289038101390412\n",
      "-1.231880673910393\n",
      "-1.5297731123520049\n",
      "-1.601970406653912\n",
      "-1.607260298243099\n",
      "-1.4381219932320715\n",
      "-1.5951454033845678\n",
      "-1.7032535050858346\n",
      "-1.6157499460563571\n",
      "-1.6905762900552168\n",
      "-1.2235995882270674\n",
      "-1.542098869148767\n",
      "-1.5307520559072825\n",
      "-1.5463477000652948\n",
      "-1.5577385882280914\n",
      "-1.6441084696720023\n",
      "-1.5566544492185603\n",
      "-1.5991030651768783\n",
      "-1.3309778448347824\n",
      "-1.610316290088613\n",
      "-1.646760675136242\n",
      "-1.7053919814091554\n",
      "-1.4137388030958402\n",
      "-1.7634018267762743\n",
      "-1.8359260035479423\n",
      "-1.4708312760337414\n",
      "-1.7640585217609595\n",
      "-1.8096373006485913\n",
      "-1.603086713678955\n",
      "-1.5573187342318815\n",
      "-1.8500997538260742\n",
      "-1.7392206083972552\n",
      "-1.8431519527215992\n",
      "-1.8973735436747237\n",
      "-1.883996377078695\n",
      "-1.6573239084142992\n",
      "-1.8526180529569742\n",
      "-1.9287413479036493\n",
      "-1.9730253560698754\n",
      "-1.710016486000568\n",
      "-2.0405580884529937\n",
      "-2.188483390643015\n",
      "-2.1210138744420055\n",
      "-1.871404096186942\n",
      "-2.1431755210177377\n",
      "-2.244447208734558\n",
      "-2.350272151437311\n",
      "-2.055197569860792\n",
      "-2.229384264665998\n",
      "-2.2384291472321904\n",
      "-2.2603634966109327\n",
      "-2.3528866923630565\n",
      "-2.2284031507199327\n",
      "-2.291459004479208\n",
      "-2.3932858097718914\n",
      "-2.289273995054446\n",
      "-2.334557000376727\n",
      "-2.1395606198384782\n",
      "-2.5397878872029045\n",
      "-2.40344968337\n",
      "-2.5068245663156876\n",
      "-0.000843278885173937\n",
      "-0.01377858387396682\n",
      "-0.015834792301486655\n",
      "-0.014141865435082947\n",
      "-0.01564421891660459\n",
      "-0.02646220184128089\n",
      "-0.1641344581692663\n",
      "-0.02645370615221436\n",
      "-0.014417694408990142\n",
      "0.11844630996573993\n",
      "0.17808891995835424\n",
      "0.32442611923964326\n",
      "0.48424147665644757\n",
      "0.5918760987539223\n",
      "0.6157868940280288\n",
      "0.6855987712818465\n",
      "0.7143336515447669\n",
      "0.7339570524418452\n",
      "0.8037738737853273\n",
      "0.7341982193184788\n",
      "0.7623455062178927\n",
      "0.6394401065973497\n",
      "0.6044532914107523\n",
      "0.5688611133461988\n",
      "0.5047460692323834\n",
      "0.5057316282875238\n",
      "0.585930050563011\n",
      "0.5785288553626405\n",
      "0.5533522094878378\n",
      "0.6346834048167398\n",
      "0.624262125258072\n",
      "0.42292157847587586\n",
      "0.32001532238707386\n",
      "0.27124391649354923\n",
      "0.2688392645214049\n",
      "0.1950282182933147\n",
      "0.24419151265172692\n",
      "0.24184688644491312\n",
      "0.11195693275005787\n",
      "0.1081702108107176\n",
      "0.14226258788918913\n",
      "0.12108626916827696\n",
      "0.056753973027344175\n",
      "-0.017474647889439456\n",
      "-0.05061400620894039\n",
      "-0.053106274468992624\n",
      "-0.09371561263476007\n",
      "-0.12046371253189404\n",
      "-0.03318629151684742\n",
      "0.05587996793909998\n",
      "0.07194445930655599\n",
      "0.03481974402895915\n",
      "0.002104794680918091\n",
      "0.050948296692526374\n",
      "0.0751640557888631\n",
      "0.014260673370514593\n",
      "0.06658944094613203\n",
      "0.1345844008781899\n",
      "0.11326811120567029\n",
      "0.11851516856733632\n",
      "0.09475705099055773\n",
      "0.11751500012405419\n",
      "0.055109958579583784\n",
      "0.13407354969761576\n",
      "0.20470372958025515\n",
      "0.1378836613423635\n",
      "0.10037069706707119\n",
      "0.11173067454457318\n",
      "0.059770321530555406\n",
      "-0.0031570473859363693\n",
      "0.38542258070383945\n",
      "0.0971329027571844\n",
      "0.037534329617403994\n",
      "-0.016732729202457924\n",
      "-0.04690964161351882\n",
      "-0.12081853860226807\n",
      "-0.05019393544097044\n",
      "-0.08795222390816165\n",
      "-0.07739617508029407\n",
      "-0.11504817293793174\n",
      "-0.1546910922251804\n",
      "-0.10098223009616321\n",
      "-0.07268431796395622\n",
      "-0.08241995954036949\n",
      "-0.1525461890790229\n",
      "-0.22208398128568185\n",
      "-0.28615574746111155\n",
      "-0.31138443603328225\n",
      "-0.34656857139399116\n",
      "-0.33586200835417707\n",
      "-0.3589321294534381\n",
      "-0.340103893050219\n",
      "-0.2689598637145025\n",
      "-0.2569693235013938\n",
      "-0.2722304001163596\n",
      "-0.28166217627521795\n",
      "-0.27824060330328043\n",
      "-0.33441465575519413\n",
      "-0.37378679589449276\n",
      "-0.3525343978256476\n",
      "-0.3714818076020205\n",
      "-0.3619159940042568\n",
      "-0.3251619643050181\n",
      "-0.26946599379989583\n",
      "-0.3388942982036953\n",
      "-0.34518806975306804\n",
      "-0.2699760071549099\n",
      "-0.28870954283699085\n",
      "-0.35630959361851056\n",
      "-0.309815118046834\n",
      "-0.24911158023218952\n",
      "-0.3004245180840169\n",
      "-0.30308349977656945\n",
      "-0.23923425588522243\n",
      "-0.2620476557634523\n",
      "-0.30627060701106484\n",
      "-0.3300326803372476\n",
      "-0.21578661784432376\n",
      "-0.34977916493396766\n",
      "-0.4052753071666027\n",
      "-0.4704622854825553\n",
      "-0.46618278018330767\n",
      "-0.41081373727507314\n",
      "-0.3107153663233976\n",
      "-0.35084403582534746\n",
      "-0.4169517257267983\n",
      "-0.2912507097613628\n",
      "-0.3920391777630828\n",
      "-0.41891373834957873\n",
      "-0.4544421203415098\n",
      "-0.4172094624797811\n",
      "-0.3827140650657926\n",
      "-0.41845977942584534\n",
      "-0.40903931409233785\n",
      "-0.4798055869377685\n",
      "-0.47693415559963154\n",
      "-0.4895492693055581\n",
      "-0.5243625256522453\n",
      "-0.46691249528791523\n",
      "-0.5054723203936298\n",
      "-0.5617137409150893\n",
      "-0.5494490042304376\n",
      "-0.5458254825935763\n",
      "-0.5511786860575835\n",
      "-0.5274297530989895\n",
      "-0.5863538857393795\n",
      "-0.7051993534657893\n",
      "-0.7805329035040283\n",
      "-0.7835238344159707\n",
      "-0.8005710454659353\n",
      "-0.7540476601455245\n",
      "-0.7818252755136923\n",
      "-0.7052249510739583\n",
      "-0.7276775219722417\n",
      "-0.7788721170667238\n",
      "-0.7402117740284742\n",
      "-0.6977430717422898\n",
      "-0.6360986637577585\n",
      "-0.610893776823128\n",
      "-0.6103353992123871\n",
      "-0.6354946507811758\n",
      "-0.6692096052403186\n",
      "-0.6558281831004891\n",
      "-0.5829272671273015\n",
      "-0.5679358759647511\n",
      "-0.5737338311067967\n",
      "-0.6100654278819954\n",
      "-0.5920138249562845\n",
      "-0.6002895945626822\n",
      "-0.6229941178940954\n",
      "-0.6216062159301596\n",
      "-0.5464154827122838\n",
      "-0.4734243026717844\n",
      "-0.4361181364293507\n",
      "-0.47488983585917244\n",
      "-0.4419179535794874\n",
      "-0.4238489035221877\n",
      "-0.4734832719746408\n",
      "-0.44596663235307477\n",
      "-0.4555181078854032\n",
      "-0.4878017840967359\n",
      "-0.41753366512590234\n",
      "-0.38279009891079646\n",
      "-0.4319404754668258\n",
      "-0.4383189777367563\n",
      "-0.3656957536347544\n",
      "-0.29405385205353507\n",
      "-0.34929534981042254\n",
      "-0.389766565143904\n",
      "-0.37497545477741046\n",
      "-0.37550993005328004\n",
      "-0.4041577235424521\n",
      "-0.38578932926011555\n",
      "-0.4073510771584654\n",
      "-0.4045944809116393\n",
      "-0.36143212583137396\n",
      "-0.3768744217516047\n",
      "-0.32902034049441314\n",
      "-0.2673290601443748\n",
      "-0.20576874450556812\n",
      "-0.20738863156493978\n",
      "-0.15573514920459977\n",
      "-0.14747083701300295\n",
      "-0.16477404964805273\n",
      "-0.14974900079572823\n",
      "-0.12173504397295867\n",
      "-0.0780039211215023\n",
      "-0.04956565460189999\n",
      "-0.026721313032004056\n",
      "-0.0017170097916692304\n",
      "-0.13585990530639197\n",
      "-0.1669854788577886\n",
      "-0.20025091481383525\n",
      "0.16214520541718475\n",
      "-0.0817903201095399\n",
      "0.18221635248961418\n",
      "0.21560888562415143\n",
      "-0.12565626775423497\n",
      "0.20796623175969303\n",
      "0.1985184008665914\n",
      "0.1378138760639868\n",
      "-0.10993279124954984\n",
      "-0.11610280919441426\n",
      "-0.2686696664569932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.275966047316156\n",
      "0.01904584547981407\n",
      "-0.09292984529012718\n",
      "0.07225438990185286\n",
      "0.025346293046192066\n",
      "0.2078182560561073\n",
      "0.07505898296306052\n",
      "0.16059834696788658\n",
      "-0.10671368631667223\n",
      "-0.1679743887854633\n",
      "-0.21703364272768014\n",
      "0.21773630599527044\n",
      "0.2004023934832787\n",
      "-0.040997953185595584\n",
      "0.11873784842373163\n",
      "0.23044855547971446\n",
      "0.2532621699721553\n",
      "-0.007750732100078275\n",
      "0.20303505342173717\n",
      "0.07353835520337099\n",
      "0.05519618120691825\n",
      "-0.3846594368423817\n",
      "-0.2079107009209768\n",
      "0.09888107594775983\n",
      "-0.09661597898563062\n",
      "0.057540415589490315\n",
      "-0.023603620803289267\n",
      "-0.23812735459725098\n",
      "-0.4153832946718381\n",
      "-0.14352491020219982\n",
      "-0.3333697221279645\n",
      "-0.6299849249113803\n",
      "-0.35974812023450325\n",
      "0.0861455654945221\n",
      "-0.1298628168879077\n",
      "-0.06425049569394571\n",
      "0.05056223014481341\n",
      "-0.1949522913595469\n",
      "-0.38839801755462644\n",
      "-0.3342673483954177\n",
      "-0.5241094267184271\n",
      "-0.32233848033604134\n",
      "-0.5042595004946887\n",
      "-0.3370074859298494\n",
      "-0.550145631004355\n",
      "-0.2523475540163425\n",
      "-0.18435505583438003\n",
      "-0.09138311401982868\n",
      "-0.1307141604715708\n",
      "-0.3873376764063124\n",
      "-0.3042880724355984\n",
      "-0.08963610501123134\n",
      "-0.026844388755480175\n",
      "-0.12334722927945684\n",
      "0.11562113549135615\n",
      "-0.32386179898759626\n",
      "-0.2209764497176474\n",
      "-0.43511683637121074\n",
      "0.07585019159674755\n",
      "-0.4328423933980059\n",
      "-0.12555362081458638\n",
      "-0.3454411078372316\n",
      "-0.08490562699481533\n",
      "-0.3104824629567711\n",
      "-0.38171415377029005\n",
      "-0.10541043090396084\n",
      "-0.6706375158910445\n",
      "-0.5505936181103237\n",
      "-0.2338404051197515\n",
      "-0.3411098020030743\n",
      "-0.390654283073001\n",
      "-0.40398794204436617\n",
      "-0.6777991871469925\n",
      "-0.749231746031976\n",
      "-0.4514427992695142\n",
      "-0.5246802410996171\n",
      "-0.08761051759210402\n",
      "-0.1022699860315555\n",
      "-0.28691011182415765\n",
      "-0.4754342598362541\n",
      "-0.6726166204547142\n",
      "-0.2556448944342446\n",
      "-0.4832119515722094\n",
      "-0.7050044935577854\n",
      "-0.6941852302990312\n",
      "-0.3443895772667711\n",
      "-0.48050113861495486\n",
      "-0.5048824836000845\n",
      "-0.6291471640100801\n",
      "-0.5738019395675731\n",
      "-0.2881864460483731\n",
      "-0.6097357718187753\n",
      "-0.3310006831033461\n",
      "-0.29658511963168127\n",
      "-0.5007237820215861\n",
      "-0.6117150455960919\n",
      "-0.6294073211412617\n",
      "-0.7398764318700629\n",
      "-0.5033833617148713\n",
      "-0.727657841854181\n",
      "-0.49515832998836273\n",
      "-0.46156062005577825\n",
      "-0.23957107143770207\n",
      "-0.23538992144077917\n",
      "-0.671633318145915\n",
      "-0.6087491865439133\n",
      "-0.4986401392290743\n",
      "-0.49242555824758094\n",
      "-0.683948921313825\n",
      "-0.6071766274001629\n",
      "-0.4814532405337714\n",
      "-0.27808055870870024\n",
      "-0.5941986252190907\n",
      "-0.9280786267149678\n",
      "-0.6780377690771584\n",
      "-0.7372355472266625\n",
      "-0.48205287632810384\n",
      "-0.751122796642209\n",
      "-0.70751000960933\n",
      "-0.4814282265623964\n",
      "-0.3398107404339624\n",
      "-0.4093764953763065\n",
      "-0.6266902434956474\n",
      "-0.5946627890609404\n",
      "-0.39287959891830376\n",
      "-0.5167675728212522\n",
      "-0.3243225313952659\n",
      "-0.24962307087128427\n",
      "-0.28614553132638093\n",
      "-0.22575462572497743\n",
      "-0.4087310852841194\n",
      "-0.5407733731377189\n",
      "-0.5910403362311901\n",
      "-0.31475417168591896\n",
      "-0.600762377159123\n",
      "-0.5122073058302617\n",
      "-0.8121096366926905\n",
      "-0.9225802761622457\n",
      "-0.8594112997082975\n",
      "-0.6671838182609702\n",
      "-0.6037322056210093\n",
      "-0.6389150224974318\n",
      "-0.8253602780658287\n",
      "-1.0075009604484042\n",
      "-0.761883023579651\n",
      "-0.6115806641088188\n",
      "-0.7385091591609126\n",
      "-0.8349755660964875\n",
      "-0.7250011262077556\n",
      "-0.6625093604538651\n",
      "-0.47468199125289856\n",
      "-0.3958844332226367\n",
      "-0.41055445718166383\n",
      "-0.5816233270267209\n",
      "-0.5473284967321256\n",
      "-0.4994747719022884\n",
      "-0.8019605448911193\n",
      "-0.6197695899715736\n",
      "-0.46174003462523233\n",
      "-0.5924592228578724\n",
      "-0.6765896329752792\n",
      "-0.7508664227461274\n",
      "-0.7619805224459165\n",
      "-0.5575522793801025\n",
      "-0.575585439613059\n",
      "-0.8573023829310182\n",
      "-0.8910157850775168\n",
      "-1.088207857930364\n",
      "-0.9101378172456712\n",
      "-0.623464101236617\n",
      "-0.6430017656975711\n",
      "-0.43298996598531153\n",
      "-0.4296551899828277\n",
      "-0.4852029751702913\n",
      "-0.8014593908364265\n",
      "-0.4686023743783582\n",
      "-0.7646814866973851\n",
      "-0.5360258403523762\n",
      "-0.5196014932592335\n",
      "-0.5346303757865409\n",
      "-0.671804384107521\n",
      "-0.4035842443900307\n",
      "-0.20211681300091466\n",
      "-0.5995962356839687\n",
      "-0.47867705167371627\n",
      "-0.5637527359762053\n",
      "-0.5926441975479713\n",
      "-0.5354480807453401\n",
      "-0.8009424700898893\n",
      "-0.8694578955282418\n",
      "-1.1043191170902174\n",
      "-0.6193911638170205\n",
      "-0.7882692173051316\n",
      "-0.8937048764812754\n",
      "-0.696234240204607\n",
      "-0.9288598424789399\n",
      "-0.6590214932248143\n",
      "-0.7032263248402133\n",
      "-0.7232147920364023\n",
      "-0.9422175505782119\n",
      "-0.7913824880811963\n",
      "-0.986031315093733\n",
      "-1.0412195547120846\n",
      "-0.8316312525119464\n",
      "-0.8258271479132071\n",
      "-0.6423261269654076\n",
      "-0.9259920669264967\n",
      "-0.726968337387968\n",
      "-0.7244572690210715\n",
      "-1.2539234754871411\n",
      "-0.9366504810143758\n",
      "-0.8605190966647012\n",
      "-0.8942724367791097\n",
      "-0.8008248493387481\n",
      "-0.661426112850554\n",
      "-0.8134507084548235\n",
      "-0.7374305878411969\n",
      "-0.8048541491869308\n",
      "-0.87131048276554\n",
      "-0.7531983570287255\n",
      "-0.995822227060202\n",
      "-0.8389361087940879\n",
      "-0.8439775643287089\n",
      "-0.7846824319133998\n",
      "-0.708860823757156\n",
      "-0.809130716266214\n",
      "-0.5913899237126188\n",
      "-0.6808996425489213\n",
      "-0.7410006863838847\n",
      "-0.5896006171494672\n",
      "-0.41798273094942756\n",
      "-0.47220180904310244\n",
      "-0.5105009935322824\n",
      "-0.7518775318854269\n",
      "-0.5929566594434175\n",
      "-0.7159999594572282\n",
      "-0.5760082183110304\n",
      "-0.603050996746557\n",
      "-0.47975752511174713\n",
      "-0.8251372508527954\n",
      "-0.4160358253907216\n",
      "-0.6673038248392943\n",
      "-0.5974841640204208\n",
      "-0.5735724797312153\n",
      "-0.7621540902107968\n",
      "-0.6212295625971216\n",
      "-0.592953077558236\n",
      "-0.6769092227395962\n",
      "-0.785274260152036\n",
      "-0.6308327926999482\n",
      "-0.6310530209862147\n",
      "-0.39217803715670485\n",
      "-0.5370317250605455\n",
      "-0.4163660063044611\n",
      "-0.49207690036293283\n",
      "-0.6713135820979115\n",
      "-0.4598085693250506\n",
      "-0.49882952847863704\n",
      "-0.3883670126668456\n",
      "-0.5548621200958306\n",
      "-0.3702771320356533\n",
      "-0.5160766823770124\n",
      "-0.7427779735683854\n",
      "-0.4183200587389089\n",
      "-0.4670694704395058\n",
      "-0.37631400710420404\n",
      "-0.2952548643974456\n",
      "-0.21826076658372837\n",
      "-0.17985588068107716\n",
      "-0.45369458567092835\n",
      "-0.3909917114145177\n",
      "-0.5574685145020147\n",
      "-0.5581354633508634\n",
      "-0.37476617527743894\n",
      "-0.31795504378085165\n",
      "-0.52243838442322\n",
      "-0.3760800269923018\n",
      "-0.2563238459792166\n",
      "-0.5153200355429168\n",
      "-0.37536398130726145\n",
      "-0.3704982125289903\n",
      "-0.3436166223844927\n",
      "-0.5967846571297489\n",
      "-0.24078568467808378\n",
      "-0.6187972264856055\n",
      "-0.4239353122435527\n",
      "-0.5056909089360833\n",
      "-0.2524634572127227\n",
      "-0.18377100165835983\n",
      "0.01716853444730805\n",
      "0.05211855319085608\n",
      "-0.015129800287426814\n",
      "-0.07284046829929702\n",
      "-0.22626598463614161\n",
      "-0.39041838593931616\n",
      "-0.27574105788858366\n",
      "-0.2903948019940384\n",
      "-0.5168560813711673\n",
      "-0.12229724731412696\n",
      "-0.4287165631033344\n",
      "-0.1819004951253068\n",
      "-0.4387847718278326\n",
      "-0.5270273447745909\n",
      "-0.7507823659757539\n",
      "-0.6842490765338612\n",
      "-0.3088144917775185\n",
      "-0.3357918405651537\n",
      "-0.36066607043602444\n",
      "-0.6462963436985344\n",
      "-0.6281397270586498\n",
      "-0.7158131875186834\n",
      "-0.7956228696146406\n",
      "-0.4765413998253188\n",
      "-0.37197612487900383\n",
      "-0.5106872263073278\n",
      "-0.3490403701229234\n",
      "-0.20610193957548084\n",
      "-0.21819086494988305\n",
      "-0.34904311514310754\n",
      "-0.12763933219822005\n",
      "-0.2632377104744727\n",
      "-0.009605077330884532\n",
      "-0.2583474646524671\n",
      "-0.11558199815912486\n",
      "-0.3316773005945929\n",
      "-0.2781610502203047\n",
      "-0.3450667018585236\n",
      "-0.24529868575252503\n",
      "-0.259631832298826\n",
      "-0.048801940937140076\n",
      "-0.35397723753766613\n",
      "-0.07972983316082097\n",
      "-0.2118780856170595\n",
      "0.11786397796467694\n",
      "-0.13130995975283116\n",
      "-0.1640460837124124\n",
      "-0.15960457868832345\n",
      "0.01284506374839552\n",
      "-0.2617209153989447\n",
      "-0.34704035083460555\n",
      "-0.23937927295003605\n",
      "-0.32266750042954023\n",
      "-0.5158135256484336\n",
      "-0.2946685970427161\n",
      "-0.4446840513051572\n",
      "-0.2606653340338271\n",
      "-0.48719630586782897\n",
      "-0.43484373895533557\n",
      "-0.042330644699920095\n",
      "0.11176516600876403\n",
      "0.2713032549232797\n",
      "0.1107471659063297\n",
      "0.0071790681874152815\n",
      "0.10107959680352113\n",
      "-0.13038833623809887\n",
      "-0.15587529576020104\n",
      "-0.028662263965513857\n",
      "-0.1992436959011387\n",
      "-0.11918254040257824\n",
      "-0.34667645804036373\n",
      "-0.5067019810432252\n",
      "-0.34551289946358454\n",
      "-0.30617705831339787\n",
      "-0.2608234616009867\n",
      "-0.11818942905206192\n",
      "-0.32233825556728224\n",
      "-0.49032842341338334\n",
      "-0.15878890211161456\n",
      "-0.278627615927951\n",
      "-0.06932179457160867\n",
      "0.002921951600401887\n",
      "-0.41429214091070454\n",
      "-0.18991763590975874\n",
      "-0.15863323741347127\n",
      "-0.40262973899218063\n",
      "-0.23191907526380573\n",
      "0.03227431470666339\n",
      "0.0691827707509941\n",
      "0.12112324661177032\n",
      "0.20417220773209258\n",
      "0.15427282211838717\n",
      "-0.07347369103261774\n",
      "0.041467566853167825\n",
      "-0.15053495818660897\n",
      "-0.18071694351392154\n",
      "-0.1396909348283977\n",
      "-0.16860171083531683\n",
      "-0.12807910793025945\n",
      "-0.2684630794829191\n",
      "-0.181335941064826\n",
      "-0.13757749499913727\n",
      "-0.47444518894066956\n",
      "-0.4825852213084057\n",
      "-0.47967646599276914\n",
      "-0.4146686794413533\n",
      "-0.16524806875596404\n",
      "-0.5920499549325234\n",
      "-0.4213653803803531\n",
      "-0.5601434625822318\n",
      "-0.6143518072261956\n",
      "-0.2768535277988601\n",
      "-0.4863157817268041\n",
      "-0.5620413768099035\n",
      "-0.5481992644955404\n",
      "-0.2612544752742534\n",
      "-0.3788526008058567\n",
      "-0.5548320536174759\n",
      "-0.4707578964678807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.5157900425264726\n",
      "-0.2232063792009925\n",
      "-0.28029377425737423\n",
      "-0.11543880875920608\n",
      "-0.3239521236018407\n",
      "-0.4926906960032454\n",
      "-0.47185974117975255\n",
      "-0.1809718283565541\n",
      "-0.47853563672560406\n",
      "-0.2615327352887059\n",
      "-0.28682914943180304\n",
      "-0.5815309441272334\n",
      "-0.4472735212289003\n",
      "-0.552868145591763\n",
      "-0.49465640035332126\n",
      "-0.47554204995924587\n",
      "-0.4106398572360611\n",
      "-0.42163328167963593\n",
      "-0.38622160426167357\n",
      "-0.44886100589398176\n",
      "-0.17857763229616624\n",
      "-0.34277096990653044\n",
      "-0.22832564505734448\n",
      "-0.15502531070821257\n",
      "-0.20130086899655744\n",
      "-0.45583836165522185\n",
      "-0.4355225893603771\n",
      "-0.30452458336476296\n",
      "-0.48389662830812996\n",
      "-0.22082637170026426\n",
      "-0.25798347530610155\n",
      "-0.22032886041332353\n",
      "-0.3726694964382424\n",
      "-0.10719461170161385\n",
      "-0.3365663671750882\n",
      "-0.014598146290488306\n",
      "-0.3359857059414635\n",
      "-0.03904431909746395\n",
      "0.03897628229816897\n",
      "-0.19619942275575214\n",
      "-0.2369829790182412\n",
      "-0.22983435750443776\n",
      "-0.04884770504719728\n",
      "0.05782863533723446\n",
      "0.11669361965436144\n",
      "0.2083131443137148\n",
      "-0.21980671921891098\n",
      "0.2554686792353962\n",
      "0.02130724952936751\n",
      "-0.05346278405976686\n",
      "0.09559593815966387\n",
      "0.12778352953104466\n",
      "-0.1210241532428693\n",
      "-0.18112882590521945\n",
      "-0.17080437003714846\n",
      "-0.19193276196312675\n",
      "-0.19531236520733963\n",
      "-0.09198034036958169\n",
      "0.0011763163432537416\n",
      "-0.12957292940192067\n",
      "-0.35520373715590886\n",
      "0.06810215285365666\n",
      "0.022736911319631563\n",
      "0.13770684767163188\n",
      "-0.36171645897137766\n",
      "-0.21346884230972843\n",
      "-0.3499790052010275\n",
      "-0.07668959461409713\n",
      "-0.41948828247944214\n",
      "-0.5036137079475843\n",
      "-0.4404705282604696\n",
      "-0.46910408053608044\n",
      "-0.1984825179839255\n",
      "-0.24163197029402586\n",
      "-0.477354589602713\n",
      "-0.5289810024475864\n",
      "-0.5842862108136612\n",
      "-0.4854161380972064\n",
      "-0.6637468390414312\n",
      "-0.555947100233031\n",
      "-0.49360891379185473\n",
      "-0.2521880458772807\n",
      "-0.5407923364324944\n",
      "-0.5290057071878098\n",
      "-0.6262385707925788\n",
      "-0.2680935816908525\n",
      "-0.3406890999659456\n",
      "-0.39137623884148054\n",
      "-0.5950148320119735\n",
      "-0.6381869720323089\n",
      "-0.7665567609411322\n",
      "-0.4149502061660614\n",
      "-0.6922617269339358\n",
      "-0.7763829988859423\n",
      "-0.7058511581567041\n",
      "-0.3565634036229533\n",
      "-0.5701148978559691\n",
      "-0.4975259779998895\n",
      "-0.3588525756678954\n",
      "-0.3401391407509257\n",
      "-0.6914955339051471\n",
      "-0.5460540447861402\n",
      "-0.839139636027552\n",
      "-0.5602234967979653\n",
      "-0.7808015231632326\n",
      "-0.9482585648813816\n",
      "-0.7292646747226804\n",
      "-0.6442424347069831\n",
      "-0.8258443623372209\n",
      "-0.6918599706307192\n",
      "-0.45578698976575005\n",
      "-0.7252075428578476\n",
      "-0.9454245930555294\n",
      "-0.8654195713038577\n",
      "-0.8370708831223994\n",
      "-0.7046690289412665\n",
      "-0.810313947806102\n",
      "-0.646815532753732\n",
      "-0.5569481101839706\n",
      "-0.5544735977338128\n",
      "-0.3673575902083073\n",
      "-0.5848778795442616\n",
      "-0.3142391359258404\n",
      "-0.6616186083051209\n",
      "-0.7668818601128927\n",
      "-0.5621855030524989\n",
      "-0.7248217165736075\n",
      "-0.7142193872518137\n",
      "-0.8194736779547771\n",
      "-0.7408896704589241\n",
      "-0.745748407605622\n",
      "-0.6836835262144807\n",
      "-0.7375141969518941\n",
      "-0.657826755083924\n",
      "-0.8064981777176019\n",
      "-1.1057123997822556\n",
      "-0.6404366101780197\n",
      "-0.6287336419701882\n",
      "-1.1156667456668021\n",
      "-0.9991989148816509\n",
      "-1.296174192119074\n",
      "-0.9614228419084291\n",
      "-1.0007694265043336\n",
      "-1.1763171037722056\n",
      "-1.2326329776236804\n",
      "-1.1798545827499631\n",
      "-1.2266157416657406\n",
      "-1.2204620932568406\n",
      "-1.0130170936139262\n",
      "-1.2836209117478996\n",
      "-1.4366304990141119\n",
      "-1.2481733626704106\n",
      "-1.2922033589663022\n",
      "-1.2178866866163824\n",
      "-1.111029861380997\n",
      "-1.3168552852603208\n",
      "-1.3520482707853392\n",
      "-1.4254706590443456\n",
      "-1.562229531320887\n",
      "-1.4106432040281058\n",
      "-1.0744869296477095\n",
      "-1.186685711443947\n",
      "-1.4686475133666614\n",
      "-1.5690181495282471\n",
      "-1.5484672292712156\n",
      "-1.4923563056864038\n",
      "-1.5894931654367308\n",
      "-1.487649323024963\n",
      "-1.7009922737594119\n",
      "-1.5632185146935758\n",
      "-1.2272315097781699\n",
      "-1.2118157985487594\n",
      "-1.346627064256349\n",
      "-1.3311465911813785\n",
      "-1.8060860916792651\n",
      "-1.6471036325769348\n",
      "-1.2772571891737328\n",
      "-1.5353630710234432\n",
      "-1.6066758378507966\n",
      "-1.4293571873301167\n",
      "-1.5878223578455677\n",
      "-1.4028282157236944\n",
      "-1.155687078161548\n",
      "-1.5746919456680666\n",
      "-1.5713608382203554\n",
      "-1.6439704945784557\n",
      "-1.422662203471228\n",
      "-1.4138031650391683\n",
      "-1.5057135100952992\n",
      "-1.505189298092014\n",
      "-1.560066321487164\n",
      "-1.424965697215506\n",
      "-1.2464279114694787\n",
      "-1.4609179620507533\n",
      "-1.5371816058950296\n",
      "-1.6014457713039572\n",
      "-1.6748186610481774\n",
      "-1.4864758140274728\n",
      "-1.6245626541161924\n",
      "-1.6236020658164914\n",
      "-1.573336893604806\n",
      "-1.7048820897973913\n",
      "-1.2918279662511818\n",
      "-1.6101138401593635\n",
      "-1.6512104735043778\n",
      "-1.6817769337324422\n",
      "-1.7159952691934943\n",
      "-1.6737127702666486\n",
      "-1.6107195273104726\n",
      "-1.3381518016429044\n",
      "-1.6948949224933123\n",
      "-1.8204227876507681\n",
      "-1.9555943802063314\n",
      "-1.6016891269011009\n",
      "-1.927608308482185\n",
      "-1.8947505577188188\n",
      "-1.8482891952198601\n",
      "-2.0771964675583647\n",
      "-1.4971924340022162\n",
      "-1.8351826012384738\n",
      "-1.9316242007661637\n",
      "-2.006785464027299\n",
      "-1.9894928963347356\n",
      "-1.924236875962423\n",
      "-1.8610089979896727\n",
      "-1.891612194675606\n",
      "-1.8763305484705681\n",
      "-1.867922762125845\n",
      "-1.9334877767123673\n",
      "-1.7977558080670812\n",
      "-1.8647710735101206\n",
      "-1.9282322138082921\n",
      "-1.6548569007709597\n",
      "-1.8736774422817757\n",
      "-1.9071601410011283\n",
      "-1.9464139746936622\n",
      "-1.994671206249942\n",
      "-1.9967392801061867\n",
      "-1.8226350809800023\n",
      "-2.0219601139417467\n",
      "-1.679485572291274\n",
      "-1.98211451542496\n",
      "-1.9722997240183642\n",
      "-2.0158611575635916\n",
      "-1.7913024369157584\n",
      "-2.0584829733472536\n",
      "-2.0793343759887275\n",
      "-1.8411263624280876\n",
      "-2.047381343051797\n",
      "-2.0553541265883557\n",
      "-1.979580802348094\n",
      "-2.1980021246455346\n",
      "-1.676722664884768\n",
      "-1.9761632204581658\n",
      "-2.017762810193816\n",
      "-2.064607485636486\n",
      "-1.79587978466511\n",
      "-2.0778562520870407\n",
      "-1.9726560596416733\n",
      "-2.1890874271800045\n",
      "-1.9535616376920413\n",
      "-2.14101098343951\n",
      "-2.2779456053293154\n",
      "-2.096422505311959\n",
      "-2.044970365691847\n",
      "-2.06331823046083\n",
      "-1.9087201928945736\n",
      "-2.014641089215754\n",
      "-1.7226625136844917\n",
      "-2.122537318685445\n",
      "-2.1819168997080354\n",
      "-2.2059349319502313\n",
      "-2.2464220193422597\n",
      "-1.8953355432282692\n",
      "-2.1882205011065006\n",
      "-2.253685707708361\n",
      "-2.332326356913862\n",
      "-2.304078262883179\n",
      "-2.0147746751849427\n",
      "-2.1795403470398425\n",
      "-2.2936489807721183\n",
      "-2.1986779855737093\n",
      "-2.2348028680304823\n",
      "-1.913846563199651\n",
      "-2.3169346691001325\n",
      "-2.294185269205545\n",
      "-2.29077338762257\n",
      "0.0009207711339353167\n",
      "0.06735261328105807\n",
      "0.20570683161171982\n",
      "0.17609785636676575\n",
      "0.019718899123077706\n",
      "0.0715705642310311\n",
      "0.18336019037473955\n",
      "0.05371559444265135\n",
      "-0.20590493366941576\n",
      "-0.05288902252347088\n",
      "0.12636852785205216\n",
      "-0.12196856642068415\n",
      "-0.0029393515752247495\n",
      "-0.3893162081855779\n",
      "-0.16568684981517284\n",
      "0.13846503665284082\n",
      "0.12316061194294335\n",
      "-0.04293573345806707\n",
      "-0.15285653073350194\n",
      "0.08296983456466374\n",
      "0.026698224625927282\n",
      "0.10496866917020901\n",
      "0.033636170537367865\n",
      "0.02238565646605708\n",
      "0.08553528030450006\n",
      "0.1525304874542756\n",
      "0.264416010630674\n",
      "0.11698245823384693\n",
      "0.08402671246245734\n",
      "0.302783238309388\n",
      "0.25720003068494063\n",
      "0.17334266648683067\n",
      "0.03547214740660456\n",
      "0.10401043611945349\n",
      "0.11782551526487026\n",
      "-0.015417556761771353\n",
      "0.21410607027307305\n",
      "0.14206317876215563\n",
      "0.0569396374687738\n",
      "0.02257860365895342\n",
      "0.027962831312054907\n",
      "0.11113092758717309\n",
      "-0.09607893476695997\n",
      "0.12482086738666402\n",
      "0.0027182285733497874\n",
      "-0.32462043293884996\n",
      "-0.09312872766654698\n",
      "0.11240559995530593\n",
      "-0.06571427535338539\n",
      "-0.38784616699572216\n",
      "-0.12952871995144558\n",
      "0.016165499051536747\n",
      "0.006506101731900511\n",
      "-0.08608142358324204\n",
      "-0.30489361536016524\n",
      "-0.40247764955842436\n",
      "-0.35682519097084053\n",
      "-0.24397863041365647\n",
      "-0.17136204094071159\n",
      "-0.37806125514275857\n",
      "-0.4168655982787505\n",
      "-0.3106872895856317\n",
      "-0.29156793351296534\n",
      "-0.1948881940312076\n",
      "-0.15092691464402436\n",
      "-0.17522056971646743\n",
      "-0.4354407225903331\n",
      "-0.4579649103859518\n",
      "-0.5025469550970049\n",
      "-0.4151830510752946\n",
      "-0.8089887893385711\n",
      "-0.2517033485234782\n",
      "-0.3513607724265714\n",
      "-0.8077423912090963\n",
      "-0.7665444097562564\n",
      "-0.3196373239502935\n",
      "-0.3637916032285994\n",
      "-0.37459816566735343\n",
      "-0.8547819753965364\n",
      "-0.7631039729063406\n",
      "-0.6537664040869139\n",
      "-0.4989153680936664\n",
      "-0.7401849359046531\n",
      "-0.5455700611910381\n",
      "-0.4217060414324845\n",
      "-0.5158383581411322\n",
      "-0.6555817833469992\n",
      "-0.6059934480112382\n",
      "-0.45639949175993133\n",
      "-0.202150218186672\n",
      "-0.4781350452075141\n",
      "-0.17165669648803392\n",
      "-0.3660649482531089\n",
      "-0.2826311406225341\n",
      "-0.2694500249136355\n",
      "-0.2872892793270654\n",
      "-0.2968708217041443\n",
      "-0.26229566951550176\n",
      "-0.5742858873908121\n",
      "-0.5922507381735053\n",
      "-0.3526759879590471\n",
      "-0.5468334516229052\n",
      "-0.39860735941172915\n",
      "-0.35073845491399835\n",
      "-0.4878810486941709\n",
      "-0.4536140209705388\n",
      "-0.7938399887717602\n",
      "-0.8125890378964761\n",
      "-0.5780641881643659\n",
      "-0.4149735490463007\n",
      "-0.466023274115199\n",
      "-0.6160559132912347\n",
      "-0.643173848850442\n",
      "-0.6728432138255352\n",
      "-0.4168512397654352\n",
      "-0.7016746751396008\n",
      "-0.6423491270940427\n",
      "-0.5435068084661598\n",
      "-0.9849850559609903\n",
      "-0.7795237305050051\n",
      "-0.5446550866312654\n",
      "-0.6384538040483096\n",
      "-0.8303253206205784\n",
      "-1.0031698358367647\n",
      "-0.86095379097939\n",
      "-0.7959547024078453\n",
      "-0.9912535449720368\n",
      "-1.085018799765723\n",
      "-0.8488124534695589\n",
      "-0.7116087116166674\n",
      "-0.7831631594392464\n",
      "-0.48706050007025337\n",
      "-0.5760342687915309\n",
      "-0.6741602215485164\n",
      "-0.6535684115331832\n",
      "-0.46447155869535195\n",
      "-0.9249004060533044\n",
      "-0.7813996887532485\n",
      "-0.7561565971132052\n",
      "-0.8302124283055461\n",
      "-0.983291763796511\n",
      "-1.006067563650342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.9060651304662909\n",
      "-0.8470694403961788\n",
      "-0.49414574347246565\n",
      "-1.0177501812957763\n",
      "-1.0603271005041517\n",
      "-0.5255972358222033\n",
      "-0.7267715188119028\n",
      "-0.7815345109891456\n",
      "-0.8933762191052281\n",
      "-0.6904075744995101\n",
      "-1.1333815012066815\n",
      "-0.6965850510027278\n",
      "-0.8515515038379814\n",
      "-0.7215670970657405\n",
      "-0.7965833969982858\n",
      "-1.1896466971809692\n",
      "-0.9182888069719464\n",
      "-0.944312067158716\n",
      "-1.0965191109594863\n",
      "-1.0317573876244697\n",
      "-0.9947845682114791\n",
      "-0.7341438145892332\n",
      "-0.49960945723033034\n",
      "-0.7232274073734563\n",
      "-0.9524101534110493\n",
      "-0.690450074902683\n",
      "-0.7877956885948748\n",
      "-0.6982732445440014\n",
      "-0.8702126882101859\n",
      "-0.9510798266573991\n",
      "-0.7384373324359681\n",
      "-0.8997482718913913\n",
      "-0.8983834535053289\n",
      "-1.1694699061911829\n",
      "-0.8751548116743784\n",
      "-0.5225544583495413\n",
      "-0.6309991694010499\n",
      "-0.8982236147765243\n",
      "-0.7988053154556536\n",
      "-1.1247631327388672\n",
      "-0.8926530256137954\n",
      "-0.999984963541189\n",
      "-1.1421101322390923\n",
      "-0.8631330913229167\n",
      "-0.647310756806998\n",
      "-0.7854342830196557\n",
      "-0.7403370017528542\n",
      "-0.7860600364772716\n",
      "-0.800608065878482\n",
      "-1.1064920231617168\n",
      "-1.0648158502169993\n",
      "-0.9297020970936044\n",
      "-0.9445293648699721\n",
      "-1.1253906218114744\n",
      "-1.096623374825292\n",
      "-1.1136523920716561\n",
      "-1.2414750779252934\n",
      "-1.1232387313036793\n",
      "-0.9784987483245503\n",
      "-1.35343921218907\n",
      "-0.8310094318218303\n",
      "-0.826731708044807\n",
      "-0.8514266603748706\n",
      "-0.7711734092674171\n",
      "-0.9473726109232808\n",
      "-1.0307217036408998\n",
      "-0.7268484620412896\n",
      "-0.7126113798686364\n",
      "-0.9564673806444646\n",
      "-0.6252736366821646\n",
      "-0.5277108756728466\n",
      "-0.8989768933725714\n",
      "-0.9474061494269329\n",
      "-0.6825848786116159\n",
      "-0.7346187609650422\n",
      "-0.8070061913917024\n",
      "-0.8348845988168091\n",
      "-0.7589156327009265\n",
      "-0.6013977003373474\n",
      "-0.6055973295534541\n",
      "-0.6887295604317334\n",
      "-0.5155425792315379\n",
      "-0.7742988567426847\n",
      "-0.8265361077198066\n",
      "-0.6139519478531468\n",
      "-0.6537841074572817\n",
      "-0.882569355426781\n",
      "-0.5984008644899607\n",
      "-0.9473953924767758\n",
      "-0.7480433375712168\n",
      "-0.6190993524545525\n",
      "-0.9701372201079298\n",
      "-0.8395123367358065\n",
      "-0.6238691555643927\n",
      "-0.6601553998024003\n",
      "-0.5918477950553176\n",
      "-0.6618439513971655\n",
      "-1.026112252036287\n",
      "-1.1250637992522425\n",
      "-1.0218263950458726\n",
      "-1.0405582235806061\n",
      "-0.8698612662437204\n",
      "-1.1335451258534899\n",
      "-1.1984622364648503\n",
      "-1.0424523202196028\n",
      "-0.8418199419045991\n",
      "-0.7865208292997833\n",
      "-0.7929286548501101\n",
      "-0.8110783177600105\n",
      "-0.6032025056705121\n",
      "-0.8216965219743805\n",
      "-1.0644640454202396\n",
      "-0.8246464579652871\n",
      "-0.548744334487484\n",
      "-0.7327933048404821\n",
      "-0.7779618898981316\n",
      "-0.7978979238948046\n",
      "-0.8849510013145684\n",
      "-0.9179620121043353\n",
      "-0.8296391932808165\n",
      "-0.6994866035805632\n",
      "-0.9588977871593869\n",
      "-1.000328029757997\n",
      "-1.1283935321409804\n",
      "-1.0937890446570235\n",
      "-0.911578717377876\n",
      "-0.8575666309301555\n",
      "-0.757430180031427\n",
      "-0.8682145656171225\n",
      "-0.9605810041000912\n",
      "-0.9472435471134165\n",
      "-1.0564065699812852\n",
      "-0.8226227540303929\n",
      "-1.1721772162121786\n",
      "-1.2196825871827306\n",
      "-1.223778599702137\n",
      "-1.2838007441682346\n",
      "-0.9840343928563883\n",
      "-0.9392117597929476\n",
      "-1.0718755743050616\n",
      "-1.3235360925810817\n",
      "-1.1560286977705678\n",
      "-1.4571421486105518\n",
      "-1.4986600255867553\n",
      "-1.4176663479286267\n",
      "-1.2753859814784039\n",
      "-1.5051589910705148\n",
      "-1.2148258162306647\n",
      "-1.1712186317988824\n",
      "-1.3546424955180225\n",
      "-1.3609696566294358\n",
      "-1.0453570428690584\n",
      "-1.0967659913942858\n",
      "-1.2840706334300245\n",
      "-1.1710371341122836\n",
      "-0.9928397804162463\n",
      "-0.8663328599068199\n",
      "-0.8828114286564577\n",
      "-1.0132666660727154\n",
      "-1.0065556132372333\n",
      "-0.9657277262688911\n",
      "-0.9889259465917949\n",
      "-0.9102000058180976\n",
      "-0.9366747793349502\n",
      "-1.096925574365553\n",
      "-1.1527137459378876\n",
      "-0.9572899994038933\n",
      "-0.9592805107655085\n",
      "-0.7776312909377869\n",
      "-0.8362225793342063\n",
      "-1.1494216549969452\n",
      "-1.0616990135370667\n",
      "-1.021432039250533\n",
      "-1.0209190433229145\n",
      "-1.0640652735753044\n",
      "-1.1193153101033155\n",
      "-1.0799831758842855\n",
      "-1.017672038086523\n",
      "-1.2069540250835649\n",
      "-1.1746883322144834\n",
      "-1.1694862496451837\n",
      "-1.037458385149965\n",
      "-1.099613545398532\n",
      "-1.135947285010229\n",
      "-1.2104423471365204\n",
      "-0.7763607782911572\n",
      "-0.9955203111633683\n",
      "-1.032224666414707\n",
      "-0.9974325325204876\n",
      "-0.7706155215607727\n",
      "-1.0972325916544077\n",
      "-1.1724188697133056\n",
      "-1.2199195717755118\n",
      "-1.2404793586411502\n",
      "-1.3017474243339793\n",
      "-1.4520803562646376\n",
      "-1.1645062087997564\n",
      "-1.5041163176500392\n",
      "-1.1850190654212587\n",
      "-1.199489907816314\n",
      "-1.181454573292446\n",
      "-1.2831773887960318\n",
      "-1.0449964003830892\n",
      "-1.5615701931985213\n",
      "-1.4491281398306994\n",
      "-1.2679193460826752\n",
      "-1.2403844457699786\n",
      "-1.1903462293654885\n",
      "-1.1612131652161288\n",
      "-0.9427572469306789\n",
      "-1.0924103169659076\n",
      "-1.033756316809764\n",
      "-1.0980478266047433\n",
      "-1.192445505273369\n",
      "-0.9452886007801443\n",
      "-1.1387353969954788\n",
      "-1.255635739216115\n",
      "-1.0263664899816631\n",
      "-0.9266154113141849\n",
      "-0.7726350809862468\n",
      "-1.0408653165076842\n",
      "-1.080304931914065\n",
      "-1.2056781896134028\n",
      "-0.9507537629633407\n",
      "-0.645117859037126\n",
      "-0.89245523139708\n",
      "-0.7601963255233952\n",
      "-0.8699468355874292\n",
      "-0.9109842526158658\n",
      "-0.9159362767071528\n",
      "-0.9976596544799686\n",
      "-1.0699807302338107\n",
      "-1.013725473353082\n",
      "-0.9497264585096638\n",
      "-0.9435439594014208\n",
      "-0.8076288886590453\n",
      "-0.4858192786383199\n",
      "-0.8003293778181347\n",
      "-0.7053704928461773\n",
      "-0.7348754597806813\n",
      "-0.8313044142312025\n",
      "-0.8241323063084334\n",
      "-0.862081484376887\n",
      "-0.8677696553430138\n",
      "-0.8082759352791733\n",
      "-0.8854755097752364\n",
      "-0.6133314974743225\n",
      "-0.6627315650549652\n",
      "-0.9299454381715778\n",
      "-1.0817168623279685\n",
      "-1.1225958314010627\n",
      "-0.7402948522223518\n",
      "-0.9626703864936542\n",
      "-0.6865535698614704\n",
      "-0.9934442063420221\n",
      "-1.1735987714047207\n",
      "-0.9384169616430179\n",
      "-0.7335040234897738\n",
      "-0.9162249730547501\n",
      "-1.0759072764627038\n",
      "-0.7366034252703452\n",
      "-1.162320349005789\n",
      "-1.0667224233933403\n",
      "-0.7193346018660531\n",
      "-0.8227878484583896\n",
      "-1.1006008267019727\n",
      "-1.2558996481782645\n",
      "-1.0228389213887916\n",
      "-1.1485038248101207\n",
      "-1.3850105138350317\n",
      "-1.5617695412177763\n",
      "-1.0712804676162029\n",
      "-1.4105139242417357\n",
      "-1.4048656057890798\n",
      "-1.2565947275879268\n",
      "-1.2216582039369115\n",
      "-1.2348241237416167\n",
      "-1.2832943826732859\n",
      "-1.415552232562178\n",
      "-1.500944911870527\n",
      "-1.4254402059955555\n",
      "-1.368725949854343\n",
      "-1.409186927034693\n",
      "-1.3509858548613238\n",
      "-1.2620622117922295\n",
      "-1.4068809193503462\n",
      "-1.445893541704758\n",
      "-1.45748804975015\n",
      "-1.2945457806201293\n",
      "-1.324581730068161\n",
      "-1.4391257613107202\n",
      "-1.3298545961978991\n",
      "-1.0779361528503573\n",
      "-1.4904008184238915\n",
      "-1.7298648851160254\n",
      "-1.5777953107048266\n",
      "-1.5452054671626814\n",
      "-1.5166007447255847\n",
      "-1.3421435507986768\n",
      "-1.4529420754375182\n",
      "-1.46476514219429\n",
      "-1.4458992022814483\n",
      "-1.433877771629705\n",
      "-1.2013930200672762\n",
      "-1.3046665930970205\n",
      "-1.076260866906308\n",
      "-1.3265639358771801\n",
      "-1.3994542109658632\n",
      "-1.3460447684231212\n",
      "-1.2772124818727584\n",
      "-1.3245238255617784\n",
      "-1.319660571419368\n",
      "-1.416047549276937\n",
      "-1.3928159005143146\n",
      "-1.4108636110093484\n",
      "-1.4139159649742605\n",
      "-1.1044722842459402\n",
      "-0.9398706232557503\n",
      "-1.3380417311624686\n",
      "-1.4400306112156909\n",
      "-1.3650628638185667\n",
      "-1.3609894544355106\n",
      "-1.4826286372085442\n",
      "-1.5822979734727687\n",
      "-1.6085704813891935\n",
      "-1.6480849326234621\n",
      "-1.6029526393433233\n",
      "-1.6666339327624526\n",
      "-1.6752170245106581\n",
      "-1.313416037498844\n",
      "-1.5572444760564341\n",
      "-1.6477763588786856\n",
      "-1.5425873256605513\n",
      "-1.5905319124331734\n",
      "-1.678222140916385\n",
      "-1.6898209418120862\n",
      "-1.2721582198585297\n",
      "-1.601875977973411\n",
      "-1.708485465786081\n",
      "-1.767020647956255\n",
      "-1.6734011338842696\n",
      "-1.671875882671737\n",
      "-1.671607498354814\n",
      "-1.688442059485034\n",
      "-1.6708448824744475\n",
      "-1.5906573901955456\n",
      "-1.5509338639341168\n",
      "-1.831741604730803\n",
      "-1.9351475428575573\n",
      "-1.4503261176748168\n",
      "-1.787345217382441\n",
      "-1.899840412764073\n",
      "-1.8922499985766934\n",
      "-1.7783191157585323\n",
      "-1.8004296660599728\n",
      "-1.5125875140225835\n",
      "-1.7286568839039569\n",
      "-1.6776194157655875\n",
      "-1.3297040132700604\n",
      "-1.4863432563035375\n",
      "-1.680030158984892\n",
      "-1.7298915570194628\n",
      "-1.837226489367696\n",
      "-1.7480755749036438\n",
      "-1.6273837364266532\n",
      "-1.4374286218516477\n",
      "-1.6191138422689098\n",
      "-1.7220872886986178\n",
      "-1.538873175268503\n",
      "-1.4697115087979187\n",
      "-1.5197504264898538\n",
      "-1.368079887401164\n",
      "-1.4135294481825964\n",
      "-1.5106240713163603\n",
      "-1.624197691955678\n",
      "-1.5698289178615354\n",
      "-1.2345134032520948\n",
      "-1.2120829863700546\n",
      "-1.6917831929811535\n",
      "-1.5430322261703973\n",
      "-1.53571352313834\n",
      "-1.615912498033753\n",
      "-1.6763341310964461\n",
      "-1.7074644073577143\n",
      "-1.6724677107558368\n",
      "-1.5696216812867636\n",
      "-1.6346508638489419\n",
      "-1.679791744232226\n",
      "-1.6639795469875152\n",
      "-1.704113680275486\n",
      "-1.4299585338354277\n",
      "-1.6950781496942815\n",
      "-1.647773934547092\n",
      "-1.822407017855999\n",
      "-1.5011163111084347\n",
      "-1.8155816528677726\n",
      "-1.8876240307726566\n",
      "-1.9553038536586584\n",
      "-1.63986722949381\n",
      "-1.7408829349173058\n",
      "-1.850433234120341\n",
      "-1.8955873589036836\n",
      "-1.811749863488723\n",
      "-1.8793032801543745\n",
      "-1.8530105726711104\n",
      "-1.6482936675588713\n",
      "-1.849251314209283\n",
      "-1.9212851364668013\n",
      "-2.0150442372146133\n",
      "-1.7480349444225762\n",
      "-2.153379072187839\n",
      "-2.030380595689917\n",
      "-2.1067780121147015\n",
      "-2.013898096340035\n",
      "-2.0295497361392623\n",
      "-2.0538609428757884\n"
     ]
    }
   ],
   "source": [
    "env = Ascento()\n",
    "env.reset_model()\n",
    "m1 = []\n",
    "m2 = []\n",
    "m3 = []\n",
    "m4 = []\n",
    "\n",
    "for i_episode in range(15):\n",
    "    observation = env.reset()\n",
    "    done = None\n",
    "    while not done:\n",
    "        env.render()\n",
    "        print(env.vx)\n",
    "        action, _ = model.predict(env._get_obs())\n",
    "        m1.append(action[0])\n",
    "        m2.append(action[1])\n",
    "        m3.append(action[2])\n",
    "        m4.append(action[3])\n",
    "#         action[2] = 1\n",
    "#         action[3] = 1\n",
    "\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(m1)\n",
    "plt.plot(m2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
